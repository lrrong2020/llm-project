The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`
Loaded dataset with 87999 training examples
Map:   0%|          | 0/87999 [00:00<?, ? examples/s]Map:   1%|          | 1000/87999 [00:00<00:28, 3049.76 examples/s]Map:   2%|▏         | 2000/87999 [00:00<00:27, 3143.59 examples/s]Map:   3%|▎         | 3000/87999 [00:00<00:26, 3188.09 examples/s]Map:   5%|▍         | 4000/87999 [00:01<00:25, 3306.35 examples/s]Map:   6%|▌         | 5000/87999 [00:01<00:25, 3315.08 examples/s]Map:   7%|▋         | 6000/87999 [00:01<00:24, 3371.59 examples/s]Map:   8%|▊         | 7000/87999 [00:02<00:23, 3392.08 examples/s]Map:   9%|▉         | 8000/87999 [00:02<00:23, 3417.49 examples/s]Map:  10%|█         | 9000/87999 [00:02<00:22, 3442.71 examples/s]Map:  11%|█▏        | 10000/87999 [00:02<00:22, 3454.58 examples/s]Map:  13%|█▎        | 11000/87999 [00:03<00:22, 3465.46 examples/s]Map:  14%|█▎        | 12000/87999 [00:03<00:21, 3480.80 examples/s]Map:  15%|█▍        | 13000/87999 [00:03<00:21, 3467.50 examples/s]Map:  16%|█▌        | 14000/87999 [00:04<00:21, 3475.02 examples/s]Map:  17%|█▋        | 15000/87999 [00:04<00:23, 3113.91 examples/s]Map:  18%|█▊        | 16000/87999 [00:04<00:22, 3221.21 examples/s]Map:  19%|█▉        | 17000/87999 [00:05<00:21, 3297.57 examples/s]Map:  20%|██        | 18000/87999 [00:05<00:20, 3346.82 examples/s]Map:  22%|██▏       | 19000/87999 [00:05<00:20, 3391.38 examples/s]Map:  23%|██▎       | 20000/87999 [00:05<00:19, 3405.18 examples/s]Map:  24%|██▍       | 21000/87999 [00:06<00:19, 3436.86 examples/s]Map:  25%|██▌       | 22000/87999 [00:06<00:19, 3449.63 examples/s]Map:  26%|██▌       | 23000/87999 [00:06<00:18, 3446.73 examples/s]Map:  27%|██▋       | 24000/87999 [00:07<00:18, 3462.85 examples/s]Map:  28%|██▊       | 25000/87999 [00:07<00:18, 3474.19 examples/s]Map:  30%|██▉       | 26000/87999 [00:07<00:18, 3424.45 examples/s]Map:  31%|███       | 27000/87999 [00:07<00:17, 3432.32 examples/s]Map:  32%|███▏      | 28000/87999 [00:08<00:17, 3456.15 examples/s]Map:  33%|███▎      | 29000/87999 [00:08<00:17, 3451.84 examples/s]Map:  34%|███▍      | 30000/87999 [00:08<00:16, 3452.02 examples/s]Map:  35%|███▌      | 31000/87999 [00:09<00:16, 3471.05 examples/s]Map:  36%|███▋      | 32000/87999 [00:09<00:16, 3468.87 examples/s]Map:  38%|███▊      | 33000/87999 [00:09<00:15, 3485.89 examples/s]Map:  39%|███▊      | 34000/87999 [00:09<00:15, 3485.34 examples/s]Map:  40%|███▉      | 35000/87999 [00:10<00:15, 3481.20 examples/s]Map:  41%|████      | 36000/87999 [00:10<00:14, 3480.09 examples/s]Map:  42%|████▏     | 37000/87999 [00:10<00:14, 3487.16 examples/s]Map:  43%|████▎     | 38000/87999 [00:11<00:14, 3468.58 examples/s]Map:  44%|████▍     | 39000/87999 [00:11<00:14, 3483.79 examples/s]Map:  45%|████▌     | 40000/87999 [00:11<00:13, 3482.01 examples/s]Map:  47%|████▋     | 41000/87999 [00:12<00:14, 3317.35 examples/s]Map:  48%|████▊     | 42000/87999 [00:12<00:13, 3360.30 examples/s]Map:  49%|████▉     | 43000/87999 [00:12<00:13, 3400.57 examples/s]Map:  50%|█████     | 44000/87999 [00:12<00:12, 3420.75 examples/s]Map:  51%|█████     | 45000/87999 [00:13<00:12, 3447.59 examples/s]Map:  52%|█████▏    | 46000/87999 [00:13<00:12, 3465.14 examples/s]Map:  53%|█████▎    | 47000/87999 [00:13<00:11, 3466.89 examples/s]Map:  55%|█████▍    | 48000/87999 [00:14<00:11, 3469.08 examples/s]Map:  56%|█████▌    | 49000/87999 [00:14<00:12, 3085.70 examples/s]Map:  57%|█████▋    | 50000/87999 [00:14<00:11, 3191.16 examples/s]Map:  58%|█████▊    | 51000/87999 [00:15<00:11, 3274.35 examples/s]Map:  59%|█████▉    | 52000/87999 [00:15<00:10, 3334.58 examples/s]Map:  60%|██████    | 53000/87999 [00:15<00:10, 3357.67 examples/s]Map:  61%|██████▏   | 54000/87999 [00:15<00:09, 3404.61 examples/s]Map:  63%|██████▎   | 55000/87999 [00:16<00:09, 3407.29 examples/s]Map:  64%|██████▎   | 56000/87999 [00:16<00:09, 3422.82 examples/s]Map:  65%|██████▍   | 57000/87999 [00:16<00:09, 3435.18 examples/s]Map:  66%|██████▌   | 58000/87999 [00:17<00:08, 3452.74 examples/s]Map:  67%|██████▋   | 59000/87999 [00:17<00:08, 3462.89 examples/s]Map:  68%|██████▊   | 60000/87999 [00:17<00:08, 3476.98 examples/s]Map:  69%|██████▉   | 61000/87999 [00:17<00:07, 3476.28 examples/s]Map:  70%|███████   | 62000/87999 [00:18<00:07, 3465.91 examples/s]Map:  72%|███████▏  | 63000/87999 [00:18<00:07, 3473.22 examples/s]Map:  73%|███████▎  | 64000/87999 [00:18<00:06, 3487.63 examples/s]Map:  74%|███████▍  | 65000/87999 [00:19<00:06, 3475.48 examples/s]Map:  75%|███████▌  | 66000/87999 [00:19<00:06, 3481.11 examples/s]Map:  76%|███████▌  | 67000/87999 [00:19<00:06, 3485.59 examples/s]Map:  77%|███████▋  | 68000/87999 [00:19<00:05, 3422.48 examples/s]Map:  78%|███████▊  | 69000/87999 [00:20<00:05, 3411.59 examples/s]Map:  80%|███████▉  | 70000/87999 [00:20<00:05, 3337.68 examples/s]Map:  81%|████████  | 71000/87999 [00:20<00:05, 3374.07 examples/s]Map:  82%|████████▏ | 72000/87999 [00:21<00:04, 3410.32 examples/s]Map:  83%|████████▎ | 73000/87999 [00:21<00:04, 3439.39 examples/s]Map:  84%|████████▍ | 74000/87999 [00:21<00:04, 3438.87 examples/s]Map:  85%|████████▌ | 75000/87999 [00:21<00:03, 3466.89 examples/s]Map:  86%|████████▋ | 76000/87999 [00:22<00:03, 3468.68 examples/s]Map:  88%|████████▊ | 77000/87999 [00:22<00:03, 2933.41 examples/s]Map:  89%|████████▊ | 78000/87999 [00:23<00:03, 3077.44 examples/s]Map:  90%|████████▉ | 79000/87999 [00:23<00:02, 3192.89 examples/s]Map:  91%|█████████ | 80000/87999 [00:23<00:02, 3251.99 examples/s]Map:  92%|█████████▏| 81000/87999 [00:23<00:02, 3333.32 examples/s]Map:  93%|█████████▎| 82000/87999 [00:24<00:01, 3377.01 examples/s]Map:  94%|█████████▍| 83000/87999 [00:24<00:01, 3401.12 examples/s]Map:  95%|█████████▌| 84000/87999 [00:24<00:01, 3055.60 examples/s]Map:  97%|█████████▋| 85000/87999 [00:25<00:00, 3179.69 examples/s]Map:  98%|█████████▊| 86000/87999 [00:25<00:00, 3256.62 examples/s]Map:  99%|█████████▉| 87000/87999 [00:25<00:00, 3332.39 examples/s]Map: 100%|██████████| 87999/87999 [00:26<00:00, 3366.07 examples/s]Map: 100%|██████████| 87999/87999 [00:26<00:00, 3349.62 examples/s]
Map:   0%|          | 0/10749 [00:00<?, ? examples/s]Map:   9%|▉         | 1000/10749 [00:00<00:02, 3361.59 examples/s]Map:  19%|█▊        | 2000/10749 [00:00<00:02, 3417.36 examples/s]Map:  28%|██▊       | 3000/10749 [00:00<00:02, 3452.63 examples/s]Map:  37%|███▋      | 4000/10749 [00:01<00:01, 3462.36 examples/s]Map:  47%|████▋     | 5000/10749 [00:01<00:01, 3484.11 examples/s]Map:  56%|█████▌    | 6000/10749 [00:01<00:01, 3464.46 examples/s]Map:  65%|██████▌   | 7000/10749 [00:02<00:01, 3479.15 examples/s]Map:  74%|███████▍  | 8000/10749 [00:02<00:00, 3493.60 examples/s]Map:  84%|████████▎ | 9000/10749 [00:02<00:00, 3479.37 examples/s]Map:  93%|█████████▎| 10000/10749 [00:02<00:00, 3449.56 examples/s]Map: 100%|██████████| 10749/10749 [00:03<00:00, 3390.49 examples/s]Map: 100%|██████████| 10749/10749 [00:03<00:00, 3358.75 examples/s]
Map:   0%|          | 0/10657 [00:00<?, ? examples/s]Map:   9%|▉         | 1000/10657 [00:00<00:02, 3365.51 examples/s]Map:  19%|█▉        | 2000/10657 [00:00<00:02, 3447.50 examples/s]Map:  28%|██▊       | 3000/10657 [00:00<00:02, 3477.73 examples/s]Map:  38%|███▊      | 4000/10657 [00:01<00:01, 3470.30 examples/s]Map:  47%|████▋     | 5000/10657 [00:01<00:01, 3438.38 examples/s]Map:  56%|█████▋    | 6000/10657 [00:01<00:01, 3411.84 examples/s]Map:  66%|██████▌   | 7000/10657 [00:02<00:01, 3426.99 examples/s]Map:  75%|███████▌  | 8000/10657 [00:02<00:00, 3457.76 examples/s]Map:  84%|████████▍ | 9000/10657 [00:02<00:00, 3480.07 examples/s]Map:  94%|█████████▍| 10000/10657 [00:02<00:00, 3492.98 examples/s]Map: 100%|██████████| 10657/10657 [00:03<00:00, 3481.68 examples/s]Map: 100%|██████████| 10657/10657 [00:03<00:00, 3255.53 examples/s]
/home/rliubk/.local/lib/python3.10/site-packages/peft/tuners/lora/layer.py:1768: UserWarning: fan_in_fan_out is set to False but the target module is `Conv1D`. Setting fan_in_fan_out to True.
  warnings.warn(
Preprocessed dataset: DatasetDict({
    train: Dataset({
        features: ['input_ids', 'attention_mask', 'labels'],
        num_rows: 87999
    })
    validation: Dataset({
        features: ['input_ids', 'attention_mask', 'labels'],
        num_rows: 10749
    })
    test: Dataset({
        features: ['input_ids', 'attention_mask', 'labels'],
        num_rows: 10657
    })
})
trainable params: 393,216 || all params: 355,613,696 || trainable%: 0.1106
Traceback (most recent call last):
  File "/home/rliubk/llm/llm-project/code/llm-gomoku-project/src/trainer.py", line 254, in <module>
    main() 
  File "/home/rliubk/llm/llm-project/code/llm-gomoku-project/src/trainer.py", line 247, in main
    trainer.train(
  File "/home/rliubk/llm/llm-project/code/llm-gomoku-project/src/trainer.py", line 162, in train
    training_args = TrainingArguments(
TypeError: TrainingArguments.__init__() got an unexpected keyword argument 'evaluation_strategy'
Running: python src/trainer.py --model gpt2-medium --epochs 1 --output_dir models

==================================================
  Training the model
==================================================
Running: python run_no_ds.py --model gpt2-medium --epochs 1 --output_dir models
Traceback (most recent call last):
  File "/home/rliubk/llm/llm-project/code/llm-gomoku-project/run_pipeline.py", line 79, in <module>
    main() 
  File "/home/rliubk/llm/llm-project/code/llm-gomoku-project/run_pipeline.py", line 59, in main
    run_command(
  File "/home/rliubk/llm/llm-project/code/llm-gomoku-project/run_pipeline.py", line 19, in run_command
    result = subprocess.run(command, shell=True, check=True)
  File "/usr/lib/python3.10/subprocess.py", line 526, in run
    raise CalledProcessError(retcode, process.args,
subprocess.CalledProcessError: Command 'python run_no_ds.py --model gpt2-medium --epochs 1 --output_dir models' returned non-zero exit status 1.
