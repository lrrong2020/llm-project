{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.899408284023669,
  "eval_steps": 10,
  "global_step": 63,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.047337278106508875,
      "grad_norm": 2.4281117916107178,
      "learning_rate": 0.0002,
      "loss": 3.6484,
      "step": 1
    },
    {
      "epoch": 0.09467455621301775,
      "grad_norm": 0.9236106872558594,
      "learning_rate": 0.00019682539682539682,
      "loss": 3.2146,
      "step": 2
    },
    {
      "epoch": 0.14201183431952663,
      "grad_norm": 1.0679776668548584,
      "learning_rate": 0.00019365079365079365,
      "loss": 3.3629,
      "step": 3
    },
    {
      "epoch": 0.1893491124260355,
      "grad_norm": 1.771140217781067,
      "learning_rate": 0.00019047619047619048,
      "loss": 3.1892,
      "step": 4
    },
    {
      "epoch": 0.23668639053254437,
      "grad_norm": 1.8284486532211304,
      "learning_rate": 0.00018730158730158731,
      "loss": 3.0983,
      "step": 5
    },
    {
      "epoch": 0.28402366863905326,
      "grad_norm": 1.441985011100769,
      "learning_rate": 0.00018412698412698412,
      "loss": 3.1827,
      "step": 6
    },
    {
      "epoch": 0.33136094674556216,
      "grad_norm": 0.5426027178764343,
      "learning_rate": 0.00018095238095238095,
      "loss": 2.9676,
      "step": 7
    },
    {
      "epoch": 0.378698224852071,
      "grad_norm": 0.6794503927230835,
      "learning_rate": 0.00017777777777777779,
      "loss": 2.8008,
      "step": 8
    },
    {
      "epoch": 0.4260355029585799,
      "grad_norm": 0.6120449900627136,
      "learning_rate": 0.00017460317460317462,
      "loss": 3.1556,
      "step": 9
    },
    {
      "epoch": 0.47337278106508873,
      "grad_norm": 0.7458957433700562,
      "learning_rate": 0.00017142857142857143,
      "loss": 2.6138,
      "step": 10
    },
    {
      "epoch": 0.47337278106508873,
      "eval_loss": 2.696044921875,
      "eval_runtime": 7.3443,
      "eval_samples_per_second": 10.348,
      "eval_steps_per_second": 1.362,
      "step": 10
    },
    {
      "epoch": 0.5207100591715976,
      "grad_norm": 0.7426609992980957,
      "learning_rate": 0.00016825396825396826,
      "loss": 2.9515,
      "step": 11
    },
    {
      "epoch": 0.5680473372781065,
      "grad_norm": 0.7238971590995789,
      "learning_rate": 0.0001650793650793651,
      "loss": 2.8824,
      "step": 12
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 0.70997554063797,
      "learning_rate": 0.00016190476190476192,
      "loss": 2.9102,
      "step": 13
    },
    {
      "epoch": 0.6627218934911243,
      "grad_norm": 0.6873654723167419,
      "learning_rate": 0.00015873015873015873,
      "loss": 3.0786,
      "step": 14
    },
    {
      "epoch": 0.7100591715976331,
      "grad_norm": 0.7195624113082886,
      "learning_rate": 0.00015555555555555556,
      "loss": 2.6718,
      "step": 15
    },
    {
      "epoch": 0.757396449704142,
      "grad_norm": 0.7358558773994446,
      "learning_rate": 0.00015238095238095237,
      "loss": 2.4944,
      "step": 16
    },
    {
      "epoch": 0.8047337278106509,
      "grad_norm": 0.6788678169250488,
      "learning_rate": 0.00014920634920634923,
      "loss": 2.7481,
      "step": 17
    },
    {
      "epoch": 0.8520710059171598,
      "grad_norm": 0.6441870331764221,
      "learning_rate": 0.00014603174603174603,
      "loss": 2.8963,
      "step": 18
    },
    {
      "epoch": 0.8994082840236687,
      "grad_norm": 0.6898464560508728,
      "learning_rate": 0.00014285714285714287,
      "loss": 2.8653,
      "step": 19
    },
    {
      "epoch": 0.9467455621301775,
      "grad_norm": 0.6676220297813416,
      "learning_rate": 0.00013968253968253967,
      "loss": 2.6908,
      "step": 20
    },
    {
      "epoch": 0.9467455621301775,
      "eval_loss": 2.5379135608673096,
      "eval_runtime": 7.3381,
      "eval_samples_per_second": 10.357,
      "eval_steps_per_second": 1.363,
      "step": 20
    },
    {
      "epoch": 0.9940828402366864,
      "grad_norm": 0.6495805382728577,
      "learning_rate": 0.0001365079365079365,
      "loss": 2.9539,
      "step": 21
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.9809077978134155,
      "learning_rate": 0.00013333333333333334,
      "loss": 2.9646,
      "step": 22
    },
    {
      "epoch": 1.047337278106509,
      "grad_norm": 0.7262681126594543,
      "learning_rate": 0.00013015873015873017,
      "loss": 3.1308,
      "step": 23
    },
    {
      "epoch": 1.0946745562130178,
      "grad_norm": 0.765538215637207,
      "learning_rate": 0.00012698412698412698,
      "loss": 2.8296,
      "step": 24
    },
    {
      "epoch": 1.1420118343195267,
      "grad_norm": 0.651275634765625,
      "learning_rate": 0.0001238095238095238,
      "loss": 2.868,
      "step": 25
    },
    {
      "epoch": 1.1893491124260356,
      "grad_norm": 0.6029660701751709,
      "learning_rate": 0.00012063492063492063,
      "loss": 2.7384,
      "step": 26
    },
    {
      "epoch": 1.2366863905325443,
      "grad_norm": 0.64450603723526,
      "learning_rate": 0.00011746031746031746,
      "loss": 2.6284,
      "step": 27
    },
    {
      "epoch": 1.2840236686390534,
      "grad_norm": 0.7551047205924988,
      "learning_rate": 0.00011428571428571428,
      "loss": 2.3505,
      "step": 28
    },
    {
      "epoch": 1.331360946745562,
      "grad_norm": 0.9523797631263733,
      "learning_rate": 0.00011111111111111112,
      "loss": 2.6841,
      "step": 29
    },
    {
      "epoch": 1.378698224852071,
      "grad_norm": 0.7304391860961914,
      "learning_rate": 0.00010793650793650794,
      "loss": 2.5778,
      "step": 30
    },
    {
      "epoch": 1.378698224852071,
      "eval_loss": 2.4650537967681885,
      "eval_runtime": 7.3387,
      "eval_samples_per_second": 10.356,
      "eval_steps_per_second": 1.363,
      "step": 30
    },
    {
      "epoch": 1.4260355029585798,
      "grad_norm": 0.6849715709686279,
      "learning_rate": 0.00010476190476190477,
      "loss": 2.6407,
      "step": 31
    },
    {
      "epoch": 1.4733727810650887,
      "grad_norm": 0.6422790288925171,
      "learning_rate": 0.00010158730158730159,
      "loss": 2.7782,
      "step": 32
    },
    {
      "epoch": 1.5207100591715976,
      "grad_norm": 0.7231149077415466,
      "learning_rate": 9.841269841269841e-05,
      "loss": 2.6006,
      "step": 33
    },
    {
      "epoch": 1.5680473372781065,
      "grad_norm": 0.8704660534858704,
      "learning_rate": 9.523809523809524e-05,
      "loss": 2.821,
      "step": 34
    },
    {
      "epoch": 1.6153846153846154,
      "grad_norm": 0.6791642308235168,
      "learning_rate": 9.206349206349206e-05,
      "loss": 2.52,
      "step": 35
    },
    {
      "epoch": 1.6627218934911243,
      "grad_norm": 0.8832123875617981,
      "learning_rate": 8.888888888888889e-05,
      "loss": 2.5256,
      "step": 36
    },
    {
      "epoch": 1.7100591715976332,
      "grad_norm": 0.6520851254463196,
      "learning_rate": 8.571428571428571e-05,
      "loss": 2.7197,
      "step": 37
    },
    {
      "epoch": 1.7573964497041419,
      "grad_norm": 0.8007437586784363,
      "learning_rate": 8.253968253968255e-05,
      "loss": 2.5015,
      "step": 38
    },
    {
      "epoch": 1.804733727810651,
      "grad_norm": 0.7845072746276855,
      "learning_rate": 7.936507936507937e-05,
      "loss": 2.6635,
      "step": 39
    },
    {
      "epoch": 1.8520710059171597,
      "grad_norm": 0.7144173979759216,
      "learning_rate": 7.619047619047618e-05,
      "loss": 2.4337,
      "step": 40
    },
    {
      "epoch": 1.8520710059171597,
      "eval_loss": 2.419642686843872,
      "eval_runtime": 7.3429,
      "eval_samples_per_second": 10.35,
      "eval_steps_per_second": 1.362,
      "step": 40
    },
    {
      "epoch": 1.8994082840236688,
      "grad_norm": 0.725051999092102,
      "learning_rate": 7.301587301587302e-05,
      "loss": 2.6458,
      "step": 41
    },
    {
      "epoch": 1.9467455621301775,
      "grad_norm": 0.7585095763206482,
      "learning_rate": 6.984126984126984e-05,
      "loss": 2.6303,
      "step": 42
    },
    {
      "epoch": 1.9940828402366864,
      "grad_norm": 0.798146665096283,
      "learning_rate": 6.666666666666667e-05,
      "loss": 2.5186,
      "step": 43
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.6187254190444946,
      "learning_rate": 6.349206349206349e-05,
      "loss": 3.3214,
      "step": 44
    },
    {
      "epoch": 2.0473372781065087,
      "grad_norm": 0.7092294692993164,
      "learning_rate": 6.0317460317460316e-05,
      "loss": 2.5911,
      "step": 45
    },
    {
      "epoch": 2.094674556213018,
      "grad_norm": 1.0677231550216675,
      "learning_rate": 5.714285714285714e-05,
      "loss": 2.4071,
      "step": 46
    },
    {
      "epoch": 2.1420118343195265,
      "grad_norm": 0.5705342888832092,
      "learning_rate": 5.396825396825397e-05,
      "loss": 2.606,
      "step": 47
    },
    {
      "epoch": 2.1893491124260356,
      "grad_norm": 0.6137920618057251,
      "learning_rate": 5.0793650793650794e-05,
      "loss": 2.5707,
      "step": 48
    },
    {
      "epoch": 2.2366863905325443,
      "grad_norm": 0.7576828598976135,
      "learning_rate": 4.761904761904762e-05,
      "loss": 2.5515,
      "step": 49
    },
    {
      "epoch": 2.2840236686390534,
      "grad_norm": 0.8901085257530212,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 2.5125,
      "step": 50
    },
    {
      "epoch": 2.2840236686390534,
      "eval_loss": 2.391417980194092,
      "eval_runtime": 7.3438,
      "eval_samples_per_second": 10.349,
      "eval_steps_per_second": 1.362,
      "step": 50
    },
    {
      "epoch": 2.331360946745562,
      "grad_norm": 0.6712899804115295,
      "learning_rate": 4.126984126984127e-05,
      "loss": 2.5234,
      "step": 51
    },
    {
      "epoch": 2.378698224852071,
      "grad_norm": 0.9483553171157837,
      "learning_rate": 3.809523809523809e-05,
      "loss": 2.2801,
      "step": 52
    },
    {
      "epoch": 2.42603550295858,
      "grad_norm": 0.6891481280326843,
      "learning_rate": 3.492063492063492e-05,
      "loss": 3.0698,
      "step": 53
    },
    {
      "epoch": 2.4733727810650885,
      "grad_norm": 0.821304202079773,
      "learning_rate": 3.1746031746031745e-05,
      "loss": 2.4249,
      "step": 54
    },
    {
      "epoch": 2.5207100591715976,
      "grad_norm": 0.6143182516098022,
      "learning_rate": 2.857142857142857e-05,
      "loss": 2.7389,
      "step": 55
    },
    {
      "epoch": 2.5680473372781067,
      "grad_norm": 0.750099241733551,
      "learning_rate": 2.5396825396825397e-05,
      "loss": 2.8653,
      "step": 56
    },
    {
      "epoch": 2.6153846153846154,
      "grad_norm": 0.7005891799926758,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 2.4588,
      "step": 57
    },
    {
      "epoch": 2.662721893491124,
      "grad_norm": 0.7431225776672363,
      "learning_rate": 1.9047619047619046e-05,
      "loss": 2.5349,
      "step": 58
    },
    {
      "epoch": 2.710059171597633,
      "grad_norm": 0.7757464647293091,
      "learning_rate": 1.5873015873015872e-05,
      "loss": 2.857,
      "step": 59
    },
    {
      "epoch": 2.757396449704142,
      "grad_norm": 0.7366903424263,
      "learning_rate": 1.2698412698412699e-05,
      "loss": 2.3968,
      "step": 60
    },
    {
      "epoch": 2.757396449704142,
      "eval_loss": 2.3801705837249756,
      "eval_runtime": 7.3374,
      "eval_samples_per_second": 10.358,
      "eval_steps_per_second": 1.363,
      "step": 60
    },
    {
      "epoch": 2.804733727810651,
      "grad_norm": 0.7812530398368835,
      "learning_rate": 9.523809523809523e-06,
      "loss": 2.543,
      "step": 61
    },
    {
      "epoch": 2.8520710059171597,
      "grad_norm": 0.98393714427948,
      "learning_rate": 6.349206349206349e-06,
      "loss": 2.2539,
      "step": 62
    },
    {
      "epoch": 2.899408284023669,
      "grad_norm": 0.7052503228187561,
      "learning_rate": 3.1746031746031746e-06,
      "loss": 2.5743,
      "step": 63
    }
  ],
  "logging_steps": 1,
  "max_steps": 63,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.960240168890368e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
