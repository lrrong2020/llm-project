{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.899408284023669,
  "eval_steps": 10,
  "global_step": 63,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.047337278106508875,
      "grad_norm": 1.2070447206497192,
      "learning_rate": 0.0002,
      "loss": 3.3343,
      "step": 1
    },
    {
      "epoch": 0.09467455621301775,
      "grad_norm": 0.6781736016273499,
      "learning_rate": 0.00019682539682539682,
      "loss": 3.2487,
      "step": 2
    },
    {
      "epoch": 0.14201183431952663,
      "grad_norm": 0.8847235441207886,
      "learning_rate": 0.00019365079365079365,
      "loss": 3.1075,
      "step": 3
    },
    {
      "epoch": 0.1893491124260355,
      "grad_norm": 1.0847804546356201,
      "learning_rate": 0.00019047619047619048,
      "loss": 3.3094,
      "step": 4
    },
    {
      "epoch": 0.23668639053254437,
      "grad_norm": 1.4724023342132568,
      "learning_rate": 0.00018730158730158731,
      "loss": 3.3601,
      "step": 5
    },
    {
      "epoch": 0.28402366863905326,
      "grad_norm": 2.045642375946045,
      "learning_rate": 0.00018412698412698412,
      "loss": 2.9556,
      "step": 6
    },
    {
      "epoch": 0.33136094674556216,
      "grad_norm": 0.8909327387809753,
      "learning_rate": 0.00018095238095238095,
      "loss": 3.2916,
      "step": 7
    },
    {
      "epoch": 0.378698224852071,
      "grad_norm": 0.5436496734619141,
      "learning_rate": 0.00017777777777777779,
      "loss": 2.8917,
      "step": 8
    },
    {
      "epoch": 0.4260355029585799,
      "grad_norm": 0.598179817199707,
      "learning_rate": 0.00017460317460317462,
      "loss": 3.05,
      "step": 9
    },
    {
      "epoch": 0.47337278106508873,
      "grad_norm": 0.5465835928916931,
      "learning_rate": 0.00017142857142857143,
      "loss": 2.7561,
      "step": 10
    },
    {
      "epoch": 0.47337278106508873,
      "eval_loss": 2.878436803817749,
      "eval_runtime": 8.3138,
      "eval_samples_per_second": 9.141,
      "eval_steps_per_second": 1.203,
      "step": 10
    },
    {
      "epoch": 0.5207100591715976,
      "grad_norm": 0.6830860376358032,
      "learning_rate": 0.00016825396825396826,
      "loss": 2.831,
      "step": 11
    },
    {
      "epoch": 0.5680473372781065,
      "grad_norm": 0.6282970905303955,
      "learning_rate": 0.0001650793650793651,
      "loss": 2.9631,
      "step": 12
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 0.6160075068473816,
      "learning_rate": 0.00016190476190476192,
      "loss": 2.9127,
      "step": 13
    },
    {
      "epoch": 0.6627218934911243,
      "grad_norm": 0.6315727829933167,
      "learning_rate": 0.00015873015873015873,
      "loss": 2.8283,
      "step": 14
    },
    {
      "epoch": 0.7100591715976331,
      "grad_norm": 0.6425405144691467,
      "learning_rate": 0.00015555555555555556,
      "loss": 2.711,
      "step": 15
    },
    {
      "epoch": 0.757396449704142,
      "grad_norm": 0.6364046931266785,
      "learning_rate": 0.00015238095238095237,
      "loss": 2.6417,
      "step": 16
    },
    {
      "epoch": 0.8047337278106509,
      "grad_norm": 0.7323920726776123,
      "learning_rate": 0.00014920634920634923,
      "loss": 2.7243,
      "step": 17
    },
    {
      "epoch": 0.8520710059171598,
      "grad_norm": 0.5889478325843811,
      "learning_rate": 0.00014603174603174603,
      "loss": 2.868,
      "step": 18
    },
    {
      "epoch": 0.8994082840236687,
      "grad_norm": 0.785050094127655,
      "learning_rate": 0.00014285714285714287,
      "loss": 2.8516,
      "step": 19
    },
    {
      "epoch": 0.9467455621301775,
      "grad_norm": 0.6332356333732605,
      "learning_rate": 0.00013968253968253967,
      "loss": 2.9701,
      "step": 20
    },
    {
      "epoch": 0.9467455621301775,
      "eval_loss": 2.72676682472229,
      "eval_runtime": 8.3229,
      "eval_samples_per_second": 9.131,
      "eval_steps_per_second": 1.202,
      "step": 20
    },
    {
      "epoch": 0.9940828402366864,
      "grad_norm": 0.5426278710365295,
      "learning_rate": 0.0001365079365079365,
      "loss": 3.0354,
      "step": 21
    },
    {
      "epoch": 1.0,
      "grad_norm": 1.2095338106155396,
      "learning_rate": 0.00013333333333333334,
      "loss": 2.1777,
      "step": 22
    },
    {
      "epoch": 1.047337278106509,
      "grad_norm": 0.6543323397636414,
      "learning_rate": 0.00013015873015873017,
      "loss": 2.7669,
      "step": 23
    },
    {
      "epoch": 1.0946745562130178,
      "grad_norm": 0.724296510219574,
      "learning_rate": 0.00012698412698412698,
      "loss": 2.6431,
      "step": 24
    },
    {
      "epoch": 1.1420118343195267,
      "grad_norm": 0.6381314992904663,
      "learning_rate": 0.0001238095238095238,
      "loss": 2.5464,
      "step": 25
    },
    {
      "epoch": 1.1893491124260356,
      "grad_norm": 0.6604070663452148,
      "learning_rate": 0.00012063492063492063,
      "loss": 2.7256,
      "step": 26
    },
    {
      "epoch": 1.2366863905325443,
      "grad_norm": 0.7231338024139404,
      "learning_rate": 0.00011746031746031746,
      "loss": 2.7048,
      "step": 27
    },
    {
      "epoch": 1.2840236686390534,
      "grad_norm": 0.5790308713912964,
      "learning_rate": 0.00011428571428571428,
      "loss": 2.6347,
      "step": 28
    },
    {
      "epoch": 1.331360946745562,
      "grad_norm": 0.6119118928909302,
      "learning_rate": 0.00011111111111111112,
      "loss": 2.3586,
      "step": 29
    },
    {
      "epoch": 1.378698224852071,
      "grad_norm": 0.666508674621582,
      "learning_rate": 0.00010793650793650794,
      "loss": 2.5988,
      "step": 30
    },
    {
      "epoch": 1.378698224852071,
      "eval_loss": 2.652411699295044,
      "eval_runtime": 8.3236,
      "eval_samples_per_second": 9.131,
      "eval_steps_per_second": 1.201,
      "step": 30
    },
    {
      "epoch": 1.4260355029585798,
      "grad_norm": 0.5963616371154785,
      "learning_rate": 0.00010476190476190477,
      "loss": 2.9643,
      "step": 31
    },
    {
      "epoch": 1.4733727810650887,
      "grad_norm": 0.6776949167251587,
      "learning_rate": 0.00010158730158730159,
      "loss": 2.5532,
      "step": 32
    },
    {
      "epoch": 1.5207100591715976,
      "grad_norm": 0.6852309107780457,
      "learning_rate": 9.841269841269841e-05,
      "loss": 2.4433,
      "step": 33
    },
    {
      "epoch": 1.5680473372781065,
      "grad_norm": 0.715022087097168,
      "learning_rate": 9.523809523809524e-05,
      "loss": 2.5354,
      "step": 34
    },
    {
      "epoch": 1.6153846153846154,
      "grad_norm": 0.6899737119674683,
      "learning_rate": 9.206349206349206e-05,
      "loss": 2.5467,
      "step": 35
    },
    {
      "epoch": 1.6627218934911243,
      "grad_norm": 0.6889362931251526,
      "learning_rate": 8.888888888888889e-05,
      "loss": 2.8443,
      "step": 36
    },
    {
      "epoch": 1.7100591715976332,
      "grad_norm": 0.7368478775024414,
      "learning_rate": 8.571428571428571e-05,
      "loss": 2.4701,
      "step": 37
    },
    {
      "epoch": 1.7573964497041419,
      "grad_norm": 0.6056791543960571,
      "learning_rate": 8.253968253968255e-05,
      "loss": 2.8386,
      "step": 38
    },
    {
      "epoch": 1.804733727810651,
      "grad_norm": 0.6470082998275757,
      "learning_rate": 7.936507936507937e-05,
      "loss": 2.7656,
      "step": 39
    },
    {
      "epoch": 1.8520710059171597,
      "grad_norm": 0.6327953338623047,
      "learning_rate": 7.619047619047618e-05,
      "loss": 2.7026,
      "step": 40
    },
    {
      "epoch": 1.8520710059171597,
      "eval_loss": 2.604199171066284,
      "eval_runtime": 8.3271,
      "eval_samples_per_second": 9.127,
      "eval_steps_per_second": 1.201,
      "step": 40
    },
    {
      "epoch": 1.8994082840236688,
      "grad_norm": 0.7367337346076965,
      "learning_rate": 7.301587301587302e-05,
      "loss": 2.4737,
      "step": 41
    },
    {
      "epoch": 1.9467455621301775,
      "grad_norm": 0.7326644659042358,
      "learning_rate": 6.984126984126984e-05,
      "loss": 2.7145,
      "step": 42
    },
    {
      "epoch": 1.9940828402366864,
      "grad_norm": 0.5870145559310913,
      "learning_rate": 6.666666666666667e-05,
      "loss": 3.0976,
      "step": 43
    },
    {
      "epoch": 2.0,
      "grad_norm": 2.176776885986328,
      "learning_rate": 6.349206349206349e-05,
      "loss": 2.5875,
      "step": 44
    },
    {
      "epoch": 2.0473372781065087,
      "grad_norm": 0.7581830024719238,
      "learning_rate": 6.0317460317460316e-05,
      "loss": 2.656,
      "step": 45
    },
    {
      "epoch": 2.094674556213018,
      "grad_norm": 0.6860682368278503,
      "learning_rate": 5.714285714285714e-05,
      "loss": 2.8399,
      "step": 46
    },
    {
      "epoch": 2.1420118343195265,
      "grad_norm": 0.622150719165802,
      "learning_rate": 5.396825396825397e-05,
      "loss": 2.6223,
      "step": 47
    },
    {
      "epoch": 2.1893491124260356,
      "grad_norm": 0.7060261368751526,
      "learning_rate": 5.0793650793650794e-05,
      "loss": 2.549,
      "step": 48
    },
    {
      "epoch": 2.2366863905325443,
      "grad_norm": 0.5521882176399231,
      "learning_rate": 4.761904761904762e-05,
      "loss": 2.4574,
      "step": 49
    },
    {
      "epoch": 2.2840236686390534,
      "grad_norm": 0.6400518417358398,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 2.527,
      "step": 50
    },
    {
      "epoch": 2.2840236686390534,
      "eval_loss": 2.579514503479004,
      "eval_runtime": 8.3185,
      "eval_samples_per_second": 9.136,
      "eval_steps_per_second": 1.202,
      "step": 50
    },
    {
      "epoch": 2.331360946745562,
      "grad_norm": 0.6631978154182434,
      "learning_rate": 4.126984126984127e-05,
      "loss": 2.452,
      "step": 51
    },
    {
      "epoch": 2.378698224852071,
      "grad_norm": 0.748166561126709,
      "learning_rate": 3.809523809523809e-05,
      "loss": 2.5966,
      "step": 52
    },
    {
      "epoch": 2.42603550295858,
      "grad_norm": 0.8011609315872192,
      "learning_rate": 3.492063492063492e-05,
      "loss": 2.6295,
      "step": 53
    },
    {
      "epoch": 2.4733727810650885,
      "grad_norm": 0.7078753113746643,
      "learning_rate": 3.1746031746031745e-05,
      "loss": 2.3048,
      "step": 54
    },
    {
      "epoch": 2.5207100591715976,
      "grad_norm": 0.6777931451797485,
      "learning_rate": 2.857142857142857e-05,
      "loss": 2.6919,
      "step": 55
    },
    {
      "epoch": 2.5680473372781067,
      "grad_norm": 0.6954334378242493,
      "learning_rate": 2.5396825396825397e-05,
      "loss": 2.5247,
      "step": 56
    },
    {
      "epoch": 2.6153846153846154,
      "grad_norm": 0.7438682913780212,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 2.3504,
      "step": 57
    },
    {
      "epoch": 2.662721893491124,
      "grad_norm": 0.8368618488311768,
      "learning_rate": 1.9047619047619046e-05,
      "loss": 2.2861,
      "step": 58
    },
    {
      "epoch": 2.710059171597633,
      "grad_norm": 0.667619526386261,
      "learning_rate": 1.5873015873015872e-05,
      "loss": 2.5275,
      "step": 59
    },
    {
      "epoch": 2.757396449704142,
      "grad_norm": 0.7106688022613525,
      "learning_rate": 1.2698412698412699e-05,
      "loss": 2.2976,
      "step": 60
    },
    {
      "epoch": 2.757396449704142,
      "eval_loss": 2.567250967025757,
      "eval_runtime": 8.3279,
      "eval_samples_per_second": 9.126,
      "eval_steps_per_second": 1.201,
      "step": 60
    },
    {
      "epoch": 2.804733727810651,
      "grad_norm": 0.6828293204307556,
      "learning_rate": 9.523809523809523e-06,
      "loss": 2.6681,
      "step": 61
    },
    {
      "epoch": 2.8520710059171597,
      "grad_norm": 0.6243354082107544,
      "learning_rate": 6.349206349206349e-06,
      "loss": 2.9499,
      "step": 62
    },
    {
      "epoch": 2.899408284023669,
      "grad_norm": 0.6378519535064697,
      "learning_rate": 3.1746031746031746e-06,
      "loss": 2.9551,
      "step": 63
    }
  ],
  "logging_steps": 1,
  "max_steps": 63,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2.966168494399488e+16,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
