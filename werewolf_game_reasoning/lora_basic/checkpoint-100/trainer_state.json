{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.1775147928994083,
  "eval_steps": 10,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011834319526627219,
      "grad_norm": 0.2852616310119629,
      "learning_rate": 0.0002,
      "loss": 3.6535,
      "step": 1
    },
    {
      "epoch": 0.023668639053254437,
      "grad_norm": 0.42725804448127747,
      "learning_rate": 0.00019920634920634922,
      "loss": 3.2292,
      "step": 2
    },
    {
      "epoch": 0.03550295857988166,
      "grad_norm": 0.2975868582725525,
      "learning_rate": 0.00019841269841269844,
      "loss": 2.3642,
      "step": 3
    },
    {
      "epoch": 0.047337278106508875,
      "grad_norm": 0.5254213213920593,
      "learning_rate": 0.00019761904761904763,
      "loss": 3.533,
      "step": 4
    },
    {
      "epoch": 0.05917159763313609,
      "grad_norm": 0.7198086977005005,
      "learning_rate": 0.00019682539682539682,
      "loss": 3.4469,
      "step": 5
    },
    {
      "epoch": 0.07100591715976332,
      "grad_norm": 0.835084080696106,
      "learning_rate": 0.00019603174603174603,
      "loss": 2.6131,
      "step": 6
    },
    {
      "epoch": 0.08284023668639054,
      "grad_norm": 0.5850217938423157,
      "learning_rate": 0.00019523809523809525,
      "loss": 2.39,
      "step": 7
    },
    {
      "epoch": 0.09467455621301775,
      "grad_norm": 2.8779730796813965,
      "learning_rate": 0.00019444444444444446,
      "loss": 2.8081,
      "step": 8
    },
    {
      "epoch": 0.10650887573964497,
      "grad_norm": 3.7347939014434814,
      "learning_rate": 0.00019365079365079365,
      "loss": 2.8685,
      "step": 9
    },
    {
      "epoch": 0.11834319526627218,
      "grad_norm": 1.1432902812957764,
      "learning_rate": 0.00019285714285714286,
      "loss": 2.9831,
      "step": 10
    },
    {
      "epoch": 0.11834319526627218,
      "eval_loss": 3.0265727043151855,
      "eval_runtime": 7.2621,
      "eval_samples_per_second": 10.465,
      "eval_steps_per_second": 1.377,
      "step": 10
    },
    {
      "epoch": 0.1301775147928994,
      "grad_norm": 2.6644093990325928,
      "learning_rate": 0.00019206349206349208,
      "loss": 2.7168,
      "step": 11
    },
    {
      "epoch": 0.14201183431952663,
      "grad_norm": 0.39588865637779236,
      "learning_rate": 0.0001912698412698413,
      "loss": 3.4442,
      "step": 12
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 0.76161128282547,
      "learning_rate": 0.00019047619047619048,
      "loss": 2.7836,
      "step": 13
    },
    {
      "epoch": 0.16568047337278108,
      "grad_norm": 0.403511106967926,
      "learning_rate": 0.0001896825396825397,
      "loss": 2.6901,
      "step": 14
    },
    {
      "epoch": 0.17751479289940827,
      "grad_norm": 0.3340049982070923,
      "learning_rate": 0.00018888888888888888,
      "loss": 2.9176,
      "step": 15
    },
    {
      "epoch": 0.1893491124260355,
      "grad_norm": 0.44705730676651,
      "learning_rate": 0.0001880952380952381,
      "loss": 3.1157,
      "step": 16
    },
    {
      "epoch": 0.20118343195266272,
      "grad_norm": 0.62772536277771,
      "learning_rate": 0.00018730158730158731,
      "loss": 2.7558,
      "step": 17
    },
    {
      "epoch": 0.21301775147928995,
      "grad_norm": 0.5882687568664551,
      "learning_rate": 0.00018650793650793653,
      "loss": 2.7065,
      "step": 18
    },
    {
      "epoch": 0.22485207100591717,
      "grad_norm": 0.4743443429470062,
      "learning_rate": 0.00018571428571428572,
      "loss": 3.3719,
      "step": 19
    },
    {
      "epoch": 0.23668639053254437,
      "grad_norm": 0.5696156620979309,
      "learning_rate": 0.00018492063492063493,
      "loss": 2.9977,
      "step": 20
    },
    {
      "epoch": 0.23668639053254437,
      "eval_loss": 2.8663079738616943,
      "eval_runtime": 7.2564,
      "eval_samples_per_second": 10.474,
      "eval_steps_per_second": 1.378,
      "step": 20
    },
    {
      "epoch": 0.2485207100591716,
      "grad_norm": 0.5697664022445679,
      "learning_rate": 0.00018412698412698412,
      "loss": 1.9846,
      "step": 21
    },
    {
      "epoch": 0.2603550295857988,
      "grad_norm": 0.4957573711872101,
      "learning_rate": 0.00018333333333333334,
      "loss": 3.1558,
      "step": 22
    },
    {
      "epoch": 0.27218934911242604,
      "grad_norm": 0.4362879693508148,
      "learning_rate": 0.00018253968253968255,
      "loss": 3.301,
      "step": 23
    },
    {
      "epoch": 0.28402366863905326,
      "grad_norm": 0.5254936814308167,
      "learning_rate": 0.00018174603174603177,
      "loss": 3.0331,
      "step": 24
    },
    {
      "epoch": 0.2958579881656805,
      "grad_norm": 0.47438421845436096,
      "learning_rate": 0.00018095238095238095,
      "loss": 3.3227,
      "step": 25
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 0.5094731450080872,
      "learning_rate": 0.00018015873015873017,
      "loss": 3.8949,
      "step": 26
    },
    {
      "epoch": 0.31952662721893493,
      "grad_norm": 0.5917863249778748,
      "learning_rate": 0.00017936507936507938,
      "loss": 3.0268,
      "step": 27
    },
    {
      "epoch": 0.33136094674556216,
      "grad_norm": 0.3595137894153595,
      "learning_rate": 0.0001785714285714286,
      "loss": 2.9957,
      "step": 28
    },
    {
      "epoch": 0.3431952662721893,
      "grad_norm": 0.47600701451301575,
      "learning_rate": 0.00017777777777777779,
      "loss": 2.1916,
      "step": 29
    },
    {
      "epoch": 0.35502958579881655,
      "grad_norm": 0.5427821278572083,
      "learning_rate": 0.00017698412698412697,
      "loss": 2.9272,
      "step": 30
    },
    {
      "epoch": 0.35502958579881655,
      "eval_loss": 2.788158416748047,
      "eval_runtime": 7.2699,
      "eval_samples_per_second": 10.454,
      "eval_steps_per_second": 1.376,
      "step": 30
    },
    {
      "epoch": 0.3668639053254438,
      "grad_norm": 0.47064968943595886,
      "learning_rate": 0.0001761904761904762,
      "loss": 2.9858,
      "step": 31
    },
    {
      "epoch": 0.378698224852071,
      "grad_norm": 0.4756056070327759,
      "learning_rate": 0.0001753968253968254,
      "loss": 2.3199,
      "step": 32
    },
    {
      "epoch": 0.3905325443786982,
      "grad_norm": 0.45889586210250854,
      "learning_rate": 0.00017460317460317462,
      "loss": 2.7038,
      "step": 33
    },
    {
      "epoch": 0.40236686390532544,
      "grad_norm": 0.45923224091529846,
      "learning_rate": 0.00017380952380952383,
      "loss": 3.4152,
      "step": 34
    },
    {
      "epoch": 0.41420118343195267,
      "grad_norm": 0.4572738707065582,
      "learning_rate": 0.00017301587301587302,
      "loss": 3.1502,
      "step": 35
    },
    {
      "epoch": 0.4260355029585799,
      "grad_norm": 0.6110097765922546,
      "learning_rate": 0.00017222222222222224,
      "loss": 2.9745,
      "step": 36
    },
    {
      "epoch": 0.4378698224852071,
      "grad_norm": 0.4958982467651367,
      "learning_rate": 0.00017142857142857143,
      "loss": 2.1988,
      "step": 37
    },
    {
      "epoch": 0.44970414201183434,
      "grad_norm": 0.5015813112258911,
      "learning_rate": 0.00017063492063492064,
      "loss": 2.6207,
      "step": 38
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 0.5053653120994568,
      "learning_rate": 0.00016984126984126986,
      "loss": 2.9909,
      "step": 39
    },
    {
      "epoch": 0.47337278106508873,
      "grad_norm": 0.6383805871009827,
      "learning_rate": 0.00016904761904761904,
      "loss": 2.4307,
      "step": 40
    },
    {
      "epoch": 0.47337278106508873,
      "eval_loss": 2.732571601867676,
      "eval_runtime": 7.2707,
      "eval_samples_per_second": 10.453,
      "eval_steps_per_second": 1.375,
      "step": 40
    },
    {
      "epoch": 0.48520710059171596,
      "grad_norm": 0.6155767440795898,
      "learning_rate": 0.00016825396825396826,
      "loss": 2.7887,
      "step": 41
    },
    {
      "epoch": 0.4970414201183432,
      "grad_norm": 0.5471430420875549,
      "learning_rate": 0.00016746031746031747,
      "loss": 2.5071,
      "step": 42
    },
    {
      "epoch": 0.5088757396449705,
      "grad_norm": 0.5839921236038208,
      "learning_rate": 0.0001666666666666667,
      "loss": 2.3487,
      "step": 43
    },
    {
      "epoch": 0.5207100591715976,
      "grad_norm": 0.8534253835678101,
      "learning_rate": 0.0001658730158730159,
      "loss": 2.3831,
      "step": 44
    },
    {
      "epoch": 0.5325443786982249,
      "grad_norm": 0.4808950424194336,
      "learning_rate": 0.0001650793650793651,
      "loss": 2.7563,
      "step": 45
    },
    {
      "epoch": 0.5443786982248521,
      "grad_norm": 0.5995768904685974,
      "learning_rate": 0.00016428571428571428,
      "loss": 2.9696,
      "step": 46
    },
    {
      "epoch": 0.5562130177514792,
      "grad_norm": 0.45817336440086365,
      "learning_rate": 0.0001634920634920635,
      "loss": 2.9663,
      "step": 47
    },
    {
      "epoch": 0.5680473372781065,
      "grad_norm": 0.479961097240448,
      "learning_rate": 0.0001626984126984127,
      "loss": 2.8644,
      "step": 48
    },
    {
      "epoch": 0.5798816568047337,
      "grad_norm": 0.695735514163971,
      "learning_rate": 0.00016190476190476192,
      "loss": 2.6259,
      "step": 49
    },
    {
      "epoch": 0.591715976331361,
      "grad_norm": 0.5882052183151245,
      "learning_rate": 0.0001611111111111111,
      "loss": 2.5268,
      "step": 50
    },
    {
      "epoch": 0.591715976331361,
      "eval_loss": 2.6890671253204346,
      "eval_runtime": 7.2755,
      "eval_samples_per_second": 10.446,
      "eval_steps_per_second": 1.374,
      "step": 50
    },
    {
      "epoch": 0.6035502958579881,
      "grad_norm": 0.5598996877670288,
      "learning_rate": 0.00016031746031746033,
      "loss": 2.7146,
      "step": 51
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 0.555019736289978,
      "learning_rate": 0.00015952380952380954,
      "loss": 2.9906,
      "step": 52
    },
    {
      "epoch": 0.6272189349112426,
      "grad_norm": 0.7015283107757568,
      "learning_rate": 0.00015873015873015873,
      "loss": 2.7494,
      "step": 53
    },
    {
      "epoch": 0.6390532544378699,
      "grad_norm": 0.532532811164856,
      "learning_rate": 0.00015793650793650795,
      "loss": 2.4279,
      "step": 54
    },
    {
      "epoch": 0.650887573964497,
      "grad_norm": 0.5694570541381836,
      "learning_rate": 0.00015714285714285716,
      "loss": 3.2177,
      "step": 55
    },
    {
      "epoch": 0.6627218934911243,
      "grad_norm": 0.4815200865268707,
      "learning_rate": 0.00015634920634920635,
      "loss": 2.6564,
      "step": 56
    },
    {
      "epoch": 0.6745562130177515,
      "grad_norm": 1.0988482236862183,
      "learning_rate": 0.00015555555555555556,
      "loss": 2.0123,
      "step": 57
    },
    {
      "epoch": 0.6863905325443787,
      "grad_norm": 0.5982100963592529,
      "learning_rate": 0.00015476190476190478,
      "loss": 2.5896,
      "step": 58
    },
    {
      "epoch": 0.6982248520710059,
      "grad_norm": 0.8859602808952332,
      "learning_rate": 0.000153968253968254,
      "loss": 2.223,
      "step": 59
    },
    {
      "epoch": 0.7100591715976331,
      "grad_norm": 0.5900657773017883,
      "learning_rate": 0.00015317460317460318,
      "loss": 3.0467,
      "step": 60
    },
    {
      "epoch": 0.7100591715976331,
      "eval_loss": 2.6644818782806396,
      "eval_runtime": 7.2734,
      "eval_samples_per_second": 10.449,
      "eval_steps_per_second": 1.375,
      "step": 60
    },
    {
      "epoch": 0.7218934911242604,
      "grad_norm": 0.6970789432525635,
      "learning_rate": 0.00015238095238095237,
      "loss": 2.8016,
      "step": 61
    },
    {
      "epoch": 0.7337278106508875,
      "grad_norm": 0.6272057890892029,
      "learning_rate": 0.00015158730158730158,
      "loss": 2.5749,
      "step": 62
    },
    {
      "epoch": 0.7455621301775148,
      "grad_norm": 0.5338342785835266,
      "learning_rate": 0.0001507936507936508,
      "loss": 2.7786,
      "step": 63
    },
    {
      "epoch": 0.757396449704142,
      "grad_norm": 0.6696319580078125,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.2884,
      "step": 64
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 1.2059160470962524,
      "learning_rate": 0.00014920634920634923,
      "loss": 1.7456,
      "step": 65
    },
    {
      "epoch": 0.7810650887573964,
      "grad_norm": 0.7062201499938965,
      "learning_rate": 0.00014841269841269842,
      "loss": 2.6934,
      "step": 66
    },
    {
      "epoch": 0.7928994082840237,
      "grad_norm": 0.6635662913322449,
      "learning_rate": 0.00014761904761904763,
      "loss": 2.6333,
      "step": 67
    },
    {
      "epoch": 0.8047337278106509,
      "grad_norm": 0.5466334223747253,
      "learning_rate": 0.00014682539682539682,
      "loss": 2.6444,
      "step": 68
    },
    {
      "epoch": 0.8165680473372781,
      "grad_norm": 0.49772873520851135,
      "learning_rate": 0.00014603174603174603,
      "loss": 2.7637,
      "step": 69
    },
    {
      "epoch": 0.8284023668639053,
      "grad_norm": 0.9404497742652893,
      "learning_rate": 0.00014523809523809525,
      "loss": 2.8166,
      "step": 70
    },
    {
      "epoch": 0.8284023668639053,
      "eval_loss": 2.6316301822662354,
      "eval_runtime": 7.2797,
      "eval_samples_per_second": 10.44,
      "eval_steps_per_second": 1.374,
      "step": 70
    },
    {
      "epoch": 0.8402366863905325,
      "grad_norm": 0.8069394826889038,
      "learning_rate": 0.00014444444444444444,
      "loss": 2.855,
      "step": 71
    },
    {
      "epoch": 0.8520710059171598,
      "grad_norm": 0.7737659811973572,
      "learning_rate": 0.00014365079365079365,
      "loss": 2.1491,
      "step": 72
    },
    {
      "epoch": 0.863905325443787,
      "grad_norm": 0.5052229762077332,
      "learning_rate": 0.00014285714285714287,
      "loss": 2.2292,
      "step": 73
    },
    {
      "epoch": 0.8757396449704142,
      "grad_norm": 0.7113141417503357,
      "learning_rate": 0.00014206349206349208,
      "loss": 2.2704,
      "step": 74
    },
    {
      "epoch": 0.8875739644970414,
      "grad_norm": 0.6412409543991089,
      "learning_rate": 0.0001412698412698413,
      "loss": 2.8841,
      "step": 75
    },
    {
      "epoch": 0.8994082840236687,
      "grad_norm": 0.5820372700691223,
      "learning_rate": 0.00014047619047619049,
      "loss": 2.983,
      "step": 76
    },
    {
      "epoch": 0.9112426035502958,
      "grad_norm": 0.5347169637680054,
      "learning_rate": 0.00013968253968253967,
      "loss": 2.3948,
      "step": 77
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 1.3480430841445923,
      "learning_rate": 0.0001388888888888889,
      "loss": 1.7131,
      "step": 78
    },
    {
      "epoch": 0.9349112426035503,
      "grad_norm": 0.5234830379486084,
      "learning_rate": 0.0001380952380952381,
      "loss": 2.8719,
      "step": 79
    },
    {
      "epoch": 0.9467455621301775,
      "grad_norm": 0.5847628116607666,
      "learning_rate": 0.00013730158730158732,
      "loss": 2.5703,
      "step": 80
    },
    {
      "epoch": 0.9467455621301775,
      "eval_loss": 2.604074716567993,
      "eval_runtime": 7.2765,
      "eval_samples_per_second": 10.445,
      "eval_steps_per_second": 1.374,
      "step": 80
    },
    {
      "epoch": 0.9585798816568047,
      "grad_norm": 0.8328595757484436,
      "learning_rate": 0.0001365079365079365,
      "loss": 2.2687,
      "step": 81
    },
    {
      "epoch": 0.9704142011834319,
      "grad_norm": 0.5822745561599731,
      "learning_rate": 0.00013571428571428572,
      "loss": 2.8484,
      "step": 82
    },
    {
      "epoch": 0.9822485207100592,
      "grad_norm": 0.6907711625099182,
      "learning_rate": 0.00013492063492063494,
      "loss": 2.9175,
      "step": 83
    },
    {
      "epoch": 0.9940828402366864,
      "grad_norm": 0.8369280695915222,
      "learning_rate": 0.00013412698412698412,
      "loss": 2.4876,
      "step": 84
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7134973406791687,
      "learning_rate": 0.00013333333333333334,
      "loss": 3.027,
      "step": 85
    },
    {
      "epoch": 1.0118343195266273,
      "grad_norm": 0.6013460755348206,
      "learning_rate": 0.00013253968253968255,
      "loss": 1.8749,
      "step": 86
    },
    {
      "epoch": 1.0236686390532543,
      "grad_norm": 0.7277452349662781,
      "learning_rate": 0.00013174603174603174,
      "loss": 2.8328,
      "step": 87
    },
    {
      "epoch": 1.0355029585798816,
      "grad_norm": 0.722467839717865,
      "learning_rate": 0.00013095238095238096,
      "loss": 2.6522,
      "step": 88
    },
    {
      "epoch": 1.047337278106509,
      "grad_norm": 0.8096456527709961,
      "learning_rate": 0.00013015873015873017,
      "loss": 2.7604,
      "step": 89
    },
    {
      "epoch": 1.0591715976331362,
      "grad_norm": 0.6360284686088562,
      "learning_rate": 0.0001293650793650794,
      "loss": 2.3219,
      "step": 90
    },
    {
      "epoch": 1.0591715976331362,
      "eval_loss": 2.5900864601135254,
      "eval_runtime": 7.2773,
      "eval_samples_per_second": 10.443,
      "eval_steps_per_second": 1.374,
      "step": 90
    },
    {
      "epoch": 1.0710059171597632,
      "grad_norm": 0.605359673500061,
      "learning_rate": 0.00012857142857142858,
      "loss": 2.1798,
      "step": 91
    },
    {
      "epoch": 1.0828402366863905,
      "grad_norm": 0.7129726409912109,
      "learning_rate": 0.00012777777777777776,
      "loss": 2.1981,
      "step": 92
    },
    {
      "epoch": 1.0946745562130178,
      "grad_norm": 0.4769239127635956,
      "learning_rate": 0.00012698412698412698,
      "loss": 2.7974,
      "step": 93
    },
    {
      "epoch": 1.106508875739645,
      "grad_norm": 0.7052208185195923,
      "learning_rate": 0.0001261904761904762,
      "loss": 2.5103,
      "step": 94
    },
    {
      "epoch": 1.1183431952662721,
      "grad_norm": 0.5450578331947327,
      "learning_rate": 0.0001253968253968254,
      "loss": 2.4584,
      "step": 95
    },
    {
      "epoch": 1.1301775147928994,
      "grad_norm": 0.9231945276260376,
      "learning_rate": 0.00012460317460317462,
      "loss": 2.2218,
      "step": 96
    },
    {
      "epoch": 1.1420118343195267,
      "grad_norm": 0.5051220059394836,
      "learning_rate": 0.0001238095238095238,
      "loss": 2.5164,
      "step": 97
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 0.9433861970901489,
      "learning_rate": 0.00012301587301587303,
      "loss": 2.5665,
      "step": 98
    },
    {
      "epoch": 1.165680473372781,
      "grad_norm": 0.5250216126441956,
      "learning_rate": 0.00012222222222222224,
      "loss": 2.456,
      "step": 99
    },
    {
      "epoch": 1.1775147928994083,
      "grad_norm": 0.9290037155151367,
      "learning_rate": 0.00012142857142857143,
      "loss": 2.3161,
      "step": 100
    },
    {
      "epoch": 1.1775147928994083,
      "eval_loss": 2.572314739227295,
      "eval_runtime": 7.2824,
      "eval_samples_per_second": 10.436,
      "eval_steps_per_second": 1.373,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 252,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.2089350086008832e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
