{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.970414201183432,
  "eval_steps": 10,
  "global_step": 252,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011834319526627219,
      "grad_norm": 0.2852616310119629,
      "learning_rate": 0.0002,
      "loss": 3.6535,
      "step": 1
    },
    {
      "epoch": 0.023668639053254437,
      "grad_norm": 0.42725804448127747,
      "learning_rate": 0.00019920634920634922,
      "loss": 3.2292,
      "step": 2
    },
    {
      "epoch": 0.03550295857988166,
      "grad_norm": 0.2975868582725525,
      "learning_rate": 0.00019841269841269844,
      "loss": 2.3642,
      "step": 3
    },
    {
      "epoch": 0.047337278106508875,
      "grad_norm": 0.5254213213920593,
      "learning_rate": 0.00019761904761904763,
      "loss": 3.533,
      "step": 4
    },
    {
      "epoch": 0.05917159763313609,
      "grad_norm": 0.7198086977005005,
      "learning_rate": 0.00019682539682539682,
      "loss": 3.4469,
      "step": 5
    },
    {
      "epoch": 0.07100591715976332,
      "grad_norm": 0.835084080696106,
      "learning_rate": 0.00019603174603174603,
      "loss": 2.6131,
      "step": 6
    },
    {
      "epoch": 0.08284023668639054,
      "grad_norm": 0.5850217938423157,
      "learning_rate": 0.00019523809523809525,
      "loss": 2.39,
      "step": 7
    },
    {
      "epoch": 0.09467455621301775,
      "grad_norm": 2.8779730796813965,
      "learning_rate": 0.00019444444444444446,
      "loss": 2.8081,
      "step": 8
    },
    {
      "epoch": 0.10650887573964497,
      "grad_norm": 3.7347939014434814,
      "learning_rate": 0.00019365079365079365,
      "loss": 2.8685,
      "step": 9
    },
    {
      "epoch": 0.11834319526627218,
      "grad_norm": 1.1432902812957764,
      "learning_rate": 0.00019285714285714286,
      "loss": 2.9831,
      "step": 10
    },
    {
      "epoch": 0.11834319526627218,
      "eval_loss": 3.0265727043151855,
      "eval_runtime": 7.2621,
      "eval_samples_per_second": 10.465,
      "eval_steps_per_second": 1.377,
      "step": 10
    },
    {
      "epoch": 0.1301775147928994,
      "grad_norm": 2.6644093990325928,
      "learning_rate": 0.00019206349206349208,
      "loss": 2.7168,
      "step": 11
    },
    {
      "epoch": 0.14201183431952663,
      "grad_norm": 0.39588865637779236,
      "learning_rate": 0.0001912698412698413,
      "loss": 3.4442,
      "step": 12
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 0.76161128282547,
      "learning_rate": 0.00019047619047619048,
      "loss": 2.7836,
      "step": 13
    },
    {
      "epoch": 0.16568047337278108,
      "grad_norm": 0.403511106967926,
      "learning_rate": 0.0001896825396825397,
      "loss": 2.6901,
      "step": 14
    },
    {
      "epoch": 0.17751479289940827,
      "grad_norm": 0.3340049982070923,
      "learning_rate": 0.00018888888888888888,
      "loss": 2.9176,
      "step": 15
    },
    {
      "epoch": 0.1893491124260355,
      "grad_norm": 0.44705730676651,
      "learning_rate": 0.0001880952380952381,
      "loss": 3.1157,
      "step": 16
    },
    {
      "epoch": 0.20118343195266272,
      "grad_norm": 0.62772536277771,
      "learning_rate": 0.00018730158730158731,
      "loss": 2.7558,
      "step": 17
    },
    {
      "epoch": 0.21301775147928995,
      "grad_norm": 0.5882687568664551,
      "learning_rate": 0.00018650793650793653,
      "loss": 2.7065,
      "step": 18
    },
    {
      "epoch": 0.22485207100591717,
      "grad_norm": 0.4743443429470062,
      "learning_rate": 0.00018571428571428572,
      "loss": 3.3719,
      "step": 19
    },
    {
      "epoch": 0.23668639053254437,
      "grad_norm": 0.5696156620979309,
      "learning_rate": 0.00018492063492063493,
      "loss": 2.9977,
      "step": 20
    },
    {
      "epoch": 0.23668639053254437,
      "eval_loss": 2.8663079738616943,
      "eval_runtime": 7.2564,
      "eval_samples_per_second": 10.474,
      "eval_steps_per_second": 1.378,
      "step": 20
    },
    {
      "epoch": 0.2485207100591716,
      "grad_norm": 0.5697664022445679,
      "learning_rate": 0.00018412698412698412,
      "loss": 1.9846,
      "step": 21
    },
    {
      "epoch": 0.2603550295857988,
      "grad_norm": 0.4957573711872101,
      "learning_rate": 0.00018333333333333334,
      "loss": 3.1558,
      "step": 22
    },
    {
      "epoch": 0.27218934911242604,
      "grad_norm": 0.4362879693508148,
      "learning_rate": 0.00018253968253968255,
      "loss": 3.301,
      "step": 23
    },
    {
      "epoch": 0.28402366863905326,
      "grad_norm": 0.5254936814308167,
      "learning_rate": 0.00018174603174603177,
      "loss": 3.0331,
      "step": 24
    },
    {
      "epoch": 0.2958579881656805,
      "grad_norm": 0.47438421845436096,
      "learning_rate": 0.00018095238095238095,
      "loss": 3.3227,
      "step": 25
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 0.5094731450080872,
      "learning_rate": 0.00018015873015873017,
      "loss": 3.8949,
      "step": 26
    },
    {
      "epoch": 0.31952662721893493,
      "grad_norm": 0.5917863249778748,
      "learning_rate": 0.00017936507936507938,
      "loss": 3.0268,
      "step": 27
    },
    {
      "epoch": 0.33136094674556216,
      "grad_norm": 0.3595137894153595,
      "learning_rate": 0.0001785714285714286,
      "loss": 2.9957,
      "step": 28
    },
    {
      "epoch": 0.3431952662721893,
      "grad_norm": 0.47600701451301575,
      "learning_rate": 0.00017777777777777779,
      "loss": 2.1916,
      "step": 29
    },
    {
      "epoch": 0.35502958579881655,
      "grad_norm": 0.5427821278572083,
      "learning_rate": 0.00017698412698412697,
      "loss": 2.9272,
      "step": 30
    },
    {
      "epoch": 0.35502958579881655,
      "eval_loss": 2.788158416748047,
      "eval_runtime": 7.2699,
      "eval_samples_per_second": 10.454,
      "eval_steps_per_second": 1.376,
      "step": 30
    },
    {
      "epoch": 0.3668639053254438,
      "grad_norm": 0.47064968943595886,
      "learning_rate": 0.0001761904761904762,
      "loss": 2.9858,
      "step": 31
    },
    {
      "epoch": 0.378698224852071,
      "grad_norm": 0.4756056070327759,
      "learning_rate": 0.0001753968253968254,
      "loss": 2.3199,
      "step": 32
    },
    {
      "epoch": 0.3905325443786982,
      "grad_norm": 0.45889586210250854,
      "learning_rate": 0.00017460317460317462,
      "loss": 2.7038,
      "step": 33
    },
    {
      "epoch": 0.40236686390532544,
      "grad_norm": 0.45923224091529846,
      "learning_rate": 0.00017380952380952383,
      "loss": 3.4152,
      "step": 34
    },
    {
      "epoch": 0.41420118343195267,
      "grad_norm": 0.4572738707065582,
      "learning_rate": 0.00017301587301587302,
      "loss": 3.1502,
      "step": 35
    },
    {
      "epoch": 0.4260355029585799,
      "grad_norm": 0.6110097765922546,
      "learning_rate": 0.00017222222222222224,
      "loss": 2.9745,
      "step": 36
    },
    {
      "epoch": 0.4378698224852071,
      "grad_norm": 0.4958982467651367,
      "learning_rate": 0.00017142857142857143,
      "loss": 2.1988,
      "step": 37
    },
    {
      "epoch": 0.44970414201183434,
      "grad_norm": 0.5015813112258911,
      "learning_rate": 0.00017063492063492064,
      "loss": 2.6207,
      "step": 38
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 0.5053653120994568,
      "learning_rate": 0.00016984126984126986,
      "loss": 2.9909,
      "step": 39
    },
    {
      "epoch": 0.47337278106508873,
      "grad_norm": 0.6383805871009827,
      "learning_rate": 0.00016904761904761904,
      "loss": 2.4307,
      "step": 40
    },
    {
      "epoch": 0.47337278106508873,
      "eval_loss": 2.732571601867676,
      "eval_runtime": 7.2707,
      "eval_samples_per_second": 10.453,
      "eval_steps_per_second": 1.375,
      "step": 40
    },
    {
      "epoch": 0.48520710059171596,
      "grad_norm": 0.6155767440795898,
      "learning_rate": 0.00016825396825396826,
      "loss": 2.7887,
      "step": 41
    },
    {
      "epoch": 0.4970414201183432,
      "grad_norm": 0.5471430420875549,
      "learning_rate": 0.00016746031746031747,
      "loss": 2.5071,
      "step": 42
    },
    {
      "epoch": 0.5088757396449705,
      "grad_norm": 0.5839921236038208,
      "learning_rate": 0.0001666666666666667,
      "loss": 2.3487,
      "step": 43
    },
    {
      "epoch": 0.5207100591715976,
      "grad_norm": 0.8534253835678101,
      "learning_rate": 0.0001658730158730159,
      "loss": 2.3831,
      "step": 44
    },
    {
      "epoch": 0.5325443786982249,
      "grad_norm": 0.4808950424194336,
      "learning_rate": 0.0001650793650793651,
      "loss": 2.7563,
      "step": 45
    },
    {
      "epoch": 0.5443786982248521,
      "grad_norm": 0.5995768904685974,
      "learning_rate": 0.00016428571428571428,
      "loss": 2.9696,
      "step": 46
    },
    {
      "epoch": 0.5562130177514792,
      "grad_norm": 0.45817336440086365,
      "learning_rate": 0.0001634920634920635,
      "loss": 2.9663,
      "step": 47
    },
    {
      "epoch": 0.5680473372781065,
      "grad_norm": 0.479961097240448,
      "learning_rate": 0.0001626984126984127,
      "loss": 2.8644,
      "step": 48
    },
    {
      "epoch": 0.5798816568047337,
      "grad_norm": 0.695735514163971,
      "learning_rate": 0.00016190476190476192,
      "loss": 2.6259,
      "step": 49
    },
    {
      "epoch": 0.591715976331361,
      "grad_norm": 0.5882052183151245,
      "learning_rate": 0.0001611111111111111,
      "loss": 2.5268,
      "step": 50
    },
    {
      "epoch": 0.591715976331361,
      "eval_loss": 2.6890671253204346,
      "eval_runtime": 7.2755,
      "eval_samples_per_second": 10.446,
      "eval_steps_per_second": 1.374,
      "step": 50
    },
    {
      "epoch": 0.6035502958579881,
      "grad_norm": 0.5598996877670288,
      "learning_rate": 0.00016031746031746033,
      "loss": 2.7146,
      "step": 51
    },
    {
      "epoch": 0.6153846153846154,
      "grad_norm": 0.555019736289978,
      "learning_rate": 0.00015952380952380954,
      "loss": 2.9906,
      "step": 52
    },
    {
      "epoch": 0.6272189349112426,
      "grad_norm": 0.7015283107757568,
      "learning_rate": 0.00015873015873015873,
      "loss": 2.7494,
      "step": 53
    },
    {
      "epoch": 0.6390532544378699,
      "grad_norm": 0.532532811164856,
      "learning_rate": 0.00015793650793650795,
      "loss": 2.4279,
      "step": 54
    },
    {
      "epoch": 0.650887573964497,
      "grad_norm": 0.5694570541381836,
      "learning_rate": 0.00015714285714285716,
      "loss": 3.2177,
      "step": 55
    },
    {
      "epoch": 0.6627218934911243,
      "grad_norm": 0.4815200865268707,
      "learning_rate": 0.00015634920634920635,
      "loss": 2.6564,
      "step": 56
    },
    {
      "epoch": 0.6745562130177515,
      "grad_norm": 1.0988482236862183,
      "learning_rate": 0.00015555555555555556,
      "loss": 2.0123,
      "step": 57
    },
    {
      "epoch": 0.6863905325443787,
      "grad_norm": 0.5982100963592529,
      "learning_rate": 0.00015476190476190478,
      "loss": 2.5896,
      "step": 58
    },
    {
      "epoch": 0.6982248520710059,
      "grad_norm": 0.8859602808952332,
      "learning_rate": 0.000153968253968254,
      "loss": 2.223,
      "step": 59
    },
    {
      "epoch": 0.7100591715976331,
      "grad_norm": 0.5900657773017883,
      "learning_rate": 0.00015317460317460318,
      "loss": 3.0467,
      "step": 60
    },
    {
      "epoch": 0.7100591715976331,
      "eval_loss": 2.6644818782806396,
      "eval_runtime": 7.2734,
      "eval_samples_per_second": 10.449,
      "eval_steps_per_second": 1.375,
      "step": 60
    },
    {
      "epoch": 0.7218934911242604,
      "grad_norm": 0.6970789432525635,
      "learning_rate": 0.00015238095238095237,
      "loss": 2.8016,
      "step": 61
    },
    {
      "epoch": 0.7337278106508875,
      "grad_norm": 0.6272057890892029,
      "learning_rate": 0.00015158730158730158,
      "loss": 2.5749,
      "step": 62
    },
    {
      "epoch": 0.7455621301775148,
      "grad_norm": 0.5338342785835266,
      "learning_rate": 0.0001507936507936508,
      "loss": 2.7786,
      "step": 63
    },
    {
      "epoch": 0.757396449704142,
      "grad_norm": 0.6696319580078125,
      "learning_rate": 0.00015000000000000001,
      "loss": 2.2884,
      "step": 64
    },
    {
      "epoch": 0.7692307692307693,
      "grad_norm": 1.2059160470962524,
      "learning_rate": 0.00014920634920634923,
      "loss": 1.7456,
      "step": 65
    },
    {
      "epoch": 0.7810650887573964,
      "grad_norm": 0.7062201499938965,
      "learning_rate": 0.00014841269841269842,
      "loss": 2.6934,
      "step": 66
    },
    {
      "epoch": 0.7928994082840237,
      "grad_norm": 0.6635662913322449,
      "learning_rate": 0.00014761904761904763,
      "loss": 2.6333,
      "step": 67
    },
    {
      "epoch": 0.8047337278106509,
      "grad_norm": 0.5466334223747253,
      "learning_rate": 0.00014682539682539682,
      "loss": 2.6444,
      "step": 68
    },
    {
      "epoch": 0.8165680473372781,
      "grad_norm": 0.49772873520851135,
      "learning_rate": 0.00014603174603174603,
      "loss": 2.7637,
      "step": 69
    },
    {
      "epoch": 0.8284023668639053,
      "grad_norm": 0.9404497742652893,
      "learning_rate": 0.00014523809523809525,
      "loss": 2.8166,
      "step": 70
    },
    {
      "epoch": 0.8284023668639053,
      "eval_loss": 2.6316301822662354,
      "eval_runtime": 7.2797,
      "eval_samples_per_second": 10.44,
      "eval_steps_per_second": 1.374,
      "step": 70
    },
    {
      "epoch": 0.8402366863905325,
      "grad_norm": 0.8069394826889038,
      "learning_rate": 0.00014444444444444444,
      "loss": 2.855,
      "step": 71
    },
    {
      "epoch": 0.8520710059171598,
      "grad_norm": 0.7737659811973572,
      "learning_rate": 0.00014365079365079365,
      "loss": 2.1491,
      "step": 72
    },
    {
      "epoch": 0.863905325443787,
      "grad_norm": 0.5052229762077332,
      "learning_rate": 0.00014285714285714287,
      "loss": 2.2292,
      "step": 73
    },
    {
      "epoch": 0.8757396449704142,
      "grad_norm": 0.7113141417503357,
      "learning_rate": 0.00014206349206349208,
      "loss": 2.2704,
      "step": 74
    },
    {
      "epoch": 0.8875739644970414,
      "grad_norm": 0.6412409543991089,
      "learning_rate": 0.0001412698412698413,
      "loss": 2.8841,
      "step": 75
    },
    {
      "epoch": 0.8994082840236687,
      "grad_norm": 0.5820372700691223,
      "learning_rate": 0.00014047619047619049,
      "loss": 2.983,
      "step": 76
    },
    {
      "epoch": 0.9112426035502958,
      "grad_norm": 0.5347169637680054,
      "learning_rate": 0.00013968253968253967,
      "loss": 2.3948,
      "step": 77
    },
    {
      "epoch": 0.9230769230769231,
      "grad_norm": 1.3480430841445923,
      "learning_rate": 0.0001388888888888889,
      "loss": 1.7131,
      "step": 78
    },
    {
      "epoch": 0.9349112426035503,
      "grad_norm": 0.5234830379486084,
      "learning_rate": 0.0001380952380952381,
      "loss": 2.8719,
      "step": 79
    },
    {
      "epoch": 0.9467455621301775,
      "grad_norm": 0.5847628116607666,
      "learning_rate": 0.00013730158730158732,
      "loss": 2.5703,
      "step": 80
    },
    {
      "epoch": 0.9467455621301775,
      "eval_loss": 2.604074716567993,
      "eval_runtime": 7.2765,
      "eval_samples_per_second": 10.445,
      "eval_steps_per_second": 1.374,
      "step": 80
    },
    {
      "epoch": 0.9585798816568047,
      "grad_norm": 0.8328595757484436,
      "learning_rate": 0.0001365079365079365,
      "loss": 2.2687,
      "step": 81
    },
    {
      "epoch": 0.9704142011834319,
      "grad_norm": 0.5822745561599731,
      "learning_rate": 0.00013571428571428572,
      "loss": 2.8484,
      "step": 82
    },
    {
      "epoch": 0.9822485207100592,
      "grad_norm": 0.6907711625099182,
      "learning_rate": 0.00013492063492063494,
      "loss": 2.9175,
      "step": 83
    },
    {
      "epoch": 0.9940828402366864,
      "grad_norm": 0.8369280695915222,
      "learning_rate": 0.00013412698412698412,
      "loss": 2.4876,
      "step": 84
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.7134973406791687,
      "learning_rate": 0.00013333333333333334,
      "loss": 3.027,
      "step": 85
    },
    {
      "epoch": 1.0118343195266273,
      "grad_norm": 0.6013460755348206,
      "learning_rate": 0.00013253968253968255,
      "loss": 1.8749,
      "step": 86
    },
    {
      "epoch": 1.0236686390532543,
      "grad_norm": 0.7277452349662781,
      "learning_rate": 0.00013174603174603174,
      "loss": 2.8328,
      "step": 87
    },
    {
      "epoch": 1.0355029585798816,
      "grad_norm": 0.722467839717865,
      "learning_rate": 0.00013095238095238096,
      "loss": 2.6522,
      "step": 88
    },
    {
      "epoch": 1.047337278106509,
      "grad_norm": 0.8096456527709961,
      "learning_rate": 0.00013015873015873017,
      "loss": 2.7604,
      "step": 89
    },
    {
      "epoch": 1.0591715976331362,
      "grad_norm": 0.6360284686088562,
      "learning_rate": 0.0001293650793650794,
      "loss": 2.3219,
      "step": 90
    },
    {
      "epoch": 1.0591715976331362,
      "eval_loss": 2.5900864601135254,
      "eval_runtime": 7.2773,
      "eval_samples_per_second": 10.443,
      "eval_steps_per_second": 1.374,
      "step": 90
    },
    {
      "epoch": 1.0710059171597632,
      "grad_norm": 0.605359673500061,
      "learning_rate": 0.00012857142857142858,
      "loss": 2.1798,
      "step": 91
    },
    {
      "epoch": 1.0828402366863905,
      "grad_norm": 0.7129726409912109,
      "learning_rate": 0.00012777777777777776,
      "loss": 2.1981,
      "step": 92
    },
    {
      "epoch": 1.0946745562130178,
      "grad_norm": 0.4769239127635956,
      "learning_rate": 0.00012698412698412698,
      "loss": 2.7974,
      "step": 93
    },
    {
      "epoch": 1.106508875739645,
      "grad_norm": 0.7052208185195923,
      "learning_rate": 0.0001261904761904762,
      "loss": 2.5103,
      "step": 94
    },
    {
      "epoch": 1.1183431952662721,
      "grad_norm": 0.5450578331947327,
      "learning_rate": 0.0001253968253968254,
      "loss": 2.4584,
      "step": 95
    },
    {
      "epoch": 1.1301775147928994,
      "grad_norm": 0.9231945276260376,
      "learning_rate": 0.00012460317460317462,
      "loss": 2.2218,
      "step": 96
    },
    {
      "epoch": 1.1420118343195267,
      "grad_norm": 0.5051220059394836,
      "learning_rate": 0.0001238095238095238,
      "loss": 2.5164,
      "step": 97
    },
    {
      "epoch": 1.1538461538461537,
      "grad_norm": 0.9433861970901489,
      "learning_rate": 0.00012301587301587303,
      "loss": 2.5665,
      "step": 98
    },
    {
      "epoch": 1.165680473372781,
      "grad_norm": 0.5250216126441956,
      "learning_rate": 0.00012222222222222224,
      "loss": 2.456,
      "step": 99
    },
    {
      "epoch": 1.1775147928994083,
      "grad_norm": 0.9290037155151367,
      "learning_rate": 0.00012142857142857143,
      "loss": 2.3161,
      "step": 100
    },
    {
      "epoch": 1.1775147928994083,
      "eval_loss": 2.572314739227295,
      "eval_runtime": 7.2824,
      "eval_samples_per_second": 10.436,
      "eval_steps_per_second": 1.373,
      "step": 100
    },
    {
      "epoch": 1.1893491124260356,
      "grad_norm": 0.5697566270828247,
      "learning_rate": 0.00012063492063492063,
      "loss": 3.0151,
      "step": 101
    },
    {
      "epoch": 1.2011834319526626,
      "grad_norm": 0.7438158988952637,
      "learning_rate": 0.00011984126984126985,
      "loss": 2.4191,
      "step": 102
    },
    {
      "epoch": 1.21301775147929,
      "grad_norm": 0.9907975196838379,
      "learning_rate": 0.00011904761904761905,
      "loss": 2.5932,
      "step": 103
    },
    {
      "epoch": 1.2248520710059172,
      "grad_norm": 0.8053844571113586,
      "learning_rate": 0.00011825396825396826,
      "loss": 2.6965,
      "step": 104
    },
    {
      "epoch": 1.2366863905325443,
      "grad_norm": 0.8778121471405029,
      "learning_rate": 0.00011746031746031746,
      "loss": 2.9142,
      "step": 105
    },
    {
      "epoch": 1.2485207100591715,
      "grad_norm": 0.8507038354873657,
      "learning_rate": 0.00011666666666666668,
      "loss": 2.314,
      "step": 106
    },
    {
      "epoch": 1.2603550295857988,
      "grad_norm": 0.5103598237037659,
      "learning_rate": 0.0001158730158730159,
      "loss": 2.46,
      "step": 107
    },
    {
      "epoch": 1.272189349112426,
      "grad_norm": 0.6257282495498657,
      "learning_rate": 0.00011507936507936508,
      "loss": 2.5705,
      "step": 108
    },
    {
      "epoch": 1.2840236686390534,
      "grad_norm": 0.6777400970458984,
      "learning_rate": 0.00011428571428571428,
      "loss": 1.7891,
      "step": 109
    },
    {
      "epoch": 1.2958579881656804,
      "grad_norm": 0.5313989520072937,
      "learning_rate": 0.0001134920634920635,
      "loss": 2.6952,
      "step": 110
    },
    {
      "epoch": 1.2958579881656804,
      "eval_loss": 2.5615217685699463,
      "eval_runtime": 7.2743,
      "eval_samples_per_second": 10.448,
      "eval_steps_per_second": 1.375,
      "step": 110
    },
    {
      "epoch": 1.3076923076923077,
      "grad_norm": 0.7306844592094421,
      "learning_rate": 0.0001126984126984127,
      "loss": 2.3494,
      "step": 111
    },
    {
      "epoch": 1.319526627218935,
      "grad_norm": 0.7643621563911438,
      "learning_rate": 0.00011190476190476191,
      "loss": 2.717,
      "step": 112
    },
    {
      "epoch": 1.331360946745562,
      "grad_norm": 0.7161374092102051,
      "learning_rate": 0.00011111111111111112,
      "loss": 2.2832,
      "step": 113
    },
    {
      "epoch": 1.3431952662721893,
      "grad_norm": 0.6994403004646301,
      "learning_rate": 0.00011031746031746033,
      "loss": 1.9673,
      "step": 114
    },
    {
      "epoch": 1.3550295857988166,
      "grad_norm": 0.5267111659049988,
      "learning_rate": 0.00010952380952380953,
      "loss": 2.6778,
      "step": 115
    },
    {
      "epoch": 1.3668639053254439,
      "grad_norm": 0.6504354476928711,
      "learning_rate": 0.00010873015873015872,
      "loss": 3.2382,
      "step": 116
    },
    {
      "epoch": 1.378698224852071,
      "grad_norm": 0.5963406562805176,
      "learning_rate": 0.00010793650793650794,
      "loss": 2.5139,
      "step": 117
    },
    {
      "epoch": 1.3905325443786982,
      "grad_norm": 0.5832500457763672,
      "learning_rate": 0.00010714285714285715,
      "loss": 2.8291,
      "step": 118
    },
    {
      "epoch": 1.4023668639053255,
      "grad_norm": 0.7362439036369324,
      "learning_rate": 0.00010634920634920635,
      "loss": 2.6421,
      "step": 119
    },
    {
      "epoch": 1.4142011834319526,
      "grad_norm": 1.0933115482330322,
      "learning_rate": 0.00010555555555555557,
      "loss": 2.108,
      "step": 120
    },
    {
      "epoch": 1.4142011834319526,
      "eval_loss": 2.547210693359375,
      "eval_runtime": 7.2794,
      "eval_samples_per_second": 10.44,
      "eval_steps_per_second": 1.374,
      "step": 120
    },
    {
      "epoch": 1.4260355029585798,
      "grad_norm": 0.5974471569061279,
      "learning_rate": 0.00010476190476190477,
      "loss": 2.689,
      "step": 121
    },
    {
      "epoch": 1.4378698224852071,
      "grad_norm": 0.9212902188301086,
      "learning_rate": 0.00010396825396825398,
      "loss": 2.2014,
      "step": 122
    },
    {
      "epoch": 1.4497041420118344,
      "grad_norm": 0.8124514222145081,
      "learning_rate": 0.00010317460317460319,
      "loss": 2.8714,
      "step": 123
    },
    {
      "epoch": 1.4615384615384617,
      "grad_norm": 0.7275286316871643,
      "learning_rate": 0.00010238095238095237,
      "loss": 2.7374,
      "step": 124
    },
    {
      "epoch": 1.4733727810650887,
      "grad_norm": 0.929499626159668,
      "learning_rate": 0.00010158730158730159,
      "loss": 1.9574,
      "step": 125
    },
    {
      "epoch": 1.485207100591716,
      "grad_norm": 0.8639349341392517,
      "learning_rate": 0.00010079365079365079,
      "loss": 2.7422,
      "step": 126
    },
    {
      "epoch": 1.497041420118343,
      "grad_norm": 0.7741735577583313,
      "learning_rate": 0.0001,
      "loss": 2.6112,
      "step": 127
    },
    {
      "epoch": 1.5088757396449703,
      "grad_norm": 0.5478761196136475,
      "learning_rate": 9.920634920634922e-05,
      "loss": 2.674,
      "step": 128
    },
    {
      "epoch": 1.5207100591715976,
      "grad_norm": 0.5716172456741333,
      "learning_rate": 9.841269841269841e-05,
      "loss": 3.0204,
      "step": 129
    },
    {
      "epoch": 1.532544378698225,
      "grad_norm": 0.9243114590644836,
      "learning_rate": 9.761904761904762e-05,
      "loss": 2.3739,
      "step": 130
    },
    {
      "epoch": 1.532544378698225,
      "eval_loss": 2.5395078659057617,
      "eval_runtime": 7.2776,
      "eval_samples_per_second": 10.443,
      "eval_steps_per_second": 1.374,
      "step": 130
    },
    {
      "epoch": 1.5443786982248522,
      "grad_norm": 0.6761171221733093,
      "learning_rate": 9.682539682539682e-05,
      "loss": 2.427,
      "step": 131
    },
    {
      "epoch": 1.5562130177514792,
      "grad_norm": 0.7756714820861816,
      "learning_rate": 9.603174603174604e-05,
      "loss": 2.4382,
      "step": 132
    },
    {
      "epoch": 1.5680473372781065,
      "grad_norm": 0.7958897948265076,
      "learning_rate": 9.523809523809524e-05,
      "loss": 2.3987,
      "step": 133
    },
    {
      "epoch": 1.5798816568047336,
      "grad_norm": 0.7800408601760864,
      "learning_rate": 9.444444444444444e-05,
      "loss": 2.4713,
      "step": 134
    },
    {
      "epoch": 1.5917159763313609,
      "grad_norm": 0.8889366984367371,
      "learning_rate": 9.365079365079366e-05,
      "loss": 2.5487,
      "step": 135
    },
    {
      "epoch": 1.6035502958579881,
      "grad_norm": 0.9200366735458374,
      "learning_rate": 9.285714285714286e-05,
      "loss": 2.2346,
      "step": 136
    },
    {
      "epoch": 1.6153846153846154,
      "grad_norm": 0.5514836311340332,
      "learning_rate": 9.206349206349206e-05,
      "loss": 3.0703,
      "step": 137
    },
    {
      "epoch": 1.6272189349112427,
      "grad_norm": 0.7489750385284424,
      "learning_rate": 9.126984126984128e-05,
      "loss": 2.3309,
      "step": 138
    },
    {
      "epoch": 1.63905325443787,
      "grad_norm": 0.7165477275848389,
      "learning_rate": 9.047619047619048e-05,
      "loss": 2.843,
      "step": 139
    },
    {
      "epoch": 1.650887573964497,
      "grad_norm": 0.705708920955658,
      "learning_rate": 8.968253968253969e-05,
      "loss": 2.726,
      "step": 140
    },
    {
      "epoch": 1.650887573964497,
      "eval_loss": 2.528157949447632,
      "eval_runtime": 7.2784,
      "eval_samples_per_second": 10.442,
      "eval_steps_per_second": 1.374,
      "step": 140
    },
    {
      "epoch": 1.6627218934911243,
      "grad_norm": 1.1112394332885742,
      "learning_rate": 8.888888888888889e-05,
      "loss": 2.1057,
      "step": 141
    },
    {
      "epoch": 1.6745562130177514,
      "grad_norm": 0.6074880361557007,
      "learning_rate": 8.80952380952381e-05,
      "loss": 2.8369,
      "step": 142
    },
    {
      "epoch": 1.6863905325443787,
      "grad_norm": 0.8061212301254272,
      "learning_rate": 8.730158730158731e-05,
      "loss": 2.4336,
      "step": 143
    },
    {
      "epoch": 1.698224852071006,
      "grad_norm": 1.2331892251968384,
      "learning_rate": 8.650793650793651e-05,
      "loss": 1.9528,
      "step": 144
    },
    {
      "epoch": 1.7100591715976332,
      "grad_norm": 0.8257815837860107,
      "learning_rate": 8.571428571428571e-05,
      "loss": 2.3596,
      "step": 145
    },
    {
      "epoch": 1.7218934911242605,
      "grad_norm": 0.7852703928947449,
      "learning_rate": 8.492063492063493e-05,
      "loss": 2.7453,
      "step": 146
    },
    {
      "epoch": 1.7337278106508875,
      "grad_norm": 1.2121977806091309,
      "learning_rate": 8.412698412698413e-05,
      "loss": 2.0199,
      "step": 147
    },
    {
      "epoch": 1.7455621301775148,
      "grad_norm": 0.7406521439552307,
      "learning_rate": 8.333333333333334e-05,
      "loss": 2.4351,
      "step": 148
    },
    {
      "epoch": 1.7573964497041419,
      "grad_norm": 1.016830563545227,
      "learning_rate": 8.253968253968255e-05,
      "loss": 2.1532,
      "step": 149
    },
    {
      "epoch": 1.7692307692307692,
      "grad_norm": 0.6803107261657715,
      "learning_rate": 8.174603174603175e-05,
      "loss": 2.8108,
      "step": 150
    },
    {
      "epoch": 1.7692307692307692,
      "eval_loss": 2.523939847946167,
      "eval_runtime": 7.2875,
      "eval_samples_per_second": 10.429,
      "eval_steps_per_second": 1.372,
      "step": 150
    },
    {
      "epoch": 1.7810650887573964,
      "grad_norm": 0.9030972123146057,
      "learning_rate": 8.095238095238096e-05,
      "loss": 2.2078,
      "step": 151
    },
    {
      "epoch": 1.7928994082840237,
      "grad_norm": 0.882210910320282,
      "learning_rate": 8.015873015873016e-05,
      "loss": 2.4751,
      "step": 152
    },
    {
      "epoch": 1.804733727810651,
      "grad_norm": 0.8757660984992981,
      "learning_rate": 7.936507936507937e-05,
      "loss": 2.4023,
      "step": 153
    },
    {
      "epoch": 1.816568047337278,
      "grad_norm": 0.950859010219574,
      "learning_rate": 7.857142857142858e-05,
      "loss": 2.3638,
      "step": 154
    },
    {
      "epoch": 1.8284023668639053,
      "grad_norm": 0.626905083656311,
      "learning_rate": 7.777777777777778e-05,
      "loss": 2.1201,
      "step": 155
    },
    {
      "epoch": 1.8402366863905324,
      "grad_norm": 0.819288969039917,
      "learning_rate": 7.6984126984127e-05,
      "loss": 2.2078,
      "step": 156
    },
    {
      "epoch": 1.8520710059171597,
      "grad_norm": 0.7903557419776917,
      "learning_rate": 7.619047619047618e-05,
      "loss": 2.1892,
      "step": 157
    },
    {
      "epoch": 1.863905325443787,
      "grad_norm": 0.9247174263000488,
      "learning_rate": 7.53968253968254e-05,
      "loss": 1.8218,
      "step": 158
    },
    {
      "epoch": 1.8757396449704142,
      "grad_norm": 0.637222409248352,
      "learning_rate": 7.460317460317461e-05,
      "loss": 2.4638,
      "step": 159
    },
    {
      "epoch": 1.8875739644970415,
      "grad_norm": 0.8414058685302734,
      "learning_rate": 7.380952380952382e-05,
      "loss": 2.2535,
      "step": 160
    },
    {
      "epoch": 1.8875739644970415,
      "eval_loss": 2.5188300609588623,
      "eval_runtime": 7.2746,
      "eval_samples_per_second": 10.447,
      "eval_steps_per_second": 1.375,
      "step": 160
    },
    {
      "epoch": 1.8994082840236688,
      "grad_norm": 0.6742753386497498,
      "learning_rate": 7.301587301587302e-05,
      "loss": 2.6272,
      "step": 161
    },
    {
      "epoch": 1.9112426035502958,
      "grad_norm": 0.8007364273071289,
      "learning_rate": 7.222222222222222e-05,
      "loss": 2.6945,
      "step": 162
    },
    {
      "epoch": 1.9230769230769231,
      "grad_norm": 1.035246729850769,
      "learning_rate": 7.142857142857143e-05,
      "loss": 2.0655,
      "step": 163
    },
    {
      "epoch": 1.9349112426035502,
      "grad_norm": 0.8273677229881287,
      "learning_rate": 7.063492063492065e-05,
      "loss": 2.5328,
      "step": 164
    },
    {
      "epoch": 1.9467455621301775,
      "grad_norm": 0.5952879190444946,
      "learning_rate": 6.984126984126984e-05,
      "loss": 2.5564,
      "step": 165
    },
    {
      "epoch": 1.9585798816568047,
      "grad_norm": 0.8959793448448181,
      "learning_rate": 6.904761904761905e-05,
      "loss": 1.9562,
      "step": 166
    },
    {
      "epoch": 1.970414201183432,
      "grad_norm": 0.7158507704734802,
      "learning_rate": 6.825396825396825e-05,
      "loss": 1.9266,
      "step": 167
    },
    {
      "epoch": 1.9822485207100593,
      "grad_norm": 0.9897952675819397,
      "learning_rate": 6.746031746031747e-05,
      "loss": 2.2961,
      "step": 168
    },
    {
      "epoch": 1.9940828402366864,
      "grad_norm": 0.8451259732246399,
      "learning_rate": 6.666666666666667e-05,
      "loss": 2.0934,
      "step": 169
    },
    {
      "epoch": 2.0,
      "grad_norm": 1.7909502983093262,
      "learning_rate": 6.587301587301587e-05,
      "loss": 2.3848,
      "step": 170
    },
    {
      "epoch": 2.0,
      "eval_loss": 2.511735200881958,
      "eval_runtime": 7.2774,
      "eval_samples_per_second": 10.443,
      "eval_steps_per_second": 1.374,
      "step": 170
    },
    {
      "epoch": 2.0118343195266273,
      "grad_norm": 0.8666543364524841,
      "learning_rate": 6.507936507936509e-05,
      "loss": 2.4761,
      "step": 171
    },
    {
      "epoch": 2.0236686390532546,
      "grad_norm": 1.0387778282165527,
      "learning_rate": 6.428571428571429e-05,
      "loss": 2.4066,
      "step": 172
    },
    {
      "epoch": 2.035502958579882,
      "grad_norm": 1.043734073638916,
      "learning_rate": 6.349206349206349e-05,
      "loss": 2.2927,
      "step": 173
    },
    {
      "epoch": 2.0473372781065087,
      "grad_norm": 0.7248689532279968,
      "learning_rate": 6.26984126984127e-05,
      "loss": 3.0591,
      "step": 174
    },
    {
      "epoch": 2.059171597633136,
      "grad_norm": 0.9651040434837341,
      "learning_rate": 6.19047619047619e-05,
      "loss": 2.2094,
      "step": 175
    },
    {
      "epoch": 2.0710059171597632,
      "grad_norm": 0.719811737537384,
      "learning_rate": 6.111111111111112e-05,
      "loss": 3.5566,
      "step": 176
    },
    {
      "epoch": 2.0828402366863905,
      "grad_norm": 0.7610357403755188,
      "learning_rate": 6.0317460317460316e-05,
      "loss": 2.131,
      "step": 177
    },
    {
      "epoch": 2.094674556213018,
      "grad_norm": 0.8120919466018677,
      "learning_rate": 5.9523809523809524e-05,
      "loss": 2.7546,
      "step": 178
    },
    {
      "epoch": 2.106508875739645,
      "grad_norm": 1.4184577465057373,
      "learning_rate": 5.873015873015873e-05,
      "loss": 1.8307,
      "step": 179
    },
    {
      "epoch": 2.1183431952662723,
      "grad_norm": 0.7758923768997192,
      "learning_rate": 5.793650793650795e-05,
      "loss": 2.7556,
      "step": 180
    },
    {
      "epoch": 2.1183431952662723,
      "eval_loss": 2.514042615890503,
      "eval_runtime": 7.2771,
      "eval_samples_per_second": 10.444,
      "eval_steps_per_second": 1.374,
      "step": 180
    },
    {
      "epoch": 2.1301775147928996,
      "grad_norm": 0.9646958708763123,
      "learning_rate": 5.714285714285714e-05,
      "loss": 1.8238,
      "step": 181
    },
    {
      "epoch": 2.1420118343195265,
      "grad_norm": 0.7159548401832581,
      "learning_rate": 5.634920634920635e-05,
      "loss": 2.5749,
      "step": 182
    },
    {
      "epoch": 2.1538461538461537,
      "grad_norm": 1.188785195350647,
      "learning_rate": 5.555555555555556e-05,
      "loss": 2.3052,
      "step": 183
    },
    {
      "epoch": 2.165680473372781,
      "grad_norm": 0.7186013460159302,
      "learning_rate": 5.4761904761904766e-05,
      "loss": 2.2546,
      "step": 184
    },
    {
      "epoch": 2.1775147928994083,
      "grad_norm": 0.9673529863357544,
      "learning_rate": 5.396825396825397e-05,
      "loss": 2.041,
      "step": 185
    },
    {
      "epoch": 2.1893491124260356,
      "grad_norm": 0.8258277177810669,
      "learning_rate": 5.3174603174603176e-05,
      "loss": 2.295,
      "step": 186
    },
    {
      "epoch": 2.201183431952663,
      "grad_norm": 1.0183186531066895,
      "learning_rate": 5.2380952380952384e-05,
      "loss": 2.3099,
      "step": 187
    },
    {
      "epoch": 2.21301775147929,
      "grad_norm": 0.6738031506538391,
      "learning_rate": 5.158730158730159e-05,
      "loss": 2.0728,
      "step": 188
    },
    {
      "epoch": 2.224852071005917,
      "grad_norm": 1.302564024925232,
      "learning_rate": 5.0793650793650794e-05,
      "loss": 1.6301,
      "step": 189
    },
    {
      "epoch": 2.2366863905325443,
      "grad_norm": 0.6299789547920227,
      "learning_rate": 5e-05,
      "loss": 2.7337,
      "step": 190
    },
    {
      "epoch": 2.2366863905325443,
      "eval_loss": 2.5083281993865967,
      "eval_runtime": 7.2841,
      "eval_samples_per_second": 10.434,
      "eval_steps_per_second": 1.373,
      "step": 190
    },
    {
      "epoch": 2.2485207100591715,
      "grad_norm": 0.8067651391029358,
      "learning_rate": 4.9206349206349204e-05,
      "loss": 2.5365,
      "step": 191
    },
    {
      "epoch": 2.260355029585799,
      "grad_norm": 0.9490525126457214,
      "learning_rate": 4.841269841269841e-05,
      "loss": 2.0249,
      "step": 192
    },
    {
      "epoch": 2.272189349112426,
      "grad_norm": 0.5898615121841431,
      "learning_rate": 4.761904761904762e-05,
      "loss": 2.7395,
      "step": 193
    },
    {
      "epoch": 2.2840236686390534,
      "grad_norm": 1.158531665802002,
      "learning_rate": 4.682539682539683e-05,
      "loss": 1.8069,
      "step": 194
    },
    {
      "epoch": 2.2958579881656807,
      "grad_norm": 1.200871229171753,
      "learning_rate": 4.603174603174603e-05,
      "loss": 2.0194,
      "step": 195
    },
    {
      "epoch": 2.3076923076923075,
      "grad_norm": 0.8036893606185913,
      "learning_rate": 4.523809523809524e-05,
      "loss": 2.1179,
      "step": 196
    },
    {
      "epoch": 2.3195266272189348,
      "grad_norm": 0.8843615055084229,
      "learning_rate": 4.4444444444444447e-05,
      "loss": 2.5392,
      "step": 197
    },
    {
      "epoch": 2.331360946745562,
      "grad_norm": 1.3491318225860596,
      "learning_rate": 4.3650793650793655e-05,
      "loss": 1.953,
      "step": 198
    },
    {
      "epoch": 2.3431952662721893,
      "grad_norm": 0.7143706679344177,
      "learning_rate": 4.2857142857142856e-05,
      "loss": 2.4738,
      "step": 199
    },
    {
      "epoch": 2.3550295857988166,
      "grad_norm": 0.9515886902809143,
      "learning_rate": 4.2063492063492065e-05,
      "loss": 2.2896,
      "step": 200
    },
    {
      "epoch": 2.3550295857988166,
      "eval_loss": 2.5081663131713867,
      "eval_runtime": 7.2697,
      "eval_samples_per_second": 10.454,
      "eval_steps_per_second": 1.376,
      "step": 200
    },
    {
      "epoch": 2.366863905325444,
      "grad_norm": 1.0560728311538696,
      "learning_rate": 4.126984126984127e-05,
      "loss": 2.131,
      "step": 201
    },
    {
      "epoch": 2.378698224852071,
      "grad_norm": 1.0017813444137573,
      "learning_rate": 4.047619047619048e-05,
      "loss": 2.4378,
      "step": 202
    },
    {
      "epoch": 2.390532544378698,
      "grad_norm": 0.9430389404296875,
      "learning_rate": 3.968253968253968e-05,
      "loss": 1.9361,
      "step": 203
    },
    {
      "epoch": 2.4023668639053253,
      "grad_norm": 1.1498010158538818,
      "learning_rate": 3.888888888888889e-05,
      "loss": 2.2551,
      "step": 204
    },
    {
      "epoch": 2.4142011834319526,
      "grad_norm": 1.9522579908370972,
      "learning_rate": 3.809523809523809e-05,
      "loss": 1.2055,
      "step": 205
    },
    {
      "epoch": 2.42603550295858,
      "grad_norm": 0.830625057220459,
      "learning_rate": 3.730158730158731e-05,
      "loss": 1.9694,
      "step": 206
    },
    {
      "epoch": 2.437869822485207,
      "grad_norm": 0.8444305658340454,
      "learning_rate": 3.650793650793651e-05,
      "loss": 2.5349,
      "step": 207
    },
    {
      "epoch": 2.4497041420118344,
      "grad_norm": 0.899649441242218,
      "learning_rate": 3.571428571428572e-05,
      "loss": 2.5918,
      "step": 208
    },
    {
      "epoch": 2.4615384615384617,
      "grad_norm": 0.9070481657981873,
      "learning_rate": 3.492063492063492e-05,
      "loss": 2.0609,
      "step": 209
    },
    {
      "epoch": 2.4733727810650885,
      "grad_norm": 0.8355130553245544,
      "learning_rate": 3.412698412698413e-05,
      "loss": 2.5221,
      "step": 210
    },
    {
      "epoch": 2.4733727810650885,
      "eval_loss": 2.50036358833313,
      "eval_runtime": 7.2786,
      "eval_samples_per_second": 10.442,
      "eval_steps_per_second": 1.374,
      "step": 210
    },
    {
      "epoch": 2.485207100591716,
      "grad_norm": 0.7328985929489136,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 2.528,
      "step": 211
    },
    {
      "epoch": 2.497041420118343,
      "grad_norm": 0.8584762215614319,
      "learning_rate": 3.253968253968254e-05,
      "loss": 2.7131,
      "step": 212
    },
    {
      "epoch": 2.5088757396449703,
      "grad_norm": 0.7421399354934692,
      "learning_rate": 3.1746031746031745e-05,
      "loss": 2.4697,
      "step": 213
    },
    {
      "epoch": 2.5207100591715976,
      "grad_norm": 0.8784375786781311,
      "learning_rate": 3.095238095238095e-05,
      "loss": 1.8183,
      "step": 214
    },
    {
      "epoch": 2.532544378698225,
      "grad_norm": 1.0757843255996704,
      "learning_rate": 3.0158730158730158e-05,
      "loss": 2.1653,
      "step": 215
    },
    {
      "epoch": 2.544378698224852,
      "grad_norm": 0.8708527088165283,
      "learning_rate": 2.9365079365079366e-05,
      "loss": 2.5012,
      "step": 216
    },
    {
      "epoch": 2.556213017751479,
      "grad_norm": 0.6480072140693665,
      "learning_rate": 2.857142857142857e-05,
      "loss": 2.8807,
      "step": 217
    },
    {
      "epoch": 2.5680473372781067,
      "grad_norm": 0.8789936304092407,
      "learning_rate": 2.777777777777778e-05,
      "loss": 2.6198,
      "step": 218
    },
    {
      "epoch": 2.5798816568047336,
      "grad_norm": 0.7682965993881226,
      "learning_rate": 2.6984126984126984e-05,
      "loss": 2.1771,
      "step": 219
    },
    {
      "epoch": 2.591715976331361,
      "grad_norm": 1.088531255722046,
      "learning_rate": 2.6190476190476192e-05,
      "loss": 2.6341,
      "step": 220
    },
    {
      "epoch": 2.591715976331361,
      "eval_loss": 2.4971275329589844,
      "eval_runtime": 7.2766,
      "eval_samples_per_second": 10.444,
      "eval_steps_per_second": 1.374,
      "step": 220
    },
    {
      "epoch": 2.603550295857988,
      "grad_norm": 0.6217735409736633,
      "learning_rate": 2.5396825396825397e-05,
      "loss": 2.2446,
      "step": 221
    },
    {
      "epoch": 2.6153846153846154,
      "grad_norm": 0.8389264345169067,
      "learning_rate": 2.4603174603174602e-05,
      "loss": 2.5311,
      "step": 222
    },
    {
      "epoch": 2.6272189349112427,
      "grad_norm": 0.9366797208786011,
      "learning_rate": 2.380952380952381e-05,
      "loss": 2.2473,
      "step": 223
    },
    {
      "epoch": 2.63905325443787,
      "grad_norm": 0.677966296672821,
      "learning_rate": 2.3015873015873015e-05,
      "loss": 2.0716,
      "step": 224
    },
    {
      "epoch": 2.6508875739644973,
      "grad_norm": 0.9736616611480713,
      "learning_rate": 2.2222222222222223e-05,
      "loss": 2.4951,
      "step": 225
    },
    {
      "epoch": 2.662721893491124,
      "grad_norm": 0.8262175917625427,
      "learning_rate": 2.1428571428571428e-05,
      "loss": 2.5331,
      "step": 226
    },
    {
      "epoch": 2.6745562130177514,
      "grad_norm": 0.9369797110557556,
      "learning_rate": 2.0634920634920636e-05,
      "loss": 1.6102,
      "step": 227
    },
    {
      "epoch": 2.6863905325443787,
      "grad_norm": 0.8104965686798096,
      "learning_rate": 1.984126984126984e-05,
      "loss": 1.6723,
      "step": 228
    },
    {
      "epoch": 2.698224852071006,
      "grad_norm": 0.8768354058265686,
      "learning_rate": 1.9047619047619046e-05,
      "loss": 2.3603,
      "step": 229
    },
    {
      "epoch": 2.710059171597633,
      "grad_norm": 1.1445156335830688,
      "learning_rate": 1.8253968253968254e-05,
      "loss": 2.1814,
      "step": 230
    },
    {
      "epoch": 2.710059171597633,
      "eval_loss": 2.4966118335723877,
      "eval_runtime": 7.2736,
      "eval_samples_per_second": 10.449,
      "eval_steps_per_second": 1.375,
      "step": 230
    },
    {
      "epoch": 2.7218934911242605,
      "grad_norm": 0.7635293006896973,
      "learning_rate": 1.746031746031746e-05,
      "loss": 2.5304,
      "step": 231
    },
    {
      "epoch": 2.7337278106508878,
      "grad_norm": 0.9260876178741455,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 1.9338,
      "step": 232
    },
    {
      "epoch": 2.7455621301775146,
      "grad_norm": 1.3086227178573608,
      "learning_rate": 1.5873015873015872e-05,
      "loss": 2.3009,
      "step": 233
    },
    {
      "epoch": 2.757396449704142,
      "grad_norm": 0.7225397229194641,
      "learning_rate": 1.5079365079365079e-05,
      "loss": 2.1065,
      "step": 234
    },
    {
      "epoch": 2.769230769230769,
      "grad_norm": 0.8113594055175781,
      "learning_rate": 1.4285714285714285e-05,
      "loss": 2.6895,
      "step": 235
    },
    {
      "epoch": 2.7810650887573964,
      "grad_norm": 0.920311689376831,
      "learning_rate": 1.3492063492063492e-05,
      "loss": 2.6238,
      "step": 236
    },
    {
      "epoch": 2.7928994082840237,
      "grad_norm": 0.9094980359077454,
      "learning_rate": 1.2698412698412699e-05,
      "loss": 2.6228,
      "step": 237
    },
    {
      "epoch": 2.804733727810651,
      "grad_norm": 0.6774507164955139,
      "learning_rate": 1.1904761904761905e-05,
      "loss": 2.6344,
      "step": 238
    },
    {
      "epoch": 2.8165680473372783,
      "grad_norm": 0.8075801134109497,
      "learning_rate": 1.1111111111111112e-05,
      "loss": 2.4911,
      "step": 239
    },
    {
      "epoch": 2.828402366863905,
      "grad_norm": 0.8455482721328735,
      "learning_rate": 1.0317460317460318e-05,
      "loss": 1.9529,
      "step": 240
    },
    {
      "epoch": 2.828402366863905,
      "eval_loss": 2.494183301925659,
      "eval_runtime": 7.2687,
      "eval_samples_per_second": 10.456,
      "eval_steps_per_second": 1.376,
      "step": 240
    },
    {
      "epoch": 2.8402366863905324,
      "grad_norm": 0.9865834712982178,
      "learning_rate": 9.523809523809523e-06,
      "loss": 2.0726,
      "step": 241
    },
    {
      "epoch": 2.8520710059171597,
      "grad_norm": 0.9246604442596436,
      "learning_rate": 8.73015873015873e-06,
      "loss": 2.5707,
      "step": 242
    },
    {
      "epoch": 2.863905325443787,
      "grad_norm": 0.7531466484069824,
      "learning_rate": 7.936507936507936e-06,
      "loss": 2.3139,
      "step": 243
    },
    {
      "epoch": 2.8757396449704142,
      "grad_norm": 0.7080157399177551,
      "learning_rate": 7.142857142857143e-06,
      "loss": 2.8019,
      "step": 244
    },
    {
      "epoch": 2.8875739644970415,
      "grad_norm": 0.7196693420410156,
      "learning_rate": 6.349206349206349e-06,
      "loss": 2.776,
      "step": 245
    },
    {
      "epoch": 2.899408284023669,
      "grad_norm": 0.7244651913642883,
      "learning_rate": 5.555555555555556e-06,
      "loss": 1.9192,
      "step": 246
    },
    {
      "epoch": 2.9112426035502956,
      "grad_norm": 0.9621744155883789,
      "learning_rate": 4.7619047619047615e-06,
      "loss": 2.105,
      "step": 247
    },
    {
      "epoch": 2.9230769230769234,
      "grad_norm": 0.9932108521461487,
      "learning_rate": 3.968253968253968e-06,
      "loss": 2.7432,
      "step": 248
    },
    {
      "epoch": 2.93491124260355,
      "grad_norm": 0.7157137393951416,
      "learning_rate": 3.1746031746031746e-06,
      "loss": 2.932,
      "step": 249
    },
    {
      "epoch": 2.9467455621301775,
      "grad_norm": 1.1892366409301758,
      "learning_rate": 2.3809523809523808e-06,
      "loss": 2.2105,
      "step": 250
    },
    {
      "epoch": 2.9467455621301775,
      "eval_loss": 2.492879629135132,
      "eval_runtime": 7.282,
      "eval_samples_per_second": 10.437,
      "eval_steps_per_second": 1.373,
      "step": 250
    },
    {
      "epoch": 2.9585798816568047,
      "grad_norm": 1.0534014701843262,
      "learning_rate": 1.5873015873015873e-06,
      "loss": 1.9375,
      "step": 251
    },
    {
      "epoch": 2.970414201183432,
      "grad_norm": 0.7287748456001282,
      "learning_rate": 7.936507936507937e-07,
      "loss": 2.5395,
      "step": 252
    }
  ],
  "logging_steps": 1,
  "max_steps": 252,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.0496752478273536e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
