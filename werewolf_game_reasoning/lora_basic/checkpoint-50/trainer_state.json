{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.591715976331361,
  "eval_steps": 10,
  "global_step": 50,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011834319526627219,
      "grad_norm": 0.2852616310119629,
      "learning_rate": 0.0002,
      "loss": 3.6535,
      "step": 1
    },
    {
      "epoch": 0.023668639053254437,
      "grad_norm": 0.42725804448127747,
      "learning_rate": 0.00019920634920634922,
      "loss": 3.2292,
      "step": 2
    },
    {
      "epoch": 0.03550295857988166,
      "grad_norm": 0.2975868582725525,
      "learning_rate": 0.00019841269841269844,
      "loss": 2.3642,
      "step": 3
    },
    {
      "epoch": 0.047337278106508875,
      "grad_norm": 0.5254213213920593,
      "learning_rate": 0.00019761904761904763,
      "loss": 3.533,
      "step": 4
    },
    {
      "epoch": 0.05917159763313609,
      "grad_norm": 0.7198086977005005,
      "learning_rate": 0.00019682539682539682,
      "loss": 3.4469,
      "step": 5
    },
    {
      "epoch": 0.07100591715976332,
      "grad_norm": 0.835084080696106,
      "learning_rate": 0.00019603174603174603,
      "loss": 2.6131,
      "step": 6
    },
    {
      "epoch": 0.08284023668639054,
      "grad_norm": 0.5850217938423157,
      "learning_rate": 0.00019523809523809525,
      "loss": 2.39,
      "step": 7
    },
    {
      "epoch": 0.09467455621301775,
      "grad_norm": 2.8779730796813965,
      "learning_rate": 0.00019444444444444446,
      "loss": 2.8081,
      "step": 8
    },
    {
      "epoch": 0.10650887573964497,
      "grad_norm": 3.7347939014434814,
      "learning_rate": 0.00019365079365079365,
      "loss": 2.8685,
      "step": 9
    },
    {
      "epoch": 0.11834319526627218,
      "grad_norm": 1.1432902812957764,
      "learning_rate": 0.00019285714285714286,
      "loss": 2.9831,
      "step": 10
    },
    {
      "epoch": 0.11834319526627218,
      "eval_loss": 3.0265727043151855,
      "eval_runtime": 7.2621,
      "eval_samples_per_second": 10.465,
      "eval_steps_per_second": 1.377,
      "step": 10
    },
    {
      "epoch": 0.1301775147928994,
      "grad_norm": 2.6644093990325928,
      "learning_rate": 0.00019206349206349208,
      "loss": 2.7168,
      "step": 11
    },
    {
      "epoch": 0.14201183431952663,
      "grad_norm": 0.39588865637779236,
      "learning_rate": 0.0001912698412698413,
      "loss": 3.4442,
      "step": 12
    },
    {
      "epoch": 0.15384615384615385,
      "grad_norm": 0.76161128282547,
      "learning_rate": 0.00019047619047619048,
      "loss": 2.7836,
      "step": 13
    },
    {
      "epoch": 0.16568047337278108,
      "grad_norm": 0.403511106967926,
      "learning_rate": 0.0001896825396825397,
      "loss": 2.6901,
      "step": 14
    },
    {
      "epoch": 0.17751479289940827,
      "grad_norm": 0.3340049982070923,
      "learning_rate": 0.00018888888888888888,
      "loss": 2.9176,
      "step": 15
    },
    {
      "epoch": 0.1893491124260355,
      "grad_norm": 0.44705730676651,
      "learning_rate": 0.0001880952380952381,
      "loss": 3.1157,
      "step": 16
    },
    {
      "epoch": 0.20118343195266272,
      "grad_norm": 0.62772536277771,
      "learning_rate": 0.00018730158730158731,
      "loss": 2.7558,
      "step": 17
    },
    {
      "epoch": 0.21301775147928995,
      "grad_norm": 0.5882687568664551,
      "learning_rate": 0.00018650793650793653,
      "loss": 2.7065,
      "step": 18
    },
    {
      "epoch": 0.22485207100591717,
      "grad_norm": 0.4743443429470062,
      "learning_rate": 0.00018571428571428572,
      "loss": 3.3719,
      "step": 19
    },
    {
      "epoch": 0.23668639053254437,
      "grad_norm": 0.5696156620979309,
      "learning_rate": 0.00018492063492063493,
      "loss": 2.9977,
      "step": 20
    },
    {
      "epoch": 0.23668639053254437,
      "eval_loss": 2.8663079738616943,
      "eval_runtime": 7.2564,
      "eval_samples_per_second": 10.474,
      "eval_steps_per_second": 1.378,
      "step": 20
    },
    {
      "epoch": 0.2485207100591716,
      "grad_norm": 0.5697664022445679,
      "learning_rate": 0.00018412698412698412,
      "loss": 1.9846,
      "step": 21
    },
    {
      "epoch": 0.2603550295857988,
      "grad_norm": 0.4957573711872101,
      "learning_rate": 0.00018333333333333334,
      "loss": 3.1558,
      "step": 22
    },
    {
      "epoch": 0.27218934911242604,
      "grad_norm": 0.4362879693508148,
      "learning_rate": 0.00018253968253968255,
      "loss": 3.301,
      "step": 23
    },
    {
      "epoch": 0.28402366863905326,
      "grad_norm": 0.5254936814308167,
      "learning_rate": 0.00018174603174603177,
      "loss": 3.0331,
      "step": 24
    },
    {
      "epoch": 0.2958579881656805,
      "grad_norm": 0.47438421845436096,
      "learning_rate": 0.00018095238095238095,
      "loss": 3.3227,
      "step": 25
    },
    {
      "epoch": 0.3076923076923077,
      "grad_norm": 0.5094731450080872,
      "learning_rate": 0.00018015873015873017,
      "loss": 3.8949,
      "step": 26
    },
    {
      "epoch": 0.31952662721893493,
      "grad_norm": 0.5917863249778748,
      "learning_rate": 0.00017936507936507938,
      "loss": 3.0268,
      "step": 27
    },
    {
      "epoch": 0.33136094674556216,
      "grad_norm": 0.3595137894153595,
      "learning_rate": 0.0001785714285714286,
      "loss": 2.9957,
      "step": 28
    },
    {
      "epoch": 0.3431952662721893,
      "grad_norm": 0.47600701451301575,
      "learning_rate": 0.00017777777777777779,
      "loss": 2.1916,
      "step": 29
    },
    {
      "epoch": 0.35502958579881655,
      "grad_norm": 0.5427821278572083,
      "learning_rate": 0.00017698412698412697,
      "loss": 2.9272,
      "step": 30
    },
    {
      "epoch": 0.35502958579881655,
      "eval_loss": 2.788158416748047,
      "eval_runtime": 7.2699,
      "eval_samples_per_second": 10.454,
      "eval_steps_per_second": 1.376,
      "step": 30
    },
    {
      "epoch": 0.3668639053254438,
      "grad_norm": 0.47064968943595886,
      "learning_rate": 0.0001761904761904762,
      "loss": 2.9858,
      "step": 31
    },
    {
      "epoch": 0.378698224852071,
      "grad_norm": 0.4756056070327759,
      "learning_rate": 0.0001753968253968254,
      "loss": 2.3199,
      "step": 32
    },
    {
      "epoch": 0.3905325443786982,
      "grad_norm": 0.45889586210250854,
      "learning_rate": 0.00017460317460317462,
      "loss": 2.7038,
      "step": 33
    },
    {
      "epoch": 0.40236686390532544,
      "grad_norm": 0.45923224091529846,
      "learning_rate": 0.00017380952380952383,
      "loss": 3.4152,
      "step": 34
    },
    {
      "epoch": 0.41420118343195267,
      "grad_norm": 0.4572738707065582,
      "learning_rate": 0.00017301587301587302,
      "loss": 3.1502,
      "step": 35
    },
    {
      "epoch": 0.4260355029585799,
      "grad_norm": 0.6110097765922546,
      "learning_rate": 0.00017222222222222224,
      "loss": 2.9745,
      "step": 36
    },
    {
      "epoch": 0.4378698224852071,
      "grad_norm": 0.4958982467651367,
      "learning_rate": 0.00017142857142857143,
      "loss": 2.1988,
      "step": 37
    },
    {
      "epoch": 0.44970414201183434,
      "grad_norm": 0.5015813112258911,
      "learning_rate": 0.00017063492063492064,
      "loss": 2.6207,
      "step": 38
    },
    {
      "epoch": 0.46153846153846156,
      "grad_norm": 0.5053653120994568,
      "learning_rate": 0.00016984126984126986,
      "loss": 2.9909,
      "step": 39
    },
    {
      "epoch": 0.47337278106508873,
      "grad_norm": 0.6383805871009827,
      "learning_rate": 0.00016904761904761904,
      "loss": 2.4307,
      "step": 40
    },
    {
      "epoch": 0.47337278106508873,
      "eval_loss": 2.732571601867676,
      "eval_runtime": 7.2707,
      "eval_samples_per_second": 10.453,
      "eval_steps_per_second": 1.375,
      "step": 40
    },
    {
      "epoch": 0.48520710059171596,
      "grad_norm": 0.6155767440795898,
      "learning_rate": 0.00016825396825396826,
      "loss": 2.7887,
      "step": 41
    },
    {
      "epoch": 0.4970414201183432,
      "grad_norm": 0.5471430420875549,
      "learning_rate": 0.00016746031746031747,
      "loss": 2.5071,
      "step": 42
    },
    {
      "epoch": 0.5088757396449705,
      "grad_norm": 0.5839921236038208,
      "learning_rate": 0.0001666666666666667,
      "loss": 2.3487,
      "step": 43
    },
    {
      "epoch": 0.5207100591715976,
      "grad_norm": 0.8534253835678101,
      "learning_rate": 0.0001658730158730159,
      "loss": 2.3831,
      "step": 44
    },
    {
      "epoch": 0.5325443786982249,
      "grad_norm": 0.4808950424194336,
      "learning_rate": 0.0001650793650793651,
      "loss": 2.7563,
      "step": 45
    },
    {
      "epoch": 0.5443786982248521,
      "grad_norm": 0.5995768904685974,
      "learning_rate": 0.00016428571428571428,
      "loss": 2.9696,
      "step": 46
    },
    {
      "epoch": 0.5562130177514792,
      "grad_norm": 0.45817336440086365,
      "learning_rate": 0.0001634920634920635,
      "loss": 2.9663,
      "step": 47
    },
    {
      "epoch": 0.5680473372781065,
      "grad_norm": 0.479961097240448,
      "learning_rate": 0.0001626984126984127,
      "loss": 2.8644,
      "step": 48
    },
    {
      "epoch": 0.5798816568047337,
      "grad_norm": 0.695735514163971,
      "learning_rate": 0.00016190476190476192,
      "loss": 2.6259,
      "step": 49
    },
    {
      "epoch": 0.591715976331361,
      "grad_norm": 0.5882052183151245,
      "learning_rate": 0.0001611111111111111,
      "loss": 2.5268,
      "step": 50
    },
    {
      "epoch": 0.591715976331361,
      "eval_loss": 2.6890671253204346,
      "eval_runtime": 7.2755,
      "eval_samples_per_second": 10.446,
      "eval_steps_per_second": 1.374,
      "step": 50
    }
  ],
  "logging_steps": 1,
  "max_steps": 252,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 50,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 6075050294476800.0,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
