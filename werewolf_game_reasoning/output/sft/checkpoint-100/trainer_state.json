{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.07326007326007326,
  "eval_steps": 10,
  "global_step": 100,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.0049987789987789985,
      "loss": 2.5911,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.004997557997557998,
      "loss": 2.4668,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.004996336996336996,
      "loss": 2.4872,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.004995115995115995,
      "loss": 2.5384,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.004993894993894994,
      "loss": 2.5063,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.004992673992673993,
      "loss": 2.4611,
      "step": 6
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004991452991452991,
      "loss": 2.4305,
      "step": 7
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.0049902319902319905,
      "loss": 2.4995,
      "step": 8
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004989010989010989,
      "loss": 2.3913,
      "step": 9
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004987789987789988,
      "loss": 2.4884,
      "step": 10
    },
    {
      "epoch": 0.01,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.7955,
      "eval_samples_per_second": 3.726,
      "eval_steps_per_second": 3.726,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.0049865689865689865,
      "loss": 2.6271,
      "step": 11
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004985347985347986,
      "loss": 2.5483,
      "step": 12
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004984126984126984,
      "loss": 2.5565,
      "step": 13
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004982905982905983,
      "loss": 2.473,
      "step": 14
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004981684981684982,
      "loss": 2.5906,
      "step": 15
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004980463980463981,
      "loss": 2.5474,
      "step": 16
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004979242979242979,
      "loss": 2.4457,
      "step": 17
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.0049780219780219785,
      "loss": 2.5576,
      "step": 18
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004976800976800977,
      "loss": 2.5655,
      "step": 19
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004975579975579976,
      "loss": 2.698,
      "step": 20
    },
    {
      "epoch": 0.01,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.7374,
      "eval_samples_per_second": 3.727,
      "eval_steps_per_second": 3.727,
      "step": 20
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.0049743589743589745,
      "loss": 2.5504,
      "step": 21
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004973137973137974,
      "loss": 2.6277,
      "step": 22
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004971916971916972,
      "loss": 2.6505,
      "step": 23
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004970695970695971,
      "loss": 2.6862,
      "step": 24
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.00496947496947497,
      "loss": 2.5353,
      "step": 25
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004968253968253968,
      "loss": 2.5363,
      "step": 26
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004967032967032967,
      "loss": 2.672,
      "step": 27
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004965811965811966,
      "loss": 2.5006,
      "step": 28
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004964590964590965,
      "loss": 2.5884,
      "step": 29
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004963369963369963,
      "loss": 2.6575,
      "step": 30
    },
    {
      "epoch": 0.02,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.7839,
      "eval_samples_per_second": 3.726,
      "eval_steps_per_second": 3.726,
      "step": 30
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.0049621489621489625,
      "loss": 2.6099,
      "step": 31
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004960927960927961,
      "loss": 2.6541,
      "step": 32
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.00495970695970696,
      "loss": 2.499,
      "step": 33
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.0049584859584859585,
      "loss": 2.5472,
      "step": 34
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004957264957264958,
      "loss": 2.61,
      "step": 35
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004956043956043956,
      "loss": 2.4383,
      "step": 36
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004954822954822955,
      "loss": 2.5583,
      "step": 37
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004953601953601954,
      "loss": 2.6219,
      "step": 38
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004952380952380953,
      "loss": 2.6433,
      "step": 39
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004951159951159951,
      "loss": 2.6367,
      "step": 40
    },
    {
      "epoch": 0.03,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.4765,
      "eval_samples_per_second": 3.73,
      "eval_steps_per_second": 3.73,
      "step": 40
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.0049499389499389505,
      "loss": 2.5938,
      "step": 41
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004948717948717949,
      "loss": 2.644,
      "step": 42
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004947496947496948,
      "loss": 2.5983,
      "step": 43
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.0049462759462759465,
      "loss": 2.6006,
      "step": 44
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004945054945054946,
      "loss": 2.596,
      "step": 45
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004943833943833944,
      "loss": 2.5553,
      "step": 46
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004942612942612943,
      "loss": 2.3928,
      "step": 47
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004941391941391942,
      "loss": 2.4708,
      "step": 48
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004940170940170941,
      "loss": 2.6212,
      "step": 49
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004938949938949939,
      "loss": 2.4701,
      "step": 50
    },
    {
      "epoch": 0.04,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.3668,
      "eval_samples_per_second": 3.731,
      "eval_steps_per_second": 3.731,
      "step": 50
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004937728937728938,
      "loss": 2.7378,
      "step": 51
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004936507936507937,
      "loss": 2.6151,
      "step": 52
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004935286935286935,
      "loss": 2.571,
      "step": 53
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.0049340659340659345,
      "loss": 2.4821,
      "step": 54
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004932844932844933,
      "loss": 2.509,
      "step": 55
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004931623931623932,
      "loss": 2.5849,
      "step": 56
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.0049304029304029304,
      "loss": 2.5245,
      "step": 57
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.00492918192918193,
      "loss": 2.5877,
      "step": 58
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004927960927960928,
      "loss": 2.6986,
      "step": 59
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004926739926739927,
      "loss": 2.4848,
      "step": 60
    },
    {
      "epoch": 0.04,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.6634,
      "eval_samples_per_second": 3.728,
      "eval_steps_per_second": 3.728,
      "step": 60
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004925518925518926,
      "loss": 2.4487,
      "step": 61
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004924297924297925,
      "loss": 2.446,
      "step": 62
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004923076923076923,
      "loss": 2.4475,
      "step": 63
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004921855921855922,
      "loss": 2.5969,
      "step": 64
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004920634920634921,
      "loss": 2.6274,
      "step": 65
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004919413919413919,
      "loss": 2.5988,
      "step": 66
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.0049181929181929184,
      "loss": 2.4752,
      "step": 67
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004916971916971917,
      "loss": 2.618,
      "step": 68
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004915750915750915,
      "loss": 2.6039,
      "step": 69
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004914529914529914,
      "loss": 2.6684,
      "step": 70
    },
    {
      "epoch": 0.05,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.6453,
      "eval_samples_per_second": 3.728,
      "eval_steps_per_second": 3.728,
      "step": 70
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004913308913308913,
      "loss": 2.5723,
      "step": 71
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004912087912087912,
      "loss": 2.5871,
      "step": 72
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.00491086691086691,
      "loss": 2.5086,
      "step": 73
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.00490964590964591,
      "loss": 2.6496,
      "step": 74
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004908424908424908,
      "loss": 2.5063,
      "step": 75
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004907203907203907,
      "loss": 2.4855,
      "step": 76
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004905982905982906,
      "loss": 2.5014,
      "step": 77
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004904761904761905,
      "loss": 2.6767,
      "step": 78
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004903540903540903,
      "loss": 2.659,
      "step": 79
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004902319902319902,
      "loss": 2.5806,
      "step": 80
    },
    {
      "epoch": 0.06,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.6095,
      "eval_samples_per_second": 3.728,
      "eval_steps_per_second": 3.728,
      "step": 80
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004901098901098901,
      "loss": 2.6116,
      "step": 81
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.0048998778998779,
      "loss": 2.5177,
      "step": 82
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004898656898656898,
      "loss": 2.5992,
      "step": 83
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004897435897435898,
      "loss": 2.5509,
      "step": 84
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004896214896214896,
      "loss": 2.5653,
      "step": 85
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004894993894993895,
      "loss": 2.5848,
      "step": 86
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004893772893772894,
      "loss": 2.5898,
      "step": 87
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004892551892551893,
      "loss": 2.4803,
      "step": 88
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004891330891330891,
      "loss": 2.6225,
      "step": 89
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.00489010989010989,
      "loss": 2.4838,
      "step": 90
    },
    {
      "epoch": 0.07,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.5371,
      "eval_samples_per_second": 3.729,
      "eval_steps_per_second": 3.729,
      "step": 90
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004888888888888889,
      "loss": 2.6455,
      "step": 91
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004887667887667888,
      "loss": 2.4986,
      "step": 92
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004886446886446886,
      "loss": 2.6513,
      "step": 93
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004885225885225885,
      "loss": 2.5914,
      "step": 94
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004884004884004884,
      "loss": 2.4755,
      "step": 95
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004882783882783882,
      "loss": 2.6611,
      "step": 96
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004881562881562882,
      "loss": 2.3841,
      "step": 97
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.00488034188034188,
      "loss": 2.6,
      "step": 98
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004879120879120879,
      "loss": 2.419,
      "step": 99
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004877899877899878,
      "loss": 2.503,
      "step": 100
    },
    {
      "epoch": 0.07,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.5122,
      "eval_samples_per_second": 3.73,
      "eval_steps_per_second": 3.73,
      "step": 100
    }
  ],
  "logging_steps": 1,
  "max_steps": 4095,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 5.17095875936256e+16,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
