{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.18315018315018314,
  "eval_steps": 10,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.1807260513305664,
      "learning_rate": 4.0650406504065046e-07,
      "loss": 2.4354,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.408429503440857,
      "learning_rate": 8.130081300813009e-07,
      "loss": 2.5737,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3173985481262207,
      "learning_rate": 1.2195121951219514e-06,
      "loss": 2.3571,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1332097053527832,
      "learning_rate": 1.6260162601626018e-06,
      "loss": 2.4204,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.208814263343811,
      "learning_rate": 2.0325203252032523e-06,
      "loss": 2.4305,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.194399118423462,
      "learning_rate": 2.4390243902439027e-06,
      "loss": 2.3606,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3456549644470215,
      "learning_rate": 2.8455284552845528e-06,
      "loss": 2.4122,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2045505046844482,
      "learning_rate": 3.2520325203252037e-06,
      "loss": 2.4875,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.993188738822937,
      "learning_rate": 3.6585365853658537e-06,
      "loss": 2.5446,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0967234373092651,
      "learning_rate": 4.0650406504065046e-06,
      "loss": 2.2822,
      "step": 10
    },
    {
      "epoch": 0.0,
      "eval_loss": 2.4522597789764404,
      "eval_runtime": 326.7826,
      "eval_samples_per_second": 3.715,
      "eval_steps_per_second": 3.715,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1855803728103638,
      "learning_rate": 4.471544715447155e-06,
      "loss": 2.3175,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1233888864517212,
      "learning_rate": 4.8780487804878055e-06,
      "loss": 2.3798,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2168267965316772,
      "learning_rate": 5.2845528455284555e-06,
      "loss": 2.3091,
      "step": 13
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.104172945022583,
      "learning_rate": 5.6910569105691056e-06,
      "loss": 2.3482,
      "step": 14
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4444849491119385,
      "learning_rate": 6.0975609756097564e-06,
      "loss": 2.3381,
      "step": 15
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2118523120880127,
      "learning_rate": 6.504065040650407e-06,
      "loss": 2.4472,
      "step": 16
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2675775289535522,
      "learning_rate": 6.910569105691057e-06,
      "loss": 2.3639,
      "step": 17
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2124836444854736,
      "learning_rate": 7.317073170731707e-06,
      "loss": 2.1979,
      "step": 18
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1547139883041382,
      "learning_rate": 7.723577235772358e-06,
      "loss": 2.3736,
      "step": 19
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1410959959030151,
      "learning_rate": 8.130081300813009e-06,
      "loss": 2.3241,
      "step": 20
    },
    {
      "epoch": 0.01,
      "eval_loss": 2.412365674972534,
      "eval_runtime": 326.8684,
      "eval_samples_per_second": 3.714,
      "eval_steps_per_second": 3.714,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2570022344589233,
      "learning_rate": 8.53658536585366e-06,
      "loss": 2.4366,
      "step": 21
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9350789189338684,
      "learning_rate": 8.94308943089431e-06,
      "loss": 2.5075,
      "step": 22
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.996505081653595,
      "learning_rate": 9.34959349593496e-06,
      "loss": 2.3451,
      "step": 23
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.051774024963379,
      "learning_rate": 9.756097560975611e-06,
      "loss": 2.4491,
      "step": 24
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9073569178581238,
      "learning_rate": 1.016260162601626e-05,
      "loss": 2.3839,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5927023887634277,
      "learning_rate": 1.0569105691056911e-05,
      "loss": 2.3958,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0582877397537231,
      "learning_rate": 1.0975609756097562e-05,
      "loss": 2.3234,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1481232643127441,
      "learning_rate": 1.1382113821138211e-05,
      "loss": 2.3005,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9161113500595093,
      "learning_rate": 1.1788617886178862e-05,
      "loss": 2.3921,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3125858306884766,
      "learning_rate": 1.2195121951219513e-05,
      "loss": 2.3973,
      "step": 30
    },
    {
      "epoch": 0.01,
      "eval_loss": 2.3516244888305664,
      "eval_runtime": 326.8496,
      "eval_samples_per_second": 3.714,
      "eval_steps_per_second": 3.714,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9008913040161133,
      "learning_rate": 1.2601626016260162e-05,
      "loss": 2.4244,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0559351444244385,
      "learning_rate": 1.3008130081300815e-05,
      "loss": 2.2565,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9710964560508728,
      "learning_rate": 1.3414634146341466e-05,
      "loss": 2.3623,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9186581969261169,
      "learning_rate": 1.3821138211382115e-05,
      "loss": 2.1046,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1416815519332886,
      "learning_rate": 1.4227642276422764e-05,
      "loss": 2.2958,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9226109981536865,
      "learning_rate": 1.4634146341463415e-05,
      "loss": 2.353,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8293136954307556,
      "learning_rate": 1.5040650406504067e-05,
      "loss": 2.2396,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9112761616706848,
      "learning_rate": 1.5447154471544717e-05,
      "loss": 2.4254,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9158889055252075,
      "learning_rate": 1.5853658536585366e-05,
      "loss": 2.3863,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8299440741539001,
      "learning_rate": 1.6260162601626018e-05,
      "loss": 2.4708,
      "step": 40
    },
    {
      "epoch": 0.01,
      "eval_loss": 2.2731287479400635,
      "eval_runtime": 326.6766,
      "eval_samples_per_second": 3.716,
      "eval_steps_per_second": 3.716,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7720086574554443,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 2.3508,
      "step": 41
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8971328139305115,
      "learning_rate": 1.707317073170732e-05,
      "loss": 2.1803,
      "step": 42
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9551953673362732,
      "learning_rate": 1.747967479674797e-05,
      "loss": 2.3714,
      "step": 43
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8126462697982788,
      "learning_rate": 1.788617886178862e-05,
      "loss": 2.3284,
      "step": 44
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8575080633163452,
      "learning_rate": 1.8292682926829268e-05,
      "loss": 2.3389,
      "step": 45
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7832810282707214,
      "learning_rate": 1.869918699186992e-05,
      "loss": 2.3447,
      "step": 46
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8090999126434326,
      "learning_rate": 1.9105691056910573e-05,
      "loss": 2.4705,
      "step": 47
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9688745737075806,
      "learning_rate": 1.9512195121951222e-05,
      "loss": 2.211,
      "step": 48
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9135887026786804,
      "learning_rate": 1.991869918699187e-05,
      "loss": 2.1467,
      "step": 49
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7019591331481934,
      "learning_rate": 2.032520325203252e-05,
      "loss": 2.2606,
      "step": 50
    },
    {
      "epoch": 0.02,
      "eval_loss": 2.1757566928863525,
      "eval_runtime": 326.4387,
      "eval_samples_per_second": 3.719,
      "eval_steps_per_second": 3.719,
      "step": 50
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0046828985214233,
      "learning_rate": 2.073170731707317e-05,
      "loss": 2.1634,
      "step": 51
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7694976925849915,
      "learning_rate": 2.1138211382113822e-05,
      "loss": 2.1424,
      "step": 52
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.865962028503418,
      "learning_rate": 2.1544715447154475e-05,
      "loss": 2.2878,
      "step": 53
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.90448397397995,
      "learning_rate": 2.1951219512195124e-05,
      "loss": 2.2397,
      "step": 54
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0173530578613281,
      "learning_rate": 2.2357723577235773e-05,
      "loss": 2.0216,
      "step": 55
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7731962203979492,
      "learning_rate": 2.2764227642276422e-05,
      "loss": 2.1647,
      "step": 56
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7913800477981567,
      "learning_rate": 2.3170731707317075e-05,
      "loss": 2.068,
      "step": 57
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8766810894012451,
      "learning_rate": 2.3577235772357724e-05,
      "loss": 2.2275,
      "step": 58
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0228992700576782,
      "learning_rate": 2.3983739837398377e-05,
      "loss": 2.2035,
      "step": 59
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9332002997398376,
      "learning_rate": 2.4390243902439026e-05,
      "loss": 2.1041,
      "step": 60
    },
    {
      "epoch": 0.02,
      "eval_loss": 2.040968179702759,
      "eval_runtime": 326.2162,
      "eval_samples_per_second": 3.721,
      "eval_steps_per_second": 3.721,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0200774669647217,
      "learning_rate": 2.4796747967479675e-05,
      "loss": 1.9946,
      "step": 61
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9349056482315063,
      "learning_rate": 2.5203252032520324e-05,
      "loss": 2.1248,
      "step": 62
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7300223708152771,
      "learning_rate": 2.5609756097560977e-05,
      "loss": 2.299,
      "step": 63
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9820848703384399,
      "learning_rate": 2.601626016260163e-05,
      "loss": 2.0009,
      "step": 64
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0291283130645752,
      "learning_rate": 2.642276422764228e-05,
      "loss": 1.991,
      "step": 65
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9412071108818054,
      "learning_rate": 2.682926829268293e-05,
      "loss": 1.8844,
      "step": 66
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9445374608039856,
      "learning_rate": 2.7235772357723577e-05,
      "loss": 1.8764,
      "step": 67
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.993418276309967,
      "learning_rate": 2.764227642276423e-05,
      "loss": 2.0493,
      "step": 68
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9592738151550293,
      "learning_rate": 2.8048780487804882e-05,
      "loss": 1.9275,
      "step": 69
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.841105043888092,
      "learning_rate": 2.8455284552845528e-05,
      "loss": 2.0795,
      "step": 70
    },
    {
      "epoch": 0.03,
      "eval_loss": 1.8460652828216553,
      "eval_runtime": 326.2213,
      "eval_samples_per_second": 3.721,
      "eval_steps_per_second": 3.721,
      "step": 70
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7738112211227417,
      "learning_rate": 2.886178861788618e-05,
      "loss": 1.9344,
      "step": 71
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4108299016952515,
      "learning_rate": 2.926829268292683e-05,
      "loss": 1.5763,
      "step": 72
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.230282187461853,
      "learning_rate": 2.9674796747967482e-05,
      "loss": 1.653,
      "step": 73
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1350009441375732,
      "learning_rate": 3.0081300813008135e-05,
      "loss": 1.7795,
      "step": 74
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8457537889480591,
      "learning_rate": 3.048780487804878e-05,
      "loss": 1.9683,
      "step": 75
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1538017988204956,
      "learning_rate": 3.089430894308943e-05,
      "loss": 1.7007,
      "step": 76
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0437917709350586,
      "learning_rate": 3.130081300813008e-05,
      "loss": 1.7716,
      "step": 77
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.09328031539917,
      "learning_rate": 3.170731707317073e-05,
      "loss": 1.687,
      "step": 78
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9789184927940369,
      "learning_rate": 3.2113821138211384e-05,
      "loss": 1.7055,
      "step": 79
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9023700952529907,
      "learning_rate": 3.2520325203252037e-05,
      "loss": 1.8462,
      "step": 80
    },
    {
      "epoch": 0.03,
      "eval_loss": 1.637189269065857,
      "eval_runtime": 326.1738,
      "eval_samples_per_second": 3.722,
      "eval_steps_per_second": 3.722,
      "step": 80
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.833107054233551,
      "learning_rate": 3.292682926829269e-05,
      "loss": 1.8689,
      "step": 81
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.19161057472229,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.2809,
      "step": 82
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.124289631843567,
      "learning_rate": 3.373983739837399e-05,
      "loss": 1.4932,
      "step": 83
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.09165620803833,
      "learning_rate": 3.414634146341464e-05,
      "loss": 1.4891,
      "step": 84
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0194751024246216,
      "learning_rate": 3.4552845528455286e-05,
      "loss": 1.3986,
      "step": 85
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1413490772247314,
      "learning_rate": 3.495934959349594e-05,
      "loss": 1.6055,
      "step": 86
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8215764760971069,
      "learning_rate": 3.5365853658536584e-05,
      "loss": 1.7743,
      "step": 87
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9572280645370483,
      "learning_rate": 3.577235772357724e-05,
      "loss": 1.403,
      "step": 88
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8137934803962708,
      "learning_rate": 3.617886178861789e-05,
      "loss": 1.5911,
      "step": 89
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9657096862792969,
      "learning_rate": 3.6585365853658535e-05,
      "loss": 1.5199,
      "step": 90
    },
    {
      "epoch": 0.03,
      "eval_loss": 1.4930168390274048,
      "eval_runtime": 326.0041,
      "eval_samples_per_second": 3.724,
      "eval_steps_per_second": 3.724,
      "step": 90
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.774365246295929,
      "learning_rate": 3.699186991869919e-05,
      "loss": 1.7257,
      "step": 91
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9638116955757141,
      "learning_rate": 3.739837398373984e-05,
      "loss": 1.2441,
      "step": 92
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9455052614212036,
      "learning_rate": 3.780487804878049e-05,
      "loss": 1.0293,
      "step": 93
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8377805948257446,
      "learning_rate": 3.8211382113821145e-05,
      "loss": 1.0716,
      "step": 94
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3332194089889526,
      "learning_rate": 3.861788617886179e-05,
      "loss": 1.3948,
      "step": 95
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9706263542175293,
      "learning_rate": 3.9024390243902444e-05,
      "loss": 1.2058,
      "step": 96
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6947608590126038,
      "learning_rate": 3.943089430894309e-05,
      "loss": 1.6998,
      "step": 97
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.067426085472107,
      "learning_rate": 3.983739837398374e-05,
      "loss": 1.1725,
      "step": 98
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7970749735832214,
      "learning_rate": 4.0243902439024395e-05,
      "loss": 1.2434,
      "step": 99
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8729394674301147,
      "learning_rate": 4.065040650406504e-05,
      "loss": 1.5179,
      "step": 100
    },
    {
      "epoch": 0.04,
      "eval_loss": 1.3956992626190186,
      "eval_runtime": 325.7534,
      "eval_samples_per_second": 3.727,
      "eval_steps_per_second": 3.727,
      "step": 100
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7873782515525818,
      "learning_rate": 4.105691056910569e-05,
      "loss": 1.785,
      "step": 101
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7723170518875122,
      "learning_rate": 4.146341463414634e-05,
      "loss": 1.8136,
      "step": 102
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8328036665916443,
      "learning_rate": 4.186991869918699e-05,
      "loss": 1.4924,
      "step": 103
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7091415524482727,
      "learning_rate": 4.2276422764227644e-05,
      "loss": 1.4669,
      "step": 104
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6786538362503052,
      "learning_rate": 4.26829268292683e-05,
      "loss": 1.5315,
      "step": 105
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1244758367538452,
      "learning_rate": 4.308943089430895e-05,
      "loss": 1.0947,
      "step": 106
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7981528043746948,
      "learning_rate": 4.3495934959349595e-05,
      "loss": 1.1985,
      "step": 107
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.5748635530471802,
      "learning_rate": 4.390243902439025e-05,
      "loss": 1.4568,
      "step": 108
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8763983845710754,
      "learning_rate": 4.43089430894309e-05,
      "loss": 1.2935,
      "step": 109
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.140655279159546,
      "learning_rate": 4.4715447154471546e-05,
      "loss": 1.0778,
      "step": 110
    },
    {
      "epoch": 0.04,
      "eval_loss": 1.3250523805618286,
      "eval_runtime": 326.0029,
      "eval_samples_per_second": 3.724,
      "eval_steps_per_second": 3.724,
      "step": 110
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9930562376976013,
      "learning_rate": 4.51219512195122e-05,
      "loss": 1.47,
      "step": 111
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.791010856628418,
      "learning_rate": 4.5528455284552844e-05,
      "loss": 1.2498,
      "step": 112
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.797151505947113,
      "learning_rate": 4.59349593495935e-05,
      "loss": 1.5441,
      "step": 113
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1353365182876587,
      "learning_rate": 4.634146341463415e-05,
      "loss": 1.0569,
      "step": 114
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7540895342826843,
      "learning_rate": 4.6747967479674795e-05,
      "loss": 1.646,
      "step": 115
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7477717399597168,
      "learning_rate": 4.715447154471545e-05,
      "loss": 1.5238,
      "step": 116
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8240853548049927,
      "learning_rate": 4.75609756097561e-05,
      "loss": 1.2654,
      "step": 117
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9059382677078247,
      "learning_rate": 4.796747967479675e-05,
      "loss": 1.7033,
      "step": 118
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7693507671356201,
      "learning_rate": 4.8373983739837406e-05,
      "loss": 1.3664,
      "step": 119
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9565718770027161,
      "learning_rate": 4.878048780487805e-05,
      "loss": 1.1451,
      "step": 120
    },
    {
      "epoch": 0.04,
      "eval_loss": 1.2634810209274292,
      "eval_runtime": 325.7944,
      "eval_samples_per_second": 3.726,
      "eval_steps_per_second": 3.726,
      "step": 120
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7601773142814636,
      "learning_rate": 4.9186991869918704e-05,
      "loss": 1.0194,
      "step": 121
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8008573055267334,
      "learning_rate": 4.959349593495935e-05,
      "loss": 1.3935,
      "step": 122
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.2699434757232666,
      "learning_rate": 5e-05,
      "loss": 1.0496,
      "step": 123
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7755095958709717,
      "learning_rate": 5.040650406504065e-05,
      "loss": 1.2898,
      "step": 124
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0492304563522339,
      "learning_rate": 5.081300813008131e-05,
      "loss": 1.3896,
      "step": 125
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.302497386932373,
      "learning_rate": 5.121951219512195e-05,
      "loss": 0.7599,
      "step": 126
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.4924302101135254,
      "learning_rate": 5.16260162601626e-05,
      "loss": 1.1285,
      "step": 127
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.299282193183899,
      "learning_rate": 5.203252032520326e-05,
      "loss": 1.2666,
      "step": 128
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8754943609237671,
      "learning_rate": 5.2439024390243904e-05,
      "loss": 1.5795,
      "step": 129
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0396995544433594,
      "learning_rate": 5.284552845528456e-05,
      "loss": 1.1697,
      "step": 130
    },
    {
      "epoch": 0.05,
      "eval_loss": 1.2119355201721191,
      "eval_runtime": 325.5108,
      "eval_samples_per_second": 3.73,
      "eval_steps_per_second": 3.73,
      "step": 130
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1425278186798096,
      "learning_rate": 5.32520325203252e-05,
      "loss": 1.1065,
      "step": 131
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9633607864379883,
      "learning_rate": 5.365853658536586e-05,
      "loss": 1.4487,
      "step": 132
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7477051019668579,
      "learning_rate": 5.406504065040651e-05,
      "loss": 1.2326,
      "step": 133
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1598808765411377,
      "learning_rate": 5.4471544715447154e-05,
      "loss": 0.8111,
      "step": 134
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.158067226409912,
      "learning_rate": 5.487804878048781e-05,
      "loss": 0.4326,
      "step": 135
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7105021476745605,
      "learning_rate": 5.528455284552846e-05,
      "loss": 1.4247,
      "step": 136
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.4563802480697632,
      "learning_rate": 5.5691056910569105e-05,
      "loss": 1.0037,
      "step": 137
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6715726852416992,
      "learning_rate": 5.6097560975609764e-05,
      "loss": 1.3359,
      "step": 138
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.791408121585846,
      "learning_rate": 5.650406504065041e-05,
      "loss": 1.2322,
      "step": 139
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8475920557975769,
      "learning_rate": 5.6910569105691056e-05,
      "loss": 1.2801,
      "step": 140
    },
    {
      "epoch": 0.05,
      "eval_loss": 1.1686697006225586,
      "eval_runtime": 325.5126,
      "eval_samples_per_second": 3.73,
      "eval_steps_per_second": 3.73,
      "step": 140
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6819143891334534,
      "learning_rate": 5.731707317073171e-05,
      "loss": 1.62,
      "step": 141
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8842762112617493,
      "learning_rate": 5.772357723577236e-05,
      "loss": 1.1084,
      "step": 142
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0945054292678833,
      "learning_rate": 5.813008130081301e-05,
      "loss": 1.3378,
      "step": 143
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7774190306663513,
      "learning_rate": 5.853658536585366e-05,
      "loss": 1.3741,
      "step": 144
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9604109525680542,
      "learning_rate": 5.894308943089432e-05,
      "loss": 1.2846,
      "step": 145
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7124897837638855,
      "learning_rate": 5.9349593495934964e-05,
      "loss": 1.5015,
      "step": 146
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7210645079612732,
      "learning_rate": 5.975609756097561e-05,
      "loss": 1.6447,
      "step": 147
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9963303208351135,
      "learning_rate": 6.016260162601627e-05,
      "loss": 0.9033,
      "step": 148
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8116875886917114,
      "learning_rate": 6.0569105691056915e-05,
      "loss": 1.1626,
      "step": 149
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9261677861213684,
      "learning_rate": 6.097560975609756e-05,
      "loss": 0.702,
      "step": 150
    },
    {
      "epoch": 0.05,
      "eval_loss": 1.1325774192810059,
      "eval_runtime": 325.3308,
      "eval_samples_per_second": 3.732,
      "eval_steps_per_second": 3.732,
      "step": 150
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.797307014465332,
      "learning_rate": 6.138211382113821e-05,
      "loss": 1.5099,
      "step": 151
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.264517068862915,
      "learning_rate": 6.178861788617887e-05,
      "loss": 0.9342,
      "step": 152
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8709571957588196,
      "learning_rate": 6.219512195121952e-05,
      "loss": 1.3985,
      "step": 153
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7828341722488403,
      "learning_rate": 6.260162601626016e-05,
      "loss": 1.1526,
      "step": 154
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9936427474021912,
      "learning_rate": 6.300813008130082e-05,
      "loss": 0.9792,
      "step": 155
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8182734251022339,
      "learning_rate": 6.341463414634146e-05,
      "loss": 1.3017,
      "step": 156
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9314256906509399,
      "learning_rate": 6.382113821138212e-05,
      "loss": 1.555,
      "step": 157
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7473167777061462,
      "learning_rate": 6.422764227642277e-05,
      "loss": 1.1697,
      "step": 158
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8253703713417053,
      "learning_rate": 6.463414634146342e-05,
      "loss": 1.0986,
      "step": 159
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.870027482509613,
      "learning_rate": 6.504065040650407e-05,
      "loss": 1.012,
      "step": 160
    },
    {
      "epoch": 0.06,
      "eval_loss": 1.1029951572418213,
      "eval_runtime": 326.4229,
      "eval_samples_per_second": 3.719,
      "eval_steps_per_second": 3.719,
      "step": 160
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7855833172798157,
      "learning_rate": 6.544715447154471e-05,
      "loss": 1.0619,
      "step": 161
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8225124478340149,
      "learning_rate": 6.585365853658538e-05,
      "loss": 1.439,
      "step": 162
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1338658332824707,
      "learning_rate": 6.626016260162602e-05,
      "loss": 1.0387,
      "step": 163
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9418333172798157,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.2,
      "step": 164
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8764670491218567,
      "learning_rate": 6.707317073170732e-05,
      "loss": 1.2466,
      "step": 165
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8701038956642151,
      "learning_rate": 6.747967479674798e-05,
      "loss": 1.1503,
      "step": 166
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.843986988067627,
      "learning_rate": 6.788617886178861e-05,
      "loss": 1.0542,
      "step": 167
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1796833276748657,
      "learning_rate": 6.829268292682928e-05,
      "loss": 0.6188,
      "step": 168
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9781550765037537,
      "learning_rate": 6.869918699186992e-05,
      "loss": 1.4088,
      "step": 169
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7705179452896118,
      "learning_rate": 6.910569105691057e-05,
      "loss": 1.3439,
      "step": 170
    },
    {
      "epoch": 0.06,
      "eval_loss": 1.0805726051330566,
      "eval_runtime": 326.3851,
      "eval_samples_per_second": 3.72,
      "eval_steps_per_second": 3.72,
      "step": 170
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7216205596923828,
      "learning_rate": 6.951219512195122e-05,
      "loss": 1.5823,
      "step": 171
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0226901769638062,
      "learning_rate": 6.991869918699188e-05,
      "loss": 1.1847,
      "step": 172
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8261892795562744,
      "learning_rate": 7.032520325203253e-05,
      "loss": 0.8384,
      "step": 173
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9352695345878601,
      "learning_rate": 7.073170731707317e-05,
      "loss": 1.3156,
      "step": 174
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.799106240272522,
      "learning_rate": 7.113821138211383e-05,
      "loss": 0.9791,
      "step": 175
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1050435304641724,
      "learning_rate": 7.154471544715447e-05,
      "loss": 0.5151,
      "step": 176
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8891284465789795,
      "learning_rate": 7.195121951219513e-05,
      "loss": 0.8357,
      "step": 177
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8139363527297974,
      "learning_rate": 7.235772357723578e-05,
      "loss": 1.3811,
      "step": 178
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9767664074897766,
      "learning_rate": 7.276422764227643e-05,
      "loss": 1.4443,
      "step": 179
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9169828295707703,
      "learning_rate": 7.317073170731707e-05,
      "loss": 0.8104,
      "step": 180
    },
    {
      "epoch": 0.07,
      "eval_loss": 1.0600314140319824,
      "eval_runtime": 326.2805,
      "eval_samples_per_second": 3.721,
      "eval_steps_per_second": 3.721,
      "step": 180
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9910956025123596,
      "learning_rate": 7.357723577235772e-05,
      "loss": 1.1296,
      "step": 181
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8450402617454529,
      "learning_rate": 7.398373983739838e-05,
      "loss": 1.0413,
      "step": 182
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9390578269958496,
      "learning_rate": 7.439024390243903e-05,
      "loss": 0.7378,
      "step": 183
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8823808431625366,
      "learning_rate": 7.479674796747968e-05,
      "loss": 0.9185,
      "step": 184
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9445410966873169,
      "learning_rate": 7.520325203252033e-05,
      "loss": 1.0597,
      "step": 185
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8242700695991516,
      "learning_rate": 7.560975609756099e-05,
      "loss": 1.1521,
      "step": 186
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7502871155738831,
      "learning_rate": 7.601626016260162e-05,
      "loss": 0.7578,
      "step": 187
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9505245089530945,
      "learning_rate": 7.642276422764229e-05,
      "loss": 0.8034,
      "step": 188
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7800757884979248,
      "learning_rate": 7.682926829268293e-05,
      "loss": 0.8383,
      "step": 189
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9595729112625122,
      "learning_rate": 7.723577235772358e-05,
      "loss": 0.9856,
      "step": 190
    },
    {
      "epoch": 0.07,
      "eval_loss": 1.0435426235198975,
      "eval_runtime": 326.1941,
      "eval_samples_per_second": 3.722,
      "eval_steps_per_second": 3.722,
      "step": 190
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9546048045158386,
      "learning_rate": 7.764227642276422e-05,
      "loss": 1.0965,
      "step": 191
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.86136394739151,
      "learning_rate": 7.804878048780489e-05,
      "loss": 1.4218,
      "step": 192
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8369916677474976,
      "learning_rate": 7.845528455284553e-05,
      "loss": 1.0795,
      "step": 193
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8701663017272949,
      "learning_rate": 7.886178861788618e-05,
      "loss": 0.8774,
      "step": 194
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8177838325500488,
      "learning_rate": 7.926829268292683e-05,
      "loss": 1.4439,
      "step": 195
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9791259169578552,
      "learning_rate": 7.967479674796748e-05,
      "loss": 0.6939,
      "step": 196
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8090195655822754,
      "learning_rate": 8.008130081300814e-05,
      "loss": 0.7174,
      "step": 197
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.974938154220581,
      "learning_rate": 8.048780487804879e-05,
      "loss": 1.0039,
      "step": 198
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9081343412399292,
      "learning_rate": 8.089430894308944e-05,
      "loss": 1.098,
      "step": 199
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9195163249969482,
      "learning_rate": 8.130081300813008e-05,
      "loss": 0.9419,
      "step": 200
    },
    {
      "epoch": 0.07,
      "eval_loss": 1.0287655591964722,
      "eval_runtime": 326.3062,
      "eval_samples_per_second": 3.72,
      "eval_steps_per_second": 3.72,
      "step": 200
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.799994945526123,
      "learning_rate": 8.170731707317073e-05,
      "loss": 0.9942,
      "step": 201
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8157487511634827,
      "learning_rate": 8.211382113821139e-05,
      "loss": 0.9711,
      "step": 202
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0199737548828125,
      "learning_rate": 8.252032520325204e-05,
      "loss": 1.0726,
      "step": 203
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.018051266670227,
      "learning_rate": 8.292682926829268e-05,
      "loss": 0.4108,
      "step": 204
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7914999127388,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.0264,
      "step": 205
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9539749622344971,
      "learning_rate": 8.373983739837398e-05,
      "loss": 1.2872,
      "step": 206
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8810439705848694,
      "learning_rate": 8.414634146341464e-05,
      "loss": 1.1894,
      "step": 207
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.927557110786438,
      "learning_rate": 8.455284552845529e-05,
      "loss": 1.0429,
      "step": 208
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9995114803314209,
      "learning_rate": 8.495934959349594e-05,
      "loss": 1.4287,
      "step": 209
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9358929991722107,
      "learning_rate": 8.53658536585366e-05,
      "loss": 1.0268,
      "step": 210
    },
    {
      "epoch": 0.08,
      "eval_loss": 1.0142097473144531,
      "eval_runtime": 326.217,
      "eval_samples_per_second": 3.721,
      "eval_steps_per_second": 3.721,
      "step": 210
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9699081182479858,
      "learning_rate": 8.577235772357723e-05,
      "loss": 1.0984,
      "step": 211
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2407060861587524,
      "learning_rate": 8.61788617886179e-05,
      "loss": 1.0904,
      "step": 212
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9110095500946045,
      "learning_rate": 8.658536585365854e-05,
      "loss": 1.0374,
      "step": 213
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9530538320541382,
      "learning_rate": 8.699186991869919e-05,
      "loss": 1.1573,
      "step": 214
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9679622650146484,
      "learning_rate": 8.739837398373984e-05,
      "loss": 1.3791,
      "step": 215
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9601581692695618,
      "learning_rate": 8.78048780487805e-05,
      "loss": 1.0592,
      "step": 216
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0071333646774292,
      "learning_rate": 8.821138211382113e-05,
      "loss": 0.8911,
      "step": 217
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.3248298168182373,
      "learning_rate": 8.86178861788618e-05,
      "loss": 1.0545,
      "step": 218
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9773963689804077,
      "learning_rate": 8.902439024390244e-05,
      "loss": 1.1423,
      "step": 219
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9770312905311584,
      "learning_rate": 8.943089430894309e-05,
      "loss": 1.5965,
      "step": 220
    },
    {
      "epoch": 0.08,
      "eval_loss": 1.0004335641860962,
      "eval_runtime": 326.375,
      "eval_samples_per_second": 3.72,
      "eval_steps_per_second": 3.72,
      "step": 220
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8625432252883911,
      "learning_rate": 8.983739837398374e-05,
      "loss": 1.1743,
      "step": 221
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.939493715763092,
      "learning_rate": 9.02439024390244e-05,
      "loss": 1.4241,
      "step": 222
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8956961631774902,
      "learning_rate": 9.065040650406505e-05,
      "loss": 0.3218,
      "step": 223
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0732840299606323,
      "learning_rate": 9.105691056910569e-05,
      "loss": 1.3027,
      "step": 224
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9051477313041687,
      "learning_rate": 9.146341463414635e-05,
      "loss": 1.2285,
      "step": 225
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9119907021522522,
      "learning_rate": 9.1869918699187e-05,
      "loss": 1.2564,
      "step": 226
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.102318286895752,
      "learning_rate": 9.227642276422765e-05,
      "loss": 0.7164,
      "step": 227
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0719971656799316,
      "learning_rate": 9.26829268292683e-05,
      "loss": 1.1222,
      "step": 228
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0267590284347534,
      "learning_rate": 9.308943089430895e-05,
      "loss": 1.5062,
      "step": 229
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1460020542144775,
      "learning_rate": 9.349593495934959e-05,
      "loss": 1.2783,
      "step": 230
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.9867081046104431,
      "eval_runtime": 326.2496,
      "eval_samples_per_second": 3.721,
      "eval_steps_per_second": 3.721,
      "step": 230
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9326720833778381,
      "learning_rate": 9.390243902439024e-05,
      "loss": 1.2625,
      "step": 231
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8374457359313965,
      "learning_rate": 9.43089430894309e-05,
      "loss": 1.0007,
      "step": 232
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9565045237541199,
      "learning_rate": 9.471544715447155e-05,
      "loss": 0.886,
      "step": 233
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0060887336730957,
      "learning_rate": 9.51219512195122e-05,
      "loss": 1.226,
      "step": 234
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.965057373046875,
      "learning_rate": 9.552845528455285e-05,
      "loss": 1.2974,
      "step": 235
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9149584174156189,
      "learning_rate": 9.59349593495935e-05,
      "loss": 1.1341,
      "step": 236
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9415076375007629,
      "learning_rate": 9.634146341463415e-05,
      "loss": 1.1951,
      "step": 237
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8042377829551697,
      "learning_rate": 9.674796747967481e-05,
      "loss": 1.5786,
      "step": 238
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0071464776992798,
      "learning_rate": 9.715447154471545e-05,
      "loss": 0.915,
      "step": 239
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0512903928756714,
      "learning_rate": 9.75609756097561e-05,
      "loss": 0.9203,
      "step": 240
    },
    {
      "epoch": 0.09,
      "eval_loss": 0.9765913486480713,
      "eval_runtime": 326.4291,
      "eval_samples_per_second": 3.719,
      "eval_steps_per_second": 3.719,
      "step": 240
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9783133864402771,
      "learning_rate": 9.796747967479674e-05,
      "loss": 0.8083,
      "step": 241
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0788142681121826,
      "learning_rate": 9.837398373983741e-05,
      "loss": 1.1461,
      "step": 242
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8150444030761719,
      "learning_rate": 9.878048780487805e-05,
      "loss": 0.5311,
      "step": 243
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8614550232887268,
      "learning_rate": 9.91869918699187e-05,
      "loss": 0.3778,
      "step": 244
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.261496663093567,
      "learning_rate": 9.959349593495935e-05,
      "loss": 1.2005,
      "step": 245
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9277626276016235,
      "learning_rate": 0.0001,
      "loss": 0.6729,
      "step": 246
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0038126707077026,
      "learning_rate": 9.999999609013937e-05,
      "loss": 1.1888,
      "step": 247
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9760969281196594,
      "learning_rate": 9.999998436055809e-05,
      "loss": 1.0591,
      "step": 248
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9807142019271851,
      "learning_rate": 9.999996481125796e-05,
      "loss": 1.5231,
      "step": 249
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7625811696052551,
      "learning_rate": 9.999993744224208e-05,
      "loss": 0.6553,
      "step": 250
    },
    {
      "epoch": 0.09,
      "eval_loss": 0.9678136706352234,
      "eval_runtime": 325.6397,
      "eval_samples_per_second": 3.728,
      "eval_steps_per_second": 3.728,
      "step": 250
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8316835165023804,
      "learning_rate": 9.999990225351471e-05,
      "loss": 1.1123,
      "step": 251
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.090338945388794,
      "learning_rate": 9.999985924508137e-05,
      "loss": 1.3295,
      "step": 252
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9618340134620667,
      "learning_rate": 9.999980841694876e-05,
      "loss": 1.1545,
      "step": 253
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2908791303634644,
      "learning_rate": 9.999974976912485e-05,
      "loss": 0.5995,
      "step": 254
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9467799663543701,
      "learning_rate": 9.99996833016188e-05,
      "loss": 0.5124,
      "step": 255
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.189963459968567,
      "learning_rate": 9.999960901444101e-05,
      "loss": 1.0339,
      "step": 256
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8844425082206726,
      "learning_rate": 9.999952690760311e-05,
      "loss": 0.6512,
      "step": 257
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.1616827249526978,
      "learning_rate": 9.99994369811179e-05,
      "loss": 1.301,
      "step": 258
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2586623430252075,
      "learning_rate": 9.999933923499951e-05,
      "loss": 1.3988,
      "step": 259
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9692146182060242,
      "learning_rate": 9.999923366926318e-05,
      "loss": 1.1402,
      "step": 260
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.9588657021522522,
      "eval_runtime": 325.3078,
      "eval_samples_per_second": 3.732,
      "eval_steps_per_second": 3.732,
      "step": 260
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9378979206085205,
      "learning_rate": 9.999912028392541e-05,
      "loss": 1.407,
      "step": 261
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9625810980796814,
      "learning_rate": 9.999899907900399e-05,
      "loss": 0.7351,
      "step": 262
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8823745250701904,
      "learning_rate": 9.999887005451781e-05,
      "loss": 0.8858,
      "step": 263
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8266088962554932,
      "learning_rate": 9.999873321048709e-05,
      "loss": 0.5598,
      "step": 264
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8318604230880737,
      "learning_rate": 9.999858854693322e-05,
      "loss": 1.0751,
      "step": 265
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0188854932785034,
      "learning_rate": 9.999843606387881e-05,
      "loss": 0.7,
      "step": 266
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9574480056762695,
      "learning_rate": 9.999827576134774e-05,
      "loss": 1.3393,
      "step": 267
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9648979902267456,
      "learning_rate": 9.999810763936506e-05,
      "loss": 1.0392,
      "step": 268
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0630820989608765,
      "learning_rate": 9.999793169795706e-05,
      "loss": 0.8513,
      "step": 269
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.019271969795227,
      "learning_rate": 9.999774793715127e-05,
      "loss": 1.0787,
      "step": 270
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.9519684314727783,
      "eval_runtime": 325.2146,
      "eval_samples_per_second": 3.733,
      "eval_steps_per_second": 3.733,
      "step": 270
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.244348168373108,
      "learning_rate": 9.999755635697641e-05,
      "loss": 0.9236,
      "step": 271
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8256751298904419,
      "learning_rate": 9.999735695746243e-05,
      "loss": 0.585,
      "step": 272
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9725598692893982,
      "learning_rate": 9.999714973864058e-05,
      "loss": 1.2308,
      "step": 273
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0194612741470337,
      "learning_rate": 9.999693470054321e-05,
      "loss": 1.2803,
      "step": 274
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9247444868087769,
      "learning_rate": 9.999671184320397e-05,
      "loss": 0.7972,
      "step": 275
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9991945624351501,
      "learning_rate": 9.99964811666577e-05,
      "loss": 0.9197,
      "step": 276
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.920225977897644,
      "learning_rate": 9.99962426709405e-05,
      "loss": 1.0605,
      "step": 277
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0983390808105469,
      "learning_rate": 9.999599635608964e-05,
      "loss": 0.5206,
      "step": 278
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.3666099309921265,
      "learning_rate": 9.999574222214367e-05,
      "loss": 0.8541,
      "step": 279
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.1414284706115723,
      "learning_rate": 9.999548026914232e-05,
      "loss": 1.1514,
      "step": 280
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.9441777467727661,
      "eval_runtime": 325.2598,
      "eval_samples_per_second": 3.732,
      "eval_steps_per_second": 3.732,
      "step": 280
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9987568855285645,
      "learning_rate": 9.999521049712656e-05,
      "loss": 1.1395,
      "step": 281
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0681555271148682,
      "learning_rate": 9.999493290613859e-05,
      "loss": 1.1423,
      "step": 282
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0330630540847778,
      "learning_rate": 9.99946474962218e-05,
      "loss": 0.7758,
      "step": 283
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0309786796569824,
      "learning_rate": 9.999435426742085e-05,
      "loss": 0.9989,
      "step": 284
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.076762080192566,
      "learning_rate": 9.999405321978159e-05,
      "loss": 0.6259,
      "step": 285
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.3180322647094727,
      "learning_rate": 9.999374435335112e-05,
      "loss": 0.7263,
      "step": 286
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9275753498077393,
      "learning_rate": 9.99934276681777e-05,
      "loss": 0.598,
      "step": 287
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8699234127998352,
      "learning_rate": 9.999310316431092e-05,
      "loss": 0.5035,
      "step": 288
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.049354910850525,
      "learning_rate": 9.999277084180147e-05,
      "loss": 0.9862,
      "step": 289
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1622639894485474,
      "learning_rate": 9.999243070070137e-05,
      "loss": 0.8874,
      "step": 290
    },
    {
      "epoch": 0.11,
      "eval_loss": 0.9381031394004822,
      "eval_runtime": 325.3056,
      "eval_samples_per_second": 3.732,
      "eval_steps_per_second": 3.732,
      "step": 290
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9852805137634277,
      "learning_rate": 9.999208274106378e-05,
      "loss": 1.2315,
      "step": 291
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9185624718666077,
      "learning_rate": 9.999172696294314e-05,
      "loss": 0.7952,
      "step": 292
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0557913780212402,
      "learning_rate": 9.999136336639509e-05,
      "loss": 0.841,
      "step": 293
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0769879817962646,
      "learning_rate": 9.99909919514765e-05,
      "loss": 1.2972,
      "step": 294
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0326718091964722,
      "learning_rate": 9.999061271824544e-05,
      "loss": 0.9179,
      "step": 295
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9868219494819641,
      "learning_rate": 9.999022566676123e-05,
      "loss": 0.9148,
      "step": 296
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8961410522460938,
      "learning_rate": 9.998983079708442e-05,
      "loss": 0.5898,
      "step": 297
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.020047664642334,
      "learning_rate": 9.998942810927673e-05,
      "loss": 1.4796,
      "step": 298
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.906444787979126,
      "learning_rate": 9.998901760340115e-05,
      "loss": 1.3382,
      "step": 299
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0148162841796875,
      "learning_rate": 9.99885992795219e-05,
      "loss": 1.1606,
      "step": 300
    },
    {
      "epoch": 0.11,
      "eval_loss": 0.9282341003417969,
      "eval_runtime": 327.5054,
      "eval_samples_per_second": 3.707,
      "eval_steps_per_second": 3.707,
      "step": 300
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0428061485290527,
      "learning_rate": 9.998817313770439e-05,
      "loss": 0.9052,
      "step": 301
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9352127313613892,
      "learning_rate": 9.998773917801525e-05,
      "loss": 1.1539,
      "step": 302
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0218499898910522,
      "learning_rate": 9.998729740052237e-05,
      "loss": 0.6392,
      "step": 303
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7467933893203735,
      "learning_rate": 9.998684780529484e-05,
      "loss": 0.4947,
      "step": 304
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9980430006980896,
      "learning_rate": 9.998639039240299e-05,
      "loss": 0.9528,
      "step": 305
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8421357870101929,
      "learning_rate": 9.998592516191832e-05,
      "loss": 0.3521,
      "step": 306
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.079756259918213,
      "learning_rate": 9.99854521139136e-05,
      "loss": 0.8174,
      "step": 307
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9219433665275574,
      "learning_rate": 9.998497124846282e-05,
      "loss": 0.7362,
      "step": 308
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1924407482147217,
      "learning_rate": 9.998448256564118e-05,
      "loss": 0.7786,
      "step": 309
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.3578217029571533,
      "learning_rate": 9.998398606552513e-05,
      "loss": 1.2103,
      "step": 310
    },
    {
      "epoch": 0.11,
      "eval_loss": 0.9244602918624878,
      "eval_runtime": 326.9799,
      "eval_samples_per_second": 3.713,
      "eval_steps_per_second": 3.713,
      "step": 310
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0997436046600342,
      "learning_rate": 9.998348174819229e-05,
      "loss": 0.9806,
      "step": 311
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0640251636505127,
      "learning_rate": 9.998296961372153e-05,
      "loss": 0.7293,
      "step": 312
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1742395162582397,
      "learning_rate": 9.998244966219298e-05,
      "loss": 1.1729,
      "step": 313
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.198685884475708,
      "learning_rate": 9.998192189368794e-05,
      "loss": 0.9521,
      "step": 314
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9107562899589539,
      "learning_rate": 9.998138630828892e-05,
      "loss": 0.7657,
      "step": 315
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7683629989624023,
      "learning_rate": 9.998084290607972e-05,
      "loss": 0.9737,
      "step": 316
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0940275192260742,
      "learning_rate": 9.99802916871453e-05,
      "loss": 1.2287,
      "step": 317
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9643294811248779,
      "learning_rate": 9.997973265157192e-05,
      "loss": 1.0949,
      "step": 318
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0150808095932007,
      "learning_rate": 9.997916579944695e-05,
      "loss": 1.294,
      "step": 319
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1065548658370972,
      "learning_rate": 9.997859113085906e-05,
      "loss": 1.2284,
      "step": 320
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.9165626168251038,
      "eval_runtime": 326.9318,
      "eval_samples_per_second": 3.713,
      "eval_steps_per_second": 3.713,
      "step": 320
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9520495533943176,
      "learning_rate": 9.997800864589812e-05,
      "loss": 0.6237,
      "step": 321
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.935294508934021,
      "learning_rate": 9.997741834465524e-05,
      "loss": 0.7892,
      "step": 322
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9223976135253906,
      "learning_rate": 9.997682022722275e-05,
      "loss": 0.8712,
      "step": 323
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9312877058982849,
      "learning_rate": 9.997621429369416e-05,
      "loss": 0.8371,
      "step": 324
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1610571146011353,
      "learning_rate": 9.997560054416426e-05,
      "loss": 1.1179,
      "step": 325
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1732457876205444,
      "learning_rate": 9.997497897872904e-05,
      "loss": 1.1057,
      "step": 326
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6929117441177368,
      "learning_rate": 9.997434959748569e-05,
      "loss": 0.7018,
      "step": 327
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0455793142318726,
      "learning_rate": 9.997371240053265e-05,
      "loss": 0.9698,
      "step": 328
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9631350636482239,
      "learning_rate": 9.997306738796957e-05,
      "loss": 0.7431,
      "step": 329
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8899025917053223,
      "learning_rate": 9.997241455989734e-05,
      "loss": 0.9372,
      "step": 330
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.9118994474411011,
      "eval_runtime": 326.619,
      "eval_samples_per_second": 3.717,
      "eval_steps_per_second": 3.717,
      "step": 330
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9096298813819885,
      "learning_rate": 9.997175391641805e-05,
      "loss": 0.9547,
      "step": 331
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8569766283035278,
      "learning_rate": 9.997108545763501e-05,
      "loss": 0.7453,
      "step": 332
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7623046040534973,
      "learning_rate": 9.997040918365279e-05,
      "loss": 0.6156,
      "step": 333
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9908808469772339,
      "learning_rate": 9.996972509457712e-05,
      "loss": 0.726,
      "step": 334
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0667710304260254,
      "learning_rate": 9.996903319051502e-05,
      "loss": 0.9045,
      "step": 335
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4858301877975464,
      "learning_rate": 9.996833347157468e-05,
      "loss": 0.9484,
      "step": 336
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1142442226409912,
      "learning_rate": 9.996762593786555e-05,
      "loss": 1.261,
      "step": 337
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8562672138214111,
      "learning_rate": 9.996691058949827e-05,
      "loss": 0.81,
      "step": 338
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0218836069107056,
      "learning_rate": 9.996618742658471e-05,
      "loss": 0.9332,
      "step": 339
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0430124998092651,
      "learning_rate": 9.996545644923798e-05,
      "loss": 1.3817,
      "step": 340
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.9044989943504333,
      "eval_runtime": 326.6943,
      "eval_samples_per_second": 3.716,
      "eval_steps_per_second": 3.716,
      "step": 340
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.158512830734253,
      "learning_rate": 9.996471765757241e-05,
      "loss": 0.7842,
      "step": 341
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0737135410308838,
      "learning_rate": 9.996397105170353e-05,
      "loss": 1.393,
      "step": 342
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8984323740005493,
      "learning_rate": 9.996321663174811e-05,
      "loss": 0.7327,
      "step": 343
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1021811962127686,
      "learning_rate": 9.996245439782413e-05,
      "loss": 0.728,
      "step": 344
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0985757112503052,
      "learning_rate": 9.99616843500508e-05,
      "loss": 1.1889,
      "step": 345
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0747137069702148,
      "learning_rate": 9.996090648854856e-05,
      "loss": 1.1921,
      "step": 346
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0248847007751465,
      "learning_rate": 9.996012081343904e-05,
      "loss": 0.9078,
      "step": 347
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0538058280944824,
      "learning_rate": 9.995932732484516e-05,
      "loss": 0.8922,
      "step": 348
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9366456866264343,
      "learning_rate": 9.995852602289097e-05,
      "loss": 0.9803,
      "step": 349
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8727009296417236,
      "learning_rate": 9.995771690770184e-05,
      "loss": 0.858,
      "step": 350
    },
    {
      "epoch": 0.13,
      "eval_loss": 0.9003121852874756,
      "eval_runtime": 327.6689,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 350
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1546971797943115,
      "learning_rate": 9.995689997940425e-05,
      "loss": 0.9925,
      "step": 351
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.2265123128890991,
      "learning_rate": 9.9956075238126e-05,
      "loss": 1.2278,
      "step": 352
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1120303869247437,
      "learning_rate": 9.995524268399607e-05,
      "loss": 0.8254,
      "step": 353
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.970176637172699,
      "learning_rate": 9.995440231714469e-05,
      "loss": 0.6803,
      "step": 354
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0955147743225098,
      "learning_rate": 9.995355413770322e-05,
      "loss": 1.2819,
      "step": 355
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0591999292373657,
      "learning_rate": 9.995269814580439e-05,
      "loss": 0.9392,
      "step": 356
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0823293924331665,
      "learning_rate": 9.995183434158202e-05,
      "loss": 0.8478,
      "step": 357
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0338075160980225,
      "learning_rate": 9.995096272517122e-05,
      "loss": 1.1368,
      "step": 358
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3271547555923462,
      "learning_rate": 9.99500832967083e-05,
      "loss": 1.3568,
      "step": 359
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0851223468780518,
      "learning_rate": 9.994919605633081e-05,
      "loss": 1.0559,
      "step": 360
    },
    {
      "epoch": 0.13,
      "eval_loss": 0.8969533443450928,
      "eval_runtime": 327.8208,
      "eval_samples_per_second": 3.703,
      "eval_steps_per_second": 3.703,
      "step": 360
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1121644973754883,
      "learning_rate": 9.994830100417753e-05,
      "loss": 0.5014,
      "step": 361
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.257051944732666,
      "learning_rate": 9.99473981403884e-05,
      "loss": 1.139,
      "step": 362
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1944279670715332,
      "learning_rate": 9.994648746510463e-05,
      "loss": 1.12,
      "step": 363
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0565859079360962,
      "learning_rate": 9.994556897846865e-05,
      "loss": 0.9484,
      "step": 364
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8487881422042847,
      "learning_rate": 9.994464268062412e-05,
      "loss": 0.6576,
      "step": 365
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0621976852416992,
      "learning_rate": 9.994370857171588e-05,
      "loss": 1.1784,
      "step": 366
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1692007780075073,
      "learning_rate": 9.994276665189006e-05,
      "loss": 0.8847,
      "step": 367
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9568784236907959,
      "learning_rate": 9.994181692129394e-05,
      "loss": 0.7769,
      "step": 368
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0426416397094727,
      "learning_rate": 9.994085938007606e-05,
      "loss": 0.9275,
      "step": 369
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1558138132095337,
      "learning_rate": 9.993989402838617e-05,
      "loss": 1.3411,
      "step": 370
    },
    {
      "epoch": 0.14,
      "eval_loss": 0.8923903107643127,
      "eval_runtime": 327.9021,
      "eval_samples_per_second": 3.702,
      "eval_steps_per_second": 3.702,
      "step": 370
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9626848697662354,
      "learning_rate": 9.993892086637524e-05,
      "loss": 0.9058,
      "step": 371
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0112080574035645,
      "learning_rate": 9.993793989419549e-05,
      "loss": 0.7114,
      "step": 372
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.008086085319519,
      "learning_rate": 9.993695111200032e-05,
      "loss": 1.0677,
      "step": 373
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0170484781265259,
      "learning_rate": 9.993595451994439e-05,
      "loss": 0.9847,
      "step": 374
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0283879041671753,
      "learning_rate": 9.993495011818352e-05,
      "loss": 0.8521,
      "step": 375
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1425178050994873,
      "learning_rate": 9.993393790687484e-05,
      "loss": 0.951,
      "step": 376
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2385247945785522,
      "learning_rate": 9.993291788617663e-05,
      "loss": 1.0197,
      "step": 377
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2062256336212158,
      "learning_rate": 9.99318900562484e-05,
      "loss": 1.0866,
      "step": 378
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9161548018455505,
      "learning_rate": 9.993085441725095e-05,
      "loss": 0.7098,
      "step": 379
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0275720357894897,
      "learning_rate": 9.99298109693462e-05,
      "loss": 0.5382,
      "step": 380
    },
    {
      "epoch": 0.14,
      "eval_loss": 0.889988124370575,
      "eval_runtime": 327.6569,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 380
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.248546838760376,
      "learning_rate": 9.992875971269736e-05,
      "loss": 1.0468,
      "step": 381
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.4772382974624634,
      "learning_rate": 9.992770064746882e-05,
      "loss": 0.8407,
      "step": 382
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1852599382400513,
      "learning_rate": 9.992663377382623e-05,
      "loss": 1.472,
      "step": 383
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2033355236053467,
      "learning_rate": 9.992555909193643e-05,
      "loss": 1.1356,
      "step": 384
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1887590885162354,
      "learning_rate": 9.992447660196753e-05,
      "loss": 0.7733,
      "step": 385
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.365098476409912,
      "learning_rate": 9.992338630408877e-05,
      "loss": 0.8272,
      "step": 386
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0497910976409912,
      "learning_rate": 9.992228819847071e-05,
      "loss": 0.7711,
      "step": 387
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1315890550613403,
      "learning_rate": 9.992118228528509e-05,
      "loss": 0.77,
      "step": 388
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9317522048950195,
      "learning_rate": 9.992006856470484e-05,
      "loss": 0.7035,
      "step": 389
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9163861274719238,
      "learning_rate": 9.991894703690414e-05,
      "loss": 0.8994,
      "step": 390
    },
    {
      "epoch": 0.14,
      "eval_loss": 0.8876945972442627,
      "eval_runtime": 327.6532,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 390
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0113011598587036,
      "learning_rate": 9.991781770205841e-05,
      "loss": 0.8643,
      "step": 391
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2991456985473633,
      "learning_rate": 9.991668056034427e-05,
      "loss": 0.5059,
      "step": 392
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1037832498550415,
      "learning_rate": 9.991553561193953e-05,
      "loss": 0.956,
      "step": 393
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3028960227966309,
      "learning_rate": 9.991438285702331e-05,
      "loss": 0.6762,
      "step": 394
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.4279154539108276,
      "learning_rate": 9.991322229577585e-05,
      "loss": 1.0079,
      "step": 395
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9074159264564514,
      "learning_rate": 9.991205392837868e-05,
      "loss": 0.589,
      "step": 396
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0587316751480103,
      "learning_rate": 9.99108777550145e-05,
      "loss": 0.6162,
      "step": 397
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.4230082035064697,
      "learning_rate": 9.99096937758673e-05,
      "loss": 1.0554,
      "step": 398
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1686733961105347,
      "learning_rate": 9.99085019911222e-05,
      "loss": 0.8521,
      "step": 399
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8225346803665161,
      "learning_rate": 9.990730240096561e-05,
      "loss": 0.5415,
      "step": 400
    },
    {
      "epoch": 0.15,
      "eval_loss": 0.881127119064331,
      "eval_runtime": 327.59,
      "eval_samples_per_second": 3.706,
      "eval_steps_per_second": 3.706,
      "step": 400
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9785767793655396,
      "learning_rate": 9.990609500558515e-05,
      "loss": 1.0061,
      "step": 401
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9121781587600708,
      "learning_rate": 9.990487980516962e-05,
      "loss": 0.837,
      "step": 402
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.16127610206604,
      "learning_rate": 9.99036567999091e-05,
      "loss": 1.0882,
      "step": 403
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.5153783559799194,
      "learning_rate": 9.990242598999486e-05,
      "loss": 1.3082,
      "step": 404
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0372884273529053,
      "learning_rate": 9.990118737561938e-05,
      "loss": 0.8811,
      "step": 405
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9651708006858826,
      "learning_rate": 9.989994095697636e-05,
      "loss": 0.8998,
      "step": 406
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.115947961807251,
      "learning_rate": 9.989868673426075e-05,
      "loss": 1.1211,
      "step": 407
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.122528314590454,
      "learning_rate": 9.98974247076687e-05,
      "loss": 0.7681,
      "step": 408
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1726967096328735,
      "learning_rate": 9.989615487739759e-05,
      "loss": 1.1305,
      "step": 409
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1397143602371216,
      "learning_rate": 9.989487724364601e-05,
      "loss": 0.8303,
      "step": 410
    },
    {
      "epoch": 0.15,
      "eval_loss": 0.8766501545906067,
      "eval_runtime": 327.874,
      "eval_samples_per_second": 3.703,
      "eval_steps_per_second": 3.703,
      "step": 410
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0417745113372803,
      "learning_rate": 9.989359180661378e-05,
      "loss": 1.0857,
      "step": 411
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.067773699760437,
      "learning_rate": 9.989229856650191e-05,
      "loss": 1.0254,
      "step": 412
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.976482093334198,
      "learning_rate": 9.989099752351269e-05,
      "loss": 0.8157,
      "step": 413
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2339369058609009,
      "learning_rate": 9.988968867784958e-05,
      "loss": 1.5125,
      "step": 414
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.244255542755127,
      "learning_rate": 9.988837202971726e-05,
      "loss": 1.1391,
      "step": 415
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0673149824142456,
      "learning_rate": 9.988704757932168e-05,
      "loss": 1.1063,
      "step": 416
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1457414627075195,
      "learning_rate": 9.988571532686995e-05,
      "loss": 1.034,
      "step": 417
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.901581883430481,
      "learning_rate": 9.988437527257045e-05,
      "loss": 1.0877,
      "step": 418
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1595642566680908,
      "learning_rate": 9.988302741663272e-05,
      "loss": 1.2469,
      "step": 419
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9295127987861633,
      "learning_rate": 9.98816717592676e-05,
      "loss": 0.8498,
      "step": 420
    },
    {
      "epoch": 0.15,
      "eval_loss": 0.8719693422317505,
      "eval_runtime": 327.6427,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 420
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.079867959022522,
      "learning_rate": 9.988030830068709e-05,
      "loss": 0.8145,
      "step": 421
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2736891508102417,
      "learning_rate": 9.987893704110441e-05,
      "loss": 0.7041,
      "step": 422
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8818795084953308,
      "learning_rate": 9.987755798073404e-05,
      "loss": 0.5195,
      "step": 423
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.188575267791748,
      "learning_rate": 9.987617111979167e-05,
      "loss": 0.8265,
      "step": 424
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9216428399085999,
      "learning_rate": 9.987477645849415e-05,
      "loss": 0.78,
      "step": 425
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1995275020599365,
      "learning_rate": 9.987337399705962e-05,
      "loss": 1.1789,
      "step": 426
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8373411893844604,
      "learning_rate": 9.987196373570744e-05,
      "loss": 0.8771,
      "step": 427
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1435261964797974,
      "learning_rate": 9.987054567465815e-05,
      "loss": 0.9624,
      "step": 428
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.062085747718811,
      "learning_rate": 9.986911981413351e-05,
      "loss": 1.0131,
      "step": 429
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9780181050300598,
      "learning_rate": 9.986768615435654e-05,
      "loss": 0.7636,
      "step": 430
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.8682220578193665,
      "eval_runtime": 327.6755,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 430
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0371886491775513,
      "learning_rate": 9.986624469555146e-05,
      "loss": 0.5906,
      "step": 431
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.4337824583053589,
      "learning_rate": 9.986479543794367e-05,
      "loss": 1.2759,
      "step": 432
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9549670815467834,
      "learning_rate": 9.986333838175987e-05,
      "loss": 0.4386,
      "step": 433
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1188794374465942,
      "learning_rate": 9.986187352722791e-05,
      "loss": 0.9073,
      "step": 434
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.3983302116394043,
      "learning_rate": 9.986040087457688e-05,
      "loss": 1.1357,
      "step": 435
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0847103595733643,
      "learning_rate": 9.985892042403712e-05,
      "loss": 0.5628,
      "step": 436
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1598190069198608,
      "learning_rate": 9.985743217584016e-05,
      "loss": 0.8207,
      "step": 437
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8508354425430298,
      "learning_rate": 9.985593613021872e-05,
      "loss": 0.8984,
      "step": 438
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0188215970993042,
      "learning_rate": 9.985443228740681e-05,
      "loss": 0.977,
      "step": 439
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8284507393836975,
      "learning_rate": 9.98529206476396e-05,
      "loss": 0.5136,
      "step": 440
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.8646613359451294,
      "eval_runtime": 327.6976,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 440
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0171877145767212,
      "learning_rate": 9.985140121115352e-05,
      "loss": 0.8695,
      "step": 441
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1601454019546509,
      "learning_rate": 9.984987397818621e-05,
      "loss": 1.2097,
      "step": 442
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1360671520233154,
      "learning_rate": 9.984833894897647e-05,
      "loss": 0.7684,
      "step": 443
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8518962264060974,
      "learning_rate": 9.984679612376443e-05,
      "loss": 0.6738,
      "step": 444
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0060768127441406,
      "learning_rate": 9.984524550279133e-05,
      "loss": 0.6646,
      "step": 445
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8444593548774719,
      "learning_rate": 9.984368708629972e-05,
      "loss": 0.5852,
      "step": 446
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1035454273223877,
      "learning_rate": 9.984212087453331e-05,
      "loss": 1.0368,
      "step": 447
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8452848792076111,
      "learning_rate": 9.984054686773703e-05,
      "loss": 0.8586,
      "step": 448
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7748528718948364,
      "learning_rate": 9.983896506615706e-05,
      "loss": 0.1133,
      "step": 449
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9527171850204468,
      "learning_rate": 9.98373754700408e-05,
      "loss": 0.764,
      "step": 450
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.8620173931121826,
      "eval_runtime": 327.7226,
      "eval_samples_per_second": 3.704,
      "eval_steps_per_second": 3.704,
      "step": 450
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8623696565628052,
      "learning_rate": 9.983577807963685e-05,
      "loss": 0.6171,
      "step": 451
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8432179093360901,
      "learning_rate": 9.983417289519501e-05,
      "loss": 0.7506,
      "step": 452
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8420207500457764,
      "learning_rate": 9.983255991696632e-05,
      "loss": 0.569,
      "step": 453
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8683856725692749,
      "learning_rate": 9.983093914520309e-05,
      "loss": 0.7279,
      "step": 454
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9396867156028748,
      "learning_rate": 9.982931058015874e-05,
      "loss": 0.5614,
      "step": 455
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.5803786516189575,
      "learning_rate": 9.982767422208801e-05,
      "loss": 1.1806,
      "step": 456
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0630779266357422,
      "learning_rate": 9.982603007124679e-05,
      "loss": 0.9929,
      "step": 457
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.18901789188385,
      "learning_rate": 9.982437812789222e-05,
      "loss": 1.1582,
      "step": 458
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9520888924598694,
      "learning_rate": 9.982271839228268e-05,
      "loss": 0.6314,
      "step": 459
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0704718828201294,
      "learning_rate": 9.982105086467772e-05,
      "loss": 0.6636,
      "step": 460
    },
    {
      "epoch": 0.17,
      "eval_loss": 0.8600401282310486,
      "eval_runtime": 327.3337,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 460
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9803924560546875,
      "learning_rate": 9.981937554533814e-05,
      "loss": 1.0832,
      "step": 461
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.027549386024475,
      "learning_rate": 9.981769243452595e-05,
      "loss": 0.8377,
      "step": 462
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.280500054359436,
      "learning_rate": 9.981600153250438e-05,
      "loss": 1.3847,
      "step": 463
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.1576601266860962,
      "learning_rate": 9.981430283953786e-05,
      "loss": 1.0744,
      "step": 464
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.2650495767593384,
      "learning_rate": 9.981259635589209e-05,
      "loss": 1.0767,
      "step": 465
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9910540580749512,
      "learning_rate": 9.981088208183392e-05,
      "loss": 0.998,
      "step": 466
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0992141962051392,
      "learning_rate": 9.980916001763148e-05,
      "loss": 1.1725,
      "step": 467
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.085988163948059,
      "learning_rate": 9.980743016355407e-05,
      "loss": 0.9399,
      "step": 468
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.047810435295105,
      "learning_rate": 9.980569251987226e-05,
      "loss": 0.8349,
      "step": 469
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9491277933120728,
      "learning_rate": 9.980394708685776e-05,
      "loss": 0.8124,
      "step": 470
    },
    {
      "epoch": 0.17,
      "eval_loss": 0.8559582233428955,
      "eval_runtime": 327.4116,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 470
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.1351910829544067,
      "learning_rate": 9.98021938647836e-05,
      "loss": 1.1822,
      "step": 471
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.2274141311645508,
      "learning_rate": 9.980043285392393e-05,
      "loss": 1.1977,
      "step": 472
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.2245728969573975,
      "learning_rate": 9.979866405455418e-05,
      "loss": 0.8378,
      "step": 473
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.374566674232483,
      "learning_rate": 9.979688746695098e-05,
      "loss": 0.9504,
      "step": 474
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0485947132110596,
      "learning_rate": 9.97951030913922e-05,
      "loss": 0.7812,
      "step": 475
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0290849208831787,
      "learning_rate": 9.979331092815686e-05,
      "loss": 1.1078,
      "step": 476
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0589619874954224,
      "learning_rate": 9.979151097752527e-05,
      "loss": 0.8694,
      "step": 477
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1698423624038696,
      "learning_rate": 9.978970323977894e-05,
      "loss": 1.1525,
      "step": 478
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0254608392715454,
      "learning_rate": 9.978788771520058e-05,
      "loss": 0.9336,
      "step": 479
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0395469665527344,
      "learning_rate": 9.978606440407412e-05,
      "loss": 0.9566,
      "step": 480
    },
    {
      "epoch": 0.18,
      "eval_loss": 0.8507027626037598,
      "eval_runtime": 327.3512,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 480
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.760418713092804,
      "learning_rate": 9.978423330668475e-05,
      "loss": 0.6164,
      "step": 481
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.2291877269744873,
      "learning_rate": 9.978239442331881e-05,
      "loss": 1.1554,
      "step": 482
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9477577209472656,
      "learning_rate": 9.978054775426389e-05,
      "loss": 0.9419,
      "step": 483
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0132375955581665,
      "learning_rate": 9.97786932998088e-05,
      "loss": 0.6345,
      "step": 484
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1971497535705566,
      "learning_rate": 9.97768310602436e-05,
      "loss": 1.1021,
      "step": 485
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1024694442749023,
      "learning_rate": 9.977496103585949e-05,
      "loss": 1.0036,
      "step": 486
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0824291706085205,
      "learning_rate": 9.977308322694895e-05,
      "loss": 1.1106,
      "step": 487
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1280707120895386,
      "learning_rate": 9.977119763380567e-05,
      "loss": 1.0314,
      "step": 488
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0214455127716064,
      "learning_rate": 9.976930425672454e-05,
      "loss": 0.9095,
      "step": 489
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.97348952293396,
      "learning_rate": 9.976740309600165e-05,
      "loss": 0.9548,
      "step": 490
    },
    {
      "epoch": 0.18,
      "eval_loss": 0.8478575348854065,
      "eval_runtime": 327.2593,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 490
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0172902345657349,
      "learning_rate": 9.976549415193437e-05,
      "loss": 0.7512,
      "step": 491
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.198768973350525,
      "learning_rate": 9.976357742482121e-05,
      "loss": 0.9435,
      "step": 492
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0586323738098145,
      "learning_rate": 9.976165291496196e-05,
      "loss": 0.5604,
      "step": 493
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0834991931915283,
      "learning_rate": 9.975972062265761e-05,
      "loss": 1.1083,
      "step": 494
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8768467903137207,
      "learning_rate": 9.975778054821032e-05,
      "loss": 0.7315,
      "step": 495
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6670326590538025,
      "learning_rate": 9.975583269192355e-05,
      "loss": 0.1626,
      "step": 496
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.332012414932251,
      "learning_rate": 9.97538770541019e-05,
      "loss": 0.8936,
      "step": 497
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.231974720954895,
      "learning_rate": 9.975191363505127e-05,
      "loss": 0.9882,
      "step": 498
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1001023054122925,
      "learning_rate": 9.974994243507866e-05,
      "loss": 1.1423,
      "step": 499
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9759262204170227,
      "learning_rate": 9.974796345449242e-05,
      "loss": 0.9723,
      "step": 500
    },
    {
      "epoch": 0.18,
      "eval_loss": 0.8481660485267639,
      "eval_runtime": 327.5961,
      "eval_samples_per_second": 3.706,
      "eval_steps_per_second": 3.706,
      "step": 500
    }
  ],
  "logging_steps": 1,
  "max_steps": 8190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 1.29273968984064e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
