{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.5128205128205128,
  "eval_steps": 10,
  "global_step": 1400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 1.1807260513305664,
      "learning_rate": 4.0650406504065046e-07,
      "loss": 2.4354,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.408429503440857,
      "learning_rate": 8.130081300813009e-07,
      "loss": 2.5737,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3173985481262207,
      "learning_rate": 1.2195121951219514e-06,
      "loss": 2.3571,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1332097053527832,
      "learning_rate": 1.6260162601626018e-06,
      "loss": 2.4204,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.208814263343811,
      "learning_rate": 2.0325203252032523e-06,
      "loss": 2.4305,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.194399118423462,
      "learning_rate": 2.4390243902439027e-06,
      "loss": 2.3606,
      "step": 6
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.3456549644470215,
      "learning_rate": 2.8455284552845528e-06,
      "loss": 2.4122,
      "step": 7
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2045505046844482,
      "learning_rate": 3.2520325203252037e-06,
      "loss": 2.4875,
      "step": 8
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.993188738822937,
      "learning_rate": 3.6585365853658537e-06,
      "loss": 2.5446,
      "step": 9
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.0967234373092651,
      "learning_rate": 4.0650406504065046e-06,
      "loss": 2.2822,
      "step": 10
    },
    {
      "epoch": 0.0,
      "eval_loss": 2.4522597789764404,
      "eval_runtime": 326.7826,
      "eval_samples_per_second": 3.715,
      "eval_steps_per_second": 3.715,
      "step": 10
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1855803728103638,
      "learning_rate": 4.471544715447155e-06,
      "loss": 2.3175,
      "step": 11
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.1233888864517212,
      "learning_rate": 4.8780487804878055e-06,
      "loss": 2.3798,
      "step": 12
    },
    {
      "epoch": 0.0,
      "grad_norm": 1.2168267965316772,
      "learning_rate": 5.2845528455284555e-06,
      "loss": 2.3091,
      "step": 13
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.104172945022583,
      "learning_rate": 5.6910569105691056e-06,
      "loss": 2.3482,
      "step": 14
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.4444849491119385,
      "learning_rate": 6.0975609756097564e-06,
      "loss": 2.3381,
      "step": 15
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2118523120880127,
      "learning_rate": 6.504065040650407e-06,
      "loss": 2.4472,
      "step": 16
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2675775289535522,
      "learning_rate": 6.910569105691057e-06,
      "loss": 2.3639,
      "step": 17
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2124836444854736,
      "learning_rate": 7.317073170731707e-06,
      "loss": 2.1979,
      "step": 18
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1547139883041382,
      "learning_rate": 7.723577235772358e-06,
      "loss": 2.3736,
      "step": 19
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1410959959030151,
      "learning_rate": 8.130081300813009e-06,
      "loss": 2.3241,
      "step": 20
    },
    {
      "epoch": 0.01,
      "eval_loss": 2.412365674972534,
      "eval_runtime": 326.8684,
      "eval_samples_per_second": 3.714,
      "eval_steps_per_second": 3.714,
      "step": 20
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.2570022344589233,
      "learning_rate": 8.53658536585366e-06,
      "loss": 2.4366,
      "step": 21
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9350789189338684,
      "learning_rate": 8.94308943089431e-06,
      "loss": 2.5075,
      "step": 22
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.996505081653595,
      "learning_rate": 9.34959349593496e-06,
      "loss": 2.3451,
      "step": 23
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.051774024963379,
      "learning_rate": 9.756097560975611e-06,
      "loss": 2.4491,
      "step": 24
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9073569178581238,
      "learning_rate": 1.016260162601626e-05,
      "loss": 2.3839,
      "step": 25
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.5927023887634277,
      "learning_rate": 1.0569105691056911e-05,
      "loss": 2.3958,
      "step": 26
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0582877397537231,
      "learning_rate": 1.0975609756097562e-05,
      "loss": 2.3234,
      "step": 27
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1481232643127441,
      "learning_rate": 1.1382113821138211e-05,
      "loss": 2.3005,
      "step": 28
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9161113500595093,
      "learning_rate": 1.1788617886178862e-05,
      "loss": 2.3921,
      "step": 29
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.3125858306884766,
      "learning_rate": 1.2195121951219513e-05,
      "loss": 2.3973,
      "step": 30
    },
    {
      "epoch": 0.01,
      "eval_loss": 2.3516244888305664,
      "eval_runtime": 326.8496,
      "eval_samples_per_second": 3.714,
      "eval_steps_per_second": 3.714,
      "step": 30
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9008913040161133,
      "learning_rate": 1.2601626016260162e-05,
      "loss": 2.4244,
      "step": 31
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.0559351444244385,
      "learning_rate": 1.3008130081300815e-05,
      "loss": 2.2565,
      "step": 32
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9710964560508728,
      "learning_rate": 1.3414634146341466e-05,
      "loss": 2.3623,
      "step": 33
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9186581969261169,
      "learning_rate": 1.3821138211382115e-05,
      "loss": 2.1046,
      "step": 34
    },
    {
      "epoch": 0.01,
      "grad_norm": 1.1416815519332886,
      "learning_rate": 1.4227642276422764e-05,
      "loss": 2.2958,
      "step": 35
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9226109981536865,
      "learning_rate": 1.4634146341463415e-05,
      "loss": 2.353,
      "step": 36
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8293136954307556,
      "learning_rate": 1.5040650406504067e-05,
      "loss": 2.2396,
      "step": 37
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9112761616706848,
      "learning_rate": 1.5447154471544717e-05,
      "loss": 2.4254,
      "step": 38
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.9158889055252075,
      "learning_rate": 1.5853658536585366e-05,
      "loss": 2.3863,
      "step": 39
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.8299440741539001,
      "learning_rate": 1.6260162601626018e-05,
      "loss": 2.4708,
      "step": 40
    },
    {
      "epoch": 0.01,
      "eval_loss": 2.2731287479400635,
      "eval_runtime": 326.6766,
      "eval_samples_per_second": 3.716,
      "eval_steps_per_second": 3.716,
      "step": 40
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7720086574554443,
      "learning_rate": 1.6666666666666667e-05,
      "loss": 2.3508,
      "step": 41
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8971328139305115,
      "learning_rate": 1.707317073170732e-05,
      "loss": 2.1803,
      "step": 42
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9551953673362732,
      "learning_rate": 1.747967479674797e-05,
      "loss": 2.3714,
      "step": 43
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8126462697982788,
      "learning_rate": 1.788617886178862e-05,
      "loss": 2.3284,
      "step": 44
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8575080633163452,
      "learning_rate": 1.8292682926829268e-05,
      "loss": 2.3389,
      "step": 45
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7832810282707214,
      "learning_rate": 1.869918699186992e-05,
      "loss": 2.3447,
      "step": 46
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8090999126434326,
      "learning_rate": 1.9105691056910573e-05,
      "loss": 2.4705,
      "step": 47
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9688745737075806,
      "learning_rate": 1.9512195121951222e-05,
      "loss": 2.211,
      "step": 48
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9135887026786804,
      "learning_rate": 1.991869918699187e-05,
      "loss": 2.1467,
      "step": 49
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7019591331481934,
      "learning_rate": 2.032520325203252e-05,
      "loss": 2.2606,
      "step": 50
    },
    {
      "epoch": 0.02,
      "eval_loss": 2.1757566928863525,
      "eval_runtime": 326.4387,
      "eval_samples_per_second": 3.719,
      "eval_steps_per_second": 3.719,
      "step": 50
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0046828985214233,
      "learning_rate": 2.073170731707317e-05,
      "loss": 2.1634,
      "step": 51
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7694976925849915,
      "learning_rate": 2.1138211382113822e-05,
      "loss": 2.1424,
      "step": 52
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.865962028503418,
      "learning_rate": 2.1544715447154475e-05,
      "loss": 2.2878,
      "step": 53
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.90448397397995,
      "learning_rate": 2.1951219512195124e-05,
      "loss": 2.2397,
      "step": 54
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0173530578613281,
      "learning_rate": 2.2357723577235773e-05,
      "loss": 2.0216,
      "step": 55
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7731962203979492,
      "learning_rate": 2.2764227642276422e-05,
      "loss": 2.1647,
      "step": 56
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7913800477981567,
      "learning_rate": 2.3170731707317075e-05,
      "loss": 2.068,
      "step": 57
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.8766810894012451,
      "learning_rate": 2.3577235772357724e-05,
      "loss": 2.2275,
      "step": 58
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0228992700576782,
      "learning_rate": 2.3983739837398377e-05,
      "loss": 2.2035,
      "step": 59
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9332002997398376,
      "learning_rate": 2.4390243902439026e-05,
      "loss": 2.1041,
      "step": 60
    },
    {
      "epoch": 0.02,
      "eval_loss": 2.040968179702759,
      "eval_runtime": 326.2162,
      "eval_samples_per_second": 3.721,
      "eval_steps_per_second": 3.721,
      "step": 60
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0200774669647217,
      "learning_rate": 2.4796747967479675e-05,
      "loss": 1.9946,
      "step": 61
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9349056482315063,
      "learning_rate": 2.5203252032520324e-05,
      "loss": 2.1248,
      "step": 62
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.7300223708152771,
      "learning_rate": 2.5609756097560977e-05,
      "loss": 2.299,
      "step": 63
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9820848703384399,
      "learning_rate": 2.601626016260163e-05,
      "loss": 2.0009,
      "step": 64
    },
    {
      "epoch": 0.02,
      "grad_norm": 1.0291283130645752,
      "learning_rate": 2.642276422764228e-05,
      "loss": 1.991,
      "step": 65
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9412071108818054,
      "learning_rate": 2.682926829268293e-05,
      "loss": 1.8844,
      "step": 66
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.9445374608039856,
      "learning_rate": 2.7235772357723577e-05,
      "loss": 1.8764,
      "step": 67
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.993418276309967,
      "learning_rate": 2.764227642276423e-05,
      "loss": 2.0493,
      "step": 68
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9592738151550293,
      "learning_rate": 2.8048780487804882e-05,
      "loss": 1.9275,
      "step": 69
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.841105043888092,
      "learning_rate": 2.8455284552845528e-05,
      "loss": 2.0795,
      "step": 70
    },
    {
      "epoch": 0.03,
      "eval_loss": 1.8460652828216553,
      "eval_runtime": 326.2213,
      "eval_samples_per_second": 3.721,
      "eval_steps_per_second": 3.721,
      "step": 70
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.7738112211227417,
      "learning_rate": 2.886178861788618e-05,
      "loss": 1.9344,
      "step": 71
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.4108299016952515,
      "learning_rate": 2.926829268292683e-05,
      "loss": 1.5763,
      "step": 72
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.230282187461853,
      "learning_rate": 2.9674796747967482e-05,
      "loss": 1.653,
      "step": 73
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1350009441375732,
      "learning_rate": 3.0081300813008135e-05,
      "loss": 1.7795,
      "step": 74
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8457537889480591,
      "learning_rate": 3.048780487804878e-05,
      "loss": 1.9683,
      "step": 75
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1538017988204956,
      "learning_rate": 3.089430894308943e-05,
      "loss": 1.7007,
      "step": 76
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0437917709350586,
      "learning_rate": 3.130081300813008e-05,
      "loss": 1.7716,
      "step": 77
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.09328031539917,
      "learning_rate": 3.170731707317073e-05,
      "loss": 1.687,
      "step": 78
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9789184927940369,
      "learning_rate": 3.2113821138211384e-05,
      "loss": 1.7055,
      "step": 79
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9023700952529907,
      "learning_rate": 3.2520325203252037e-05,
      "loss": 1.8462,
      "step": 80
    },
    {
      "epoch": 0.03,
      "eval_loss": 1.637189269065857,
      "eval_runtime": 326.1738,
      "eval_samples_per_second": 3.722,
      "eval_steps_per_second": 3.722,
      "step": 80
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.833107054233551,
      "learning_rate": 3.292682926829269e-05,
      "loss": 1.8689,
      "step": 81
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.19161057472229,
      "learning_rate": 3.3333333333333335e-05,
      "loss": 1.2809,
      "step": 82
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.124289631843567,
      "learning_rate": 3.373983739837399e-05,
      "loss": 1.4932,
      "step": 83
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.09165620803833,
      "learning_rate": 3.414634146341464e-05,
      "loss": 1.4891,
      "step": 84
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.0194751024246216,
      "learning_rate": 3.4552845528455286e-05,
      "loss": 1.3986,
      "step": 85
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.1413490772247314,
      "learning_rate": 3.495934959349594e-05,
      "loss": 1.6055,
      "step": 86
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8215764760971069,
      "learning_rate": 3.5365853658536584e-05,
      "loss": 1.7743,
      "step": 87
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9572280645370483,
      "learning_rate": 3.577235772357724e-05,
      "loss": 1.403,
      "step": 88
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8137934803962708,
      "learning_rate": 3.617886178861789e-05,
      "loss": 1.5911,
      "step": 89
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9657096862792969,
      "learning_rate": 3.6585365853658535e-05,
      "loss": 1.5199,
      "step": 90
    },
    {
      "epoch": 0.03,
      "eval_loss": 1.4930168390274048,
      "eval_runtime": 326.0041,
      "eval_samples_per_second": 3.724,
      "eval_steps_per_second": 3.724,
      "step": 90
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.774365246295929,
      "learning_rate": 3.699186991869919e-05,
      "loss": 1.7257,
      "step": 91
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9638116955757141,
      "learning_rate": 3.739837398373984e-05,
      "loss": 1.2441,
      "step": 92
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.9455052614212036,
      "learning_rate": 3.780487804878049e-05,
      "loss": 1.0293,
      "step": 93
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.8377805948257446,
      "learning_rate": 3.8211382113821145e-05,
      "loss": 1.0716,
      "step": 94
    },
    {
      "epoch": 0.03,
      "grad_norm": 1.3332194089889526,
      "learning_rate": 3.861788617886179e-05,
      "loss": 1.3948,
      "step": 95
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9706263542175293,
      "learning_rate": 3.9024390243902444e-05,
      "loss": 1.2058,
      "step": 96
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6947608590126038,
      "learning_rate": 3.943089430894309e-05,
      "loss": 1.6998,
      "step": 97
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.067426085472107,
      "learning_rate": 3.983739837398374e-05,
      "loss": 1.1725,
      "step": 98
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7970749735832214,
      "learning_rate": 4.0243902439024395e-05,
      "loss": 1.2434,
      "step": 99
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8729394674301147,
      "learning_rate": 4.065040650406504e-05,
      "loss": 1.5179,
      "step": 100
    },
    {
      "epoch": 0.04,
      "eval_loss": 1.3956992626190186,
      "eval_runtime": 325.7534,
      "eval_samples_per_second": 3.727,
      "eval_steps_per_second": 3.727,
      "step": 100
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7873782515525818,
      "learning_rate": 4.105691056910569e-05,
      "loss": 1.785,
      "step": 101
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7723170518875122,
      "learning_rate": 4.146341463414634e-05,
      "loss": 1.8136,
      "step": 102
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8328036665916443,
      "learning_rate": 4.186991869918699e-05,
      "loss": 1.4924,
      "step": 103
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7091415524482727,
      "learning_rate": 4.2276422764227644e-05,
      "loss": 1.4669,
      "step": 104
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.6786538362503052,
      "learning_rate": 4.26829268292683e-05,
      "loss": 1.5315,
      "step": 105
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1244758367538452,
      "learning_rate": 4.308943089430895e-05,
      "loss": 1.0947,
      "step": 106
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7981528043746948,
      "learning_rate": 4.3495934959349595e-05,
      "loss": 1.1985,
      "step": 107
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.5748635530471802,
      "learning_rate": 4.390243902439025e-05,
      "loss": 1.4568,
      "step": 108
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8763983845710754,
      "learning_rate": 4.43089430894309e-05,
      "loss": 1.2935,
      "step": 109
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.140655279159546,
      "learning_rate": 4.4715447154471546e-05,
      "loss": 1.0778,
      "step": 110
    },
    {
      "epoch": 0.04,
      "eval_loss": 1.3250523805618286,
      "eval_runtime": 326.0029,
      "eval_samples_per_second": 3.724,
      "eval_steps_per_second": 3.724,
      "step": 110
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9930562376976013,
      "learning_rate": 4.51219512195122e-05,
      "loss": 1.47,
      "step": 111
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.791010856628418,
      "learning_rate": 4.5528455284552844e-05,
      "loss": 1.2498,
      "step": 112
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.797151505947113,
      "learning_rate": 4.59349593495935e-05,
      "loss": 1.5441,
      "step": 113
    },
    {
      "epoch": 0.04,
      "grad_norm": 1.1353365182876587,
      "learning_rate": 4.634146341463415e-05,
      "loss": 1.0569,
      "step": 114
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7540895342826843,
      "learning_rate": 4.6747967479674795e-05,
      "loss": 1.646,
      "step": 115
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7477717399597168,
      "learning_rate": 4.715447154471545e-05,
      "loss": 1.5238,
      "step": 116
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8240853548049927,
      "learning_rate": 4.75609756097561e-05,
      "loss": 1.2654,
      "step": 117
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9059382677078247,
      "learning_rate": 4.796747967479675e-05,
      "loss": 1.7033,
      "step": 118
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7693507671356201,
      "learning_rate": 4.8373983739837406e-05,
      "loss": 1.3664,
      "step": 119
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.9565718770027161,
      "learning_rate": 4.878048780487805e-05,
      "loss": 1.1451,
      "step": 120
    },
    {
      "epoch": 0.04,
      "eval_loss": 1.2634810209274292,
      "eval_runtime": 325.7944,
      "eval_samples_per_second": 3.726,
      "eval_steps_per_second": 3.726,
      "step": 120
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.7601773142814636,
      "learning_rate": 4.9186991869918704e-05,
      "loss": 1.0194,
      "step": 121
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.8008573055267334,
      "learning_rate": 4.959349593495935e-05,
      "loss": 1.3935,
      "step": 122
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.2699434757232666,
      "learning_rate": 5e-05,
      "loss": 1.0496,
      "step": 123
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7755095958709717,
      "learning_rate": 5.040650406504065e-05,
      "loss": 1.2898,
      "step": 124
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0492304563522339,
      "learning_rate": 5.081300813008131e-05,
      "loss": 1.3896,
      "step": 125
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.302497386932373,
      "learning_rate": 5.121951219512195e-05,
      "loss": 0.7599,
      "step": 126
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.4924302101135254,
      "learning_rate": 5.16260162601626e-05,
      "loss": 1.1285,
      "step": 127
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.299282193183899,
      "learning_rate": 5.203252032520326e-05,
      "loss": 1.2666,
      "step": 128
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8754943609237671,
      "learning_rate": 5.2439024390243904e-05,
      "loss": 1.5795,
      "step": 129
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0396995544433594,
      "learning_rate": 5.284552845528456e-05,
      "loss": 1.1697,
      "step": 130
    },
    {
      "epoch": 0.05,
      "eval_loss": 1.2119355201721191,
      "eval_runtime": 325.5108,
      "eval_samples_per_second": 3.73,
      "eval_steps_per_second": 3.73,
      "step": 130
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1425278186798096,
      "learning_rate": 5.32520325203252e-05,
      "loss": 1.1065,
      "step": 131
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9633607864379883,
      "learning_rate": 5.365853658536586e-05,
      "loss": 1.4487,
      "step": 132
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7477051019668579,
      "learning_rate": 5.406504065040651e-05,
      "loss": 1.2326,
      "step": 133
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.1598808765411377,
      "learning_rate": 5.4471544715447154e-05,
      "loss": 0.8111,
      "step": 134
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.158067226409912,
      "learning_rate": 5.487804878048781e-05,
      "loss": 0.4326,
      "step": 135
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7105021476745605,
      "learning_rate": 5.528455284552846e-05,
      "loss": 1.4247,
      "step": 136
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.4563802480697632,
      "learning_rate": 5.5691056910569105e-05,
      "loss": 1.0037,
      "step": 137
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6715726852416992,
      "learning_rate": 5.6097560975609764e-05,
      "loss": 1.3359,
      "step": 138
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.791408121585846,
      "learning_rate": 5.650406504065041e-05,
      "loss": 1.2322,
      "step": 139
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8475920557975769,
      "learning_rate": 5.6910569105691056e-05,
      "loss": 1.2801,
      "step": 140
    },
    {
      "epoch": 0.05,
      "eval_loss": 1.1686697006225586,
      "eval_runtime": 325.5126,
      "eval_samples_per_second": 3.73,
      "eval_steps_per_second": 3.73,
      "step": 140
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.6819143891334534,
      "learning_rate": 5.731707317073171e-05,
      "loss": 1.62,
      "step": 141
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8842762112617493,
      "learning_rate": 5.772357723577236e-05,
      "loss": 1.1084,
      "step": 142
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.0945054292678833,
      "learning_rate": 5.813008130081301e-05,
      "loss": 1.3378,
      "step": 143
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7774190306663513,
      "learning_rate": 5.853658536585366e-05,
      "loss": 1.3741,
      "step": 144
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9604109525680542,
      "learning_rate": 5.894308943089432e-05,
      "loss": 1.2846,
      "step": 145
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7124897837638855,
      "learning_rate": 5.9349593495934964e-05,
      "loss": 1.5015,
      "step": 146
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.7210645079612732,
      "learning_rate": 5.975609756097561e-05,
      "loss": 1.6447,
      "step": 147
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9963303208351135,
      "learning_rate": 6.016260162601627e-05,
      "loss": 0.9033,
      "step": 148
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.8116875886917114,
      "learning_rate": 6.0569105691056915e-05,
      "loss": 1.1626,
      "step": 149
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.9261677861213684,
      "learning_rate": 6.097560975609756e-05,
      "loss": 0.702,
      "step": 150
    },
    {
      "epoch": 0.05,
      "eval_loss": 1.1325774192810059,
      "eval_runtime": 325.3308,
      "eval_samples_per_second": 3.732,
      "eval_steps_per_second": 3.732,
      "step": 150
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.797307014465332,
      "learning_rate": 6.138211382113821e-05,
      "loss": 1.5099,
      "step": 151
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.264517068862915,
      "learning_rate": 6.178861788617887e-05,
      "loss": 0.9342,
      "step": 152
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8709571957588196,
      "learning_rate": 6.219512195121952e-05,
      "loss": 1.3985,
      "step": 153
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7828341722488403,
      "learning_rate": 6.260162601626016e-05,
      "loss": 1.1526,
      "step": 154
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9936427474021912,
      "learning_rate": 6.300813008130082e-05,
      "loss": 0.9792,
      "step": 155
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8182734251022339,
      "learning_rate": 6.341463414634146e-05,
      "loss": 1.3017,
      "step": 156
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9314256906509399,
      "learning_rate": 6.382113821138212e-05,
      "loss": 1.555,
      "step": 157
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7473167777061462,
      "learning_rate": 6.422764227642277e-05,
      "loss": 1.1697,
      "step": 158
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8253703713417053,
      "learning_rate": 6.463414634146342e-05,
      "loss": 1.0986,
      "step": 159
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.870027482509613,
      "learning_rate": 6.504065040650407e-05,
      "loss": 1.012,
      "step": 160
    },
    {
      "epoch": 0.06,
      "eval_loss": 1.1029951572418213,
      "eval_runtime": 326.4229,
      "eval_samples_per_second": 3.719,
      "eval_steps_per_second": 3.719,
      "step": 160
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7855833172798157,
      "learning_rate": 6.544715447154471e-05,
      "loss": 1.0619,
      "step": 161
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8225124478340149,
      "learning_rate": 6.585365853658538e-05,
      "loss": 1.439,
      "step": 162
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1338658332824707,
      "learning_rate": 6.626016260162602e-05,
      "loss": 1.0387,
      "step": 163
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9418333172798157,
      "learning_rate": 6.666666666666667e-05,
      "loss": 1.2,
      "step": 164
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8764670491218567,
      "learning_rate": 6.707317073170732e-05,
      "loss": 1.2466,
      "step": 165
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8701038956642151,
      "learning_rate": 6.747967479674798e-05,
      "loss": 1.1503,
      "step": 166
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.843986988067627,
      "learning_rate": 6.788617886178861e-05,
      "loss": 1.0542,
      "step": 167
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1796833276748657,
      "learning_rate": 6.829268292682928e-05,
      "loss": 0.6188,
      "step": 168
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9781550765037537,
      "learning_rate": 6.869918699186992e-05,
      "loss": 1.4088,
      "step": 169
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7705179452896118,
      "learning_rate": 6.910569105691057e-05,
      "loss": 1.3439,
      "step": 170
    },
    {
      "epoch": 0.06,
      "eval_loss": 1.0805726051330566,
      "eval_runtime": 326.3851,
      "eval_samples_per_second": 3.72,
      "eval_steps_per_second": 3.72,
      "step": 170
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.7216205596923828,
      "learning_rate": 6.951219512195122e-05,
      "loss": 1.5823,
      "step": 171
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.0226901769638062,
      "learning_rate": 6.991869918699188e-05,
      "loss": 1.1847,
      "step": 172
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8261892795562744,
      "learning_rate": 7.032520325203253e-05,
      "loss": 0.8384,
      "step": 173
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.9352695345878601,
      "learning_rate": 7.073170731707317e-05,
      "loss": 1.3156,
      "step": 174
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.799106240272522,
      "learning_rate": 7.113821138211383e-05,
      "loss": 0.9791,
      "step": 175
    },
    {
      "epoch": 0.06,
      "grad_norm": 1.1050435304641724,
      "learning_rate": 7.154471544715447e-05,
      "loss": 0.5151,
      "step": 176
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.8891284465789795,
      "learning_rate": 7.195121951219513e-05,
      "loss": 0.8357,
      "step": 177
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8139363527297974,
      "learning_rate": 7.235772357723578e-05,
      "loss": 1.3811,
      "step": 178
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9767664074897766,
      "learning_rate": 7.276422764227643e-05,
      "loss": 1.4443,
      "step": 179
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9169828295707703,
      "learning_rate": 7.317073170731707e-05,
      "loss": 0.8104,
      "step": 180
    },
    {
      "epoch": 0.07,
      "eval_loss": 1.0600314140319824,
      "eval_runtime": 326.2805,
      "eval_samples_per_second": 3.721,
      "eval_steps_per_second": 3.721,
      "step": 180
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9910956025123596,
      "learning_rate": 7.357723577235772e-05,
      "loss": 1.1296,
      "step": 181
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8450402617454529,
      "learning_rate": 7.398373983739838e-05,
      "loss": 1.0413,
      "step": 182
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9390578269958496,
      "learning_rate": 7.439024390243903e-05,
      "loss": 0.7378,
      "step": 183
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8823808431625366,
      "learning_rate": 7.479674796747968e-05,
      "loss": 0.9185,
      "step": 184
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9445410966873169,
      "learning_rate": 7.520325203252033e-05,
      "loss": 1.0597,
      "step": 185
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8242700695991516,
      "learning_rate": 7.560975609756099e-05,
      "loss": 1.1521,
      "step": 186
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7502871155738831,
      "learning_rate": 7.601626016260162e-05,
      "loss": 0.7578,
      "step": 187
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9505245089530945,
      "learning_rate": 7.642276422764229e-05,
      "loss": 0.8034,
      "step": 188
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.7800757884979248,
      "learning_rate": 7.682926829268293e-05,
      "loss": 0.8383,
      "step": 189
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9595729112625122,
      "learning_rate": 7.723577235772358e-05,
      "loss": 0.9856,
      "step": 190
    },
    {
      "epoch": 0.07,
      "eval_loss": 1.0435426235198975,
      "eval_runtime": 326.1941,
      "eval_samples_per_second": 3.722,
      "eval_steps_per_second": 3.722,
      "step": 190
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9546048045158386,
      "learning_rate": 7.764227642276422e-05,
      "loss": 1.0965,
      "step": 191
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.86136394739151,
      "learning_rate": 7.804878048780489e-05,
      "loss": 1.4218,
      "step": 192
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8369916677474976,
      "learning_rate": 7.845528455284553e-05,
      "loss": 1.0795,
      "step": 193
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8701663017272949,
      "learning_rate": 7.886178861788618e-05,
      "loss": 0.8774,
      "step": 194
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8177838325500488,
      "learning_rate": 7.926829268292683e-05,
      "loss": 1.4439,
      "step": 195
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9791259169578552,
      "learning_rate": 7.967479674796748e-05,
      "loss": 0.6939,
      "step": 196
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8090195655822754,
      "learning_rate": 8.008130081300814e-05,
      "loss": 0.7174,
      "step": 197
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.974938154220581,
      "learning_rate": 8.048780487804879e-05,
      "loss": 1.0039,
      "step": 198
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9081343412399292,
      "learning_rate": 8.089430894308944e-05,
      "loss": 1.098,
      "step": 199
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.9195163249969482,
      "learning_rate": 8.130081300813008e-05,
      "loss": 0.9419,
      "step": 200
    },
    {
      "epoch": 0.07,
      "eval_loss": 1.0287655591964722,
      "eval_runtime": 326.3062,
      "eval_samples_per_second": 3.72,
      "eval_steps_per_second": 3.72,
      "step": 200
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.799994945526123,
      "learning_rate": 8.170731707317073e-05,
      "loss": 0.9942,
      "step": 201
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.8157487511634827,
      "learning_rate": 8.211382113821139e-05,
      "loss": 0.9711,
      "step": 202
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.0199737548828125,
      "learning_rate": 8.252032520325204e-05,
      "loss": 1.0726,
      "step": 203
    },
    {
      "epoch": 0.07,
      "grad_norm": 1.018051266670227,
      "learning_rate": 8.292682926829268e-05,
      "loss": 0.4108,
      "step": 204
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.7914999127388,
      "learning_rate": 8.333333333333334e-05,
      "loss": 1.0264,
      "step": 205
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9539749622344971,
      "learning_rate": 8.373983739837398e-05,
      "loss": 1.2872,
      "step": 206
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8810439705848694,
      "learning_rate": 8.414634146341464e-05,
      "loss": 1.1894,
      "step": 207
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.927557110786438,
      "learning_rate": 8.455284552845529e-05,
      "loss": 1.0429,
      "step": 208
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9995114803314209,
      "learning_rate": 8.495934959349594e-05,
      "loss": 1.4287,
      "step": 209
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9358929991722107,
      "learning_rate": 8.53658536585366e-05,
      "loss": 1.0268,
      "step": 210
    },
    {
      "epoch": 0.08,
      "eval_loss": 1.0142097473144531,
      "eval_runtime": 326.217,
      "eval_samples_per_second": 3.721,
      "eval_steps_per_second": 3.721,
      "step": 210
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9699081182479858,
      "learning_rate": 8.577235772357723e-05,
      "loss": 1.0984,
      "step": 211
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.2407060861587524,
      "learning_rate": 8.61788617886179e-05,
      "loss": 1.0904,
      "step": 212
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9110095500946045,
      "learning_rate": 8.658536585365854e-05,
      "loss": 1.0374,
      "step": 213
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9530538320541382,
      "learning_rate": 8.699186991869919e-05,
      "loss": 1.1573,
      "step": 214
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9679622650146484,
      "learning_rate": 8.739837398373984e-05,
      "loss": 1.3791,
      "step": 215
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9601581692695618,
      "learning_rate": 8.78048780487805e-05,
      "loss": 1.0592,
      "step": 216
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0071333646774292,
      "learning_rate": 8.821138211382113e-05,
      "loss": 0.8911,
      "step": 217
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.3248298168182373,
      "learning_rate": 8.86178861788618e-05,
      "loss": 1.0545,
      "step": 218
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9773963689804077,
      "learning_rate": 8.902439024390244e-05,
      "loss": 1.1423,
      "step": 219
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9770312905311584,
      "learning_rate": 8.943089430894309e-05,
      "loss": 1.5965,
      "step": 220
    },
    {
      "epoch": 0.08,
      "eval_loss": 1.0004335641860962,
      "eval_runtime": 326.375,
      "eval_samples_per_second": 3.72,
      "eval_steps_per_second": 3.72,
      "step": 220
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8625432252883911,
      "learning_rate": 8.983739837398374e-05,
      "loss": 1.1743,
      "step": 221
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.939493715763092,
      "learning_rate": 9.02439024390244e-05,
      "loss": 1.4241,
      "step": 222
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8956961631774902,
      "learning_rate": 9.065040650406505e-05,
      "loss": 0.3218,
      "step": 223
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0732840299606323,
      "learning_rate": 9.105691056910569e-05,
      "loss": 1.3027,
      "step": 224
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9051477313041687,
      "learning_rate": 9.146341463414635e-05,
      "loss": 1.2285,
      "step": 225
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9119907021522522,
      "learning_rate": 9.1869918699187e-05,
      "loss": 1.2564,
      "step": 226
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.102318286895752,
      "learning_rate": 9.227642276422765e-05,
      "loss": 0.7164,
      "step": 227
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0719971656799316,
      "learning_rate": 9.26829268292683e-05,
      "loss": 1.1222,
      "step": 228
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.0267590284347534,
      "learning_rate": 9.308943089430895e-05,
      "loss": 1.5062,
      "step": 229
    },
    {
      "epoch": 0.08,
      "grad_norm": 1.1460020542144775,
      "learning_rate": 9.349593495934959e-05,
      "loss": 1.2783,
      "step": 230
    },
    {
      "epoch": 0.08,
      "eval_loss": 0.9867081046104431,
      "eval_runtime": 326.2496,
      "eval_samples_per_second": 3.721,
      "eval_steps_per_second": 3.721,
      "step": 230
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.9326720833778381,
      "learning_rate": 9.390243902439024e-05,
      "loss": 1.2625,
      "step": 231
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.8374457359313965,
      "learning_rate": 9.43089430894309e-05,
      "loss": 1.0007,
      "step": 232
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9565045237541199,
      "learning_rate": 9.471544715447155e-05,
      "loss": 0.886,
      "step": 233
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0060887336730957,
      "learning_rate": 9.51219512195122e-05,
      "loss": 1.226,
      "step": 234
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.965057373046875,
      "learning_rate": 9.552845528455285e-05,
      "loss": 1.2974,
      "step": 235
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9149584174156189,
      "learning_rate": 9.59349593495935e-05,
      "loss": 1.1341,
      "step": 236
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9415076375007629,
      "learning_rate": 9.634146341463415e-05,
      "loss": 1.1951,
      "step": 237
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8042377829551697,
      "learning_rate": 9.674796747967481e-05,
      "loss": 1.5786,
      "step": 238
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0071464776992798,
      "learning_rate": 9.715447154471545e-05,
      "loss": 0.915,
      "step": 239
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0512903928756714,
      "learning_rate": 9.75609756097561e-05,
      "loss": 0.9203,
      "step": 240
    },
    {
      "epoch": 0.09,
      "eval_loss": 0.9765913486480713,
      "eval_runtime": 326.4291,
      "eval_samples_per_second": 3.719,
      "eval_steps_per_second": 3.719,
      "step": 240
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9783133864402771,
      "learning_rate": 9.796747967479674e-05,
      "loss": 0.8083,
      "step": 241
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0788142681121826,
      "learning_rate": 9.837398373983741e-05,
      "loss": 1.1461,
      "step": 242
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8150444030761719,
      "learning_rate": 9.878048780487805e-05,
      "loss": 0.5311,
      "step": 243
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8614550232887268,
      "learning_rate": 9.91869918699187e-05,
      "loss": 0.3778,
      "step": 244
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.261496663093567,
      "learning_rate": 9.959349593495935e-05,
      "loss": 1.2005,
      "step": 245
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9277626276016235,
      "learning_rate": 0.0001,
      "loss": 0.6729,
      "step": 246
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.0038126707077026,
      "learning_rate": 9.999999609013937e-05,
      "loss": 1.1888,
      "step": 247
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9760969281196594,
      "learning_rate": 9.999998436055809e-05,
      "loss": 1.0591,
      "step": 248
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9807142019271851,
      "learning_rate": 9.999996481125796e-05,
      "loss": 1.5231,
      "step": 249
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.7625811696052551,
      "learning_rate": 9.999993744224208e-05,
      "loss": 0.6553,
      "step": 250
    },
    {
      "epoch": 0.09,
      "eval_loss": 0.9678136706352234,
      "eval_runtime": 325.6397,
      "eval_samples_per_second": 3.728,
      "eval_steps_per_second": 3.728,
      "step": 250
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8316835165023804,
      "learning_rate": 9.999990225351471e-05,
      "loss": 1.1123,
      "step": 251
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.090338945388794,
      "learning_rate": 9.999985924508137e-05,
      "loss": 1.3295,
      "step": 252
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9618340134620667,
      "learning_rate": 9.999980841694876e-05,
      "loss": 1.1545,
      "step": 253
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2908791303634644,
      "learning_rate": 9.999974976912485e-05,
      "loss": 0.5995,
      "step": 254
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.9467799663543701,
      "learning_rate": 9.99996833016188e-05,
      "loss": 0.5124,
      "step": 255
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.189963459968567,
      "learning_rate": 9.999960901444101e-05,
      "loss": 1.0339,
      "step": 256
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.8844425082206726,
      "learning_rate": 9.999952690760311e-05,
      "loss": 0.6512,
      "step": 257
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.1616827249526978,
      "learning_rate": 9.99994369811179e-05,
      "loss": 1.301,
      "step": 258
    },
    {
      "epoch": 0.09,
      "grad_norm": 1.2586623430252075,
      "learning_rate": 9.999933923499951e-05,
      "loss": 1.3988,
      "step": 259
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9692146182060242,
      "learning_rate": 9.999923366926318e-05,
      "loss": 1.1402,
      "step": 260
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.9588657021522522,
      "eval_runtime": 325.3078,
      "eval_samples_per_second": 3.732,
      "eval_steps_per_second": 3.732,
      "step": 260
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9378979206085205,
      "learning_rate": 9.999912028392541e-05,
      "loss": 1.407,
      "step": 261
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9625810980796814,
      "learning_rate": 9.999899907900399e-05,
      "loss": 0.7351,
      "step": 262
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8823745250701904,
      "learning_rate": 9.999887005451781e-05,
      "loss": 0.8858,
      "step": 263
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8266088962554932,
      "learning_rate": 9.999873321048709e-05,
      "loss": 0.5598,
      "step": 264
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8318604230880737,
      "learning_rate": 9.999858854693322e-05,
      "loss": 1.0751,
      "step": 265
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0188854932785034,
      "learning_rate": 9.999843606387881e-05,
      "loss": 0.7,
      "step": 266
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9574480056762695,
      "learning_rate": 9.999827576134774e-05,
      "loss": 1.3393,
      "step": 267
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9648979902267456,
      "learning_rate": 9.999810763936506e-05,
      "loss": 1.0392,
      "step": 268
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0630820989608765,
      "learning_rate": 9.999793169795706e-05,
      "loss": 0.8513,
      "step": 269
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.019271969795227,
      "learning_rate": 9.999774793715127e-05,
      "loss": 1.0787,
      "step": 270
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.9519684314727783,
      "eval_runtime": 325.2146,
      "eval_samples_per_second": 3.733,
      "eval_steps_per_second": 3.733,
      "step": 270
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.244348168373108,
      "learning_rate": 9.999755635697641e-05,
      "loss": 0.9236,
      "step": 271
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.8256751298904419,
      "learning_rate": 9.999735695746243e-05,
      "loss": 0.585,
      "step": 272
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9725598692893982,
      "learning_rate": 9.999714973864058e-05,
      "loss": 1.2308,
      "step": 273
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0194612741470337,
      "learning_rate": 9.999693470054321e-05,
      "loss": 1.2803,
      "step": 274
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9247444868087769,
      "learning_rate": 9.999671184320397e-05,
      "loss": 0.7972,
      "step": 275
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9991945624351501,
      "learning_rate": 9.99964811666577e-05,
      "loss": 0.9197,
      "step": 276
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.920225977897644,
      "learning_rate": 9.99962426709405e-05,
      "loss": 1.0605,
      "step": 277
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0983390808105469,
      "learning_rate": 9.999599635608964e-05,
      "loss": 0.5206,
      "step": 278
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.3666099309921265,
      "learning_rate": 9.999574222214367e-05,
      "loss": 0.8541,
      "step": 279
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.1414284706115723,
      "learning_rate": 9.999548026914232e-05,
      "loss": 1.1514,
      "step": 280
    },
    {
      "epoch": 0.1,
      "eval_loss": 0.9441777467727661,
      "eval_runtime": 325.2598,
      "eval_samples_per_second": 3.732,
      "eval_steps_per_second": 3.732,
      "step": 280
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.9987568855285645,
      "learning_rate": 9.999521049712656e-05,
      "loss": 1.1395,
      "step": 281
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0681555271148682,
      "learning_rate": 9.999493290613859e-05,
      "loss": 1.1423,
      "step": 282
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0330630540847778,
      "learning_rate": 9.99946474962218e-05,
      "loss": 0.7758,
      "step": 283
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.0309786796569824,
      "learning_rate": 9.999435426742085e-05,
      "loss": 0.9989,
      "step": 284
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.076762080192566,
      "learning_rate": 9.999405321978159e-05,
      "loss": 0.6259,
      "step": 285
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.3180322647094727,
      "learning_rate": 9.999374435335112e-05,
      "loss": 0.7263,
      "step": 286
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9275753498077393,
      "learning_rate": 9.99934276681777e-05,
      "loss": 0.598,
      "step": 287
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8699234127998352,
      "learning_rate": 9.999310316431092e-05,
      "loss": 0.5035,
      "step": 288
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.049354910850525,
      "learning_rate": 9.999277084180147e-05,
      "loss": 0.9862,
      "step": 289
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1622639894485474,
      "learning_rate": 9.999243070070137e-05,
      "loss": 0.8874,
      "step": 290
    },
    {
      "epoch": 0.11,
      "eval_loss": 0.9381031394004822,
      "eval_runtime": 325.3056,
      "eval_samples_per_second": 3.732,
      "eval_steps_per_second": 3.732,
      "step": 290
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9852805137634277,
      "learning_rate": 9.999208274106378e-05,
      "loss": 1.2315,
      "step": 291
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9185624718666077,
      "learning_rate": 9.999172696294314e-05,
      "loss": 0.7952,
      "step": 292
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0557913780212402,
      "learning_rate": 9.999136336639509e-05,
      "loss": 0.841,
      "step": 293
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0769879817962646,
      "learning_rate": 9.99909919514765e-05,
      "loss": 1.2972,
      "step": 294
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0326718091964722,
      "learning_rate": 9.999061271824544e-05,
      "loss": 0.9179,
      "step": 295
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9868219494819641,
      "learning_rate": 9.999022566676123e-05,
      "loss": 0.9148,
      "step": 296
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8961410522460938,
      "learning_rate": 9.998983079708442e-05,
      "loss": 0.5898,
      "step": 297
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.020047664642334,
      "learning_rate": 9.998942810927673e-05,
      "loss": 1.4796,
      "step": 298
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.906444787979126,
      "learning_rate": 9.998901760340115e-05,
      "loss": 1.3382,
      "step": 299
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0148162841796875,
      "learning_rate": 9.99885992795219e-05,
      "loss": 1.1606,
      "step": 300
    },
    {
      "epoch": 0.11,
      "eval_loss": 0.9282341003417969,
      "eval_runtime": 327.5054,
      "eval_samples_per_second": 3.707,
      "eval_steps_per_second": 3.707,
      "step": 300
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0428061485290527,
      "learning_rate": 9.998817313770439e-05,
      "loss": 0.9052,
      "step": 301
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9352127313613892,
      "learning_rate": 9.998773917801525e-05,
      "loss": 1.1539,
      "step": 302
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0218499898910522,
      "learning_rate": 9.998729740052237e-05,
      "loss": 0.6392,
      "step": 303
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.7467933893203735,
      "learning_rate": 9.998684780529484e-05,
      "loss": 0.4947,
      "step": 304
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9980430006980896,
      "learning_rate": 9.998639039240299e-05,
      "loss": 0.9528,
      "step": 305
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.8421357870101929,
      "learning_rate": 9.998592516191832e-05,
      "loss": 0.3521,
      "step": 306
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.079756259918213,
      "learning_rate": 9.99854521139136e-05,
      "loss": 0.8174,
      "step": 307
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.9219433665275574,
      "learning_rate": 9.998497124846282e-05,
      "loss": 0.7362,
      "step": 308
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1924407482147217,
      "learning_rate": 9.998448256564118e-05,
      "loss": 0.7786,
      "step": 309
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.3578217029571533,
      "learning_rate": 9.998398606552513e-05,
      "loss": 1.2103,
      "step": 310
    },
    {
      "epoch": 0.11,
      "eval_loss": 0.9244602918624878,
      "eval_runtime": 326.9799,
      "eval_samples_per_second": 3.713,
      "eval_steps_per_second": 3.713,
      "step": 310
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0997436046600342,
      "learning_rate": 9.998348174819229e-05,
      "loss": 0.9806,
      "step": 311
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.0640251636505127,
      "learning_rate": 9.998296961372153e-05,
      "loss": 0.7293,
      "step": 312
    },
    {
      "epoch": 0.11,
      "grad_norm": 1.1742395162582397,
      "learning_rate": 9.998244966219298e-05,
      "loss": 1.1729,
      "step": 313
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.198685884475708,
      "learning_rate": 9.998192189368794e-05,
      "loss": 0.9521,
      "step": 314
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9107562899589539,
      "learning_rate": 9.998138630828892e-05,
      "loss": 0.7657,
      "step": 315
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7683629989624023,
      "learning_rate": 9.998084290607972e-05,
      "loss": 0.9737,
      "step": 316
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0940275192260742,
      "learning_rate": 9.99802916871453e-05,
      "loss": 1.2287,
      "step": 317
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9643294811248779,
      "learning_rate": 9.997973265157192e-05,
      "loss": 1.0949,
      "step": 318
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0150808095932007,
      "learning_rate": 9.997916579944695e-05,
      "loss": 1.294,
      "step": 319
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1065548658370972,
      "learning_rate": 9.997859113085906e-05,
      "loss": 1.2284,
      "step": 320
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.9165626168251038,
      "eval_runtime": 326.9318,
      "eval_samples_per_second": 3.713,
      "eval_steps_per_second": 3.713,
      "step": 320
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9520495533943176,
      "learning_rate": 9.997800864589812e-05,
      "loss": 0.6237,
      "step": 321
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.935294508934021,
      "learning_rate": 9.997741834465524e-05,
      "loss": 0.7892,
      "step": 322
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9223976135253906,
      "learning_rate": 9.997682022722275e-05,
      "loss": 0.8712,
      "step": 323
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9312877058982849,
      "learning_rate": 9.997621429369416e-05,
      "loss": 0.8371,
      "step": 324
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1610571146011353,
      "learning_rate": 9.997560054416426e-05,
      "loss": 1.1179,
      "step": 325
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1732457876205444,
      "learning_rate": 9.997497897872904e-05,
      "loss": 1.1057,
      "step": 326
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.6929117441177368,
      "learning_rate": 9.997434959748569e-05,
      "loss": 0.7018,
      "step": 327
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0455793142318726,
      "learning_rate": 9.997371240053265e-05,
      "loss": 0.9698,
      "step": 328
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9631350636482239,
      "learning_rate": 9.997306738796957e-05,
      "loss": 0.7431,
      "step": 329
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8899025917053223,
      "learning_rate": 9.997241455989734e-05,
      "loss": 0.9372,
      "step": 330
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.9118994474411011,
      "eval_runtime": 326.619,
      "eval_samples_per_second": 3.717,
      "eval_steps_per_second": 3.717,
      "step": 330
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9096298813819885,
      "learning_rate": 9.997175391641805e-05,
      "loss": 0.9547,
      "step": 331
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8569766283035278,
      "learning_rate": 9.997108545763501e-05,
      "loss": 0.7453,
      "step": 332
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.7623046040534973,
      "learning_rate": 9.997040918365279e-05,
      "loss": 0.6156,
      "step": 333
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.9908808469772339,
      "learning_rate": 9.996972509457712e-05,
      "loss": 0.726,
      "step": 334
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0667710304260254,
      "learning_rate": 9.996903319051502e-05,
      "loss": 0.9045,
      "step": 335
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.4858301877975464,
      "learning_rate": 9.996833347157468e-05,
      "loss": 0.9484,
      "step": 336
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.1142442226409912,
      "learning_rate": 9.996762593786555e-05,
      "loss": 1.261,
      "step": 337
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.8562672138214111,
      "learning_rate": 9.996691058949827e-05,
      "loss": 0.81,
      "step": 338
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0218836069107056,
      "learning_rate": 9.996618742658471e-05,
      "loss": 0.9332,
      "step": 339
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.0430124998092651,
      "learning_rate": 9.996545644923798e-05,
      "loss": 1.3817,
      "step": 340
    },
    {
      "epoch": 0.12,
      "eval_loss": 0.9044989943504333,
      "eval_runtime": 326.6943,
      "eval_samples_per_second": 3.716,
      "eval_steps_per_second": 3.716,
      "step": 340
    },
    {
      "epoch": 0.12,
      "grad_norm": 1.158512830734253,
      "learning_rate": 9.996471765757241e-05,
      "loss": 0.7842,
      "step": 341
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0737135410308838,
      "learning_rate": 9.996397105170353e-05,
      "loss": 1.393,
      "step": 342
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8984323740005493,
      "learning_rate": 9.996321663174811e-05,
      "loss": 0.7327,
      "step": 343
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1021811962127686,
      "learning_rate": 9.996245439782413e-05,
      "loss": 0.728,
      "step": 344
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0985757112503052,
      "learning_rate": 9.99616843500508e-05,
      "loss": 1.1889,
      "step": 345
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0747137069702148,
      "learning_rate": 9.996090648854856e-05,
      "loss": 1.1921,
      "step": 346
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0248847007751465,
      "learning_rate": 9.996012081343904e-05,
      "loss": 0.9078,
      "step": 347
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0538058280944824,
      "learning_rate": 9.995932732484516e-05,
      "loss": 0.8922,
      "step": 348
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9366456866264343,
      "learning_rate": 9.995852602289097e-05,
      "loss": 0.9803,
      "step": 349
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8727009296417236,
      "learning_rate": 9.995771690770184e-05,
      "loss": 0.858,
      "step": 350
    },
    {
      "epoch": 0.13,
      "eval_loss": 0.9003121852874756,
      "eval_runtime": 327.6689,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 350
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1546971797943115,
      "learning_rate": 9.995689997940425e-05,
      "loss": 0.9925,
      "step": 351
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.2265123128890991,
      "learning_rate": 9.9956075238126e-05,
      "loss": 1.2278,
      "step": 352
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1120303869247437,
      "learning_rate": 9.995524268399607e-05,
      "loss": 0.8254,
      "step": 353
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.970176637172699,
      "learning_rate": 9.995440231714469e-05,
      "loss": 0.6803,
      "step": 354
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0955147743225098,
      "learning_rate": 9.995355413770322e-05,
      "loss": 1.2819,
      "step": 355
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0591999292373657,
      "learning_rate": 9.995269814580439e-05,
      "loss": 0.9392,
      "step": 356
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0823293924331665,
      "learning_rate": 9.995183434158202e-05,
      "loss": 0.8478,
      "step": 357
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0338075160980225,
      "learning_rate": 9.995096272517122e-05,
      "loss": 1.1368,
      "step": 358
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.3271547555923462,
      "learning_rate": 9.99500832967083e-05,
      "loss": 1.3568,
      "step": 359
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0851223468780518,
      "learning_rate": 9.994919605633081e-05,
      "loss": 1.0559,
      "step": 360
    },
    {
      "epoch": 0.13,
      "eval_loss": 0.8969533443450928,
      "eval_runtime": 327.8208,
      "eval_samples_per_second": 3.703,
      "eval_steps_per_second": 3.703,
      "step": 360
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1121644973754883,
      "learning_rate": 9.994830100417753e-05,
      "loss": 0.5014,
      "step": 361
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.257051944732666,
      "learning_rate": 9.99473981403884e-05,
      "loss": 1.139,
      "step": 362
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1944279670715332,
      "learning_rate": 9.994648746510463e-05,
      "loss": 1.12,
      "step": 363
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0565859079360962,
      "learning_rate": 9.994556897846865e-05,
      "loss": 0.9484,
      "step": 364
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.8487881422042847,
      "learning_rate": 9.994464268062412e-05,
      "loss": 0.6576,
      "step": 365
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.0621976852416992,
      "learning_rate": 9.994370857171588e-05,
      "loss": 1.1784,
      "step": 366
    },
    {
      "epoch": 0.13,
      "grad_norm": 1.1692007780075073,
      "learning_rate": 9.994276665189006e-05,
      "loss": 0.8847,
      "step": 367
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.9568784236907959,
      "learning_rate": 9.994181692129394e-05,
      "loss": 0.7769,
      "step": 368
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0426416397094727,
      "learning_rate": 9.994085938007606e-05,
      "loss": 0.9275,
      "step": 369
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1558138132095337,
      "learning_rate": 9.993989402838617e-05,
      "loss": 1.3411,
      "step": 370
    },
    {
      "epoch": 0.14,
      "eval_loss": 0.8923903107643127,
      "eval_runtime": 327.9021,
      "eval_samples_per_second": 3.702,
      "eval_steps_per_second": 3.702,
      "step": 370
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9626848697662354,
      "learning_rate": 9.993892086637524e-05,
      "loss": 0.9058,
      "step": 371
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0112080574035645,
      "learning_rate": 9.993793989419549e-05,
      "loss": 0.7114,
      "step": 372
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.008086085319519,
      "learning_rate": 9.993695111200032e-05,
      "loss": 1.0677,
      "step": 373
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0170484781265259,
      "learning_rate": 9.993595451994439e-05,
      "loss": 0.9847,
      "step": 374
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0283879041671753,
      "learning_rate": 9.993495011818352e-05,
      "loss": 0.8521,
      "step": 375
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1425178050994873,
      "learning_rate": 9.993393790687484e-05,
      "loss": 0.951,
      "step": 376
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2385247945785522,
      "learning_rate": 9.993291788617663e-05,
      "loss": 1.0197,
      "step": 377
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2062256336212158,
      "learning_rate": 9.99318900562484e-05,
      "loss": 1.0866,
      "step": 378
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9161548018455505,
      "learning_rate": 9.993085441725095e-05,
      "loss": 0.7098,
      "step": 379
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0275720357894897,
      "learning_rate": 9.99298109693462e-05,
      "loss": 0.5382,
      "step": 380
    },
    {
      "epoch": 0.14,
      "eval_loss": 0.889988124370575,
      "eval_runtime": 327.6569,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 380
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.248546838760376,
      "learning_rate": 9.992875971269736e-05,
      "loss": 1.0468,
      "step": 381
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.4772382974624634,
      "learning_rate": 9.992770064746882e-05,
      "loss": 0.8407,
      "step": 382
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1852599382400513,
      "learning_rate": 9.992663377382623e-05,
      "loss": 1.472,
      "step": 383
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2033355236053467,
      "learning_rate": 9.992555909193643e-05,
      "loss": 1.1356,
      "step": 384
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1887590885162354,
      "learning_rate": 9.992447660196753e-05,
      "loss": 0.7733,
      "step": 385
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.365098476409912,
      "learning_rate": 9.992338630408877e-05,
      "loss": 0.8272,
      "step": 386
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0497910976409912,
      "learning_rate": 9.992228819847071e-05,
      "loss": 0.7711,
      "step": 387
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1315890550613403,
      "learning_rate": 9.992118228528509e-05,
      "loss": 0.77,
      "step": 388
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9317522048950195,
      "learning_rate": 9.992006856470484e-05,
      "loss": 0.7035,
      "step": 389
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.9163861274719238,
      "learning_rate": 9.991894703690414e-05,
      "loss": 0.8994,
      "step": 390
    },
    {
      "epoch": 0.14,
      "eval_loss": 0.8876945972442627,
      "eval_runtime": 327.6532,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 390
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.0113011598587036,
      "learning_rate": 9.991781770205841e-05,
      "loss": 0.8643,
      "step": 391
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.2991456985473633,
      "learning_rate": 9.991668056034427e-05,
      "loss": 0.5059,
      "step": 392
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.1037832498550415,
      "learning_rate": 9.991553561193953e-05,
      "loss": 0.956,
      "step": 393
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.3028960227966309,
      "learning_rate": 9.991438285702331e-05,
      "loss": 0.6762,
      "step": 394
    },
    {
      "epoch": 0.14,
      "grad_norm": 1.4279154539108276,
      "learning_rate": 9.991322229577585e-05,
      "loss": 1.0079,
      "step": 395
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9074159264564514,
      "learning_rate": 9.991205392837868e-05,
      "loss": 0.589,
      "step": 396
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0587316751480103,
      "learning_rate": 9.99108777550145e-05,
      "loss": 0.6162,
      "step": 397
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.4230082035064697,
      "learning_rate": 9.99096937758673e-05,
      "loss": 1.0554,
      "step": 398
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1686733961105347,
      "learning_rate": 9.99085019911222e-05,
      "loss": 0.8521,
      "step": 399
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8225346803665161,
      "learning_rate": 9.990730240096561e-05,
      "loss": 0.5415,
      "step": 400
    },
    {
      "epoch": 0.15,
      "eval_loss": 0.881127119064331,
      "eval_runtime": 327.59,
      "eval_samples_per_second": 3.706,
      "eval_steps_per_second": 3.706,
      "step": 400
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9785767793655396,
      "learning_rate": 9.990609500558515e-05,
      "loss": 1.0061,
      "step": 401
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9121781587600708,
      "learning_rate": 9.990487980516962e-05,
      "loss": 0.837,
      "step": 402
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.16127610206604,
      "learning_rate": 9.99036567999091e-05,
      "loss": 1.0882,
      "step": 403
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.5153783559799194,
      "learning_rate": 9.990242598999486e-05,
      "loss": 1.3082,
      "step": 404
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0372884273529053,
      "learning_rate": 9.990118737561938e-05,
      "loss": 0.8811,
      "step": 405
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9651708006858826,
      "learning_rate": 9.989994095697636e-05,
      "loss": 0.8998,
      "step": 406
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.115947961807251,
      "learning_rate": 9.989868673426075e-05,
      "loss": 1.1211,
      "step": 407
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.122528314590454,
      "learning_rate": 9.98974247076687e-05,
      "loss": 0.7681,
      "step": 408
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1726967096328735,
      "learning_rate": 9.989615487739759e-05,
      "loss": 1.1305,
      "step": 409
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1397143602371216,
      "learning_rate": 9.989487724364601e-05,
      "loss": 0.8303,
      "step": 410
    },
    {
      "epoch": 0.15,
      "eval_loss": 0.8766501545906067,
      "eval_runtime": 327.874,
      "eval_samples_per_second": 3.703,
      "eval_steps_per_second": 3.703,
      "step": 410
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0417745113372803,
      "learning_rate": 9.989359180661378e-05,
      "loss": 1.0857,
      "step": 411
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.067773699760437,
      "learning_rate": 9.989229856650191e-05,
      "loss": 1.0254,
      "step": 412
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.976482093334198,
      "learning_rate": 9.989099752351269e-05,
      "loss": 0.8157,
      "step": 413
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2339369058609009,
      "learning_rate": 9.988968867784958e-05,
      "loss": 1.5125,
      "step": 414
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.244255542755127,
      "learning_rate": 9.988837202971726e-05,
      "loss": 1.1391,
      "step": 415
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.0673149824142456,
      "learning_rate": 9.988704757932168e-05,
      "loss": 1.1063,
      "step": 416
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1457414627075195,
      "learning_rate": 9.988571532686995e-05,
      "loss": 1.034,
      "step": 417
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.901581883430481,
      "learning_rate": 9.988437527257045e-05,
      "loss": 1.0877,
      "step": 418
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.1595642566680908,
      "learning_rate": 9.988302741663272e-05,
      "loss": 1.2469,
      "step": 419
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.9295127987861633,
      "learning_rate": 9.98816717592676e-05,
      "loss": 0.8498,
      "step": 420
    },
    {
      "epoch": 0.15,
      "eval_loss": 0.8719693422317505,
      "eval_runtime": 327.6427,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 420
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.079867959022522,
      "learning_rate": 9.988030830068709e-05,
      "loss": 0.8145,
      "step": 421
    },
    {
      "epoch": 0.15,
      "grad_norm": 1.2736891508102417,
      "learning_rate": 9.987893704110441e-05,
      "loss": 0.7041,
      "step": 422
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.8818795084953308,
      "learning_rate": 9.987755798073404e-05,
      "loss": 0.5195,
      "step": 423
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.188575267791748,
      "learning_rate": 9.987617111979167e-05,
      "loss": 0.8265,
      "step": 424
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9216428399085999,
      "learning_rate": 9.987477645849415e-05,
      "loss": 0.78,
      "step": 425
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1995275020599365,
      "learning_rate": 9.987337399705962e-05,
      "loss": 1.1789,
      "step": 426
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.8373411893844604,
      "learning_rate": 9.987196373570744e-05,
      "loss": 0.8771,
      "step": 427
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1435261964797974,
      "learning_rate": 9.987054567465815e-05,
      "loss": 0.9624,
      "step": 428
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.062085747718811,
      "learning_rate": 9.986911981413351e-05,
      "loss": 1.0131,
      "step": 429
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9780181050300598,
      "learning_rate": 9.986768615435654e-05,
      "loss": 0.7636,
      "step": 430
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.8682220578193665,
      "eval_runtime": 327.6755,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 430
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0371886491775513,
      "learning_rate": 9.986624469555146e-05,
      "loss": 0.5906,
      "step": 431
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.4337824583053589,
      "learning_rate": 9.986479543794367e-05,
      "loss": 1.2759,
      "step": 432
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9549670815467834,
      "learning_rate": 9.986333838175987e-05,
      "loss": 0.4386,
      "step": 433
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1188794374465942,
      "learning_rate": 9.986187352722791e-05,
      "loss": 0.9073,
      "step": 434
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.3983302116394043,
      "learning_rate": 9.986040087457688e-05,
      "loss": 1.1357,
      "step": 435
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0847103595733643,
      "learning_rate": 9.985892042403712e-05,
      "loss": 0.5628,
      "step": 436
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1598190069198608,
      "learning_rate": 9.985743217584016e-05,
      "loss": 0.8207,
      "step": 437
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8508354425430298,
      "learning_rate": 9.985593613021872e-05,
      "loss": 0.8984,
      "step": 438
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0188215970993042,
      "learning_rate": 9.985443228740681e-05,
      "loss": 0.977,
      "step": 439
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8284507393836975,
      "learning_rate": 9.98529206476396e-05,
      "loss": 0.5136,
      "step": 440
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.8646613359451294,
      "eval_runtime": 327.6976,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 440
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0171877145767212,
      "learning_rate": 9.985140121115352e-05,
      "loss": 0.8695,
      "step": 441
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1601454019546509,
      "learning_rate": 9.984987397818621e-05,
      "loss": 1.2097,
      "step": 442
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1360671520233154,
      "learning_rate": 9.984833894897647e-05,
      "loss": 0.7684,
      "step": 443
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8518962264060974,
      "learning_rate": 9.984679612376443e-05,
      "loss": 0.6738,
      "step": 444
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.0060768127441406,
      "learning_rate": 9.984524550279133e-05,
      "loss": 0.6646,
      "step": 445
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8444593548774719,
      "learning_rate": 9.984368708629972e-05,
      "loss": 0.5852,
      "step": 446
    },
    {
      "epoch": 0.16,
      "grad_norm": 1.1035454273223877,
      "learning_rate": 9.984212087453331e-05,
      "loss": 1.0368,
      "step": 447
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.8452848792076111,
      "learning_rate": 9.984054686773703e-05,
      "loss": 0.8586,
      "step": 448
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.7748528718948364,
      "learning_rate": 9.983896506615706e-05,
      "loss": 0.1133,
      "step": 449
    },
    {
      "epoch": 0.16,
      "grad_norm": 0.9527171850204468,
      "learning_rate": 9.98373754700408e-05,
      "loss": 0.764,
      "step": 450
    },
    {
      "epoch": 0.16,
      "eval_loss": 0.8620173931121826,
      "eval_runtime": 327.7226,
      "eval_samples_per_second": 3.704,
      "eval_steps_per_second": 3.704,
      "step": 450
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8623696565628052,
      "learning_rate": 9.983577807963685e-05,
      "loss": 0.6171,
      "step": 451
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8432179093360901,
      "learning_rate": 9.983417289519501e-05,
      "loss": 0.7506,
      "step": 452
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8420207500457764,
      "learning_rate": 9.983255991696632e-05,
      "loss": 0.569,
      "step": 453
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.8683856725692749,
      "learning_rate": 9.983093914520309e-05,
      "loss": 0.7279,
      "step": 454
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9396867156028748,
      "learning_rate": 9.982931058015874e-05,
      "loss": 0.5614,
      "step": 455
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.5803786516189575,
      "learning_rate": 9.982767422208801e-05,
      "loss": 1.1806,
      "step": 456
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0630779266357422,
      "learning_rate": 9.982603007124679e-05,
      "loss": 0.9929,
      "step": 457
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.18901789188385,
      "learning_rate": 9.982437812789222e-05,
      "loss": 1.1582,
      "step": 458
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9520888924598694,
      "learning_rate": 9.982271839228268e-05,
      "loss": 0.6314,
      "step": 459
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0704718828201294,
      "learning_rate": 9.982105086467772e-05,
      "loss": 0.6636,
      "step": 460
    },
    {
      "epoch": 0.17,
      "eval_loss": 0.8600401282310486,
      "eval_runtime": 327.3337,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 460
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9803924560546875,
      "learning_rate": 9.981937554533814e-05,
      "loss": 1.0832,
      "step": 461
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.027549386024475,
      "learning_rate": 9.981769243452595e-05,
      "loss": 0.8377,
      "step": 462
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.280500054359436,
      "learning_rate": 9.981600153250438e-05,
      "loss": 1.3847,
      "step": 463
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.1576601266860962,
      "learning_rate": 9.981430283953786e-05,
      "loss": 1.0744,
      "step": 464
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.2650495767593384,
      "learning_rate": 9.981259635589209e-05,
      "loss": 1.0767,
      "step": 465
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9910540580749512,
      "learning_rate": 9.981088208183392e-05,
      "loss": 0.998,
      "step": 466
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0992141962051392,
      "learning_rate": 9.980916001763148e-05,
      "loss": 1.1725,
      "step": 467
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.085988163948059,
      "learning_rate": 9.980743016355407e-05,
      "loss": 0.9399,
      "step": 468
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.047810435295105,
      "learning_rate": 9.980569251987226e-05,
      "loss": 0.8349,
      "step": 469
    },
    {
      "epoch": 0.17,
      "grad_norm": 0.9491277933120728,
      "learning_rate": 9.980394708685776e-05,
      "loss": 0.8124,
      "step": 470
    },
    {
      "epoch": 0.17,
      "eval_loss": 0.8559582233428955,
      "eval_runtime": 327.4116,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 470
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.1351910829544067,
      "learning_rate": 9.98021938647836e-05,
      "loss": 1.1822,
      "step": 471
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.2274141311645508,
      "learning_rate": 9.980043285392393e-05,
      "loss": 1.1977,
      "step": 472
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.2245728969573975,
      "learning_rate": 9.979866405455418e-05,
      "loss": 0.8378,
      "step": 473
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.374566674232483,
      "learning_rate": 9.979688746695098e-05,
      "loss": 0.9504,
      "step": 474
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0485947132110596,
      "learning_rate": 9.97951030913922e-05,
      "loss": 0.7812,
      "step": 475
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0290849208831787,
      "learning_rate": 9.979331092815686e-05,
      "loss": 1.1078,
      "step": 476
    },
    {
      "epoch": 0.17,
      "grad_norm": 1.0589619874954224,
      "learning_rate": 9.979151097752527e-05,
      "loss": 0.8694,
      "step": 477
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1698423624038696,
      "learning_rate": 9.978970323977894e-05,
      "loss": 1.1525,
      "step": 478
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0254608392715454,
      "learning_rate": 9.978788771520058e-05,
      "loss": 0.9336,
      "step": 479
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0395469665527344,
      "learning_rate": 9.978606440407412e-05,
      "loss": 0.9566,
      "step": 480
    },
    {
      "epoch": 0.18,
      "eval_loss": 0.8507027626037598,
      "eval_runtime": 327.3512,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 480
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.760418713092804,
      "learning_rate": 9.978423330668475e-05,
      "loss": 0.6164,
      "step": 481
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.2291877269744873,
      "learning_rate": 9.978239442331881e-05,
      "loss": 1.1554,
      "step": 482
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9477577209472656,
      "learning_rate": 9.978054775426389e-05,
      "loss": 0.9419,
      "step": 483
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0132375955581665,
      "learning_rate": 9.97786932998088e-05,
      "loss": 0.6345,
      "step": 484
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1971497535705566,
      "learning_rate": 9.97768310602436e-05,
      "loss": 1.1021,
      "step": 485
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1024694442749023,
      "learning_rate": 9.977496103585949e-05,
      "loss": 1.0036,
      "step": 486
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0824291706085205,
      "learning_rate": 9.977308322694895e-05,
      "loss": 1.1106,
      "step": 487
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1280707120895386,
      "learning_rate": 9.977119763380567e-05,
      "loss": 1.0314,
      "step": 488
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0214455127716064,
      "learning_rate": 9.976930425672454e-05,
      "loss": 0.9095,
      "step": 489
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.97348952293396,
      "learning_rate": 9.976740309600165e-05,
      "loss": 0.9548,
      "step": 490
    },
    {
      "epoch": 0.18,
      "eval_loss": 0.8478575348854065,
      "eval_runtime": 327.2593,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 490
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0172902345657349,
      "learning_rate": 9.976549415193437e-05,
      "loss": 0.7512,
      "step": 491
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.198768973350525,
      "learning_rate": 9.976357742482121e-05,
      "loss": 0.9435,
      "step": 492
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0586323738098145,
      "learning_rate": 9.976165291496196e-05,
      "loss": 0.5604,
      "step": 493
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0834991931915283,
      "learning_rate": 9.975972062265761e-05,
      "loss": 1.1083,
      "step": 494
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.8768467903137207,
      "learning_rate": 9.975778054821032e-05,
      "loss": 0.7315,
      "step": 495
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.6670326590538025,
      "learning_rate": 9.975583269192355e-05,
      "loss": 0.1626,
      "step": 496
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.332012414932251,
      "learning_rate": 9.97538770541019e-05,
      "loss": 0.8936,
      "step": 497
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.231974720954895,
      "learning_rate": 9.975191363505127e-05,
      "loss": 0.9882,
      "step": 498
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1001023054122925,
      "learning_rate": 9.974994243507866e-05,
      "loss": 1.1423,
      "step": 499
    },
    {
      "epoch": 0.18,
      "grad_norm": 0.9759262204170227,
      "learning_rate": 9.974796345449242e-05,
      "loss": 0.9723,
      "step": 500
    },
    {
      "epoch": 0.18,
      "eval_loss": 0.8481660485267639,
      "eval_runtime": 327.5961,
      "eval_samples_per_second": 3.706,
      "eval_steps_per_second": 3.706,
      "step": 500
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1992706060409546,
      "learning_rate": 9.9745976693602e-05,
      "loss": 0.9036,
      "step": 501
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1435718536376953,
      "learning_rate": 9.974398215271815e-05,
      "loss": 1.1238,
      "step": 502
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1875684261322021,
      "learning_rate": 9.974197983215278e-05,
      "loss": 0.9114,
      "step": 503
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.0531724691390991,
      "learning_rate": 9.973996973221907e-05,
      "loss": 1.0612,
      "step": 504
    },
    {
      "epoch": 0.18,
      "grad_norm": 1.1926544904708862,
      "learning_rate": 9.973795185323138e-05,
      "loss": 0.8669,
      "step": 505
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1264086961746216,
      "learning_rate": 9.973592619550528e-05,
      "loss": 1.3323,
      "step": 506
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.2676304578781128,
      "learning_rate": 9.973389275935759e-05,
      "loss": 1.1434,
      "step": 507
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9532020688056946,
      "learning_rate": 9.973185154510632e-05,
      "loss": 1.3853,
      "step": 508
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.0205210447311401,
      "learning_rate": 9.972980255307068e-05,
      "loss": 0.9607,
      "step": 509
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9765514135360718,
      "learning_rate": 9.972774578357117e-05,
      "loss": 0.8306,
      "step": 510
    },
    {
      "epoch": 0.19,
      "eval_loss": 0.8437750339508057,
      "eval_runtime": 327.2538,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 510
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.4054756164550781,
      "learning_rate": 9.972568123692943e-05,
      "loss": 1.1149,
      "step": 511
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.0071746110916138,
      "learning_rate": 9.972360891346833e-05,
      "loss": 0.7529,
      "step": 512
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.99601811170578,
      "learning_rate": 9.9721528813512e-05,
      "loss": 0.7835,
      "step": 513
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1219260692596436,
      "learning_rate": 9.971944093738575e-05,
      "loss": 0.7615,
      "step": 514
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.5208262205123901,
      "learning_rate": 9.971734528541608e-05,
      "loss": 0.9671,
      "step": 515
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.368390440940857,
      "learning_rate": 9.971524185793078e-05,
      "loss": 0.9615,
      "step": 516
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.0059301853179932,
      "learning_rate": 9.97131306552588e-05,
      "loss": 1.089,
      "step": 517
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1268367767333984,
      "learning_rate": 9.971101167773031e-05,
      "loss": 0.9721,
      "step": 518
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.221368670463562,
      "learning_rate": 9.970888492567671e-05,
      "loss": 1.0473,
      "step": 519
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9733850359916687,
      "learning_rate": 9.970675039943062e-05,
      "loss": 0.9721,
      "step": 520
    },
    {
      "epoch": 0.19,
      "eval_loss": 0.8396456837654114,
      "eval_runtime": 327.2846,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 520
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1364036798477173,
      "learning_rate": 9.970460809932586e-05,
      "loss": 0.8932,
      "step": 521
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.0552141666412354,
      "learning_rate": 9.970245802569749e-05,
      "loss": 1.121,
      "step": 522
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.098437786102295,
      "learning_rate": 9.970030017888175e-05,
      "loss": 0.9471,
      "step": 523
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.048923134803772,
      "learning_rate": 9.969813455921611e-05,
      "loss": 0.6184,
      "step": 524
    },
    {
      "epoch": 0.19,
      "grad_norm": 0.9921844601631165,
      "learning_rate": 9.969596116703927e-05,
      "loss": 0.8153,
      "step": 525
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.124369740486145,
      "learning_rate": 9.969378000269116e-05,
      "loss": 1.1591,
      "step": 526
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1854286193847656,
      "learning_rate": 9.969159106651286e-05,
      "loss": 0.9498,
      "step": 527
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.0754406452178955,
      "learning_rate": 9.968939435884674e-05,
      "loss": 1.1395,
      "step": 528
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.1052416563034058,
      "learning_rate": 9.968718988003636e-05,
      "loss": 0.9642,
      "step": 529
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.0246385335922241,
      "learning_rate": 9.968497763042643e-05,
      "loss": 0.6606,
      "step": 530
    },
    {
      "epoch": 0.19,
      "eval_loss": 0.8376800417900085,
      "eval_runtime": 327.5239,
      "eval_samples_per_second": 3.707,
      "eval_steps_per_second": 3.707,
      "step": 530
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.088755488395691,
      "learning_rate": 9.9682757610363e-05,
      "loss": 0.7012,
      "step": 531
    },
    {
      "epoch": 0.19,
      "grad_norm": 1.146515130996704,
      "learning_rate": 9.968052982019325e-05,
      "loss": 0.5646,
      "step": 532
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1840590238571167,
      "learning_rate": 9.967829426026556e-05,
      "loss": 1.0531,
      "step": 533
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8987073302268982,
      "learning_rate": 9.96760509309296e-05,
      "loss": 0.6998,
      "step": 534
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1376078128814697,
      "learning_rate": 9.96737998325362e-05,
      "loss": 1.2566,
      "step": 535
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.266257643699646,
      "learning_rate": 9.967154096543742e-05,
      "loss": 1.0303,
      "step": 536
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0580382347106934,
      "learning_rate": 9.966927432998651e-05,
      "loss": 0.7255,
      "step": 537
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.083937406539917,
      "learning_rate": 9.9666999926538e-05,
      "loss": 0.6665,
      "step": 538
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9462631940841675,
      "learning_rate": 9.966471775544759e-05,
      "loss": 0.6587,
      "step": 539
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0921152830123901,
      "learning_rate": 9.966242781707217e-05,
      "loss": 0.9091,
      "step": 540
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.8356728553771973,
      "eval_runtime": 327.311,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 540
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0871033668518066,
      "learning_rate": 9.966013011176989e-05,
      "loss": 0.9594,
      "step": 541
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0065350532531738,
      "learning_rate": 9.96578246399001e-05,
      "loss": 0.8593,
      "step": 542
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1094422340393066,
      "learning_rate": 9.965551140182335e-05,
      "loss": 0.7474,
      "step": 543
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1739447116851807,
      "learning_rate": 9.965319039790143e-05,
      "loss": 0.7987,
      "step": 544
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0183160305023193,
      "learning_rate": 9.965086162849733e-05,
      "loss": 0.6224,
      "step": 545
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9296939373016357,
      "learning_rate": 9.964852509397526e-05,
      "loss": 0.8479,
      "step": 546
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1030688285827637,
      "learning_rate": 9.964618079470062e-05,
      "loss": 0.7531,
      "step": 547
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9485145211219788,
      "learning_rate": 9.964382873104009e-05,
      "loss": 1.1927,
      "step": 548
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.094789981842041,
      "learning_rate": 9.964146890336148e-05,
      "loss": 0.767,
      "step": 549
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1076325178146362,
      "learning_rate": 9.963910131203386e-05,
      "loss": 1.0308,
      "step": 550
    },
    {
      "epoch": 0.2,
      "eval_loss": 0.8356127142906189,
      "eval_runtime": 327.3579,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 550
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1457374095916748,
      "learning_rate": 9.96367259574275e-05,
      "loss": 0.7339,
      "step": 551
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1681276559829712,
      "learning_rate": 9.963434283991393e-05,
      "loss": 0.7791,
      "step": 552
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0169419050216675,
      "learning_rate": 9.963195195986583e-05,
      "loss": 0.8278,
      "step": 553
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.2934491634368896,
      "learning_rate": 9.96295533176571e-05,
      "loss": 0.6318,
      "step": 554
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.8601409792900085,
      "learning_rate": 9.962714691366293e-05,
      "loss": 0.4753,
      "step": 555
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.133936882019043,
      "learning_rate": 9.962473274825962e-05,
      "loss": 0.6937,
      "step": 556
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.0340478420257568,
      "learning_rate": 9.962231082182474e-05,
      "loss": 0.8321,
      "step": 557
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.9816802144050598,
      "learning_rate": 9.961988113473708e-05,
      "loss": 0.8945,
      "step": 558
    },
    {
      "epoch": 0.2,
      "grad_norm": 1.1056146621704102,
      "learning_rate": 9.961744368737663e-05,
      "loss": 0.8213,
      "step": 559
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.7928311824798584,
      "learning_rate": 9.961499848012456e-05,
      "loss": 0.5154,
      "step": 560
    },
    {
      "epoch": 0.21,
      "eval_loss": 0.8339780569076538,
      "eval_runtime": 327.3067,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 560
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2290575504302979,
      "learning_rate": 9.961254551336334e-05,
      "loss": 0.9666,
      "step": 561
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2957661151885986,
      "learning_rate": 9.961008478747655e-05,
      "loss": 1.1982,
      "step": 562
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0971542596817017,
      "learning_rate": 9.960761630284907e-05,
      "loss": 0.8484,
      "step": 563
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.953036367893219,
      "learning_rate": 9.960514005986694e-05,
      "loss": 0.8474,
      "step": 564
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0240076780319214,
      "learning_rate": 9.960265605891744e-05,
      "loss": 0.7811,
      "step": 565
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0296927690505981,
      "learning_rate": 9.960016430038903e-05,
      "loss": 1.1162,
      "step": 566
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.071537971496582,
      "learning_rate": 9.959766478467145e-05,
      "loss": 1.0502,
      "step": 567
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.8144804239273071,
      "learning_rate": 9.959515751215557e-05,
      "loss": 0.4031,
      "step": 568
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1751326322555542,
      "learning_rate": 9.959264248323353e-05,
      "loss": 1.1542,
      "step": 569
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1022826433181763,
      "learning_rate": 9.959011969829866e-05,
      "loss": 0.8598,
      "step": 570
    },
    {
      "epoch": 0.21,
      "eval_loss": 0.8276901245117188,
      "eval_runtime": 327.5198,
      "eval_samples_per_second": 3.707,
      "eval_steps_per_second": 3.707,
      "step": 570
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9263461232185364,
      "learning_rate": 9.958758915774553e-05,
      "loss": 0.8597,
      "step": 571
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2210025787353516,
      "learning_rate": 9.958505086196987e-05,
      "loss": 0.821,
      "step": 572
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.1573150157928467,
      "learning_rate": 9.958250481136869e-05,
      "loss": 1.0628,
      "step": 573
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9953874945640564,
      "learning_rate": 9.957995100634015e-05,
      "loss": 0.6692,
      "step": 574
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9432519674301147,
      "learning_rate": 9.957738944728368e-05,
      "loss": 0.767,
      "step": 575
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.117294430732727,
      "learning_rate": 9.957482013459986e-05,
      "loss": 1.259,
      "step": 576
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.772933304309845,
      "learning_rate": 9.957224306869053e-05,
      "loss": 0.7243,
      "step": 577
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0624427795410156,
      "learning_rate": 9.956965824995871e-05,
      "loss": 0.9733,
      "step": 578
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0104694366455078,
      "learning_rate": 9.956706567880871e-05,
      "loss": 0.9578,
      "step": 579
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.24178946018219,
      "learning_rate": 9.956446535564594e-05,
      "loss": 1.2447,
      "step": 580
    },
    {
      "epoch": 0.21,
      "eval_loss": 0.8246873021125793,
      "eval_runtime": 327.304,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 580
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0477226972579956,
      "learning_rate": 9.95618572808771e-05,
      "loss": 1.0617,
      "step": 581
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2544986009597778,
      "learning_rate": 9.955924145491005e-05,
      "loss": 0.8818,
      "step": 582
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0142126083374023,
      "learning_rate": 9.955661787815391e-05,
      "loss": 0.6712,
      "step": 583
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.2064528465270996,
      "learning_rate": 9.955398655101902e-05,
      "loss": 1.1826,
      "step": 584
    },
    {
      "epoch": 0.21,
      "grad_norm": 0.9963505864143372,
      "learning_rate": 9.955134747391685e-05,
      "loss": 0.8581,
      "step": 585
    },
    {
      "epoch": 0.21,
      "grad_norm": 1.0992692708969116,
      "learning_rate": 9.954870064726017e-05,
      "loss": 0.7276,
      "step": 586
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7912733554840088,
      "learning_rate": 9.954604607146294e-05,
      "loss": 0.3748,
      "step": 587
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2960811853408813,
      "learning_rate": 9.954338374694029e-05,
      "loss": 1.0881,
      "step": 588
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9827867150306702,
      "learning_rate": 9.95407136741086e-05,
      "loss": 0.756,
      "step": 589
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8458946943283081,
      "learning_rate": 9.953803585338548e-05,
      "loss": 0.4413,
      "step": 590
    },
    {
      "epoch": 0.22,
      "eval_loss": 0.8228771090507507,
      "eval_runtime": 327.1813,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 590
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0875670909881592,
      "learning_rate": 9.95353502851897e-05,
      "loss": 1.1109,
      "step": 591
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2154154777526855,
      "learning_rate": 9.953265696994128e-05,
      "loss": 0.8039,
      "step": 592
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.4536972045898438,
      "learning_rate": 9.952995590806142e-05,
      "loss": 1.0297,
      "step": 593
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0598618984222412,
      "learning_rate": 9.952724709997259e-05,
      "loss": 0.6342,
      "step": 594
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9784420728683472,
      "learning_rate": 9.952453054609838e-05,
      "loss": 0.7657,
      "step": 595
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8810468316078186,
      "learning_rate": 9.952180624686369e-05,
      "loss": 0.5094,
      "step": 596
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.4341065883636475,
      "learning_rate": 9.951907420269457e-05,
      "loss": 0.8548,
      "step": 597
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.4510468244552612,
      "learning_rate": 9.95163344140183e-05,
      "loss": 1.2658,
      "step": 598
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8377417922019958,
      "learning_rate": 9.951358688126335e-05,
      "loss": 0.5939,
      "step": 599
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.203303575515747,
      "learning_rate": 9.951083160485944e-05,
      "loss": 0.9345,
      "step": 600
    },
    {
      "epoch": 0.22,
      "eval_loss": 0.8207150101661682,
      "eval_runtime": 327.387,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 600
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.360903263092041,
      "learning_rate": 9.950806858523748e-05,
      "loss": 0.8021,
      "step": 601
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9058175086975098,
      "learning_rate": 9.950529782282955e-05,
      "loss": 0.5615,
      "step": 602
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.0997648239135742,
      "learning_rate": 9.950251931806903e-05,
      "loss": 0.7993,
      "step": 603
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9863609075546265,
      "learning_rate": 9.949973307139045e-05,
      "loss": 0.745,
      "step": 604
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.7844063639640808,
      "learning_rate": 9.949693908322955e-05,
      "loss": 0.3577,
      "step": 605
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2611771821975708,
      "learning_rate": 9.94941373540233e-05,
      "loss": 1.063,
      "step": 606
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.1790293455123901,
      "learning_rate": 9.94913278842099e-05,
      "loss": 1.0482,
      "step": 607
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.9569603204727173,
      "learning_rate": 9.948851067422871e-05,
      "loss": 0.5137,
      "step": 608
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.3023709058761597,
      "learning_rate": 9.948568572452031e-05,
      "loss": 1.1234,
      "step": 609
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2228574752807617,
      "learning_rate": 9.948285303552654e-05,
      "loss": 0.8423,
      "step": 610
    },
    {
      "epoch": 0.22,
      "eval_loss": 0.816953182220459,
      "eval_runtime": 327.2974,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 610
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.152138590812683,
      "learning_rate": 9.94800126076904e-05,
      "loss": 0.6881,
      "step": 611
    },
    {
      "epoch": 0.22,
      "grad_norm": 0.8533918857574463,
      "learning_rate": 9.947716444145612e-05,
      "loss": 0.8224,
      "step": 612
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.3168138265609741,
      "learning_rate": 9.947430853726914e-05,
      "loss": 0.988,
      "step": 613
    },
    {
      "epoch": 0.22,
      "grad_norm": 1.2558847665786743,
      "learning_rate": 9.947144489557612e-05,
      "loss": 0.9225,
      "step": 614
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.2126314640045166,
      "learning_rate": 9.946857351682488e-05,
      "loss": 0.8006,
      "step": 615
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8736874461174011,
      "learning_rate": 9.946569440146452e-05,
      "loss": 0.3419,
      "step": 616
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3162871599197388,
      "learning_rate": 9.946280754994531e-05,
      "loss": 1.2447,
      "step": 617
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.8455754518508911,
      "learning_rate": 9.945991296271873e-05,
      "loss": 0.5868,
      "step": 618
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.4413223266601562,
      "learning_rate": 9.945701064023746e-05,
      "loss": 0.6976,
      "step": 619
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9476346969604492,
      "learning_rate": 9.945410058295546e-05,
      "loss": 0.9443,
      "step": 620
    },
    {
      "epoch": 0.23,
      "eval_loss": 0.8156238794326782,
      "eval_runtime": 327.2144,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 620
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.054233431816101,
      "learning_rate": 9.945118279132782e-05,
      "loss": 1.3627,
      "step": 621
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3350008726119995,
      "learning_rate": 9.944825726581084e-05,
      "loss": 0.8138,
      "step": 622
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.0361144542694092,
      "learning_rate": 9.944532400686209e-05,
      "loss": 0.6572,
      "step": 623
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9970215559005737,
      "learning_rate": 9.944238301494031e-05,
      "loss": 0.7536,
      "step": 624
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.4946709871292114,
      "learning_rate": 9.943943429050543e-05,
      "loss": 0.7754,
      "step": 625
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.2150723934173584,
      "learning_rate": 9.943647783401867e-05,
      "loss": 0.8586,
      "step": 626
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.0873425006866455,
      "learning_rate": 9.943351364594233e-05,
      "loss": 0.5972,
      "step": 627
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9278303384780884,
      "learning_rate": 9.943054172674003e-05,
      "loss": 0.6544,
      "step": 628
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1607599258422852,
      "learning_rate": 9.942756207687657e-05,
      "loss": 0.74,
      "step": 629
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1111189126968384,
      "learning_rate": 9.942457469681794e-05,
      "loss": 0.7075,
      "step": 630
    },
    {
      "epoch": 0.23,
      "eval_loss": 0.815135657787323,
      "eval_runtime": 327.3807,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 630
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.12138032913208,
      "learning_rate": 9.942157958703136e-05,
      "loss": 1.2631,
      "step": 631
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9274953007698059,
      "learning_rate": 9.941857674798523e-05,
      "loss": 0.9382,
      "step": 632
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.175951600074768,
      "learning_rate": 9.941556618014917e-05,
      "loss": 0.7657,
      "step": 633
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.1940786838531494,
      "learning_rate": 9.941254788399406e-05,
      "loss": 1.0515,
      "step": 634
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.3334087133407593,
      "learning_rate": 9.94095218599919e-05,
      "loss": 1.2101,
      "step": 635
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.027343988418579,
      "learning_rate": 9.940648810861597e-05,
      "loss": 0.5166,
      "step": 636
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.7913880348205566,
      "learning_rate": 9.940344663034071e-05,
      "loss": 1.0597,
      "step": 637
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.4586163759231567,
      "learning_rate": 9.940039742564182e-05,
      "loss": 0.8935,
      "step": 638
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.112516164779663,
      "learning_rate": 9.939734049499614e-05,
      "loss": 0.6545,
      "step": 639
    },
    {
      "epoch": 0.23,
      "grad_norm": 0.9575780034065247,
      "learning_rate": 9.939427583888178e-05,
      "loss": 0.7141,
      "step": 640
    },
    {
      "epoch": 0.23,
      "eval_loss": 0.8176533579826355,
      "eval_runtime": 327.016,
      "eval_samples_per_second": 3.712,
      "eval_steps_per_second": 3.712,
      "step": 640
    },
    {
      "epoch": 0.23,
      "grad_norm": 1.4482518434524536,
      "learning_rate": 9.939120345777806e-05,
      "loss": 1.0823,
      "step": 641
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1859896183013916,
      "learning_rate": 9.938812335216543e-05,
      "loss": 1.1128,
      "step": 642
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9205965995788574,
      "learning_rate": 9.938503552252563e-05,
      "loss": 0.8373,
      "step": 643
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.12591552734375,
      "learning_rate": 9.938193996934158e-05,
      "loss": 1.1991,
      "step": 644
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.102999210357666,
      "learning_rate": 9.937883669309741e-05,
      "loss": 0.9205,
      "step": 645
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0237016677856445,
      "learning_rate": 9.937572569427845e-05,
      "loss": 0.4926,
      "step": 646
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0192047357559204,
      "learning_rate": 9.937260697337123e-05,
      "loss": 0.2916,
      "step": 647
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.3133485317230225,
      "learning_rate": 9.936948053086352e-05,
      "loss": 1.0189,
      "step": 648
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9719817042350769,
      "learning_rate": 9.936634636724426e-05,
      "loss": 0.7309,
      "step": 649
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9258187413215637,
      "learning_rate": 9.936320448300364e-05,
      "loss": 0.8321,
      "step": 650
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.8093917369842529,
      "eval_runtime": 327.2781,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 650
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.2184230089187622,
      "learning_rate": 9.936005487863302e-05,
      "loss": 0.9028,
      "step": 651
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.8279833197593689,
      "learning_rate": 9.935689755462499e-05,
      "loss": 0.5078,
      "step": 652
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9921261072158813,
      "learning_rate": 9.935373251147331e-05,
      "loss": 0.6873,
      "step": 653
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0263558626174927,
      "learning_rate": 9.935055974967299e-05,
      "loss": 0.5695,
      "step": 654
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0412720441818237,
      "learning_rate": 9.934737926972024e-05,
      "loss": 0.7134,
      "step": 655
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0102465152740479,
      "learning_rate": 9.934419107211247e-05,
      "loss": 0.6527,
      "step": 656
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.0470749139785767,
      "learning_rate": 9.93409951573483e-05,
      "loss": 0.5357,
      "step": 657
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.158207893371582,
      "learning_rate": 9.933779152592753e-05,
      "loss": 0.771,
      "step": 658
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1137950420379639,
      "learning_rate": 9.93345801783512e-05,
      "loss": 0.6935,
      "step": 659
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.813948929309845,
      "learning_rate": 9.933136111512156e-05,
      "loss": 0.5258,
      "step": 660
    },
    {
      "epoch": 0.24,
      "eval_loss": 0.8091380596160889,
      "eval_runtime": 327.0763,
      "eval_samples_per_second": 3.712,
      "eval_steps_per_second": 3.712,
      "step": 660
    },
    {
      "epoch": 0.24,
      "grad_norm": 0.9806516170501709,
      "learning_rate": 9.932813433674204e-05,
      "loss": 0.1599,
      "step": 661
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.237111210823059,
      "learning_rate": 9.932489984371731e-05,
      "loss": 1.16,
      "step": 662
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.4969452619552612,
      "learning_rate": 9.932165763655319e-05,
      "loss": 1.1286,
      "step": 663
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.103185772895813,
      "learning_rate": 9.931840771575677e-05,
      "loss": 0.6107,
      "step": 664
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1281152963638306,
      "learning_rate": 9.931515008183633e-05,
      "loss": 1.2087,
      "step": 665
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.1380813121795654,
      "learning_rate": 9.931188473530132e-05,
      "loss": 0.791,
      "step": 666
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.4193660020828247,
      "learning_rate": 9.930861167666244e-05,
      "loss": 0.7798,
      "step": 667
    },
    {
      "epoch": 0.24,
      "grad_norm": 1.8080477714538574,
      "learning_rate": 9.930533090643155e-05,
      "loss": 0.7888,
      "step": 668
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0334244966506958,
      "learning_rate": 9.930204242512177e-05,
      "loss": 0.545,
      "step": 669
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0360954999923706,
      "learning_rate": 9.92987462332474e-05,
      "loss": 0.9137,
      "step": 670
    },
    {
      "epoch": 0.25,
      "eval_loss": 0.807817816734314,
      "eval_runtime": 327.0445,
      "eval_samples_per_second": 3.712,
      "eval_steps_per_second": 3.712,
      "step": 670
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2254188060760498,
      "learning_rate": 9.929544233132396e-05,
      "loss": 0.8552,
      "step": 671
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.1890597343444824,
      "learning_rate": 9.929213071986811e-05,
      "loss": 0.6828,
      "step": 672
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9906372427940369,
      "learning_rate": 9.928881139939781e-05,
      "loss": 0.5784,
      "step": 673
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0650447607040405,
      "learning_rate": 9.928548437043219e-05,
      "loss": 0.7768,
      "step": 674
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8480598330497742,
      "learning_rate": 9.928214963349155e-05,
      "loss": 0.4975,
      "step": 675
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.292184591293335,
      "learning_rate": 9.927880718909743e-05,
      "loss": 0.7787,
      "step": 676
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.064723253250122,
      "learning_rate": 9.927545703777259e-05,
      "loss": 0.9132,
      "step": 677
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.7522180080413818,
      "learning_rate": 9.927209918004095e-05,
      "loss": 0.1186,
      "step": 678
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2626142501831055,
      "learning_rate": 9.926873361642768e-05,
      "loss": 1.1011,
      "step": 679
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8493808507919312,
      "learning_rate": 9.926536034745911e-05,
      "loss": 0.4467,
      "step": 680
    },
    {
      "epoch": 0.25,
      "eval_loss": 0.8066816329956055,
      "eval_runtime": 327.2465,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 680
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2501461505889893,
      "learning_rate": 9.926197937366284e-05,
      "loss": 1.0191,
      "step": 681
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.042434573173523,
      "learning_rate": 9.92585906955676e-05,
      "loss": 0.8175,
      "step": 682
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.8303159475326538,
      "learning_rate": 9.925519431370336e-05,
      "loss": 0.7666,
      "step": 683
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.1317625045776367,
      "learning_rate": 9.925179022860132e-05,
      "loss": 0.963,
      "step": 684
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2410553693771362,
      "learning_rate": 9.924837844079385e-05,
      "loss": 1.0534,
      "step": 685
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2067456245422363,
      "learning_rate": 9.924495895081454e-05,
      "loss": 0.4634,
      "step": 686
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0784274339675903,
      "learning_rate": 9.924153175919816e-05,
      "loss": 0.6335,
      "step": 687
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.269621729850769,
      "learning_rate": 9.923809686648073e-05,
      "loss": 1.1523,
      "step": 688
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0683839321136475,
      "learning_rate": 9.923465427319941e-05,
      "loss": 0.7528,
      "step": 689
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9957156181335449,
      "learning_rate": 9.923120397989264e-05,
      "loss": 0.9456,
      "step": 690
    },
    {
      "epoch": 0.25,
      "eval_loss": 0.8071786761283875,
      "eval_runtime": 327.0886,
      "eval_samples_per_second": 3.712,
      "eval_steps_per_second": 3.712,
      "step": 690
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2168176174163818,
      "learning_rate": 9.92277459871e-05,
      "loss": 0.9247,
      "step": 691
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.2713829278945923,
      "learning_rate": 9.922428029536234e-05,
      "loss": 1.2411,
      "step": 692
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.0346338748931885,
      "learning_rate": 9.922080690522162e-05,
      "loss": 0.5331,
      "step": 693
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.9564691781997681,
      "learning_rate": 9.921732581722111e-05,
      "loss": 0.7671,
      "step": 694
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.29441499710083,
      "learning_rate": 9.92138370319052e-05,
      "loss": 1.0792,
      "step": 695
    },
    {
      "epoch": 0.25,
      "grad_norm": 1.1589274406433105,
      "learning_rate": 9.921034054981953e-05,
      "loss": 0.8443,
      "step": 696
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.279909372329712,
      "learning_rate": 9.920683637151092e-05,
      "loss": 0.9679,
      "step": 697
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.310913324356079,
      "learning_rate": 9.92033244975274e-05,
      "loss": 1.0697,
      "step": 698
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9942982196807861,
      "learning_rate": 9.919980492841824e-05,
      "loss": 0.7068,
      "step": 699
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.238340973854065,
      "learning_rate": 9.919627766473385e-05,
      "loss": 0.8107,
      "step": 700
    },
    {
      "epoch": 0.26,
      "eval_loss": 0.80259770154953,
      "eval_runtime": 327.0266,
      "eval_samples_per_second": 3.712,
      "eval_steps_per_second": 3.712,
      "step": 700
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.191250205039978,
      "learning_rate": 9.919274270702588e-05,
      "loss": 0.7882,
      "step": 701
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1794793605804443,
      "learning_rate": 9.918920005584719e-05,
      "loss": 0.7214,
      "step": 702
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0727580785751343,
      "learning_rate": 9.918564971175181e-05,
      "loss": 0.9194,
      "step": 703
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1784909963607788,
      "learning_rate": 9.918209167529501e-05,
      "loss": 0.7565,
      "step": 704
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0133516788482666,
      "learning_rate": 9.917852594703326e-05,
      "loss": 1.0987,
      "step": 705
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9062074422836304,
      "learning_rate": 9.917495252752418e-05,
      "loss": 0.9554,
      "step": 706
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.11226487159729,
      "learning_rate": 9.917137141732667e-05,
      "loss": 0.7112,
      "step": 707
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8328918218612671,
      "learning_rate": 9.916778261700077e-05,
      "loss": 0.3035,
      "step": 708
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.290934681892395,
      "learning_rate": 9.916418612710777e-05,
      "loss": 0.8674,
      "step": 709
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0061774253845215,
      "learning_rate": 9.916058194821013e-05,
      "loss": 0.7269,
      "step": 710
    },
    {
      "epoch": 0.26,
      "eval_loss": 0.8012221455574036,
      "eval_runtime": 327.1923,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 710
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.9279139041900635,
      "learning_rate": 9.915697008087153e-05,
      "loss": 0.6291,
      "step": 711
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0667636394500732,
      "learning_rate": 9.915335052565683e-05,
      "loss": 1.4507,
      "step": 712
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.23924720287323,
      "learning_rate": 9.914972328313213e-05,
      "loss": 0.6881,
      "step": 713
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1016414165496826,
      "learning_rate": 9.914608835386467e-05,
      "loss": 0.5444,
      "step": 714
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1046645641326904,
      "learning_rate": 9.9142445738423e-05,
      "loss": 1.0563,
      "step": 715
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8323281407356262,
      "learning_rate": 9.913879543737674e-05,
      "loss": 0.5066,
      "step": 716
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.979046106338501,
      "learning_rate": 9.913513745129681e-05,
      "loss": 1.0394,
      "step": 717
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.0701696872711182,
      "learning_rate": 9.91314717807553e-05,
      "loss": 0.755,
      "step": 718
    },
    {
      "epoch": 0.26,
      "grad_norm": 0.8303736448287964,
      "learning_rate": 9.912779842632549e-05,
      "loss": 0.4787,
      "step": 719
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1576988697052002,
      "learning_rate": 9.912411738858187e-05,
      "loss": 0.9547,
      "step": 720
    },
    {
      "epoch": 0.26,
      "eval_loss": 0.7999892830848694,
      "eval_runtime": 327.3726,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 720
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1561638116836548,
      "learning_rate": 9.912042866810013e-05,
      "loss": 0.7379,
      "step": 721
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.1343388557434082,
      "learning_rate": 9.91167322654572e-05,
      "loss": 1.2147,
      "step": 722
    },
    {
      "epoch": 0.26,
      "grad_norm": 1.061799168586731,
      "learning_rate": 9.911302818123114e-05,
      "loss": 0.8538,
      "step": 723
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9658262133598328,
      "learning_rate": 9.910931641600126e-05,
      "loss": 0.6762,
      "step": 724
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.132776141166687,
      "learning_rate": 9.910559697034805e-05,
      "loss": 1.0771,
      "step": 725
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1882350444793701,
      "learning_rate": 9.910186984485321e-05,
      "loss": 0.9479,
      "step": 726
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8812717199325562,
      "learning_rate": 9.909813504009966e-05,
      "loss": 0.565,
      "step": 727
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1373343467712402,
      "learning_rate": 9.90943925566715e-05,
      "loss": 0.9805,
      "step": 728
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.0082951784133911,
      "learning_rate": 9.909064239515403e-05,
      "loss": 0.8311,
      "step": 729
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.203153371810913,
      "learning_rate": 9.908688455613374e-05,
      "loss": 0.966,
      "step": 730
    },
    {
      "epoch": 0.27,
      "eval_loss": 0.7986170649528503,
      "eval_runtime": 327.6801,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 730
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2315497398376465,
      "learning_rate": 9.908311904019834e-05,
      "loss": 0.8989,
      "step": 731
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2874791622161865,
      "learning_rate": 9.907934584793675e-05,
      "loss": 0.9685,
      "step": 732
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.8147260546684265,
      "learning_rate": 9.907556497993906e-05,
      "loss": 0.3693,
      "step": 733
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.301050066947937,
      "learning_rate": 9.90717764367966e-05,
      "loss": 0.9365,
      "step": 734
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.0517706871032715,
      "learning_rate": 9.906798021910184e-05,
      "loss": 0.4603,
      "step": 735
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2831835746765137,
      "learning_rate": 9.906417632744853e-05,
      "loss": 1.128,
      "step": 736
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.3524868488311768,
      "learning_rate": 9.906036476243154e-05,
      "loss": 0.9035,
      "step": 737
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.3020100593566895,
      "learning_rate": 9.9056545524647e-05,
      "loss": 0.7573,
      "step": 738
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.204641580581665,
      "learning_rate": 9.90527186146922e-05,
      "loss": 0.9345,
      "step": 739
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.175588607788086,
      "learning_rate": 9.904888403316569e-05,
      "loss": 1.0683,
      "step": 740
    },
    {
      "epoch": 0.27,
      "eval_loss": 0.7951207160949707,
      "eval_runtime": 327.4316,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 740
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1599712371826172,
      "learning_rate": 9.904504178066713e-05,
      "loss": 1.0317,
      "step": 741
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.7025723457336426,
      "learning_rate": 9.904119185779743e-05,
      "loss": 0.4978,
      "step": 742
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1400872468948364,
      "learning_rate": 9.903733426515872e-05,
      "loss": 0.8776,
      "step": 743
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1656086444854736,
      "learning_rate": 9.90334690033543e-05,
      "loss": 1.1331,
      "step": 744
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2106457948684692,
      "learning_rate": 9.902959607298866e-05,
      "loss": 1.1321,
      "step": 745
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.0696020126342773,
      "learning_rate": 9.902571547466753e-05,
      "loss": 0.778,
      "step": 746
    },
    {
      "epoch": 0.27,
      "grad_norm": 0.9905250072479248,
      "learning_rate": 9.902182720899778e-05,
      "loss": 0.6382,
      "step": 747
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.2064964771270752,
      "learning_rate": 9.901793127658753e-05,
      "loss": 0.8821,
      "step": 748
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1065466403961182,
      "learning_rate": 9.90140276780461e-05,
      "loss": 1.0007,
      "step": 749
    },
    {
      "epoch": 0.27,
      "grad_norm": 1.1656101942062378,
      "learning_rate": 9.901011641398398e-05,
      "loss": 1.2162,
      "step": 750
    },
    {
      "epoch": 0.27,
      "eval_loss": 0.793969988822937,
      "eval_runtime": 327.2592,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 750
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1036456823349,
      "learning_rate": 9.900619748501285e-05,
      "loss": 0.6777,
      "step": 751
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9198763370513916,
      "learning_rate": 9.900227089174562e-05,
      "loss": 0.7457,
      "step": 752
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2632700204849243,
      "learning_rate": 9.899833663479642e-05,
      "loss": 0.9699,
      "step": 753
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2511670589447021,
      "learning_rate": 9.89943947147805e-05,
      "loss": 0.9544,
      "step": 754
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0748214721679688,
      "learning_rate": 9.899044513231436e-05,
      "loss": 0.9269,
      "step": 755
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7119568586349487,
      "learning_rate": 9.898648788801572e-05,
      "loss": 0.6436,
      "step": 756
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2759491205215454,
      "learning_rate": 9.898252298250345e-05,
      "loss": 0.8095,
      "step": 757
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9705768823623657,
      "learning_rate": 9.897855041639764e-05,
      "loss": 0.708,
      "step": 758
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8675347566604614,
      "learning_rate": 9.897457019031959e-05,
      "loss": 0.7917,
      "step": 759
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1148391962051392,
      "learning_rate": 9.897058230489177e-05,
      "loss": 1.0672,
      "step": 760
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.7924638986587524,
      "eval_runtime": 327.5253,
      "eval_samples_per_second": 3.707,
      "eval_steps_per_second": 3.707,
      "step": 760
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1274610757827759,
      "learning_rate": 9.896658676073787e-05,
      "loss": 0.7842,
      "step": 761
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1870673894882202,
      "learning_rate": 9.896258355848278e-05,
      "loss": 1.0018,
      "step": 762
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2337968349456787,
      "learning_rate": 9.895857269875255e-05,
      "loss": 0.8505,
      "step": 763
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.2054729461669922,
      "learning_rate": 9.89545541821745e-05,
      "loss": 1.135,
      "step": 764
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.064205288887024,
      "learning_rate": 9.895052800937706e-05,
      "loss": 1.096,
      "step": 765
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0832945108413696,
      "learning_rate": 9.894649418098991e-05,
      "loss": 0.8299,
      "step": 766
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0782830715179443,
      "learning_rate": 9.894245269764395e-05,
      "loss": 1.1695,
      "step": 767
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.7383642196655273,
      "learning_rate": 9.893840355997121e-05,
      "loss": 0.274,
      "step": 768
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1311874389648438,
      "learning_rate": 9.893434676860499e-05,
      "loss": 0.8594,
      "step": 769
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9916790723800659,
      "learning_rate": 9.893028232417969e-05,
      "loss": 0.8765,
      "step": 770
    },
    {
      "epoch": 0.28,
      "eval_loss": 0.7876769304275513,
      "eval_runtime": 327.2754,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 770
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0644536018371582,
      "learning_rate": 9.892621022733102e-05,
      "loss": 0.8766,
      "step": 771
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8796265125274658,
      "learning_rate": 9.892213047869581e-05,
      "loss": 0.8679,
      "step": 772
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.9248084425926208,
      "learning_rate": 9.891804307891213e-05,
      "loss": 0.5601,
      "step": 773
    },
    {
      "epoch": 0.28,
      "grad_norm": 0.8340782523155212,
      "learning_rate": 9.89139480286192e-05,
      "loss": 0.6086,
      "step": 774
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0176606178283691,
      "learning_rate": 9.890984532845747e-05,
      "loss": 0.7005,
      "step": 775
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.130948781967163,
      "learning_rate": 9.890573497906859e-05,
      "loss": 1.0427,
      "step": 776
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.1295078992843628,
      "learning_rate": 9.890161698109539e-05,
      "loss": 0.6829,
      "step": 777
    },
    {
      "epoch": 0.28,
      "grad_norm": 1.0704433917999268,
      "learning_rate": 9.88974913351819e-05,
      "loss": 0.4859,
      "step": 778
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8743248581886292,
      "learning_rate": 9.889335804197335e-05,
      "loss": 0.7061,
      "step": 779
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0792971849441528,
      "learning_rate": 9.888921710211616e-05,
      "loss": 0.8251,
      "step": 780
    },
    {
      "epoch": 0.29,
      "eval_loss": 0.7881146669387817,
      "eval_runtime": 327.3747,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 780
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0608539581298828,
      "learning_rate": 9.888506851625796e-05,
      "loss": 0.9134,
      "step": 781
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.8051620721817017,
      "learning_rate": 9.888091228504757e-05,
      "loss": 0.5939,
      "step": 782
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9349941611289978,
      "learning_rate": 9.887674840913496e-05,
      "loss": 0.6648,
      "step": 783
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9659472703933716,
      "learning_rate": 9.88725768891714e-05,
      "loss": 0.7117,
      "step": 784
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.800702691078186,
      "learning_rate": 9.886839772580925e-05,
      "loss": 0.4338,
      "step": 785
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2242833375930786,
      "learning_rate": 9.886421091970211e-05,
      "loss": 0.9983,
      "step": 786
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2262192964553833,
      "learning_rate": 9.88600164715048e-05,
      "loss": 0.847,
      "step": 787
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.2125864028930664,
      "learning_rate": 9.885581438187327e-05,
      "loss": 1.0295,
      "step": 788
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.3812092542648315,
      "learning_rate": 9.885160465146473e-05,
      "loss": 0.8896,
      "step": 789
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.1774775981903076,
      "learning_rate": 9.884738728093754e-05,
      "loss": 0.7567,
      "step": 790
    },
    {
      "epoch": 0.29,
      "eval_loss": 0.7840166091918945,
      "eval_runtime": 327.2264,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 790
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.1329708099365234,
      "learning_rate": 9.884316227095129e-05,
      "loss": 0.7901,
      "step": 791
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0605822801589966,
      "learning_rate": 9.883892962216677e-05,
      "loss": 0.5383,
      "step": 792
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.1966456174850464,
      "learning_rate": 9.883468933524589e-05,
      "loss": 0.9705,
      "step": 793
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9514212608337402,
      "learning_rate": 9.883044141085183e-05,
      "loss": 0.7696,
      "step": 794
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.1405186653137207,
      "learning_rate": 9.882618584964895e-05,
      "loss": 0.8677,
      "step": 795
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0636260509490967,
      "learning_rate": 9.88219226523028e-05,
      "loss": 0.5838,
      "step": 796
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0384414196014404,
      "learning_rate": 9.881765181948009e-05,
      "loss": 1.0569,
      "step": 797
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.9786311984062195,
      "learning_rate": 9.881337335184878e-05,
      "loss": 0.644,
      "step": 798
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0963752269744873,
      "learning_rate": 9.880908725007801e-05,
      "loss": 0.8205,
      "step": 799
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0863831043243408,
      "learning_rate": 9.880479351483806e-05,
      "loss": 0.867,
      "step": 800
    },
    {
      "epoch": 0.29,
      "eval_loss": 0.7820793390274048,
      "eval_runtime": 327.1979,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 800
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0942734479904175,
      "learning_rate": 9.880049214680049e-05,
      "loss": 0.7447,
      "step": 801
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.0777238607406616,
      "learning_rate": 9.879618314663799e-05,
      "loss": 0.8688,
      "step": 802
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.1754035949707031,
      "learning_rate": 9.879186651502448e-05,
      "loss": 1.1743,
      "step": 803
    },
    {
      "epoch": 0.29,
      "grad_norm": 1.159253478050232,
      "learning_rate": 9.878754225263502e-05,
      "loss": 0.7702,
      "step": 804
    },
    {
      "epoch": 0.29,
      "grad_norm": 0.6935550570487976,
      "learning_rate": 9.878321036014593e-05,
      "loss": 0.6038,
      "step": 805
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9063940048217773,
      "learning_rate": 9.877887083823469e-05,
      "loss": 0.5984,
      "step": 806
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1460014581680298,
      "learning_rate": 9.877452368757998e-05,
      "loss": 1.0616,
      "step": 807
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.001702070236206,
      "learning_rate": 9.877016890886165e-05,
      "loss": 0.7729,
      "step": 808
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0934048891067505,
      "learning_rate": 9.876580650276078e-05,
      "loss": 0.8463,
      "step": 809
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1604536771774292,
      "learning_rate": 9.876143646995963e-05,
      "loss": 0.9164,
      "step": 810
    },
    {
      "epoch": 0.3,
      "eval_loss": 0.7820639610290527,
      "eval_runtime": 327.5362,
      "eval_samples_per_second": 3.706,
      "eval_steps_per_second": 3.706,
      "step": 810
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1912323236465454,
      "learning_rate": 9.875705881114164e-05,
      "loss": 0.8358,
      "step": 811
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.95912104845047,
      "learning_rate": 9.875267352699146e-05,
      "loss": 0.8456,
      "step": 812
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9119742512702942,
      "learning_rate": 9.874828061819491e-05,
      "loss": 0.8707,
      "step": 813
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0992026329040527,
      "learning_rate": 9.874388008543903e-05,
      "loss": 0.6918,
      "step": 814
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.184781789779663,
      "learning_rate": 9.873947192941202e-05,
      "loss": 1.1282,
      "step": 815
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9853927493095398,
      "learning_rate": 9.873505615080332e-05,
      "loss": 0.7154,
      "step": 816
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1566894054412842,
      "learning_rate": 9.873063275030351e-05,
      "loss": 0.8808,
      "step": 817
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9885205030441284,
      "learning_rate": 9.872620172860439e-05,
      "loss": 0.5233,
      "step": 818
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9802234768867493,
      "learning_rate": 9.872176308639895e-05,
      "loss": 0.9953,
      "step": 819
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1099801063537598,
      "learning_rate": 9.871731682438138e-05,
      "loss": 1.0009,
      "step": 820
    },
    {
      "epoch": 0.3,
      "eval_loss": 0.7795964479446411,
      "eval_runtime": 327.3981,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 820
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1471744775772095,
      "learning_rate": 9.871286294324702e-05,
      "loss": 0.9962,
      "step": 821
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1438868045806885,
      "learning_rate": 9.870840144369246e-05,
      "loss": 0.8214,
      "step": 822
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.3076481819152832,
      "learning_rate": 9.870393232641546e-05,
      "loss": 1.0718,
      "step": 823
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9871701002120972,
      "learning_rate": 9.869945559211494e-05,
      "loss": 0.911,
      "step": 824
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.12319016456604,
      "learning_rate": 9.869497124149103e-05,
      "loss": 0.7453,
      "step": 825
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1355507373809814,
      "learning_rate": 9.869047927524508e-05,
      "loss": 0.7691,
      "step": 826
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9399113655090332,
      "learning_rate": 9.868597969407961e-05,
      "loss": 0.7057,
      "step": 827
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.2070138454437256,
      "learning_rate": 9.868147249869833e-05,
      "loss": 1.0728,
      "step": 828
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.8674232959747314,
      "learning_rate": 9.867695768980612e-05,
      "loss": 0.5409,
      "step": 829
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.9943962693214417,
      "learning_rate": 9.867243526810908e-05,
      "loss": 0.6333,
      "step": 830
    },
    {
      "epoch": 0.3,
      "eval_loss": 0.778329610824585,
      "eval_runtime": 327.4207,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 830
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.0625247955322266,
      "learning_rate": 9.866790523431448e-05,
      "loss": 0.7626,
      "step": 831
    },
    {
      "epoch": 0.3,
      "grad_norm": 1.1781176328659058,
      "learning_rate": 9.866336758913083e-05,
      "loss": 0.8338,
      "step": 832
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.083023190498352,
      "learning_rate": 9.865882233326775e-05,
      "loss": 0.9566,
      "step": 833
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.2424211502075195,
      "learning_rate": 9.865426946743614e-05,
      "loss": 1.1605,
      "step": 834
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9316428303718567,
      "learning_rate": 9.8649708992348e-05,
      "loss": 0.7536,
      "step": 835
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1892809867858887,
      "learning_rate": 9.864514090871657e-05,
      "loss": 0.8461,
      "step": 836
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1371171474456787,
      "learning_rate": 9.864056521725628e-05,
      "loss": 0.8716,
      "step": 837
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1516894102096558,
      "learning_rate": 9.863598191868274e-05,
      "loss": 1.1188,
      "step": 838
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.051652193069458,
      "learning_rate": 9.863139101371277e-05,
      "loss": 0.7531,
      "step": 839
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1545228958129883,
      "learning_rate": 9.862679250306433e-05,
      "loss": 1.0346,
      "step": 840
    },
    {
      "epoch": 0.31,
      "eval_loss": 0.7739566564559937,
      "eval_runtime": 327.6677,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 840
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7235641479492188,
      "learning_rate": 9.862218638745662e-05,
      "loss": 0.4826,
      "step": 841
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0222992897033691,
      "learning_rate": 9.861757266761002e-05,
      "loss": 0.4579,
      "step": 842
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.7495096325874329,
      "learning_rate": 9.861295134424608e-05,
      "loss": 0.5129,
      "step": 843
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.908821165561676,
      "learning_rate": 9.860832241808752e-05,
      "loss": 0.5856,
      "step": 844
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1390935182571411,
      "learning_rate": 9.860368588985834e-05,
      "loss": 0.8012,
      "step": 845
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1138277053833008,
      "learning_rate": 9.859904176028362e-05,
      "loss": 0.9163,
      "step": 846
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0534601211547852,
      "learning_rate": 9.85943900300897e-05,
      "loss": 1.0379,
      "step": 847
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0486798286437988,
      "learning_rate": 9.858973070000406e-05,
      "loss": 1.0509,
      "step": 848
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.27480947971344,
      "learning_rate": 9.858506377075542e-05,
      "loss": 0.9833,
      "step": 849
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.2859852313995361,
      "learning_rate": 9.858038924307364e-05,
      "loss": 0.8251,
      "step": 850
    },
    {
      "epoch": 0.31,
      "eval_loss": 0.7732362747192383,
      "eval_runtime": 327.2529,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 850
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8009073138237,
      "learning_rate": 9.85757071176898e-05,
      "loss": 0.5991,
      "step": 851
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.4325305223464966,
      "learning_rate": 9.857101739533616e-05,
      "loss": 0.6399,
      "step": 852
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.8361289501190186,
      "learning_rate": 9.856632007674616e-05,
      "loss": 0.5126,
      "step": 853
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.194187879562378,
      "learning_rate": 9.856161516265444e-05,
      "loss": 0.8523,
      "step": 854
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.0777673721313477,
      "learning_rate": 9.855690265379682e-05,
      "loss": 1.0713,
      "step": 855
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1318018436431885,
      "learning_rate": 9.855218255091032e-05,
      "loss": 0.8858,
      "step": 856
    },
    {
      "epoch": 0.31,
      "grad_norm": 0.9378726482391357,
      "learning_rate": 9.85474548547331e-05,
      "loss": 0.6429,
      "step": 857
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.1639407873153687,
      "learning_rate": 9.854271956600462e-05,
      "loss": 0.9921,
      "step": 858
    },
    {
      "epoch": 0.31,
      "grad_norm": 1.350834608078003,
      "learning_rate": 9.853797668546538e-05,
      "loss": 1.0737,
      "step": 859
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2679954767227173,
      "learning_rate": 9.853322621385716e-05,
      "loss": 0.7646,
      "step": 860
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.770867109298706,
      "eval_runtime": 327.4814,
      "eval_samples_per_second": 3.707,
      "eval_steps_per_second": 3.707,
      "step": 860
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.176344633102417,
      "learning_rate": 9.852846815192294e-05,
      "loss": 0.9772,
      "step": 861
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.122532844543457,
      "learning_rate": 9.852370250040681e-05,
      "loss": 0.8421,
      "step": 862
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0954844951629639,
      "learning_rate": 9.85189292600541e-05,
      "loss": 0.774,
      "step": 863
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0062555074691772,
      "learning_rate": 9.851414843161135e-05,
      "loss": 0.821,
      "step": 864
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0534112453460693,
      "learning_rate": 9.850936001582622e-05,
      "loss": 0.4936,
      "step": 865
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.011589527130127,
      "learning_rate": 9.85045640134476e-05,
      "loss": 0.625,
      "step": 866
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2455037832260132,
      "learning_rate": 9.849976042522558e-05,
      "loss": 0.715,
      "step": 867
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8319311738014221,
      "learning_rate": 9.849494925191138e-05,
      "loss": 0.3766,
      "step": 868
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.5536563396453857,
      "learning_rate": 9.849013049425748e-05,
      "loss": 0.7702,
      "step": 869
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.1046972274780273,
      "learning_rate": 9.848530415301747e-05,
      "loss": 0.6084,
      "step": 870
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.7692927122116089,
      "eval_runtime": 327.262,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 870
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2415125370025635,
      "learning_rate": 9.848047022894617e-05,
      "loss": 0.7227,
      "step": 871
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2451372146606445,
      "learning_rate": 9.847562872279958e-05,
      "loss": 1.0913,
      "step": 872
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.204676628112793,
      "learning_rate": 9.847077963533491e-05,
      "loss": 1.057,
      "step": 873
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.965294361114502,
      "learning_rate": 9.84659229673105e-05,
      "loss": 0.673,
      "step": 874
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.8812766075134277,
      "learning_rate": 9.846105871948593e-05,
      "loss": 0.7528,
      "step": 875
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.707874596118927,
      "learning_rate": 9.845618689262192e-05,
      "loss": 0.458,
      "step": 876
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2558364868164062,
      "learning_rate": 9.845130748748041e-05,
      "loss": 0.9167,
      "step": 877
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9629396796226501,
      "learning_rate": 9.844642050482448e-05,
      "loss": 0.5695,
      "step": 878
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9343413710594177,
      "learning_rate": 9.844152594541848e-05,
      "loss": 0.5458,
      "step": 879
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9498879909515381,
      "learning_rate": 9.843662381002788e-05,
      "loss": 0.3364,
      "step": 880
    },
    {
      "epoch": 0.32,
      "eval_loss": 0.7720434665679932,
      "eval_runtime": 327.4227,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 880
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.2618563175201416,
      "learning_rate": 9.843171409941929e-05,
      "loss": 0.7565,
      "step": 881
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.0626991987228394,
      "learning_rate": 9.842679681436062e-05,
      "loss": 0.6665,
      "step": 882
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.3144457340240479,
      "learning_rate": 9.842187195562089e-05,
      "loss": 1.0087,
      "step": 883
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.1430591344833374,
      "learning_rate": 9.841693952397033e-05,
      "loss": 0.8487,
      "step": 884
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9849126935005188,
      "learning_rate": 9.841199952018032e-05,
      "loss": 0.5749,
      "step": 885
    },
    {
      "epoch": 0.32,
      "grad_norm": 0.9876025319099426,
      "learning_rate": 9.840705194502347e-05,
      "loss": 0.8848,
      "step": 886
    },
    {
      "epoch": 0.32,
      "grad_norm": 1.1729395389556885,
      "learning_rate": 9.840209679927355e-05,
      "loss": 0.9635,
      "step": 887
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0619174242019653,
      "learning_rate": 9.839713408370551e-05,
      "loss": 0.6427,
      "step": 888
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.104231595993042,
      "learning_rate": 9.839216379909549e-05,
      "loss": 0.7068,
      "step": 889
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9351949095726013,
      "learning_rate": 9.838718594622083e-05,
      "loss": 0.2903,
      "step": 890
    },
    {
      "epoch": 0.33,
      "eval_loss": 0.7656203508377075,
      "eval_runtime": 327.3797,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 890
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.2678899765014648,
      "learning_rate": 9.838220052586003e-05,
      "loss": 1.0011,
      "step": 891
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9660629630088806,
      "learning_rate": 9.837720753879276e-05,
      "loss": 0.5589,
      "step": 892
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0385102033615112,
      "learning_rate": 9.837220698579992e-05,
      "loss": 0.6187,
      "step": 893
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.2459887266159058,
      "learning_rate": 9.836719886766356e-05,
      "loss": 0.7306,
      "step": 894
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0523074865341187,
      "learning_rate": 9.836218318516695e-05,
      "loss": 0.6926,
      "step": 895
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.4630014896392822,
      "learning_rate": 9.835715993909447e-05,
      "loss": 0.9562,
      "step": 896
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1869665384292603,
      "learning_rate": 9.835212913023175e-05,
      "loss": 0.8283,
      "step": 897
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9427247643470764,
      "learning_rate": 9.834709075936558e-05,
      "loss": 0.4884,
      "step": 898
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1606805324554443,
      "learning_rate": 9.834204482728394e-05,
      "loss": 0.9608,
      "step": 899
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1623631715774536,
      "learning_rate": 9.833699133477598e-05,
      "loss": 0.8896,
      "step": 900
    },
    {
      "epoch": 0.33,
      "eval_loss": 0.7645209431648254,
      "eval_runtime": 327.2493,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 900
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.3561530113220215,
      "learning_rate": 9.833193028263202e-05,
      "loss": 0.8457,
      "step": 901
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0572583675384521,
      "learning_rate": 9.83268616716436e-05,
      "loss": 0.763,
      "step": 902
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1050447225570679,
      "learning_rate": 9.832178550260343e-05,
      "loss": 0.9348,
      "step": 903
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0378488302230835,
      "learning_rate": 9.831670177630536e-05,
      "loss": 0.4847,
      "step": 904
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9310539364814758,
      "learning_rate": 9.83116104935445e-05,
      "loss": 0.7146,
      "step": 905
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0916906595230103,
      "learning_rate": 9.830651165511706e-05,
      "loss": 0.9207,
      "step": 906
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.9482269883155823,
      "learning_rate": 9.83014052618205e-05,
      "loss": 0.4522,
      "step": 907
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.0866763591766357,
      "learning_rate": 9.829629131445342e-05,
      "loss": 1.0197,
      "step": 908
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1825202703475952,
      "learning_rate": 9.829116981381561e-05,
      "loss": 1.0493,
      "step": 909
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.852511465549469,
      "learning_rate": 9.828604076070804e-05,
      "loss": 0.4898,
      "step": 910
    },
    {
      "epoch": 0.33,
      "eval_loss": 0.7627753615379333,
      "eval_runtime": 327.1736,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 910
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8720936179161072,
      "learning_rate": 9.828090415593288e-05,
      "loss": 0.5835,
      "step": 911
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.113255262374878,
      "learning_rate": 9.827576000029344e-05,
      "loss": 0.9893,
      "step": 912
    },
    {
      "epoch": 0.33,
      "grad_norm": 1.1843687295913696,
      "learning_rate": 9.827060829459427e-05,
      "loss": 0.8246,
      "step": 913
    },
    {
      "epoch": 0.33,
      "grad_norm": 0.8423638343811035,
      "learning_rate": 9.826544903964105e-05,
      "loss": 0.6322,
      "step": 914
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.056490421295166,
      "learning_rate": 9.826028223624067e-05,
      "loss": 0.8879,
      "step": 915
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1328520774841309,
      "learning_rate": 9.825510788520115e-05,
      "loss": 0.9999,
      "step": 916
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8787379264831543,
      "learning_rate": 9.824992598733179e-05,
      "loss": 0.8819,
      "step": 917
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8312644958496094,
      "learning_rate": 9.824473654344297e-05,
      "loss": 0.5745,
      "step": 918
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1996480226516724,
      "learning_rate": 9.82395395543463e-05,
      "loss": 1.0439,
      "step": 919
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2311816215515137,
      "learning_rate": 9.823433502085457e-05,
      "loss": 0.8651,
      "step": 920
    },
    {
      "epoch": 0.34,
      "eval_loss": 0.7612864375114441,
      "eval_runtime": 327.3456,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 920
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.3041355609893799,
      "learning_rate": 9.822912294378173e-05,
      "loss": 1.0068,
      "step": 921
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2931513786315918,
      "learning_rate": 9.822390332394291e-05,
      "loss": 0.9916,
      "step": 922
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.4038472175598145,
      "learning_rate": 9.821867616215444e-05,
      "loss": 0.8383,
      "step": 923
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8383054733276367,
      "learning_rate": 9.821344145923381e-05,
      "loss": 0.3265,
      "step": 924
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1307048797607422,
      "learning_rate": 9.820819921599973e-05,
      "loss": 0.9019,
      "step": 925
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.0510389804840088,
      "learning_rate": 9.820294943327201e-05,
      "loss": 0.8181,
      "step": 926
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.0634840726852417,
      "learning_rate": 9.819769211187174e-05,
      "loss": 0.5644,
      "step": 927
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.8968350291252136,
      "learning_rate": 9.819242725262108e-05,
      "loss": 0.4753,
      "step": 928
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1967413425445557,
      "learning_rate": 9.818715485634347e-05,
      "loss": 0.663,
      "step": 929
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9889925122261047,
      "learning_rate": 9.818187492386346e-05,
      "loss": 0.4718,
      "step": 930
    },
    {
      "epoch": 0.34,
      "eval_loss": 0.7592704892158508,
      "eval_runtime": 327.1728,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 930
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.0418626070022583,
      "learning_rate": 9.817658745600682e-05,
      "loss": 0.8262,
      "step": 931
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2074071168899536,
      "learning_rate": 9.817129245360045e-05,
      "loss": 0.6334,
      "step": 932
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9383836388587952,
      "learning_rate": 9.816598991747248e-05,
      "loss": 0.5937,
      "step": 933
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.3374853134155273,
      "learning_rate": 9.816067984845219e-05,
      "loss": 0.8004,
      "step": 934
    },
    {
      "epoch": 0.34,
      "grad_norm": 0.9805819392204285,
      "learning_rate": 9.815536224737005e-05,
      "loss": 0.8071,
      "step": 935
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1915425062179565,
      "learning_rate": 9.815003711505772e-05,
      "loss": 0.6584,
      "step": 936
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1640576124191284,
      "learning_rate": 9.814470445234798e-05,
      "loss": 0.8597,
      "step": 937
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1025605201721191,
      "learning_rate": 9.813936426007487e-05,
      "loss": 0.7501,
      "step": 938
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.1659200191497803,
      "learning_rate": 9.813401653907353e-05,
      "loss": 0.6797,
      "step": 939
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2829374074935913,
      "learning_rate": 9.812866129018035e-05,
      "loss": 1.0001,
      "step": 940
    },
    {
      "epoch": 0.34,
      "eval_loss": 0.7600950598716736,
      "eval_runtime": 327.4396,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 940
    },
    {
      "epoch": 0.34,
      "grad_norm": 1.2248430252075195,
      "learning_rate": 9.812329851423283e-05,
      "loss": 0.8745,
      "step": 941
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9027082920074463,
      "learning_rate": 9.811792821206969e-05,
      "loss": 0.7711,
      "step": 942
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0369566679000854,
      "learning_rate": 9.811255038453082e-05,
      "loss": 0.6153,
      "step": 943
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.3949699401855469,
      "learning_rate": 9.810716503245729e-05,
      "loss": 0.9313,
      "step": 944
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.2478952407836914,
      "learning_rate": 9.810177215669132e-05,
      "loss": 1.0042,
      "step": 945
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1814417839050293,
      "learning_rate": 9.809637175807634e-05,
      "loss": 0.864,
      "step": 946
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0287998914718628,
      "learning_rate": 9.80909638374569e-05,
      "loss": 0.844,
      "step": 947
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.3256025314331055,
      "learning_rate": 9.808554839567885e-05,
      "loss": 0.9557,
      "step": 948
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.3112703561782837,
      "learning_rate": 9.808012543358906e-05,
      "loss": 0.8718,
      "step": 949
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9695655703544617,
      "learning_rate": 9.807469495203569e-05,
      "loss": 0.5945,
      "step": 950
    },
    {
      "epoch": 0.35,
      "eval_loss": 0.7567372918128967,
      "eval_runtime": 327.3581,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 950
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1786280870437622,
      "learning_rate": 9.806925695186804e-05,
      "loss": 0.6246,
      "step": 951
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1194394826889038,
      "learning_rate": 9.806381143393656e-05,
      "loss": 0.8303,
      "step": 952
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9049245119094849,
      "learning_rate": 9.80583583990929e-05,
      "loss": 0.8908,
      "step": 953
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.258041262626648,
      "learning_rate": 9.805289784818991e-05,
      "loss": 1.1789,
      "step": 954
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.8707952499389648,
      "learning_rate": 9.804742978208156e-05,
      "loss": 0.5002,
      "step": 955
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9960780739784241,
      "learning_rate": 9.804195420162305e-05,
      "loss": 0.5833,
      "step": 956
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.306080937385559,
      "learning_rate": 9.80364711076707e-05,
      "loss": 0.693,
      "step": 957
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.271544337272644,
      "learning_rate": 9.803098050108205e-05,
      "loss": 0.846,
      "step": 958
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1751207113265991,
      "learning_rate": 9.802548238271583e-05,
      "loss": 0.8417,
      "step": 959
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.374721884727478,
      "learning_rate": 9.801997675343189e-05,
      "loss": 1.156,
      "step": 960
    },
    {
      "epoch": 0.35,
      "eval_loss": 0.7541972398757935,
      "eval_runtime": 327.1486,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 960
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1367096900939941,
      "learning_rate": 9.801446361409125e-05,
      "loss": 0.6776,
      "step": 961
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9844064712524414,
      "learning_rate": 9.800894296555618e-05,
      "loss": 0.6492,
      "step": 962
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.067413330078125,
      "learning_rate": 9.800341480869006e-05,
      "loss": 0.9081,
      "step": 963
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1371705532073975,
      "learning_rate": 9.799787914435747e-05,
      "loss": 0.933,
      "step": 964
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1732884645462036,
      "learning_rate": 9.799233597342414e-05,
      "loss": 0.5984,
      "step": 965
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.1243844032287598,
      "learning_rate": 9.7986785296757e-05,
      "loss": 0.7774,
      "step": 966
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.0725167989730835,
      "learning_rate": 9.798122711522418e-05,
      "loss": 0.6759,
      "step": 967
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.050357699394226,
      "learning_rate": 9.797566142969488e-05,
      "loss": 0.6494,
      "step": 968
    },
    {
      "epoch": 0.35,
      "grad_norm": 1.2919644117355347,
      "learning_rate": 9.79700882410396e-05,
      "loss": 0.5241,
      "step": 969
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1615428924560547,
      "learning_rate": 9.796450755012991e-05,
      "loss": 0.8622,
      "step": 970
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.75200355052948,
      "eval_runtime": 327.0941,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 970
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0100725889205933,
      "learning_rate": 9.795891935783864e-05,
      "loss": 0.6718,
      "step": 971
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.7357797026634216,
      "learning_rate": 9.795332366503973e-05,
      "loss": 0.3324,
      "step": 972
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1396440267562866,
      "learning_rate": 9.794772047260832e-05,
      "loss": 0.7519,
      "step": 973
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3570111989974976,
      "learning_rate": 9.794210978142072e-05,
      "loss": 1.0384,
      "step": 974
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3632065057754517,
      "learning_rate": 9.793649159235441e-05,
      "loss": 1.142,
      "step": 975
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1707762479782104,
      "learning_rate": 9.793086590628804e-05,
      "loss": 0.602,
      "step": 976
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.203464150428772,
      "learning_rate": 9.792523272410143e-05,
      "loss": 1.1762,
      "step": 977
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.303985595703125,
      "learning_rate": 9.79195920466756e-05,
      "loss": 0.9281,
      "step": 978
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0598905086517334,
      "learning_rate": 9.791394387489271e-05,
      "loss": 0.8997,
      "step": 979
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1625584363937378,
      "learning_rate": 9.790828820963609e-05,
      "loss": 0.8023,
      "step": 980
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.7505658268928528,
      "eval_runtime": 327.2376,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 980
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.9506374001502991,
      "learning_rate": 9.790262505179026e-05,
      "loss": 0.3857,
      "step": 981
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.3643198013305664,
      "learning_rate": 9.789695440224093e-05,
      "loss": 0.8279,
      "step": 982
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.24534273147583,
      "learning_rate": 9.789127626187494e-05,
      "loss": 0.6401,
      "step": 983
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.2048041820526123,
      "learning_rate": 9.78855906315803e-05,
      "loss": 0.692,
      "step": 984
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1675148010253906,
      "learning_rate": 9.787989751224622e-05,
      "loss": 0.8556,
      "step": 985
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.2845025062561035,
      "learning_rate": 9.787419690476309e-05,
      "loss": 1.0203,
      "step": 986
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1818854808807373,
      "learning_rate": 9.786848881002245e-05,
      "loss": 0.9794,
      "step": 987
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1942224502563477,
      "learning_rate": 9.786277322891702e-05,
      "loss": 0.8711,
      "step": 988
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1802453994750977,
      "learning_rate": 9.785705016234065e-05,
      "loss": 0.8446,
      "step": 989
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.0423508882522583,
      "learning_rate": 9.785131961118844e-05,
      "loss": 0.6593,
      "step": 990
    },
    {
      "epoch": 0.36,
      "eval_loss": 0.7486959099769592,
      "eval_runtime": 327.2053,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 990
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1059452295303345,
      "learning_rate": 9.784558157635657e-05,
      "loss": 0.9901,
      "step": 991
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.1842581033706665,
      "learning_rate": 9.783983605874248e-05,
      "loss": 0.8658,
      "step": 992
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.102605938911438,
      "learning_rate": 9.783408305924472e-05,
      "loss": 0.5326,
      "step": 993
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.048669695854187,
      "learning_rate": 9.782832257876302e-05,
      "loss": 0.8932,
      "step": 994
    },
    {
      "epoch": 0.36,
      "grad_norm": 1.2197686433792114,
      "learning_rate": 9.782255461819829e-05,
      "loss": 0.9832,
      "step": 995
    },
    {
      "epoch": 0.36,
      "grad_norm": 0.936531126499176,
      "learning_rate": 9.781677917845262e-05,
      "loss": 1.0868,
      "step": 996
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.2299665212631226,
      "learning_rate": 9.781099626042924e-05,
      "loss": 0.8361,
      "step": 997
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1293967962265015,
      "learning_rate": 9.780520586503258e-05,
      "loss": 0.5528,
      "step": 998
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.2500337362289429,
      "learning_rate": 9.779940799316821e-05,
      "loss": 0.7283,
      "step": 999
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.2410144805908203,
      "learning_rate": 9.77936026457429e-05,
      "loss": 0.9616,
      "step": 1000
    },
    {
      "epoch": 0.37,
      "eval_loss": 0.7468338012695312,
      "eval_runtime": 327.1221,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 1000
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1073404550552368,
      "learning_rate": 9.778778982366456e-05,
      "loss": 0.9333,
      "step": 1001
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0993115901947021,
      "learning_rate": 9.778196952784229e-05,
      "loss": 0.5281,
      "step": 1002
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.7856203317642212,
      "learning_rate": 9.777614175918636e-05,
      "loss": 0.4245,
      "step": 1003
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.3514466285705566,
      "learning_rate": 9.777030651860819e-05,
      "loss": 0.8975,
      "step": 1004
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1188114881515503,
      "learning_rate": 9.776446380702037e-05,
      "loss": 0.7812,
      "step": 1005
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9767030477523804,
      "learning_rate": 9.77586136253367e-05,
      "loss": 0.5006,
      "step": 1006
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.293859839439392,
      "learning_rate": 9.775275597447208e-05,
      "loss": 0.8184,
      "step": 1007
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.5133970975875854,
      "learning_rate": 9.774689085534263e-05,
      "loss": 1.0637,
      "step": 1008
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1703358888626099,
      "learning_rate": 9.774101826886561e-05,
      "loss": 1.3363,
      "step": 1009
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.869731068611145,
      "learning_rate": 9.77351382159595e-05,
      "loss": 0.6152,
      "step": 1010
    },
    {
      "epoch": 0.37,
      "eval_loss": 0.7492358088493347,
      "eval_runtime": 327.1637,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 1010
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0465480089187622,
      "learning_rate": 9.772925069754386e-05,
      "loss": 0.6982,
      "step": 1011
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.852435827255249,
      "learning_rate": 9.772335571453947e-05,
      "loss": 0.4114,
      "step": 1012
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.2009365558624268,
      "learning_rate": 9.771745326786831e-05,
      "loss": 0.8293,
      "step": 1013
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.3534619808197021,
      "learning_rate": 9.771154335845345e-05,
      "loss": 1.0111,
      "step": 1014
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.464500904083252,
      "learning_rate": 9.77056259872192e-05,
      "loss": 0.765,
      "step": 1015
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.8290925621986389,
      "learning_rate": 9.769970115509098e-05,
      "loss": 0.5418,
      "step": 1016
    },
    {
      "epoch": 0.37,
      "grad_norm": 0.9169389605522156,
      "learning_rate": 9.769376886299538e-05,
      "loss": 0.2801,
      "step": 1017
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.0434982776641846,
      "learning_rate": 9.768782911186022e-05,
      "loss": 0.6115,
      "step": 1018
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.393538236618042,
      "learning_rate": 9.768188190261444e-05,
      "loss": 0.8689,
      "step": 1019
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.876379370689392,
      "learning_rate": 9.767592723618813e-05,
      "loss": 0.7882,
      "step": 1020
    },
    {
      "epoch": 0.37,
      "eval_loss": 0.7475573420524597,
      "eval_runtime": 327.1096,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 1020
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.2036547660827637,
      "learning_rate": 9.766996511351259e-05,
      "loss": 0.7328,
      "step": 1021
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.1195441484451294,
      "learning_rate": 9.766399553552021e-05,
      "loss": 0.7575,
      "step": 1022
    },
    {
      "epoch": 0.37,
      "grad_norm": 1.209708333015442,
      "learning_rate": 9.765801850314466e-05,
      "loss": 0.6643,
      "step": 1023
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9957442283630371,
      "learning_rate": 9.76520340173207e-05,
      "loss": 0.7472,
      "step": 1024
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1523388624191284,
      "learning_rate": 9.764604207898425e-05,
      "loss": 0.6209,
      "step": 1025
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.0337855815887451,
      "learning_rate": 9.764004268907243e-05,
      "loss": 0.6001,
      "step": 1026
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.2038376331329346,
      "learning_rate": 9.763403584852351e-05,
      "loss": 1.0852,
      "step": 1027
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9364312291145325,
      "learning_rate": 9.762802155827693e-05,
      "loss": 0.7589,
      "step": 1028
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.0817995071411133,
      "learning_rate": 9.762199981927328e-05,
      "loss": 0.6025,
      "step": 1029
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.4377063512802124,
      "learning_rate": 9.761597063245433e-05,
      "loss": 1.1096,
      "step": 1030
    },
    {
      "epoch": 0.38,
      "eval_loss": 0.7455630898475647,
      "eval_runtime": 327.1888,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 1030
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1525287628173828,
      "learning_rate": 9.760993399876301e-05,
      "loss": 1.0112,
      "step": 1031
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9730115532875061,
      "learning_rate": 9.760388991914343e-05,
      "loss": 0.6186,
      "step": 1032
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1437536478042603,
      "learning_rate": 9.759783839454084e-05,
      "loss": 1.1004,
      "step": 1033
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1293890476226807,
      "learning_rate": 9.759177942590165e-05,
      "loss": 0.9835,
      "step": 1034
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1966205835342407,
      "learning_rate": 9.758571301417347e-05,
      "loss": 0.864,
      "step": 1035
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.017713189125061,
      "learning_rate": 9.757963916030505e-05,
      "loss": 0.7015,
      "step": 1036
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.249738335609436,
      "learning_rate": 9.757355786524632e-05,
      "loss": 0.8787,
      "step": 1037
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1923846006393433,
      "learning_rate": 9.756746912994832e-05,
      "loss": 0.9722,
      "step": 1038
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.0806572437286377,
      "learning_rate": 9.756137295536333e-05,
      "loss": 0.833,
      "step": 1039
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1726200580596924,
      "learning_rate": 9.755526934244475e-05,
      "loss": 1.1019,
      "step": 1040
    },
    {
      "epoch": 0.38,
      "eval_loss": 0.7406055927276611,
      "eval_runtime": 326.9782,
      "eval_samples_per_second": 3.713,
      "eval_steps_per_second": 3.713,
      "step": 1040
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9777591824531555,
      "learning_rate": 9.754915829214713e-05,
      "loss": 0.911,
      "step": 1041
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9028063416481018,
      "learning_rate": 9.754303980542623e-05,
      "loss": 0.7141,
      "step": 1042
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.44351065158844,
      "learning_rate": 9.753691388323894e-05,
      "loss": 0.7708,
      "step": 1043
    },
    {
      "epoch": 0.38,
      "grad_norm": 0.9021912217140198,
      "learning_rate": 9.753078052654332e-05,
      "loss": 0.2733,
      "step": 1044
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.250643014907837,
      "learning_rate": 9.752463973629859e-05,
      "loss": 0.7673,
      "step": 1045
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.2376303672790527,
      "learning_rate": 9.751849151346513e-05,
      "loss": 0.85,
      "step": 1046
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.372674584388733,
      "learning_rate": 9.75123358590045e-05,
      "loss": 0.9325,
      "step": 1047
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.311962366104126,
      "learning_rate": 9.750617277387942e-05,
      "loss": 0.5738,
      "step": 1048
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.0933055877685547,
      "learning_rate": 9.750000225905371e-05,
      "loss": 0.7542,
      "step": 1049
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1476072072982788,
      "learning_rate": 9.749382431549248e-05,
      "loss": 0.8445,
      "step": 1050
    },
    {
      "epoch": 0.38,
      "eval_loss": 0.7380634546279907,
      "eval_runtime": 327.2709,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 1050
    },
    {
      "epoch": 0.38,
      "grad_norm": 1.1176480054855347,
      "learning_rate": 9.748763894416186e-05,
      "loss": 0.9267,
      "step": 1051
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1329936981201172,
      "learning_rate": 9.748144614602926e-05,
      "loss": 0.9597,
      "step": 1052
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.912164568901062,
      "learning_rate": 9.747524592206315e-05,
      "loss": 0.5786,
      "step": 1053
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.274705410003662,
      "learning_rate": 9.746903827323324e-05,
      "loss": 0.869,
      "step": 1054
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1870931386947632,
      "learning_rate": 9.746282320051037e-05,
      "loss": 0.632,
      "step": 1055
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1214872598648071,
      "learning_rate": 9.745660070486653e-05,
      "loss": 1.0047,
      "step": 1056
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.23750901222229,
      "learning_rate": 9.74503707872749e-05,
      "loss": 0.7481,
      "step": 1057
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.021355390548706,
      "learning_rate": 9.744413344870979e-05,
      "loss": 0.7588,
      "step": 1058
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9299391508102417,
      "learning_rate": 9.74378886901467e-05,
      "loss": 0.3939,
      "step": 1059
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.3727869987487793,
      "learning_rate": 9.743163651256226e-05,
      "loss": 0.7567,
      "step": 1060
    },
    {
      "epoch": 0.39,
      "eval_loss": 0.7372454404830933,
      "eval_runtime": 327.3795,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 1060
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1149613857269287,
      "learning_rate": 9.742537691693428e-05,
      "loss": 0.9666,
      "step": 1061
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9749336242675781,
      "learning_rate": 9.741910990424174e-05,
      "loss": 0.6145,
      "step": 1062
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2709192037582397,
      "learning_rate": 9.741283547546474e-05,
      "loss": 0.7274,
      "step": 1063
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2501808404922485,
      "learning_rate": 9.740655363158458e-05,
      "loss": 0.9152,
      "step": 1064
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9793238639831543,
      "learning_rate": 9.740026437358372e-05,
      "loss": 0.6523,
      "step": 1065
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1175546646118164,
      "learning_rate": 9.739396770244574e-05,
      "loss": 0.6635,
      "step": 1066
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.388317346572876,
      "learning_rate": 9.738766361915542e-05,
      "loss": 0.8475,
      "step": 1067
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1236671209335327,
      "learning_rate": 9.738135212469867e-05,
      "loss": 0.6661,
      "step": 1068
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2604398727416992,
      "learning_rate": 9.737503322006259e-05,
      "loss": 0.8175,
      "step": 1069
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.0604767799377441,
      "learning_rate": 9.73687069062354e-05,
      "loss": 0.8613,
      "step": 1070
    },
    {
      "epoch": 0.39,
      "eval_loss": 0.733832836151123,
      "eval_runtime": 327.4958,
      "eval_samples_per_second": 3.707,
      "eval_steps_per_second": 3.707,
      "step": 1070
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9099407196044922,
      "learning_rate": 9.736237318420653e-05,
      "loss": 0.5569,
      "step": 1071
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2835382223129272,
      "learning_rate": 9.73560320549665e-05,
      "loss": 0.8433,
      "step": 1072
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.4890114068984985,
      "learning_rate": 9.734968351950706e-05,
      "loss": 0.8528,
      "step": 1073
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.2701643705368042,
      "learning_rate": 9.734332757882108e-05,
      "loss": 0.9365,
      "step": 1074
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.1355109214782715,
      "learning_rate": 9.733696423390257e-05,
      "loss": 0.9227,
      "step": 1075
    },
    {
      "epoch": 0.39,
      "grad_norm": 0.9084652662277222,
      "learning_rate": 9.733059348574676e-05,
      "loss": 0.4829,
      "step": 1076
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.5553044080734253,
      "learning_rate": 9.732421533534997e-05,
      "loss": 0.7554,
      "step": 1077
    },
    {
      "epoch": 0.39,
      "grad_norm": 1.0044233798980713,
      "learning_rate": 9.73178297837097e-05,
      "loss": 0.3674,
      "step": 1078
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9621245861053467,
      "learning_rate": 9.731143683182464e-05,
      "loss": 0.7713,
      "step": 1079
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1997791528701782,
      "learning_rate": 9.730503648069462e-05,
      "loss": 0.8155,
      "step": 1080
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.7342174053192139,
      "eval_runtime": 327.5728,
      "eval_samples_per_second": 3.706,
      "eval_steps_per_second": 3.706,
      "step": 1080
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1819267272949219,
      "learning_rate": 9.729862873132059e-05,
      "loss": 0.8209,
      "step": 1081
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.3262872695922852,
      "learning_rate": 9.729221358470468e-05,
      "loss": 1.0823,
      "step": 1082
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9332996010780334,
      "learning_rate": 9.728579104185023e-05,
      "loss": 0.4652,
      "step": 1083
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.109463095664978,
      "learning_rate": 9.727936110376164e-05,
      "loss": 0.3536,
      "step": 1084
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1797829866409302,
      "learning_rate": 9.727292377144455e-05,
      "loss": 1.1314,
      "step": 1085
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2105252742767334,
      "learning_rate": 9.726647904590571e-05,
      "loss": 0.4318,
      "step": 1086
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.3536924123764038,
      "learning_rate": 9.726002692815304e-05,
      "loss": 0.8977,
      "step": 1087
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2360622882843018,
      "learning_rate": 9.72535674191956e-05,
      "loss": 0.6594,
      "step": 1088
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1397552490234375,
      "learning_rate": 9.724710052004365e-05,
      "loss": 0.6944,
      "step": 1089
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.208768367767334,
      "learning_rate": 9.724062623170855e-05,
      "loss": 0.63,
      "step": 1090
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.7311382293701172,
      "eval_runtime": 327.3476,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 1090
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0643670558929443,
      "learning_rate": 9.723414455520287e-05,
      "loss": 0.7369,
      "step": 1091
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0196017026901245,
      "learning_rate": 9.722765549154029e-05,
      "loss": 0.9106,
      "step": 1092
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.3225009441375732,
      "learning_rate": 9.722115904173568e-05,
      "loss": 0.7113,
      "step": 1093
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9014216661453247,
      "learning_rate": 9.721465520680501e-05,
      "loss": 0.748,
      "step": 1094
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0684127807617188,
      "learning_rate": 9.720814398776547e-05,
      "loss": 1.0398,
      "step": 1095
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2883429527282715,
      "learning_rate": 9.72016253856354e-05,
      "loss": 0.886,
      "step": 1096
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9016198515892029,
      "learning_rate": 9.719509940143425e-05,
      "loss": 0.3099,
      "step": 1097
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.0977634191513062,
      "learning_rate": 9.718856603618263e-05,
      "loss": 0.8615,
      "step": 1098
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.2195179462432861,
      "learning_rate": 9.718202529090234e-05,
      "loss": 0.9303,
      "step": 1099
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1458501815795898,
      "learning_rate": 9.717547716661632e-05,
      "loss": 0.88,
      "step": 1100
    },
    {
      "epoch": 0.4,
      "eval_loss": 0.7286005020141602,
      "eval_runtime": 327.1596,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 1100
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.046945333480835,
      "learning_rate": 9.716892166434867e-05,
      "loss": 0.745,
      "step": 1101
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.063732385635376,
      "learning_rate": 9.71623587851246e-05,
      "loss": 0.5408,
      "step": 1102
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.1669071912765503,
      "learning_rate": 9.715578852997055e-05,
      "loss": 0.719,
      "step": 1103
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.8977034687995911,
      "learning_rate": 9.714921089991403e-05,
      "loss": 0.3809,
      "step": 1104
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.440247893333435,
      "learning_rate": 9.714262589598378e-05,
      "loss": 0.7175,
      "step": 1105
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.151671051979065,
      "learning_rate": 9.713603351920964e-05,
      "loss": 0.7113,
      "step": 1106
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.1319752931594849,
      "learning_rate": 9.71294337706226e-05,
      "loss": 0.7543,
      "step": 1107
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0795537233352661,
      "learning_rate": 9.712282665125488e-05,
      "loss": 0.7293,
      "step": 1108
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2174640893936157,
      "learning_rate": 9.711621216213973e-05,
      "loss": 0.755,
      "step": 1109
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.115134596824646,
      "learning_rate": 9.710959030431167e-05,
      "loss": 0.6377,
      "step": 1110
    },
    {
      "epoch": 0.41,
      "eval_loss": 0.729058027267456,
      "eval_runtime": 327.1043,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 1110
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9092136025428772,
      "learning_rate": 9.71029610788063e-05,
      "loss": 0.6426,
      "step": 1111
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.020467758178711,
      "learning_rate": 9.70963244866604e-05,
      "loss": 0.6188,
      "step": 1112
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.274570345878601,
      "learning_rate": 9.70896805289119e-05,
      "loss": 0.9632,
      "step": 1113
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.059658408164978,
      "learning_rate": 9.708302920659986e-05,
      "loss": 0.5386,
      "step": 1114
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9157177805900574,
      "learning_rate": 9.707637052076453e-05,
      "loss": 0.4853,
      "step": 1115
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.3580604791641235,
      "learning_rate": 9.706970447244727e-05,
      "loss": 0.6738,
      "step": 1116
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0441052913665771,
      "learning_rate": 9.706303106269066e-05,
      "loss": 0.4216,
      "step": 1117
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.04804265499115,
      "learning_rate": 9.705635029253832e-05,
      "loss": 0.617,
      "step": 1118
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.6156656742095947,
      "learning_rate": 9.704966216303512e-05,
      "loss": 1.1007,
      "step": 1119
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2036420106887817,
      "learning_rate": 9.704296667522704e-05,
      "loss": 0.7588,
      "step": 1120
    },
    {
      "epoch": 0.41,
      "eval_loss": 0.7290172576904297,
      "eval_runtime": 327.3067,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 1120
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.274336814880371,
      "learning_rate": 9.703626383016122e-05,
      "loss": 0.7884,
      "step": 1121
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.0918828248977661,
      "learning_rate": 9.702955362888595e-05,
      "loss": 0.8855,
      "step": 1122
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.118255376815796,
      "learning_rate": 9.702283607245066e-05,
      "loss": 0.6528,
      "step": 1123
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2424495220184326,
      "learning_rate": 9.701611116190595e-05,
      "loss": 0.7188,
      "step": 1124
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.345710039138794,
      "learning_rate": 9.700937889830355e-05,
      "loss": 0.7632,
      "step": 1125
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.260467529296875,
      "learning_rate": 9.700263928269635e-05,
      "loss": 0.8445,
      "step": 1126
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.171414852142334,
      "learning_rate": 9.699589231613837e-05,
      "loss": 0.8577,
      "step": 1127
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.15547776222229,
      "learning_rate": 9.698913799968483e-05,
      "loss": 0.696,
      "step": 1128
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.294776439666748,
      "learning_rate": 9.698237633439206e-05,
      "loss": 0.8615,
      "step": 1129
    },
    {
      "epoch": 0.41,
      "grad_norm": 0.9895334839820862,
      "learning_rate": 9.697560732131753e-05,
      "loss": 0.8298,
      "step": 1130
    },
    {
      "epoch": 0.41,
      "eval_loss": 0.7290365695953369,
      "eval_runtime": 327.1554,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 1130
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2588953971862793,
      "learning_rate": 9.69688309615199e-05,
      "loss": 0.777,
      "step": 1131
    },
    {
      "epoch": 0.41,
      "grad_norm": 1.2754989862442017,
      "learning_rate": 9.696204725605891e-05,
      "loss": 1.0478,
      "step": 1132
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9502053260803223,
      "learning_rate": 9.695525620599554e-05,
      "loss": 0.6708,
      "step": 1133
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.259202241897583,
      "learning_rate": 9.694845781239187e-05,
      "loss": 0.6866,
      "step": 1134
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1026870012283325,
      "learning_rate": 9.694165207631111e-05,
      "loss": 1.1294,
      "step": 1135
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.241424798965454,
      "learning_rate": 9.693483899881764e-05,
      "loss": 1.062,
      "step": 1136
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9703335165977478,
      "learning_rate": 9.6928018580977e-05,
      "loss": 0.5996,
      "step": 1137
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2015035152435303,
      "learning_rate": 9.692119082385586e-05,
      "loss": 0.9629,
      "step": 1138
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.225719928741455,
      "learning_rate": 9.691435572852204e-05,
      "loss": 0.9171,
      "step": 1139
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.0723364353179932,
      "learning_rate": 9.690751329604452e-05,
      "loss": 0.4506,
      "step": 1140
    },
    {
      "epoch": 0.42,
      "eval_loss": 0.7245553135871887,
      "eval_runtime": 326.9279,
      "eval_samples_per_second": 3.713,
      "eval_steps_per_second": 3.713,
      "step": 1140
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2595912218093872,
      "learning_rate": 9.69006635274934e-05,
      "loss": 0.6002,
      "step": 1141
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.122470498085022,
      "learning_rate": 9.689380642393998e-05,
      "loss": 0.6862,
      "step": 1142
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9614905118942261,
      "learning_rate": 9.688694198645663e-05,
      "loss": 0.4363,
      "step": 1143
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.8695048689842224,
      "learning_rate": 9.688007021611692e-05,
      "loss": 0.2816,
      "step": 1144
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2717418670654297,
      "learning_rate": 9.687319111399558e-05,
      "loss": 0.8101,
      "step": 1145
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1632663011550903,
      "learning_rate": 9.686630468116846e-05,
      "loss": 0.8121,
      "step": 1146
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.1793689727783203,
      "learning_rate": 9.685941091871254e-05,
      "loss": 0.6324,
      "step": 1147
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.383225440979004,
      "learning_rate": 9.685250982770597e-05,
      "loss": 0.8595,
      "step": 1148
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2944855690002441,
      "learning_rate": 9.684560140922805e-05,
      "loss": 0.8991,
      "step": 1149
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2476311922073364,
      "learning_rate": 9.683868566435922e-05,
      "loss": 0.8609,
      "step": 1150
    },
    {
      "epoch": 0.42,
      "eval_loss": 0.7237295508384705,
      "eval_runtime": 327.6554,
      "eval_samples_per_second": 3.705,
      "eval_steps_per_second": 3.705,
      "step": 1150
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.5429545640945435,
      "learning_rate": 9.683176259418105e-05,
      "loss": 0.8882,
      "step": 1151
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.4271893501281738,
      "learning_rate": 9.682483219977629e-05,
      "loss": 0.8623,
      "step": 1152
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9882667064666748,
      "learning_rate": 9.68178944822288e-05,
      "loss": 0.5269,
      "step": 1153
    },
    {
      "epoch": 0.42,
      "grad_norm": 0.9252533316612244,
      "learning_rate": 9.68109494426236e-05,
      "loss": 0.4636,
      "step": 1154
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3515888452529907,
      "learning_rate": 9.680399708204688e-05,
      "loss": 0.8434,
      "step": 1155
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2459907531738281,
      "learning_rate": 9.679703740158593e-05,
      "loss": 0.926,
      "step": 1156
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.353151798248291,
      "learning_rate": 9.679007040232918e-05,
      "loss": 0.7363,
      "step": 1157
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3464953899383545,
      "learning_rate": 9.678309608536626e-05,
      "loss": 0.7077,
      "step": 1158
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.3816523551940918,
      "learning_rate": 9.677611445178793e-05,
      "loss": 0.7852,
      "step": 1159
    },
    {
      "epoch": 0.42,
      "grad_norm": 1.2198331356048584,
      "learning_rate": 9.676912550268604e-05,
      "loss": 0.7954,
      "step": 1160
    },
    {
      "epoch": 0.42,
      "eval_loss": 0.7203530073165894,
      "eval_runtime": 327.402,
      "eval_samples_per_second": 3.708,
      "eval_steps_per_second": 3.708,
      "step": 1160
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1685866117477417,
      "learning_rate": 9.676212923915365e-05,
      "loss": 0.7181,
      "step": 1161
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2869329452514648,
      "learning_rate": 9.675512566228493e-05,
      "loss": 0.8677,
      "step": 1162
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.249133586883545,
      "learning_rate": 9.674811477317518e-05,
      "loss": 0.5382,
      "step": 1163
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2834572792053223,
      "learning_rate": 9.67410965729209e-05,
      "loss": 1.0181,
      "step": 1164
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0592528581619263,
      "learning_rate": 9.673407106261968e-05,
      "loss": 0.6201,
      "step": 1165
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2662451267242432,
      "learning_rate": 9.672703824337026e-05,
      "loss": 1.1102,
      "step": 1166
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.066486120223999,
      "learning_rate": 9.671999811627256e-05,
      "loss": 0.8773,
      "step": 1167
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1617976427078247,
      "learning_rate": 9.671295068242759e-05,
      "loss": 0.9811,
      "step": 1168
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8960211277008057,
      "learning_rate": 9.670589594293755e-05,
      "loss": 0.4734,
      "step": 1169
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.36154043674469,
      "learning_rate": 9.669883389890573e-05,
      "loss": 0.8055,
      "step": 1170
    },
    {
      "epoch": 0.43,
      "eval_loss": 0.719220757484436,
      "eval_runtime": 327.2669,
      "eval_samples_per_second": 3.71,
      "eval_steps_per_second": 3.71,
      "step": 1170
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0677167177200317,
      "learning_rate": 9.669176455143662e-05,
      "loss": 0.7302,
      "step": 1171
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1659815311431885,
      "learning_rate": 9.668468790163584e-05,
      "loss": 0.944,
      "step": 1172
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2360775470733643,
      "learning_rate": 9.667760395061011e-05,
      "loss": 0.8921,
      "step": 1173
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.1623984575271606,
      "learning_rate": 9.667051269946735e-05,
      "loss": 0.8834,
      "step": 1174
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.8305831551551819,
      "learning_rate": 9.666341414931655e-05,
      "loss": 0.4448,
      "step": 1175
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2378944158554077,
      "learning_rate": 9.66563083012679e-05,
      "loss": 0.84,
      "step": 1176
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0628231763839722,
      "learning_rate": 9.664919515643276e-05,
      "loss": 0.6692,
      "step": 1177
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2796180248260498,
      "learning_rate": 9.664207471592353e-05,
      "loss": 0.9726,
      "step": 1178
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2487188577651978,
      "learning_rate": 9.663494698085381e-05,
      "loss": 1.0181,
      "step": 1179
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.2356621026992798,
      "learning_rate": 9.662781195233837e-05,
      "loss": 0.9101,
      "step": 1180
    },
    {
      "epoch": 0.43,
      "eval_loss": 0.7155988812446594,
      "eval_runtime": 327.3065,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 1180
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.7560021877288818,
      "learning_rate": 9.662066963149307e-05,
      "loss": 0.4418,
      "step": 1181
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.3405693769454956,
      "learning_rate": 9.661352001943493e-05,
      "loss": 1.0473,
      "step": 1182
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0085371732711792,
      "learning_rate": 9.660636311728212e-05,
      "loss": 0.7663,
      "step": 1183
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.9924250841140747,
      "learning_rate": 9.659919892615393e-05,
      "loss": 0.7287,
      "step": 1184
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.0363917350769043,
      "learning_rate": 9.659202744717078e-05,
      "loss": 0.9987,
      "step": 1185
    },
    {
      "epoch": 0.43,
      "grad_norm": 1.3416215181350708,
      "learning_rate": 9.658484868145429e-05,
      "loss": 0.8335,
      "step": 1186
    },
    {
      "epoch": 0.43,
      "grad_norm": 0.949804961681366,
      "learning_rate": 9.657766263012715e-05,
      "loss": 0.3599,
      "step": 1187
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.117350459098816,
      "learning_rate": 9.657046929431324e-05,
      "loss": 0.8141,
      "step": 1188
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9193905591964722,
      "learning_rate": 9.656326867513753e-05,
      "loss": 0.7496,
      "step": 1189
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.3346081972122192,
      "learning_rate": 9.655606077372618e-05,
      "loss": 0.9274,
      "step": 1190
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.715469479560852,
      "eval_runtime": 327.29,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 1190
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2723034620285034,
      "learning_rate": 9.654884559120646e-05,
      "loss": 0.7742,
      "step": 1191
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.370092749595642,
      "learning_rate": 9.654162312870677e-05,
      "loss": 1.0154,
      "step": 1192
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.015793800354004,
      "learning_rate": 9.653439338735669e-05,
      "loss": 0.8297,
      "step": 1193
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1564339399337769,
      "learning_rate": 9.652715636828687e-05,
      "loss": 0.4369,
      "step": 1194
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2716490030288696,
      "learning_rate": 9.651991207262918e-05,
      "loss": 0.8023,
      "step": 1195
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0381717681884766,
      "learning_rate": 9.651266050151657e-05,
      "loss": 0.6121,
      "step": 1196
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.4982566833496094,
      "learning_rate": 9.650540165608315e-05,
      "loss": 0.9813,
      "step": 1197
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.5675123929977417,
      "learning_rate": 9.649813553746416e-05,
      "loss": 0.7494,
      "step": 1198
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.9030483961105347,
      "learning_rate": 9.649086214679599e-05,
      "loss": 0.4226,
      "step": 1199
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2961080074310303,
      "learning_rate": 9.648358148521614e-05,
      "loss": 0.8512,
      "step": 1200
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.7148517966270447,
      "eval_runtime": 327.4837,
      "eval_samples_per_second": 3.707,
      "eval_steps_per_second": 3.707,
      "step": 1200
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.240808129310608,
      "learning_rate": 9.647629355386327e-05,
      "loss": 0.8883,
      "step": 1201
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.184745192527771,
      "learning_rate": 9.646899835387719e-05,
      "loss": 0.978,
      "step": 1202
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2933979034423828,
      "learning_rate": 9.64616958863988e-05,
      "loss": 0.751,
      "step": 1203
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0720919370651245,
      "learning_rate": 9.645438615257019e-05,
      "loss": 0.5706,
      "step": 1204
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1275339126586914,
      "learning_rate": 9.644706915353454e-05,
      "loss": 0.9729,
      "step": 1205
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.3230440616607666,
      "learning_rate": 9.64397448904362e-05,
      "loss": 0.6888,
      "step": 1206
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2715210914611816,
      "learning_rate": 9.643241336442064e-05,
      "loss": 1.071,
      "step": 1207
    },
    {
      "epoch": 0.44,
      "grad_norm": 0.900000810623169,
      "learning_rate": 9.642507457663447e-05,
      "loss": 0.4459,
      "step": 1208
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0923316478729248,
      "learning_rate": 9.641772852822545e-05,
      "loss": 0.9106,
      "step": 1209
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1705766916275024,
      "learning_rate": 9.641037522034246e-05,
      "loss": 0.7294,
      "step": 1210
    },
    {
      "epoch": 0.44,
      "eval_loss": 0.7128203511238098,
      "eval_runtime": 327.3389,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 1210
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.1198688745498657,
      "learning_rate": 9.64030146541355e-05,
      "loss": 0.6784,
      "step": 1211
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.2532726526260376,
      "learning_rate": 9.63956468307557e-05,
      "loss": 0.7904,
      "step": 1212
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.0595868825912476,
      "learning_rate": 9.638827175135541e-05,
      "loss": 0.7532,
      "step": 1213
    },
    {
      "epoch": 0.44,
      "grad_norm": 1.3086423873901367,
      "learning_rate": 9.638088941708799e-05,
      "loss": 0.8963,
      "step": 1214
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.1372431516647339,
      "learning_rate": 9.637349982910803e-05,
      "loss": 0.5249,
      "step": 1215
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.7975536584854126,
      "learning_rate": 9.636610298857121e-05,
      "loss": 0.4426,
      "step": 1216
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.435209035873413,
      "learning_rate": 9.635869889663435e-05,
      "loss": 0.925,
      "step": 1217
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.3516138792037964,
      "learning_rate": 9.635128755445541e-05,
      "loss": 0.8457,
      "step": 1218
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0652806758880615,
      "learning_rate": 9.634386896319351e-05,
      "loss": 0.8966,
      "step": 1219
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.327199101448059,
      "learning_rate": 9.633644312400883e-05,
      "loss": 0.8957,
      "step": 1220
    },
    {
      "epoch": 0.45,
      "eval_loss": 0.7096975445747375,
      "eval_runtime": 327.4688,
      "eval_samples_per_second": 3.707,
      "eval_steps_per_second": 3.707,
      "step": 1220
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.231490969657898,
      "learning_rate": 9.632901003806277e-05,
      "loss": 0.9261,
      "step": 1221
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.1755698919296265,
      "learning_rate": 9.63215697065178e-05,
      "loss": 0.7478,
      "step": 1222
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2419378757476807,
      "learning_rate": 9.631412213053755e-05,
      "loss": 0.7768,
      "step": 1223
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9860924482345581,
      "learning_rate": 9.630666731128678e-05,
      "loss": 0.6133,
      "step": 1224
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.1494247913360596,
      "learning_rate": 9.629920524993138e-05,
      "loss": 0.7015,
      "step": 1225
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2799384593963623,
      "learning_rate": 9.629173594763839e-05,
      "loss": 0.6314,
      "step": 1226
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2646912336349487,
      "learning_rate": 9.628425940557596e-05,
      "loss": 0.6991,
      "step": 1227
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.4174396991729736,
      "learning_rate": 9.627677562491337e-05,
      "loss": 1.0225,
      "step": 1228
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0866236686706543,
      "learning_rate": 9.626928460682106e-05,
      "loss": 0.7756,
      "step": 1229
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.1118324995040894,
      "learning_rate": 9.626178635247054e-05,
      "loss": 0.7984,
      "step": 1230
    },
    {
      "epoch": 0.45,
      "eval_loss": 0.7093915343284607,
      "eval_runtime": 327.5664,
      "eval_samples_per_second": 3.706,
      "eval_steps_per_second": 3.706,
      "step": 1230
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9200209975242615,
      "learning_rate": 9.625428086303455e-05,
      "loss": 0.5886,
      "step": 1231
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.1880308389663696,
      "learning_rate": 9.624676813968687e-05,
      "loss": 1.039,
      "step": 1232
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.407127857208252,
      "learning_rate": 9.623924818360248e-05,
      "loss": 0.6144,
      "step": 1233
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2340667247772217,
      "learning_rate": 9.623172099595743e-05,
      "loss": 0.7105,
      "step": 1234
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.2997792959213257,
      "learning_rate": 9.622418657792893e-05,
      "loss": 0.8463,
      "step": 1235
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0635383129119873,
      "learning_rate": 9.621664493069533e-05,
      "loss": 0.7398,
      "step": 1236
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.1455693244934082,
      "learning_rate": 9.620909605543612e-05,
      "loss": 0.366,
      "step": 1237
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.0235668420791626,
      "learning_rate": 9.620153995333188e-05,
      "loss": 0.7822,
      "step": 1238
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.279742956161499,
      "learning_rate": 9.619397662556435e-05,
      "loss": 0.6339,
      "step": 1239
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.5149728059768677,
      "learning_rate": 9.618640607331637e-05,
      "loss": 0.8835,
      "step": 1240
    },
    {
      "epoch": 0.45,
      "eval_loss": 0.7066676616668701,
      "eval_runtime": 327.5259,
      "eval_samples_per_second": 3.707,
      "eval_steps_per_second": 3.707,
      "step": 1240
    },
    {
      "epoch": 0.45,
      "grad_norm": 1.144757866859436,
      "learning_rate": 9.617882829777198e-05,
      "loss": 0.6181,
      "step": 1241
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.898604691028595,
      "learning_rate": 9.617124330011624e-05,
      "loss": 0.5138,
      "step": 1242
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.202249526977539,
      "learning_rate": 9.616365108153547e-05,
      "loss": 0.9172,
      "step": 1243
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2417546510696411,
      "learning_rate": 9.6156051643217e-05,
      "loss": 0.7455,
      "step": 1244
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.286643385887146,
      "learning_rate": 9.614844498634934e-05,
      "loss": 0.8137,
      "step": 1245
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2280532121658325,
      "learning_rate": 9.614083111212216e-05,
      "loss": 0.86,
      "step": 1246
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.3524885177612305,
      "learning_rate": 9.613321002172622e-05,
      "loss": 0.7014,
      "step": 1247
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2973774671554565,
      "learning_rate": 9.612558171635338e-05,
      "loss": 0.7591,
      "step": 1248
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1641961336135864,
      "learning_rate": 9.611794619719671e-05,
      "loss": 0.7661,
      "step": 1249
    },
    {
      "epoch": 0.46,
      "grad_norm": 2.8230698108673096,
      "learning_rate": 9.611030346545035e-05,
      "loss": 0.6287,
      "step": 1250
    },
    {
      "epoch": 0.46,
      "eval_loss": 0.7065222263336182,
      "eval_runtime": 327.2901,
      "eval_samples_per_second": 3.709,
      "eval_steps_per_second": 3.709,
      "step": 1250
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.119346022605896,
      "learning_rate": 9.610265352230956e-05,
      "loss": 0.4892,
      "step": 1251
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2806673049926758,
      "learning_rate": 9.609499636897077e-05,
      "loss": 0.6682,
      "step": 1252
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9317693114280701,
      "learning_rate": 9.608733200663151e-05,
      "loss": 0.2402,
      "step": 1253
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0685707330703735,
      "learning_rate": 9.607966043649046e-05,
      "loss": 0.3648,
      "step": 1254
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.3905078172683716,
      "learning_rate": 9.607198165974738e-05,
      "loss": 0.5946,
      "step": 1255
    },
    {
      "epoch": 0.46,
      "grad_norm": 3.0971407890319824,
      "learning_rate": 9.606429567760319e-05,
      "loss": 1.0235,
      "step": 1256
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.4192543029785156,
      "learning_rate": 9.605660249125996e-05,
      "loss": 0.6361,
      "step": 1257
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.016917109489441,
      "learning_rate": 9.604890210192085e-05,
      "loss": 0.6856,
      "step": 1258
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.2760342359542847,
      "learning_rate": 9.604119451079015e-05,
      "loss": 0.8948,
      "step": 1259
    },
    {
      "epoch": 0.46,
      "grad_norm": 0.9377330541610718,
      "learning_rate": 9.603347971907328e-05,
      "loss": 0.5674,
      "step": 1260
    },
    {
      "epoch": 0.46,
      "eval_loss": 0.7061220407485962,
      "eval_runtime": 327.0154,
      "eval_samples_per_second": 3.712,
      "eval_steps_per_second": 3.712,
      "step": 1260
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.3685868978500366,
      "learning_rate": 9.602575772797682e-05,
      "loss": 0.7724,
      "step": 1261
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1051931381225586,
      "learning_rate": 9.601802853870843e-05,
      "loss": 0.7361,
      "step": 1262
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.1235417127609253,
      "learning_rate": 9.601029215247689e-05,
      "loss": 0.9149,
      "step": 1263
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.39596426486969,
      "learning_rate": 9.600254857049215e-05,
      "loss": 1.0873,
      "step": 1264
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0526740550994873,
      "learning_rate": 9.599479779396528e-05,
      "loss": 0.3967,
      "step": 1265
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.171878457069397,
      "learning_rate": 9.598703982410842e-05,
      "loss": 0.6909,
      "step": 1266
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0235188007354736,
      "learning_rate": 9.59792746621349e-05,
      "loss": 0.3512,
      "step": 1267
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.0186110734939575,
      "learning_rate": 9.597150230925914e-05,
      "loss": 0.634,
      "step": 1268
    },
    {
      "epoch": 0.46,
      "grad_norm": 1.4655170440673828,
      "learning_rate": 9.596372276669667e-05,
      "loss": 0.9351,
      "step": 1269
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.191089391708374,
      "learning_rate": 9.595593603566422e-05,
      "loss": 0.8279,
      "step": 1270
    },
    {
      "epoch": 0.47,
      "eval_loss": 0.7045026421546936,
      "eval_runtime": 326.8983,
      "eval_samples_per_second": 3.714,
      "eval_steps_per_second": 3.714,
      "step": 1270
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2936800718307495,
      "learning_rate": 9.594814211737955e-05,
      "loss": 1.0863,
      "step": 1271
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.150005578994751,
      "learning_rate": 9.594034101306159e-05,
      "loss": 0.807,
      "step": 1272
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9702546000480652,
      "learning_rate": 9.593253272393039e-05,
      "loss": 0.6327,
      "step": 1273
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9769794344902039,
      "learning_rate": 9.592471725120714e-05,
      "loss": 0.3969,
      "step": 1274
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.4004119634628296,
      "learning_rate": 9.591689459611413e-05,
      "loss": 0.7679,
      "step": 1275
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3859682083129883,
      "learning_rate": 9.590906475987476e-05,
      "loss": 0.761,
      "step": 1276
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.040541172027588,
      "learning_rate": 9.590122774371359e-05,
      "loss": 0.7549,
      "step": 1277
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1352590322494507,
      "learning_rate": 9.589338354885629e-05,
      "loss": 0.8962,
      "step": 1278
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.216615915298462,
      "learning_rate": 9.588553217652962e-05,
      "loss": 0.9494,
      "step": 1279
    },
    {
      "epoch": 0.47,
      "grad_norm": 0.9420251846313477,
      "learning_rate": 9.587767362796153e-05,
      "loss": 0.5677,
      "step": 1280
    },
    {
      "epoch": 0.47,
      "eval_loss": 0.7042204141616821,
      "eval_runtime": 326.9005,
      "eval_samples_per_second": 3.714,
      "eval_steps_per_second": 3.714,
      "step": 1280
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.219765543937683,
      "learning_rate": 9.586980790438105e-05,
      "loss": 0.5323,
      "step": 1281
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3166252374649048,
      "learning_rate": 9.58619350070183e-05,
      "loss": 0.8459,
      "step": 1282
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0667998790740967,
      "learning_rate": 9.585405493710457e-05,
      "loss": 0.4451,
      "step": 1283
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6336212158203125,
      "learning_rate": 9.584616769587229e-05,
      "loss": 0.9247,
      "step": 1284
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.127168893814087,
      "learning_rate": 9.583827328455494e-05,
      "loss": 0.4769,
      "step": 1285
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.1243362426757812,
      "learning_rate": 9.583037170438718e-05,
      "loss": 0.6809,
      "step": 1286
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6343134641647339,
      "learning_rate": 9.582246295660478e-05,
      "loss": 0.8918,
      "step": 1287
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2081178426742554,
      "learning_rate": 9.58145470424446e-05,
      "loss": 0.669,
      "step": 1288
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2694412469863892,
      "learning_rate": 9.580662396314469e-05,
      "loss": 0.8622,
      "step": 1289
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0286532640457153,
      "learning_rate": 9.579869371994413e-05,
      "loss": 0.5463,
      "step": 1290
    },
    {
      "epoch": 0.47,
      "eval_loss": 0.70130455493927,
      "eval_runtime": 326.4077,
      "eval_samples_per_second": 3.719,
      "eval_steps_per_second": 3.719,
      "step": 1290
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.178612470626831,
      "learning_rate": 9.579075631408317e-05,
      "loss": 0.5566,
      "step": 1291
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.3962150812149048,
      "learning_rate": 9.57828117468032e-05,
      "loss": 0.6452,
      "step": 1292
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.6736418008804321,
      "learning_rate": 9.57748600193467e-05,
      "loss": 0.8396,
      "step": 1293
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.0474839210510254,
      "learning_rate": 9.576690113295725e-05,
      "loss": 0.5558,
      "step": 1294
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.2454702854156494,
      "learning_rate": 9.57589350888796e-05,
      "loss": 0.7522,
      "step": 1295
    },
    {
      "epoch": 0.47,
      "grad_norm": 1.170978307723999,
      "learning_rate": 9.575096188835961e-05,
      "loss": 0.7535,
      "step": 1296
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.2352946996688843,
      "learning_rate": 9.574298153264422e-05,
      "loss": 0.8403,
      "step": 1297
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9333877563476562,
      "learning_rate": 9.573499402298152e-05,
      "loss": 0.4101,
      "step": 1298
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3114326000213623,
      "learning_rate": 9.572699936062069e-05,
      "loss": 0.8028,
      "step": 1299
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.1433689594268799,
      "learning_rate": 9.571899754681209e-05,
      "loss": 0.6739,
      "step": 1300
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.6973986625671387,
      "eval_runtime": 326.5842,
      "eval_samples_per_second": 3.717,
      "eval_steps_per_second": 3.717,
      "step": 1300
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9502914547920227,
      "learning_rate": 9.571098858280713e-05,
      "loss": 0.8331,
      "step": 1301
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3518610000610352,
      "learning_rate": 9.570297246985837e-05,
      "loss": 0.8301,
      "step": 1302
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0950876474380493,
      "learning_rate": 9.569494920921951e-05,
      "loss": 0.4799,
      "step": 1303
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0390498638153076,
      "learning_rate": 9.56869188021453e-05,
      "loss": 0.5319,
      "step": 1304
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0244216918945312,
      "learning_rate": 9.56788812498917e-05,
      "loss": 0.5314,
      "step": 1305
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.2496397495269775,
      "learning_rate": 9.567083655371571e-05,
      "loss": 0.644,
      "step": 1306
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0181382894515991,
      "learning_rate": 9.566278471487547e-05,
      "loss": 0.5308,
      "step": 1307
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9698922038078308,
      "learning_rate": 9.565472573463027e-05,
      "loss": 0.401,
      "step": 1308
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.2115306854248047,
      "learning_rate": 9.564665961424046e-05,
      "loss": 0.7062,
      "step": 1309
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.9246317744255066,
      "learning_rate": 9.563858635496756e-05,
      "loss": 0.4437,
      "step": 1310
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.6963239312171936,
      "eval_runtime": 326.7095,
      "eval_samples_per_second": 3.716,
      "eval_steps_per_second": 3.716,
      "step": 1310
    },
    {
      "epoch": 0.48,
      "grad_norm": 0.6905509233474731,
      "learning_rate": 9.563050595807415e-05,
      "loss": 0.2243,
      "step": 1311
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.258551001548767,
      "learning_rate": 9.5622418424824e-05,
      "loss": 0.9116,
      "step": 1312
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0642157793045044,
      "learning_rate": 9.561432375648193e-05,
      "loss": 0.7581,
      "step": 1313
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.1867033243179321,
      "learning_rate": 9.56062219543139e-05,
      "loss": 0.5728,
      "step": 1314
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.2863945960998535,
      "learning_rate": 9.5598113019587e-05,
      "loss": 1.02,
      "step": 1315
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.172974705696106,
      "learning_rate": 9.558999695356943e-05,
      "loss": 0.8623,
      "step": 1316
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.3317445516586304,
      "learning_rate": 9.558187375753046e-05,
      "loss": 0.7588,
      "step": 1317
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4449903964996338,
      "learning_rate": 9.557374343274055e-05,
      "loss": 0.8412,
      "step": 1318
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5270731449127197,
      "learning_rate": 9.556560598047122e-05,
      "loss": 0.9447,
      "step": 1319
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.090330719947815,
      "learning_rate": 9.555746140199511e-05,
      "loss": 0.6417,
      "step": 1320
    },
    {
      "epoch": 0.48,
      "eval_loss": 0.6944208741188049,
      "eval_runtime": 326.651,
      "eval_samples_per_second": 3.717,
      "eval_steps_per_second": 3.717,
      "step": 1320
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.0030713081359863,
      "learning_rate": 9.554930969858602e-05,
      "loss": 0.3371,
      "step": 1321
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.4209438562393188,
      "learning_rate": 9.554115087151881e-05,
      "loss": 0.779,
      "step": 1322
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.317909836769104,
      "learning_rate": 9.553298492206947e-05,
      "loss": 0.942,
      "step": 1323
    },
    {
      "epoch": 0.48,
      "grad_norm": 1.5690538883209229,
      "learning_rate": 9.552481185151513e-05,
      "loss": 0.9209,
      "step": 1324
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2152092456817627,
      "learning_rate": 9.551663166113399e-05,
      "loss": 0.9695,
      "step": 1325
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.205839991569519,
      "learning_rate": 9.550844435220539e-05,
      "loss": 0.8268,
      "step": 1326
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2668198347091675,
      "learning_rate": 9.55002499260098e-05,
      "loss": 0.7617,
      "step": 1327
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.6956263184547424,
      "learning_rate": 9.549204838382876e-05,
      "loss": 0.2379,
      "step": 1328
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7343953847885132,
      "learning_rate": 9.548383972694496e-05,
      "loss": 0.8261,
      "step": 1329
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2981024980545044,
      "learning_rate": 9.547562395664218e-05,
      "loss": 0.694,
      "step": 1330
    },
    {
      "epoch": 0.49,
      "eval_loss": 0.6951366066932678,
      "eval_runtime": 326.5628,
      "eval_samples_per_second": 3.718,
      "eval_steps_per_second": 3.718,
      "step": 1330
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.1890137195587158,
      "learning_rate": 9.546740107420531e-05,
      "loss": 0.8833,
      "step": 1331
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2527095079421997,
      "learning_rate": 9.545917108092038e-05,
      "loss": 0.5756,
      "step": 1332
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.9497896432876587,
      "learning_rate": 9.545093397807452e-05,
      "loss": 0.8322,
      "step": 1333
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.878954291343689,
      "learning_rate": 9.544268976695595e-05,
      "loss": 1.0487,
      "step": 1334
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.7358156442642212,
      "learning_rate": 9.543443844885403e-05,
      "loss": 0.6806,
      "step": 1335
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9076201319694519,
      "learning_rate": 9.542618002505921e-05,
      "loss": 0.4364,
      "step": 1336
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.3683995008468628,
      "learning_rate": 9.541791449686308e-05,
      "loss": 1.0579,
      "step": 1337
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4997729063034058,
      "learning_rate": 9.54096418655583e-05,
      "loss": 0.7057,
      "step": 1338
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.1602213382720947,
      "learning_rate": 9.540136213243866e-05,
      "loss": 0.8573,
      "step": 1339
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0139058828353882,
      "learning_rate": 9.539307529879911e-05,
      "loss": 0.3279,
      "step": 1340
    },
    {
      "epoch": 0.49,
      "eval_loss": 0.693810760974884,
      "eval_runtime": 326.6332,
      "eval_samples_per_second": 3.717,
      "eval_steps_per_second": 3.717,
      "step": 1340
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.3014464378356934,
      "learning_rate": 9.538478136593561e-05,
      "loss": 0.9624,
      "step": 1341
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.339146614074707,
      "learning_rate": 9.53764803351453e-05,
      "loss": 0.6855,
      "step": 1342
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2029927968978882,
      "learning_rate": 9.536817220772644e-05,
      "loss": 0.5728,
      "step": 1343
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4158180952072144,
      "learning_rate": 9.535985698497836e-05,
      "loss": 0.8147,
      "step": 1344
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.4509060382843018,
      "learning_rate": 9.535153466820149e-05,
      "loss": 0.478,
      "step": 1345
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.288139820098877,
      "learning_rate": 9.534320525869742e-05,
      "loss": 0.6637,
      "step": 1346
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.2662245035171509,
      "learning_rate": 9.533486875776884e-05,
      "loss": 0.851,
      "step": 1347
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.0960131883621216,
      "learning_rate": 9.53265251667195e-05,
      "loss": 0.5556,
      "step": 1348
    },
    {
      "epoch": 0.49,
      "grad_norm": 0.9741668105125427,
      "learning_rate": 9.53181744868543e-05,
      "loss": 0.651,
      "step": 1349
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.279191255569458,
      "learning_rate": 9.530981671947923e-05,
      "loss": 0.7378,
      "step": 1350
    },
    {
      "epoch": 0.49,
      "eval_loss": 0.6919353008270264,
      "eval_runtime": 326.7652,
      "eval_samples_per_second": 3.715,
      "eval_steps_per_second": 3.715,
      "step": 1350
    },
    {
      "epoch": 0.49,
      "grad_norm": 1.213263988494873,
      "learning_rate": 9.530145186590141e-05,
      "loss": 0.6212,
      "step": 1351
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.094364881515503,
      "learning_rate": 9.529307992742907e-05,
      "loss": 0.5457,
      "step": 1352
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3308348655700684,
      "learning_rate": 9.528470090537152e-05,
      "loss": 0.7679,
      "step": 1353
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0230263471603394,
      "learning_rate": 9.527631480103917e-05,
      "loss": 0.5297,
      "step": 1354
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2510862350463867,
      "learning_rate": 9.526792161574362e-05,
      "loss": 0.8478,
      "step": 1355
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2101556062698364,
      "learning_rate": 9.525952135079746e-05,
      "loss": 0.8023,
      "step": 1356
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0802668333053589,
      "learning_rate": 9.525111400751447e-05,
      "loss": 0.4307,
      "step": 1357
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0318095684051514,
      "learning_rate": 9.52426995872095e-05,
      "loss": 0.5739,
      "step": 1358
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3132590055465698,
      "learning_rate": 9.523427809119854e-05,
      "loss": 0.8046,
      "step": 1359
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.145283579826355,
      "learning_rate": 9.522584952079862e-05,
      "loss": 0.6506,
      "step": 1360
    },
    {
      "epoch": 0.5,
      "eval_loss": 0.6907675862312317,
      "eval_runtime": 326.7806,
      "eval_samples_per_second": 3.715,
      "eval_steps_per_second": 3.715,
      "step": 1360
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0315738916397095,
      "learning_rate": 9.521741387732799e-05,
      "loss": 0.9407,
      "step": 1361
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1943215131759644,
      "learning_rate": 9.520897116210588e-05,
      "loss": 0.5906,
      "step": 1362
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1193984746932983,
      "learning_rate": 9.52005213764527e-05,
      "loss": 0.5526,
      "step": 1363
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.259595513343811,
      "learning_rate": 9.519206452168996e-05,
      "loss": 0.7515,
      "step": 1364
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3876625299453735,
      "learning_rate": 9.518360059914025e-05,
      "loss": 0.7382,
      "step": 1365
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9481674432754517,
      "learning_rate": 9.517512961012729e-05,
      "loss": 0.4602,
      "step": 1366
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.3672274351119995,
      "learning_rate": 9.516665155597588e-05,
      "loss": 1.0389,
      "step": 1367
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2778156995773315,
      "learning_rate": 9.515816643801197e-05,
      "loss": 0.6443,
      "step": 1368
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0095680952072144,
      "learning_rate": 9.514967425756258e-05,
      "loss": 0.5468,
      "step": 1369
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1284213066101074,
      "learning_rate": 9.51411750159558e-05,
      "loss": 0.7162,
      "step": 1370
    },
    {
      "epoch": 0.5,
      "eval_loss": 0.6879427433013916,
      "eval_runtime": 326.9856,
      "eval_samples_per_second": 3.713,
      "eval_steps_per_second": 3.713,
      "step": 1370
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.979199230670929,
      "learning_rate": 9.513266871452091e-05,
      "loss": 0.3978,
      "step": 1371
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.2395234107971191,
      "learning_rate": 9.512415535458824e-05,
      "loss": 0.7217,
      "step": 1372
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.532841682434082,
      "learning_rate": 9.51156349374892e-05,
      "loss": 0.5828,
      "step": 1373
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.4794811010360718,
      "learning_rate": 9.510710746455636e-05,
      "loss": 0.7451,
      "step": 1374
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.1975514888763428,
      "learning_rate": 9.509857293712338e-05,
      "loss": 0.8624,
      "step": 1375
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.0689079761505127,
      "learning_rate": 9.509003135652499e-05,
      "loss": 0.7698,
      "step": 1376
    },
    {
      "epoch": 0.5,
      "grad_norm": 1.239490032196045,
      "learning_rate": 9.508148272409704e-05,
      "loss": 1.076,
      "step": 1377
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8560236096382141,
      "learning_rate": 9.507292704117654e-05,
      "loss": 0.2058,
      "step": 1378
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2865023612976074,
      "learning_rate": 9.506436430910149e-05,
      "loss": 0.576,
      "step": 1379
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2467364072799683,
      "learning_rate": 9.505579452921109e-05,
      "loss": 0.8933,
      "step": 1380
    },
    {
      "epoch": 0.51,
      "eval_loss": 0.686713457107544,
      "eval_runtime": 326.7792,
      "eval_samples_per_second": 3.715,
      "eval_steps_per_second": 3.715,
      "step": 1380
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.3885505199432373,
      "learning_rate": 9.504721770284559e-05,
      "loss": 0.5417,
      "step": 1381
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.294251799583435,
      "learning_rate": 9.503863383134636e-05,
      "loss": 1.1262,
      "step": 1382
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.3769441843032837,
      "learning_rate": 9.503004291605587e-05,
      "loss": 0.8126,
      "step": 1383
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.591406226158142,
      "learning_rate": 9.50214449583177e-05,
      "loss": 1.0597,
      "step": 1384
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.360514760017395,
      "learning_rate": 9.501283995947652e-05,
      "loss": 0.8671,
      "step": 1385
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2047621011734009,
      "learning_rate": 9.500422792087808e-05,
      "loss": 0.9217,
      "step": 1386
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2465641498565674,
      "learning_rate": 9.499560884386929e-05,
      "loss": 0.8549,
      "step": 1387
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.3628026247024536,
      "learning_rate": 9.49869827297981e-05,
      "loss": 0.9069,
      "step": 1388
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.165479302406311,
      "learning_rate": 9.497834958001362e-05,
      "loss": 0.5385,
      "step": 1389
    },
    {
      "epoch": 0.51,
      "grad_norm": 0.765984296798706,
      "learning_rate": 9.496970939586598e-05,
      "loss": 0.5086,
      "step": 1390
    },
    {
      "epoch": 0.51,
      "eval_loss": 0.6843752264976501,
      "eval_runtime": 327.0028,
      "eval_samples_per_second": 3.713,
      "eval_steps_per_second": 3.713,
      "step": 1390
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2583180665969849,
      "learning_rate": 9.496106217870648e-05,
      "loss": 0.7516,
      "step": 1391
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.0148133039474487,
      "learning_rate": 9.495240792988751e-05,
      "loss": 0.6471,
      "step": 1392
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.6427719593048096,
      "learning_rate": 9.494374665076251e-05,
      "loss": 0.7738,
      "step": 1393
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2822386026382446,
      "learning_rate": 9.49350783426861e-05,
      "loss": 0.6767,
      "step": 1394
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1904743909835815,
      "learning_rate": 9.492640300701392e-05,
      "loss": 0.8329,
      "step": 1395
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2045402526855469,
      "learning_rate": 9.491772064510275e-05,
      "loss": 0.7822,
      "step": 1396
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.2955538034439087,
      "learning_rate": 9.490903125831048e-05,
      "loss": 1.0175,
      "step": 1397
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.1452250480651855,
      "learning_rate": 9.490033484799608e-05,
      "loss": 0.3949,
      "step": 1398
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.388791799545288,
      "learning_rate": 9.48916314155196e-05,
      "loss": 0.7807,
      "step": 1399
    },
    {
      "epoch": 0.51,
      "grad_norm": 1.073722004890442,
      "learning_rate": 9.488292096224222e-05,
      "loss": 0.6271,
      "step": 1400
    },
    {
      "epoch": 0.51,
      "eval_loss": 0.6832455396652222,
      "eval_runtime": 327.1618,
      "eval_samples_per_second": 3.711,
      "eval_steps_per_second": 3.711,
      "step": 1400
    }
  ],
  "logging_steps": 1,
  "max_steps": 8190,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 3.619671131553792e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
