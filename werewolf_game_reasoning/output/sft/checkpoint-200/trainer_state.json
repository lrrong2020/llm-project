{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.14652014652014653,
  "eval_steps": 10,
  "global_step": 200,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.0049987789987789985,
      "loss": 2.5911,
      "step": 1
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.004997557997557998,
      "loss": 2.4668,
      "step": 2
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.004996336996336996,
      "loss": 2.4872,
      "step": 3
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.004995115995115995,
      "loss": 2.5384,
      "step": 4
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.004993894993894994,
      "loss": 2.5063,
      "step": 5
    },
    {
      "epoch": 0.0,
      "grad_norm": 0.0,
      "learning_rate": 0.004992673992673993,
      "loss": 2.4611,
      "step": 6
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004991452991452991,
      "loss": 2.4305,
      "step": 7
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.0049902319902319905,
      "loss": 2.4995,
      "step": 8
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004989010989010989,
      "loss": 2.3913,
      "step": 9
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004987789987789988,
      "loss": 2.4884,
      "step": 10
    },
    {
      "epoch": 0.01,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.7955,
      "eval_samples_per_second": 3.726,
      "eval_steps_per_second": 3.726,
      "step": 10
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.0049865689865689865,
      "loss": 2.6271,
      "step": 11
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004985347985347986,
      "loss": 2.5483,
      "step": 12
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004984126984126984,
      "loss": 2.5565,
      "step": 13
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004982905982905983,
      "loss": 2.473,
      "step": 14
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004981684981684982,
      "loss": 2.5906,
      "step": 15
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004980463980463981,
      "loss": 2.5474,
      "step": 16
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004979242979242979,
      "loss": 2.4457,
      "step": 17
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.0049780219780219785,
      "loss": 2.5576,
      "step": 18
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004976800976800977,
      "loss": 2.5655,
      "step": 19
    },
    {
      "epoch": 0.01,
      "grad_norm": 0.0,
      "learning_rate": 0.004975579975579976,
      "loss": 2.698,
      "step": 20
    },
    {
      "epoch": 0.01,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.7374,
      "eval_samples_per_second": 3.727,
      "eval_steps_per_second": 3.727,
      "step": 20
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.0049743589743589745,
      "loss": 2.5504,
      "step": 21
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004973137973137974,
      "loss": 2.6277,
      "step": 22
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004971916971916972,
      "loss": 2.6505,
      "step": 23
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004970695970695971,
      "loss": 2.6862,
      "step": 24
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.00496947496947497,
      "loss": 2.5353,
      "step": 25
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004968253968253968,
      "loss": 2.5363,
      "step": 26
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004967032967032967,
      "loss": 2.672,
      "step": 27
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004965811965811966,
      "loss": 2.5006,
      "step": 28
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004964590964590965,
      "loss": 2.5884,
      "step": 29
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004963369963369963,
      "loss": 2.6575,
      "step": 30
    },
    {
      "epoch": 0.02,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.7839,
      "eval_samples_per_second": 3.726,
      "eval_steps_per_second": 3.726,
      "step": 30
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.0049621489621489625,
      "loss": 2.6099,
      "step": 31
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.004960927960927961,
      "loss": 2.6541,
      "step": 32
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.00495970695970696,
      "loss": 2.499,
      "step": 33
    },
    {
      "epoch": 0.02,
      "grad_norm": 0.0,
      "learning_rate": 0.0049584859584859585,
      "loss": 2.5472,
      "step": 34
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004957264957264958,
      "loss": 2.61,
      "step": 35
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004956043956043956,
      "loss": 2.4383,
      "step": 36
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004954822954822955,
      "loss": 2.5583,
      "step": 37
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004953601953601954,
      "loss": 2.6219,
      "step": 38
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004952380952380953,
      "loss": 2.6433,
      "step": 39
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004951159951159951,
      "loss": 2.6367,
      "step": 40
    },
    {
      "epoch": 0.03,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.4765,
      "eval_samples_per_second": 3.73,
      "eval_steps_per_second": 3.73,
      "step": 40
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.0049499389499389505,
      "loss": 2.5938,
      "step": 41
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004948717948717949,
      "loss": 2.644,
      "step": 42
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004947496947496948,
      "loss": 2.5983,
      "step": 43
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.0049462759462759465,
      "loss": 2.6006,
      "step": 44
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004945054945054946,
      "loss": 2.596,
      "step": 45
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004943833943833944,
      "loss": 2.5553,
      "step": 46
    },
    {
      "epoch": 0.03,
      "grad_norm": 0.0,
      "learning_rate": 0.004942612942612943,
      "loss": 2.3928,
      "step": 47
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004941391941391942,
      "loss": 2.4708,
      "step": 48
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004940170940170941,
      "loss": 2.6212,
      "step": 49
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004938949938949939,
      "loss": 2.4701,
      "step": 50
    },
    {
      "epoch": 0.04,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.3668,
      "eval_samples_per_second": 3.731,
      "eval_steps_per_second": 3.731,
      "step": 50
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004937728937728938,
      "loss": 2.7378,
      "step": 51
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004936507936507937,
      "loss": 2.6151,
      "step": 52
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004935286935286935,
      "loss": 2.571,
      "step": 53
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.0049340659340659345,
      "loss": 2.4821,
      "step": 54
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004932844932844933,
      "loss": 2.509,
      "step": 55
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004931623931623932,
      "loss": 2.5849,
      "step": 56
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.0049304029304029304,
      "loss": 2.5245,
      "step": 57
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.00492918192918193,
      "loss": 2.5877,
      "step": 58
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004927960927960928,
      "loss": 2.6986,
      "step": 59
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004926739926739927,
      "loss": 2.4848,
      "step": 60
    },
    {
      "epoch": 0.04,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.6634,
      "eval_samples_per_second": 3.728,
      "eval_steps_per_second": 3.728,
      "step": 60
    },
    {
      "epoch": 0.04,
      "grad_norm": 0.0,
      "learning_rate": 0.004925518925518926,
      "loss": 2.4487,
      "step": 61
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004924297924297925,
      "loss": 2.446,
      "step": 62
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004923076923076923,
      "loss": 2.4475,
      "step": 63
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004921855921855922,
      "loss": 2.5969,
      "step": 64
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004920634920634921,
      "loss": 2.6274,
      "step": 65
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004919413919413919,
      "loss": 2.5988,
      "step": 66
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.0049181929181929184,
      "loss": 2.4752,
      "step": 67
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004916971916971917,
      "loss": 2.618,
      "step": 68
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004915750915750915,
      "loss": 2.6039,
      "step": 69
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004914529914529914,
      "loss": 2.6684,
      "step": 70
    },
    {
      "epoch": 0.05,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.6453,
      "eval_samples_per_second": 3.728,
      "eval_steps_per_second": 3.728,
      "step": 70
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004913308913308913,
      "loss": 2.5723,
      "step": 71
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004912087912087912,
      "loss": 2.5871,
      "step": 72
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.00491086691086691,
      "loss": 2.5086,
      "step": 73
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.00490964590964591,
      "loss": 2.6496,
      "step": 74
    },
    {
      "epoch": 0.05,
      "grad_norm": 0.0,
      "learning_rate": 0.004908424908424908,
      "loss": 2.5063,
      "step": 75
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004907203907203907,
      "loss": 2.4855,
      "step": 76
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004905982905982906,
      "loss": 2.5014,
      "step": 77
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004904761904761905,
      "loss": 2.6767,
      "step": 78
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004903540903540903,
      "loss": 2.659,
      "step": 79
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004902319902319902,
      "loss": 2.5806,
      "step": 80
    },
    {
      "epoch": 0.06,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.6095,
      "eval_samples_per_second": 3.728,
      "eval_steps_per_second": 3.728,
      "step": 80
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004901098901098901,
      "loss": 2.6116,
      "step": 81
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.0048998778998779,
      "loss": 2.5177,
      "step": 82
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004898656898656898,
      "loss": 2.5992,
      "step": 83
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004897435897435898,
      "loss": 2.5509,
      "step": 84
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004896214896214896,
      "loss": 2.5653,
      "step": 85
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004894993894993895,
      "loss": 2.5848,
      "step": 86
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004893772893772894,
      "loss": 2.5898,
      "step": 87
    },
    {
      "epoch": 0.06,
      "grad_norm": 0.0,
      "learning_rate": 0.004892551892551893,
      "loss": 2.4803,
      "step": 88
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004891330891330891,
      "loss": 2.6225,
      "step": 89
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.00489010989010989,
      "loss": 2.4838,
      "step": 90
    },
    {
      "epoch": 0.07,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.5371,
      "eval_samples_per_second": 3.729,
      "eval_steps_per_second": 3.729,
      "step": 90
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004888888888888889,
      "loss": 2.6455,
      "step": 91
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004887667887667888,
      "loss": 2.4986,
      "step": 92
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004886446886446886,
      "loss": 2.6513,
      "step": 93
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004885225885225885,
      "loss": 2.5914,
      "step": 94
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004884004884004884,
      "loss": 2.4755,
      "step": 95
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004882783882783882,
      "loss": 2.6611,
      "step": 96
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004881562881562882,
      "loss": 2.3841,
      "step": 97
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.00488034188034188,
      "loss": 2.6,
      "step": 98
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004879120879120879,
      "loss": 2.419,
      "step": 99
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004877899877899878,
      "loss": 2.503,
      "step": 100
    },
    {
      "epoch": 0.07,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.5122,
      "eval_samples_per_second": 3.73,
      "eval_steps_per_second": 3.73,
      "step": 100
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004876678876678877,
      "loss": 2.5003,
      "step": 101
    },
    {
      "epoch": 0.07,
      "grad_norm": 0.0,
      "learning_rate": 0.004875457875457875,
      "loss": 2.5018,
      "step": 102
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004874236874236874,
      "loss": 2.6412,
      "step": 103
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004873015873015873,
      "loss": 2.5353,
      "step": 104
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004871794871794872,
      "loss": 2.6758,
      "step": 105
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.00487057387057387,
      "loss": 2.6315,
      "step": 106
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.00486935286935287,
      "loss": 2.5401,
      "step": 107
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004868131868131868,
      "loss": 2.5237,
      "step": 108
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004866910866910867,
      "loss": 2.5894,
      "step": 109
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004865689865689866,
      "loss": 2.6762,
      "step": 110
    },
    {
      "epoch": 0.08,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.3627,
      "eval_samples_per_second": 3.731,
      "eval_steps_per_second": 3.731,
      "step": 110
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004864468864468865,
      "loss": 2.7598,
      "step": 111
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004863247863247863,
      "loss": 2.4804,
      "step": 112
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004862026862026862,
      "loss": 2.6676,
      "step": 113
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004860805860805861,
      "loss": 2.5947,
      "step": 114
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.00485958485958486,
      "loss": 2.5908,
      "step": 115
    },
    {
      "epoch": 0.08,
      "grad_norm": 0.0,
      "learning_rate": 0.004858363858363858,
      "loss": 2.5357,
      "step": 116
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004857142857142858,
      "loss": 2.4865,
      "step": 117
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004855921855921856,
      "loss": 2.5995,
      "step": 118
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004854700854700854,
      "loss": 2.7026,
      "step": 119
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004853479853479854,
      "loss": 2.556,
      "step": 120
    },
    {
      "epoch": 0.09,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.3594,
      "eval_samples_per_second": 3.731,
      "eval_steps_per_second": 3.731,
      "step": 120
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004852258852258852,
      "loss": 2.5631,
      "step": 121
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004851037851037851,
      "loss": 2.4708,
      "step": 122
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.0048498168498168496,
      "loss": 2.6419,
      "step": 123
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004848595848595849,
      "loss": 2.6416,
      "step": 124
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004847374847374847,
      "loss": 2.6574,
      "step": 125
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004846153846153846,
      "loss": 2.5977,
      "step": 126
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004844932844932845,
      "loss": 2.4771,
      "step": 127
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004843711843711844,
      "loss": 2.5217,
      "step": 128
    },
    {
      "epoch": 0.09,
      "grad_norm": 0.0,
      "learning_rate": 0.004842490842490842,
      "loss": 2.5773,
      "step": 129
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.004841269841269842,
      "loss": 2.5797,
      "step": 130
    },
    {
      "epoch": 0.1,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 324.6702,
      "eval_samples_per_second": 3.739,
      "eval_steps_per_second": 3.739,
      "step": 130
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.00484004884004884,
      "loss": 2.506,
      "step": 131
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.004838827838827839,
      "loss": 2.5518,
      "step": 132
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.0048376068376068376,
      "loss": 2.5142,
      "step": 133
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.004836385836385837,
      "loss": 2.546,
      "step": 134
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.004835164835164835,
      "loss": 2.4725,
      "step": 135
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.004833943833943834,
      "loss": 2.4289,
      "step": 136
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.004832722832722833,
      "loss": 2.5467,
      "step": 137
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.004831501831501832,
      "loss": 2.466,
      "step": 138
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.00483028083028083,
      "loss": 2.44,
      "step": 139
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.00482905982905983,
      "loss": 2.534,
      "step": 140
    },
    {
      "epoch": 0.1,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 324.6789,
      "eval_samples_per_second": 3.739,
      "eval_steps_per_second": 3.739,
      "step": 140
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.004827838827838828,
      "loss": 2.5673,
      "step": 141
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.004826617826617827,
      "loss": 2.559,
      "step": 142
    },
    {
      "epoch": 0.1,
      "grad_norm": 0.0,
      "learning_rate": 0.0048253968253968256,
      "loss": 2.4515,
      "step": 143
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004824175824175824,
      "loss": 2.4245,
      "step": 144
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004822954822954823,
      "loss": 2.5492,
      "step": 145
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.0048217338217338215,
      "loss": 2.6423,
      "step": 146
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004820512820512821,
      "loss": 2.6359,
      "step": 147
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004819291819291819,
      "loss": 2.506,
      "step": 148
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004818070818070818,
      "loss": 2.6237,
      "step": 149
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004816849816849817,
      "loss": 2.5883,
      "step": 150
    },
    {
      "epoch": 0.11,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.2688,
      "eval_samples_per_second": 3.732,
      "eval_steps_per_second": 3.732,
      "step": 150
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004815628815628816,
      "loss": 2.6133,
      "step": 151
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004814407814407814,
      "loss": 2.4923,
      "step": 152
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004813186813186814,
      "loss": 2.5694,
      "step": 153
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004811965811965812,
      "loss": 2.4935,
      "step": 154
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.004810744810744811,
      "loss": 2.5647,
      "step": 155
    },
    {
      "epoch": 0.11,
      "grad_norm": 0.0,
      "learning_rate": 0.0048095238095238095,
      "loss": 2.4925,
      "step": 156
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004808302808302809,
      "loss": 2.6433,
      "step": 157
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004807081807081807,
      "loss": 2.5584,
      "step": 158
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004805860805860806,
      "loss": 2.6621,
      "step": 159
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004804639804639805,
      "loss": 2.698,
      "step": 160
    },
    {
      "epoch": 0.12,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.2356,
      "eval_samples_per_second": 3.733,
      "eval_steps_per_second": 3.733,
      "step": 160
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004803418803418804,
      "loss": 2.3859,
      "step": 161
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004802197802197802,
      "loss": 2.5903,
      "step": 162
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004800976800976802,
      "loss": 2.65,
      "step": 163
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.0047997557997558,
      "loss": 2.565,
      "step": 164
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004798534798534799,
      "loss": 2.5267,
      "step": 165
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.0047973137973137975,
      "loss": 2.4011,
      "step": 166
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004796092796092797,
      "loss": 2.4449,
      "step": 167
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004794871794871795,
      "loss": 2.3881,
      "step": 168
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.0047936507936507935,
      "loss": 2.6567,
      "step": 169
    },
    {
      "epoch": 0.12,
      "grad_norm": 0.0,
      "learning_rate": 0.004792429792429793,
      "loss": 2.6721,
      "step": 170
    },
    {
      "epoch": 0.12,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.2238,
      "eval_samples_per_second": 3.733,
      "eval_steps_per_second": 3.733,
      "step": 170
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004791208791208791,
      "loss": 2.6524,
      "step": 171
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.00478998778998779,
      "loss": 2.5164,
      "step": 172
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004788766788766789,
      "loss": 2.6244,
      "step": 173
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004787545787545788,
      "loss": 2.55,
      "step": 174
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004786324786324786,
      "loss": 2.5969,
      "step": 175
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.0047851037851037856,
      "loss": 2.6438,
      "step": 176
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004783882783882784,
      "loss": 2.6151,
      "step": 177
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004782661782661783,
      "loss": 2.6143,
      "step": 178
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.0047814407814407815,
      "loss": 2.4405,
      "step": 179
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004780219780219781,
      "loss": 2.5871,
      "step": 180
    },
    {
      "epoch": 0.13,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.2357,
      "eval_samples_per_second": 3.733,
      "eval_steps_per_second": 3.733,
      "step": 180
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004778998778998779,
      "loss": 2.5984,
      "step": 181
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004777777777777778,
      "loss": 2.4776,
      "step": 182
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004776556776556777,
      "loss": 2.5305,
      "step": 183
    },
    {
      "epoch": 0.13,
      "grad_norm": 0.0,
      "learning_rate": 0.004775335775335776,
      "loss": 2.5645,
      "step": 184
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.004774114774114774,
      "loss": 2.6136,
      "step": 185
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.0047728937728937736,
      "loss": 2.5183,
      "step": 186
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.004771672771672772,
      "loss": 2.6298,
      "step": 187
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.004770451770451771,
      "loss": 2.6478,
      "step": 188
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.0047692307692307695,
      "loss": 2.5924,
      "step": 189
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.004768009768009769,
      "loss": 2.4423,
      "step": 190
    },
    {
      "epoch": 0.14,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.4066,
      "eval_samples_per_second": 3.731,
      "eval_steps_per_second": 3.731,
      "step": 190
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.004766788766788767,
      "loss": 2.478,
      "step": 191
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.0047655677655677655,
      "loss": 2.6668,
      "step": 192
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.004764346764346764,
      "loss": 2.5282,
      "step": 193
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.004763125763125763,
      "loss": 2.526,
      "step": 194
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.0047619047619047615,
      "loss": 2.5176,
      "step": 195
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.004760683760683761,
      "loss": 2.5539,
      "step": 196
    },
    {
      "epoch": 0.14,
      "grad_norm": 0.0,
      "learning_rate": 0.004759462759462759,
      "loss": 2.509,
      "step": 197
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.0,
      "learning_rate": 0.004758241758241758,
      "loss": 2.6022,
      "step": 198
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.0,
      "learning_rate": 0.004757020757020757,
      "loss": 2.6035,
      "step": 199
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.0,
      "learning_rate": 0.004755799755799756,
      "loss": 2.4268,
      "step": 200
    },
    {
      "epoch": 0.15,
      "eval_loss": 2.553285598754883,
      "eval_runtime": 325.2506,
      "eval_samples_per_second": 3.733,
      "eval_steps_per_second": 3.733,
      "step": 200
    }
  ],
  "logging_steps": 1,
  "max_steps": 4095,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 100,
  "total_flos": 1.034191751872512e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
