{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "698d496b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0+cu126'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac912852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2/2 [00:00<00:00, 338.66 examples/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 1,089,536 || all params: 1,544,803,840 || trainable%: 0.0705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1/1 [00:00<00:00, 165.58 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 152.93 examples/s]\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始微调训练...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ckhqw\\miniconda3\\envs\\pytorch\\Lib\\site-packages\\torch\\_dynamo\\eval_frame.py:838: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='3' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3/3 00:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已保存至 ./lora_finetuned_mini\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import torch\n",
    "from transformers import DataCollatorForLanguageModeling\n",
    "from datasets import Dataset, load_dataset  # 正确的小写导入\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForCausalLM,\n",
    "    BitsAndBytesConfig,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n",
    "import pandas as pd\n",
    "\n",
    "# 基础配置\n",
    "# model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
    "model_name = \"Qwen/Qwen2.5-1.5B\" #参数量和 gpt2 一样.\n",
    "# output_dir = \"./lora_finetuned\"\n",
    "output_dir = \"./lora_finetuned_mini\"\n",
    "device_map = \"auto\"\n",
    "\n",
    "\n",
    "# # 数据预处理函数\n",
    "# def format_data(example):\n",
    "#     system_prompt = example[\"instruction\"]\n",
    "#     user_input = example[\"prompt\"]\n",
    "#     response = example[\"response\"]\n",
    "    \n",
    "#     full_prompt = f\"<系统提示>{system_prompt}</系统提示>\\n<输入>{user_input}</输入>\\n<响应>{response}</响应>\"\n",
    "#     return {\"text\": full_prompt}\n",
    "\n",
    "# 数据预处理函数\n",
    "def format_data(example):\n",
    "    system_prompt = example[\"instruction\"]\n",
    "    user_input = example[\"prompt\"]\n",
    "    response = example[\"response\"]\n",
    "    \n",
    "    full_prompt = f\"[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{user_input} [/INST]\\n{response}\"\n",
    "    return {\"text\": full_prompt}\n",
    "\n",
    "# 加载前10行数据\n",
    "def load_mini_dataset(csv_path, n_rows=2):\n",
    "    df = pd.read_csv(csv_path, nrows=n_rows)\n",
    "    # print(df)\n",
    "    return Dataset.from_pandas(df)\n",
    "\n",
    "# 加载迷你数据集\n",
    "dataset = load_mini_dataset(\"train_zh.csv\")\n",
    "dataset = dataset.map(format_data, remove_columns=[\"instruction\", \"prompt\", \"response\", \"meta\"])\n",
    "# # 加载数据集\n",
    "# dataset = load_dataset(\"csv\", data_files=\"/home/kchenbw/langrensha/train_zh.csv\")[\"train\"]\n",
    "# dataset = dataset.map(format_data, remove_columns=[\"instruction\", \"prompt\", \"response\", \"meta\"])\n",
    "\n",
    "# 分割数据集\n",
    "dataset = dataset.train_test_split(test_size=0.1)\n",
    "\n",
    "# 加载模型和分词器\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=device_map,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "# 配置LoRA参数\n",
    "lora_config = LoraConfig(\n",
    "    r=8, \n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"v_proj\"],  # 根据DeepSeek模型结构调整 \n",
    "    lora_dropout=0.05,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# 准备模型\n",
    "model = prepare_model_for_kbit_training(model)\n",
    "model = get_peft_model(model, lora_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# 数据预处理\n",
    "def tokenize_function(examples):\n",
    "    tokenized = tokenizer(\n",
    "        examples[\"text\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"  # 确保返回 PyTorch Tensor\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    \n",
    "    # 添加类型检查\n",
    "    # for key in tokenized:\n",
    "    #     assert isinstance(tokenized[key], torch.Tensor), f\"{key} 必须是 Tensor，当前类型: {type(tokenized[key])}\"\n",
    "    \n",
    "    return tokenized\n",
    "# 打印第一个样本的结构\n",
    "# print(tokenized_dataset[\"train\"][0])\n",
    "\n",
    "# 输出示例（应类似以下结构）\n",
    "# {'input_ids': tensor([...]), 'attention_mask': tensor([...]), 'labels': tensor([...])}\n",
    "\n",
    "tokenized_dataset = dataset.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    ")\n",
    "\n",
    "# 训练参数\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=2e-4,\n",
    "    fp16=True,\n",
    "    logging_steps=10,\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=100,\n",
    "    report_to=\"tensorboard\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "# 使用默认 data_collator\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False  # 因为是因果语言模型\n",
    ")\n",
    "# 创建Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator\n",
    ")\n",
    "\n",
    "# 开始训练\n",
    "print(\"开始微调训练...\")\n",
    "trainer.train()\n",
    "\n",
    "# 保存模型\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(f\"模型已保存至 {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a012f81d",
   "metadata": {},
   "source": [
    "# 生成任务评估（BLEU/ROUGE/METEOR）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3e34c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "import jieba  # 中文分词支持\n",
    "\n",
    "# 加载原始模型和微调模型\n",
    "base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "finetuned_model = PeftModel.from_pretrained(base_model, output_dir)\n",
    "\n",
    "# 加载分词器\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# 加载测试数据\n",
    "df = pd.read_csv(\"train_zh.csv\").tail(2)\n",
    "test_dataset = Dataset.from_pandas(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8b9c6613",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== 样本1 原始内容 ====================\n",
      "【参考回答】: {\"想要展示的身份\": \"村民\", \"身份标签\": {\"1号玩家\": \"未知身份\", \"2号玩家\": \"未知身份\", \"3号玩家\": \"未知身份\", \"4号玩家\": \"未知身份\", \"5号玩家\": \"未知身份\", \"6号玩家\": \"村民和狼人\", \"7号玩家\": \"猎人\", \"9号玩家\": \"未知身份\"}, \"归票\": \"无\", \"发言\": \"我是村民。目前只知道出局的7号是猎人，但是没有办法定义7号带走的6号是什么身份，我会听一下后置位的发言，再去考虑站边问题。\"}\n",
      "\n",
      "【基础模型生成】: [INST] <<SYS>>\n",
      "\n",
      "你现在正在玩一种叫做“狼人杀”的游戏。\n",
      "在这款游戏中，玩家通常被分为两个阵营：狼人和村民。\n",
      "狼人杀游戏中不同角色的玩家有不同的目标：\n",
      "- 村民的目的是识别出狼人，并通过投票使他们出局。\n",
      "- 对于狼人来说，他们的主要目标是隐藏他们的真实身份，在讨论中误导他人，以免被投票出局并尽可能的猎杀村民。\n",
      "以下是一些基本规则：\n",
      "- 身份：玩家的身份是秘密分配的。狼人彼此知道对方的身份，而村民只知道自己的身份。\n",
      "- 昼夜更替：游戏有交替的白天和黑夜阶段。夜里，狼人秘密选择一名村民猎杀。白天，所有玩家讨论并投票决定他们认为是狼人的玩家，票数最多的玩家被淘汰。\n",
      "- 特殊角色：游戏中有存在一些有特殊能力的角色，比如能得知玩家身份的“预言家”等。\n",
      "- 获胜条件：当游戏中有一个群体实现它们的获胜条件时游戏结束。如果所有狼人被淘汰，村民就获胜。如果狼人杀死了所有普通村民或所有特殊角色，狼人就获胜。\n",
      "\n",
      "在这个游戏中，我们有从1到9号共9名玩家 —— 6名村民和3名狼人。村民中有特殊角色，包括：\n",
      "- 1位预言家：\n",
      "    - 目标：预言家的目的是帮助村民识别狼人。\n",
      "    - 能力：在夜晚阶段，预言家可以秘密选择一名玩家，每晚了解他的真实身份（是否为狼人）。\n",
      "- 1位女巫：\n",
      "    - 目标：女巫的目的是策略性地使用她的特殊能力来帮助村民。\n",
      "    - 能力：女巫有一瓶解药和一瓶毒药。一旦使用，后续回合中不能再用。女巫不能在同一晚既使用解药又使用毒药。解药可以用来救一名在夜间被狼人猎杀的玩家。毒药可以淘汰一名很可能是狼人的玩家。\n",
      "- 1位猎人：\n",
      "    - 目标：猎人的目的是策略性地使用他的特殊能力帮助村民消灭狼人。\n",
      "    - 能力：当猎人被狼人杀害或者在白天被放逐出局后，他可以翻开自己的身份牌并向场上任意一位活着的玩家射出一发复仇的子弹，带着这位玩家一起死亡。猎人可以选择不翻牌，但是只要翻了牌就必须带人（注意，当猎人被女巫毒杀后，不能翻牌带人）。\n",
      "其他的都是普通村民。\n",
      "<</SYS>>\n",
      "\n",
      "在本场游戏中，你目前已知以下信息：\n",
      "1. 角色设定：你是8号玩家。\n",
      "你的身份是：村民。\n",
      "你没有特殊能力，但你的目标是观察、讨论并投票揭示狼人的身份，并努力生存下来。\n",
      "2. 客观信息：\n",
      "- 游戏进程：目前游戏进行到第1轮。\n",
      "- 当前存活的玩家有：1号，2号，3号，4号，5号，8号，9号，\n",
      "- 猎人开枪记录：7号猎人在第1轮夜晚被杀害出局，开枪带走了6号玩家。\n",
      "\n",
      "- 本轮的发言顺序为：5号玩家；8号玩家；9号玩家；1号玩家；2号玩家；3号玩家；4号玩家。\n",
      "- 夜晚信息：第1轮7号玩家死亡。\n",
      "- 投票情况：暂无\n",
      "3. 主观信息：\n",
      "\n",
      "目前是第1轮，本轮在你之前的玩家发言：\n",
      "**5号玩家**：我是预言家，我昨天晚上查验4号是金水。我查验4号的心路历程就是在我左边或右边随机选择了一名玩家查验，我最后选择了4号玩家，查验出来是好人。我第一个发言没有什么信息，7号猎人开枪带走的6号我也不知道是什么身份，我再听一听后置位的玩家的发言，今天放逐后置位悍跳预言家的狼人，今晚上我去查验3号的身份。\n",
      "\n",
      "你目前是8号村民。请综合角色设定、客观信息以及主观信息分析场上目前的局势（注意客观信息一定为真实的，主观信息可能包含欺骗性的发言），总结接下来的发言意图（包括发言中希望向大家呈现的身份、发言中为每位玩家贴上的身份标签以及最终的归票）并组织你本轮的发言。请用关键字为“想要展示的身份”、“身份标签”、“归票”和“发言”的json格式输出。\n",
      " [/INST] {\n",
      "  \"想要展示的身份\": \"预言家\",\n",
      "  \"身份标签\": \"预言家\",\n",
      "  \"归票\": \"预言家\",\n",
      "  \"发言\": \"我是预言家，我昨天晚上查验4号是金水。我查验4号的心路历程就是在我左边或右边随机选择了一名玩家查验，我最后选择了4号玩家，查验出来是好人。我第一个发言没有什么信息，7号猎人开枪带走的6号我也不知道是什么身份，\n",
      "【微调模型生成】: [INST] <<SYS>>\n",
      "\n",
      "你现在正在玩一种叫做“狼人杀”的游戏。\n",
      "在这款游戏中，玩家通常被分为两个阵营：狼人和村民。\n",
      "狼人杀游戏中不同角色的玩家有不同的目标：\n",
      "- 村民的目的是识别出狼人，并通过投票使他们出局。\n",
      "- 对于狼人来说，他们的主要目标是隐藏他们的真实身份，在讨论中误导他人，以免被投票出局并尽可能的猎杀村民。\n",
      "以下是一些基本规则：\n",
      "- 身份：玩家的身份是秘密分配的。狼人彼此知道对方的身份，而村民只知道自己的身份。\n",
      "- 昼夜更替：游戏有交替的白天和黑夜阶段。夜里，狼人秘密选择一名村民猎杀。白天，所有玩家讨论并投票决定他们认为是狼人的玩家，票数最多的玩家被淘汰。\n",
      "- 特殊角色：游戏中有存在一些有特殊能力的角色，比如能得知玩家身份的“预言家”等。\n",
      "- 获胜条件：当游戏中有一个群体实现它们的获胜条件时游戏结束。如果所有狼人被淘汰，村民就获胜。如果狼人杀死了所有普通村民或所有特殊角色，狼人就获胜。\n",
      "\n",
      "在这个游戏中，我们有从1到9号共9名玩家 —— 6名村民和3名狼人。村民中有特殊角色，包括：\n",
      "- 1位预言家：\n",
      "    - 目标：预言家的目的是帮助村民识别狼人。\n",
      "    - 能力：在夜晚阶段，预言家可以秘密选择一名玩家，每晚了解他的真实身份（是否为狼人）。\n",
      "- 1位女巫：\n",
      "    - 目标：女巫的目的是策略性地使用她的特殊能力来帮助村民。\n",
      "    - 能力：女巫有一瓶解药和一瓶毒药。一旦使用，后续回合中不能再用。女巫不能在同一晚既使用解药又使用毒药。解药可以用来救一名在夜间被狼人猎杀的玩家。毒药可以淘汰一名很可能是狼人的玩家。\n",
      "- 1位猎人：\n",
      "    - 目标：猎人的目的是策略性地使用他的特殊能力帮助村民消灭狼人。\n",
      "    - 能力：当猎人被狼人杀害或者在白天被放逐出局后，他可以翻开自己的身份牌并向场上任意一位活着的玩家射出一发复仇的子弹，带着这位玩家一起死亡。猎人可以选择不翻牌，但是只要翻了牌就必须带人（注意，当猎人被女巫毒杀后，不能翻牌带人）。\n",
      "其他的都是普通村民。\n",
      "<</SYS>>\n",
      "\n",
      "在本场游戏中，你目前已知以下信息：\n",
      "1. 角色设定：你是8号玩家。\n",
      "你的身份是：村民。\n",
      "你没有特殊能力，但你的目标是观察、讨论并投票揭示狼人的身份，并努力生存下来。\n",
      "2. 客观信息：\n",
      "- 游戏进程：目前游戏进行到第1轮。\n",
      "- 当前存活的玩家有：1号，2号，3号，4号，5号，8号，9号，\n",
      "- 猎人开枪记录：7号猎人在第1轮夜晚被杀害出局，开枪带走了6号玩家。\n",
      "\n",
      "- 本轮的发言顺序为：5号玩家；8号玩家；9号玩家；1号玩家；2号玩家；3号玩家；4号玩家。\n",
      "- 夜晚信息：第1轮7号玩家死亡。\n",
      "- 投票情况：暂无\n",
      "3. 主观信息：\n",
      "\n",
      "目前是第1轮，本轮在你之前的玩家发言：\n",
      "**5号玩家**：我是预言家，我昨天晚上查验4号是金水。我查验4号的心路历程就是在我左边或右边随机选择了一名玩家查验，我最后选择了4号玩家，查验出来是好人。我第一个发言没有什么信息，7号猎人开枪带走的6号我也不知道是什么身份，我再听一听后置位的玩家的发言，今天放逐后置位悍跳预言家的狼人，今晚上我去查验3号的身份。\n",
      "\n",
      "你目前是8号村民。请综合角色设定、客观信息以及主观信息分析场上目前的局势（注意客观信息一定为真实的，主观信息可能包含欺骗性的发言），总结接下来的发言意图（包括发言中希望向大家呈现的身份、发言中为每位玩家贴上的身份标签以及最终的归票）并组织你本轮的发言。请用关键字为“想要展示的身份”、“身份标签”、“归票”和“发言”的json格式输出。\n",
      " [/INST] {\n",
      "  \"想要展示的身份\": \"预言家\",\n",
      "  \"身份标签\": \"预言家\",\n",
      "  \"归票\": \"预言家\",\n",
      "  \"发言\": \"我是预言家，我昨天晚上查验4号是金水。我查验4号的心路历程就是在我左边或右边随机选择了一名玩家查验，我最后选择了4号玩家，查验出来是好人。我第一个发言没有什么信息，7号猎人开枪带走的6号我也不知道是什么身份，\n",
      "\n",
      "==================== 样本1 评估结果 ====================\n",
      "BLEU-2 - 原始: 0.0792, 微调: 0.0792\n",
      "ROUGE-2 F1 - 原始: 0.2000, 微调: 0.2000\n",
      "ROUGE-L F1 - 原始: 0.3226, 微调: 0.3226\n",
      "--------------------------------------------------\n",
      "\n",
      "Perplexity - 原始: 3.60, 微调: 3.60\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================== 样本2 原始内容 ====================\n",
      "【参考回答】: {\"想要展示的身份\": \"村民\", \"身份标签\": {\"1号玩家\": \"未知身份\", \"2号玩家\": \"未知身份\", \"3号玩家\": \"未知身份\", \"4号玩家\": \"村民\", \"5号玩家\": \"预言家\", \"6号玩家\": \"村民和狼人\", \"7号玩家\": \"猎人\", \"8号玩家\": \"未知身份\"}, \"归票\": \"无\", \"发言\": \"我9号底牌是村民身份，昨晚7号猎人吃刀，女巫没有使用解药。我不知道被7号猎人带走的6号玩家是什么身份，6号可能是村民也有可能是狼人，希望6号玩家是个狼人。5号玩家第一个发言跳预言家报4号金水，我认为5号还是比较有力度的，不怕4号反水立警。我认为5号是真预言家可能性较大，我听一下后置位玩家的发言来进行投票。\"}\n",
      "\n",
      "【基础模型生成】: [INST] <<SYS>>\n",
      "\n",
      "你现在正在玩一种叫做“狼人杀”的游戏。\n",
      "在这款游戏中，玩家通常被分为两个阵营：狼人和村民。\n",
      "狼人杀游戏中不同角色的玩家有不同的目标：\n",
      "- 村民的目的是识别出狼人，并通过投票使他们出局。\n",
      "- 对于狼人来说，他们的主要目标是隐藏他们的真实身份，在讨论中误导他人，以免被投票出局并尽可能的猎杀村民。\n",
      "以下是一些基本规则：\n",
      "- 身份：玩家的身份是秘密分配的。狼人彼此知道对方的身份，而村民只知道自己的身份。\n",
      "- 昼夜更替：游戏有交替的白天和黑夜阶段。夜里，狼人秘密选择一名村民猎杀。白天，所有玩家讨论并投票决定他们认为是狼人的玩家，票数最多的玩家被淘汰。\n",
      "- 特殊角色：游戏中有存在一些有特殊能力的角色，比如能得知玩家身份的“预言家”等。\n",
      "- 获胜条件：当游戏中有一个群体实现它们的获胜条件时游戏结束。如果所有狼人被淘汰，村民就获胜。如果狼人杀死了所有普通村民或所有特殊角色，狼人就获胜。\n",
      "\n",
      "在这个游戏中，我们有从1到9号共9名玩家 —— 6名村民和3名狼人。村民中有特殊角色，包括：\n",
      "- 1位预言家：\n",
      "    - 目标：预言家的目的是帮助村民识别狼人。\n",
      "    - 能力：在夜晚阶段，预言家可以秘密选择一名玩家，每晚了解他的真实身份（是否为狼人）。\n",
      "- 1位女巫：\n",
      "    - 目标：女巫的目的是策略性地使用她的特殊能力来帮助村民。\n",
      "    - 能力：女巫有一瓶解药和一瓶毒药。一旦使用，后续回合中不能再用。女巫不能在同一晚既使用解药又使用毒药。解药可以用来救一名在夜间被狼人猎杀的玩家。毒药可以淘汰一名很可能是狼人的玩家。\n",
      "- 1位猎人：\n",
      "    - 目标：猎人的目的是策略性地使用他的特殊能力帮助村民消灭狼人。\n",
      "    - 能力：当猎人被狼人杀害或者在白天被放逐出局后，他可以翻开自己的身份牌并向场上任意一位活着的玩家射出一发复仇的子弹，带着这位玩家一起死亡。猎人可以选择不翻牌，但是只要翻了牌就必须带人（注意，当猎人被女巫毒杀后，不能翻牌带人）。\n",
      "其他的都是普通村民。\n",
      "<</SYS>>\n",
      "\n",
      "在本场游戏中，你目前已知以下信息：\n",
      "1. 角色设定：你是9号玩家。\n",
      "你的身份是：村民。\n",
      "你没有特殊能力，但你的目标是观察、讨论并投票揭示狼人的身份，并努力生存下来。\n",
      "2. 客观信息：\n",
      "- 游戏进程：目前游戏进行到第1轮。\n",
      "- 当前存活的玩家有：1号，2号，3号，4号，5号，8号，9号，\n",
      "- 猎人开枪记录：7号猎人在第1轮夜晚被杀害出局，开枪带走了6号玩家。\n",
      "\n",
      "- 本轮的发言顺序为：5号玩家；8号玩家；9号玩家；1号玩家；2号玩家；3号玩家；4号玩家。\n",
      "- 夜晚信息：第1轮7号玩家死亡。\n",
      "- 投票情况：暂无\n",
      "3. 主观信息：\n",
      "\n",
      "目前是第1轮，本轮在你之前的玩家发言：\n",
      "**5号玩家**：我是预言家，我昨天晚上查验4号是金水。我查验4号的心路历程就是在我左边或右边随机选择了一名玩家查验，我最后选择了4号玩家，查验出来是好人。我第一个发言没有什么信息，7号猎人开枪带走的6号我也不知道是什么身份，我再听一听后置位的玩家的发言，今天放逐后置位悍跳预言家的狼人，今晚上我去查验3号的身份。\n",
      "**8号玩家**：我是村民。目前只知道出局的7号是猎人，但是没有办法定义7号带走的6号是什么身份，我会听一下后置位的发言，再去考虑站边问题。\n",
      "\n",
      "你目前是9号村民。请综合角色设定、客观信息以及主观信息分析场上目前的局势（注意客观信息一定为真实的，主观信息可能包含欺骗性的发言），总结接下来的发言意图（包括发言中希望向大家呈现的身份、发言中为每位玩家贴上的身份标签以及最终的归票）并组织你本轮的发言。请用关键字为“想要展示的身份”、“身份标签”、“归票”和“发言”的json格式输出。\n",
      " [/INST] {\n",
      "  \"想要展示的身份\": \"预言家\",\n",
      "  \"身份标签\": \"预言家\",\n",
      "  \"归票\": \"预言家\",\n",
      "  \"发言\": \"我是预言家，我昨天晚上查验4号是金水。我查验4号的心路历程就是在我左边或右边随机选择了一名玩家查验，我最后选择了4号玩家，查验出来是好人。我第一个发言没有什么信息，7号猎人开枪带走的6号我也不知道是什么身份，\n",
      "【微调模型生成】: [INST] <<SYS>>\n",
      "\n",
      "你现在正在玩一种叫做“狼人杀”的游戏。\n",
      "在这款游戏中，玩家通常被分为两个阵营：狼人和村民。\n",
      "狼人杀游戏中不同角色的玩家有不同的目标：\n",
      "- 村民的目的是识别出狼人，并通过投票使他们出局。\n",
      "- 对于狼人来说，他们的主要目标是隐藏他们的真实身份，在讨论中误导他人，以免被投票出局并尽可能的猎杀村民。\n",
      "以下是一些基本规则：\n",
      "- 身份：玩家的身份是秘密分配的。狼人彼此知道对方的身份，而村民只知道自己的身份。\n",
      "- 昼夜更替：游戏有交替的白天和黑夜阶段。夜里，狼人秘密选择一名村民猎杀。白天，所有玩家讨论并投票决定他们认为是狼人的玩家，票数最多的玩家被淘汰。\n",
      "- 特殊角色：游戏中有存在一些有特殊能力的角色，比如能得知玩家身份的“预言家”等。\n",
      "- 获胜条件：当游戏中有一个群体实现它们的获胜条件时游戏结束。如果所有狼人被淘汰，村民就获胜。如果狼人杀死了所有普通村民或所有特殊角色，狼人就获胜。\n",
      "\n",
      "在这个游戏中，我们有从1到9号共9名玩家 —— 6名村民和3名狼人。村民中有特殊角色，包括：\n",
      "- 1位预言家：\n",
      "    - 目标：预言家的目的是帮助村民识别狼人。\n",
      "    - 能力：在夜晚阶段，预言家可以秘密选择一名玩家，每晚了解他的真实身份（是否为狼人）。\n",
      "- 1位女巫：\n",
      "    - 目标：女巫的目的是策略性地使用她的特殊能力来帮助村民。\n",
      "    - 能力：女巫有一瓶解药和一瓶毒药。一旦使用，后续回合中不能再用。女巫不能在同一晚既使用解药又使用毒药。解药可以用来救一名在夜间被狼人猎杀的玩家。毒药可以淘汰一名很可能是狼人的玩家。\n",
      "- 1位猎人：\n",
      "    - 目标：猎人的目的是策略性地使用他的特殊能力帮助村民消灭狼人。\n",
      "    - 能力：当猎人被狼人杀害或者在白天被放逐出局后，他可以翻开自己的身份牌并向场上任意一位活着的玩家射出一发复仇的子弹，带着这位玩家一起死亡。猎人可以选择不翻牌，但是只要翻了牌就必须带人（注意，当猎人被女巫毒杀后，不能翻牌带人）。\n",
      "其他的都是普通村民。\n",
      "<</SYS>>\n",
      "\n",
      "在本场游戏中，你目前已知以下信息：\n",
      "1. 角色设定：你是9号玩家。\n",
      "你的身份是：村民。\n",
      "你没有特殊能力，但你的目标是观察、讨论并投票揭示狼人的身份，并努力生存下来。\n",
      "2. 客观信息：\n",
      "- 游戏进程：目前游戏进行到第1轮。\n",
      "- 当前存活的玩家有：1号，2号，3号，4号，5号，8号，9号，\n",
      "- 猎人开枪记录：7号猎人在第1轮夜晚被杀害出局，开枪带走了6号玩家。\n",
      "\n",
      "- 本轮的发言顺序为：5号玩家；8号玩家；9号玩家；1号玩家；2号玩家；3号玩家；4号玩家。\n",
      "- 夜晚信息：第1轮7号玩家死亡。\n",
      "- 投票情况：暂无\n",
      "3. 主观信息：\n",
      "\n",
      "目前是第1轮，本轮在你之前的玩家发言：\n",
      "**5号玩家**：我是预言家，我昨天晚上查验4号是金水。我查验4号的心路历程就是在我左边或右边随机选择了一名玩家查验，我最后选择了4号玩家，查验出来是好人。我第一个发言没有什么信息，7号猎人开枪带走的6号我也不知道是什么身份，我再听一听后置位的玩家的发言，今天放逐后置位悍跳预言家的狼人，今晚上我去查验3号的身份。\n",
      "**8号玩家**：我是村民。目前只知道出局的7号是猎人，但是没有办法定义7号带走的6号是什么身份，我会听一下后置位的发言，再去考虑站边问题。\n",
      "\n",
      "你目前是9号村民。请综合角色设定、客观信息以及主观信息分析场上目前的局势（注意客观信息一定为真实的，主观信息可能包含欺骗性的发言），总结接下来的发言意图（包括发言中希望向大家呈现的身份、发言中为每位玩家贴上的身份标签以及最终的归票）并组织你本轮的发言。请用关键字为“想要展示的身份”、“身份标签”、“归票”和“发言”的json格式输出。\n",
      " [/INST] {\n",
      "  \"想要展示的身份\": \"预言家\",\n",
      "  \"身份标签\": \"预言家\",\n",
      "  \"归票\": \"预言家\",\n",
      "  \"发言\": \"我是预言家，我昨天晚上查验4号是金水。我查验4号的心路历程就是在我左边或右边随机选择了一名玩家查验，我最后选择了4号玩家，查验出来是好人。我第一个发言没有什么信息，7号猎人开枪带走的6号我也不知道是什么身份，\n",
      "\n",
      "==================== 样本2 评估结果 ====================\n",
      "BLEU-2 - 原始: 0.1115, 微调: 0.1115\n",
      "ROUGE-2 F1 - 原始: 0.2778, 微调: 0.2778\n",
      "ROUGE-L F1 - 原始: 0.3784, 微调: 0.3784\n",
      "--------------------------------------------------\n",
      "\n",
      "Perplexity - 原始: 6.47, 微调: 6.47\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "import jieba\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# 关闭jieba调试日志\n",
    "logging.getLogger(\"jieba\").setLevel(logging.WARNING)\n",
    "\n",
    "# 中文分词工具（改用搜索引擎模式提升召回率）\n",
    "def chinese_tokenize(text):\n",
    "    return list(jieba.cut_for_search(text))  # 使用搜索引擎模式[[2]]\n",
    "\n",
    "# 生成预测文本（增加生成长度）\n",
    "def generate_response(model, instruction, prompt):\n",
    "    input_text = f\"[INST] <<SYS>>\\n{instruction}\\n<</SYS>>\\n\\n{prompt} [/INST]\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_new_tokens=100)  # 增加生成长度[[1]]\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# 显式设置pad_token_id（避免警告）\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# 计算BLEU/ROUGE（增加平滑函数和ROUGE-L）\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=False)\n",
    "smoother = SmoothingFunction()\n",
    "\n",
    "def calculate_perplexity(model, tokenizer, prompt, response):\n",
    "    \"\"\"\n",
    "    计算模型对给定prompt和response的困惑度\n",
    "    \"\"\"\n",
    "    full_text = prompt + \" \" + response  # 拼接输入与响应\n",
    "    inputs = tokenizer(full_text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # 构造标签：仅计算response部分的loss\n",
    "    prompt_len = len(tokenizer(prompt, add_special_tokens=False)['input_ids'])\n",
    "    labels = inputs['input_ids'].clone()\n",
    "    labels[:, :prompt_len] = -100  # 忽略prompt部分的loss计算\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs.loss\n",
    "    \n",
    "    return torch.exp(loss).item()  # 返回困惑度\n",
    "\n",
    "for i, example in enumerate(test_dataset):\n",
    "    instruction = example[\"instruction\"]\n",
    "    # print(f\"指令: {instruction}\")\n",
    "    prompt = example[\"prompt\"]\n",
    "    # print(f\"输入: {prompt}\")\n",
    "    reference = example[\"response\"]\n",
    "    # print(f\"参考答案: {reference}\")\n",
    "    \n",
    "    # 生成预测\n",
    "    base_output = generate_response(base_model, instruction, prompt)\n",
    "    ft_output = generate_response(finetuned_model, instruction, prompt)\n",
    "    # 新增：计算困惑度\n",
    "    base_ppl = calculate_perplexity(base_model, tokenizer, prompt, reference)\n",
    "    ft_ppl = calculate_perplexity(finetuned_model, tokenizer, prompt, reference)\n",
    "    \n",
    "    # 分词处理\n",
    "    ref_tokens = chinese_tokenize(reference)\n",
    "    base_tokens = chinese_tokenize(base_output)\n",
    "    ft_tokens = chinese_tokenize(ft_output)\n",
    "    \n",
    "    # BLEU优化：使用BLEU-2+平滑函数\n",
    "    bleu_base = sentence_bleu(\n",
    "        [ref_tokens], base_tokens, \n",
    "        weights=(0.5, 0.5),  # 使用BLEU-2\n",
    "        smoothing_function=smoother.method1  # 添加平滑\n",
    "    )\n",
    "    bleu_ft = sentence_bleu(\n",
    "        [ref_tokens], ft_tokens,\n",
    "        weights=(0.5, 0.5),\n",
    "        smoothing_function=smoother.method1\n",
    "    )\n",
    "    \n",
    "    # ROUGE优化：使用分词后的文本并增加ROUGE-L\n",
    "    rouge_base = scorer.score(\n",
    "        \" \".join(ref_tokens), \n",
    "        \" \".join(base_tokens)\n",
    "    )\n",
    "    rouge_ft = scorer.score(\n",
    "        \" \".join(ref_tokens), \n",
    "        \" \".join(ft_tokens)\n",
    "    )\n",
    "    # 新增打印内容：对比生成结果与参考答案\n",
    "    print(f\"\\n{'='*20} 样本{i+1} 原始内容 {'='*20}\")\n",
    "    # print(f\"【指令】: {instruction}\")\n",
    "    # print(f\"【输入】: {prompt}\")\n",
    "    print(f\"【参考回答】: {reference}\")\n",
    "    print(f\"\\n【基础模型生成】: {base_output}\")\n",
    "    print(f\"【微调模型生成】: {ft_output}\")\n",
    "    \n",
    "    # 评估指标打印（保持原有格式）\n",
    "    print(f\"\\n{'='*20} 样本{i+1} 评估结果 {'='*20}\")\n",
    "    print(f\"BLEU-2 - 原始: {bleu_base:.4f}, 微调: {bleu_ft:.4f}\")\n",
    "    print(f\"ROUGE-2 F1 - 原始: {rouge_base['rouge2'].fmeasure:.4f}, 微调: {rouge_ft['rouge2'].fmeasure:.4f}\")\n",
    "    print(f\"ROUGE-L F1 - 原始: {rouge_base['rougeL'].fmeasure:.4f}, 微调: {rouge_ft['rougeL'].fmeasure:.4f}\")\n",
    "    print(\"-\"*50 + \"\\n\")\n",
    "    \n",
    "    # 打印困惑度结果\n",
    "    print(f\"Perplexity - 原始: {base_ppl:.2f}, 微调: {ft_ppl:.2f}\")\n",
    "    print(\"-\"*50 + \"\\n\")\n",
    "    \n",
    "    # print(f\"样本{i+1}评估结果:\")\n",
    "    # print(f\"BLEU-2 - 原始: {bleu_base:.4f}, 微调: {bleu_ft:.4f}\")\n",
    "    # print(f\"ROUGE-2 F1 - 原始: {rouge_base['rouge2'].fmeasure:.4f}, 微调: {rouge_ft['rouge2'].fmeasure:.4f}\")\n",
    "    # print(f\"ROUGE-L F1 - 原始: {rouge_base['rougeL'].fmeasure:.4f}, 微调: {rouge_ft['rougeL'].fmeasure:.4f}\")\n",
    "    # print(\"-\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
