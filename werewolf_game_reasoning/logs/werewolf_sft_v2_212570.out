Mon May  5 03:21:53 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:1B:00.0 Off |                    0 |
| N/A   21C    P0              67W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
/home/rliubk/.conda/envs/werewolf/bin/python
PyTorch: 2.2.0+cu121, CUDA: True, 设备: NVIDIA H800
===== 开始 SFT 微调 (v2 - 禁用FP16) Mon May  5 03:21:56 AM HKT 2025 =====
开始训练 - 阶段: sft
数据目录: .
输出目录: output
模型路径: Qwen/Qwen2.5-1.5B
批次大小: 1，梯度累积: 8
SwanLab: 使用提供的API密钥
加载SFT数据集: train_zh.csv
限制训练样本数量为 2000 (原始数量: 12134)
开始处理SFT数据: 2000 样本
加载tokenizer: Qwen/Qwen2.5-1.5B
使用最大序列长度: 2048
开始tokenize数据...
Tokenize完成，训练集大小: 1800 样本
加载基础模型: Qwen/Qwen2.5-1.5B
加载LoRA适配器: output/basic
trainable params: 0 || all params: 1,548,416,512 || trainable%: 0.0000
配置训练参数 - 禁用FP16混合精度
正在使用API密钥登录SwanLab...
[1m[34mswanlab[0m[0m: \ Waiting for the swanlab cloud response.                                                                                                    SwanLab登录成功!
开始SFT训练...
[1m[34mswanlab[0m[0m: \ Getting project...[1m[34mswanlab[0m[0m: | Getting project...                                                                                                    [1m[34mswanlab[0m[0m: \ Creating experiment...[1m[34mswanlab[0m[0m: | Creating experiment...[1m[34mswanlab[0m[0m: / Creating experiment...                                                                                                    [1m[34mswanlab[0m[0m: Tracking run with swanlab version 0.5.7
[1m[34mswanlab[0m[0m: Run data will be saved locally in [35m[1m/home/rliubk/llm-project/werewolf_game_reasoning/swanlog/run-20250505_032221-a3b1799d[0m[0m
[1m[34mswanlab[0m[0m: 👋 Hi [1m[39msurmountrt[0m[0m, welcome to swanlab!
[1m[34mswanlab[0m[0m: Syncing run [33msft[0m to the cloud
[1m[34mswanlab[0m[0m: 🏠 View project at [34m[4mhttps://swanlab.cn/@surmountrt/Werewolf-LoRA[0m[0m
[1m[34mswanlab[0m[0m: 🚀 View run at [34m[4mhttps://swanlab.cn/@surmountrt/Werewolf-LoRA/runs/ckkag56z6reuo5gczouuh[0m[0m
{'loss': 2.5936, 'grad_norm': 0.0, 'learning_rate': 9.985185185185185e-05, 'epoch': 0.0}
{'loss': 2.4892, 'grad_norm': 0.0, 'learning_rate': 9.970370370370371e-05, 'epoch': 0.01}
{'loss': 2.496, 'grad_norm': 0.0, 'learning_rate': 9.955555555555556e-05, 'epoch': 0.01}
{'loss': 2.5959, 'grad_norm': 0.0, 'learning_rate': 9.940740740740742e-05, 'epoch': 0.02}
{'loss': 2.5483, 'grad_norm': 0.0, 'learning_rate': 9.925925925925926e-05, 'epoch': 0.02}
{'loss': 2.5132, 'grad_norm': 0.0, 'learning_rate': 9.911111111111112e-05, 'epoch': 0.03}
{'loss': 2.5356, 'grad_norm': 0.0, 'learning_rate': 9.896296296296297e-05, 'epoch': 0.03}
{'loss': 2.5838, 'grad_norm': 0.0, 'learning_rate': 9.881481481481482e-05, 'epoch': 0.04}
{'loss': 2.5615, 'grad_norm': 0.0, 'learning_rate': 9.866666666666668e-05, 'epoch': 0.04}
{'loss': 2.4431, 'grad_norm': 0.0, 'learning_rate': 9.851851851851852e-05, 'epoch': 0.04}
[1m[33mswanlab[0m[0m: Step 10 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 10 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3236, 'eval_samples_per_second': 21.451, 'eval_steps_per_second': 2.681, 'epoch': 0.04}
{'loss': 2.5478, 'grad_norm': 0.0, 'learning_rate': 9.837037037037038e-05, 'epoch': 0.05}
{'loss': 2.6527, 'grad_norm': 0.0, 'learning_rate': 9.822222222222223e-05, 'epoch': 0.05}
{'loss': 2.6241, 'grad_norm': 0.0, 'learning_rate': 9.807407407407407e-05, 'epoch': 0.06}
{'loss': 2.613, 'grad_norm': 0.0, 'learning_rate': 9.792592592592593e-05, 'epoch': 0.06}
{'loss': 2.4917, 'grad_norm': 0.0, 'learning_rate': 9.777777777777778e-05, 'epoch': 0.07}
{'loss': 2.6597, 'grad_norm': 0.0, 'learning_rate': 9.762962962962964e-05, 'epoch': 0.07}
{'loss': 2.6773, 'grad_norm': 0.0, 'learning_rate': 9.748148148148149e-05, 'epoch': 0.08}
{'loss': 2.4845, 'grad_norm': 0.0, 'learning_rate': 9.733333333333335e-05, 'epoch': 0.08}
{'loss': 2.4728, 'grad_norm': 0.0, 'learning_rate': 9.718518518518519e-05, 'epoch': 0.08}
{'loss': 2.643, 'grad_norm': 0.0, 'learning_rate': 9.703703703703704e-05, 'epoch': 0.09}
[1m[33mswanlab[0m[0m: Step 20 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 20 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3138, 'eval_samples_per_second': 21.474, 'eval_steps_per_second': 2.684, 'epoch': 0.09}
{'loss': 2.3505, 'grad_norm': 0.0, 'learning_rate': 9.68888888888889e-05, 'epoch': 0.09}
{'loss': 2.488, 'grad_norm': 0.0, 'learning_rate': 9.674074074074074e-05, 'epoch': 0.1}
{'loss': 2.5492, 'grad_norm': 0.0, 'learning_rate': 9.65925925925926e-05, 'epoch': 0.1}
{'loss': 2.5158, 'grad_norm': 0.0, 'learning_rate': 9.644444444444445e-05, 'epoch': 0.11}
{'loss': 2.4807, 'grad_norm': 0.0, 'learning_rate': 9.62962962962963e-05, 'epoch': 0.11}
{'loss': 2.5794, 'grad_norm': 0.0, 'learning_rate': 9.614814814814816e-05, 'epoch': 0.12}
{'loss': 2.6129, 'grad_norm': 0.0, 'learning_rate': 9.6e-05, 'epoch': 0.12}
{'loss': 2.6711, 'grad_norm': 0.0, 'learning_rate': 9.585185185185186e-05, 'epoch': 0.12}
{'loss': 2.5458, 'grad_norm': 0.0, 'learning_rate': 9.570370370370371e-05, 'epoch': 0.13}
{'loss': 2.4368, 'grad_norm': 0.0, 'learning_rate': 9.555555555555557e-05, 'epoch': 0.13}
[1m[33mswanlab[0m[0m: Step 30 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 30 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3172, 'eval_samples_per_second': 21.466, 'eval_steps_per_second': 2.683, 'epoch': 0.13}
{'loss': 2.5788, 'grad_norm': 0.0, 'learning_rate': 9.540740740740741e-05, 'epoch': 0.14}
{'loss': 2.5504, 'grad_norm': 0.0, 'learning_rate': 9.525925925925926e-05, 'epoch': 0.14}
{'loss': 2.5052, 'grad_norm': 0.0, 'learning_rate': 9.511111111111112e-05, 'epoch': 0.15}
{'loss': 2.4991, 'grad_norm': 0.0, 'learning_rate': 9.496296296296297e-05, 'epoch': 0.15}
{'loss': 2.4721, 'grad_norm': 0.0, 'learning_rate': 9.481481481481483e-05, 'epoch': 0.16}
{'loss': 2.609, 'grad_norm': 0.0, 'learning_rate': 9.466666666666667e-05, 'epoch': 0.16}
{'loss': 2.5366, 'grad_norm': 0.0, 'learning_rate': 9.451851851851853e-05, 'epoch': 0.16}
{'loss': 2.4971, 'grad_norm': 0.0, 'learning_rate': 9.437037037037038e-05, 'epoch': 0.17}
{'loss': 2.5182, 'grad_norm': 0.0, 'learning_rate': 9.422222222222223e-05, 'epoch': 0.17}
{'loss': 2.528, 'grad_norm': 0.0, 'learning_rate': 9.407407407407408e-05, 'epoch': 0.18}
[1m[33mswanlab[0m[0m: Step 40 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 40 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3213, 'eval_samples_per_second': 21.456, 'eval_steps_per_second': 2.682, 'epoch': 0.18}
{'loss': 2.5806, 'grad_norm': 0.0, 'learning_rate': 9.392592592592593e-05, 'epoch': 0.18}
{'loss': 2.5658, 'grad_norm': 0.0, 'learning_rate': 9.377777777777779e-05, 'epoch': 0.19}
{'loss': 2.4452, 'grad_norm': 0.0, 'learning_rate': 9.362962962962964e-05, 'epoch': 0.19}
{'loss': 2.536, 'grad_norm': 0.0, 'learning_rate': 9.348148148148148e-05, 'epoch': 0.2}
{'loss': 2.527, 'grad_norm': 0.0, 'learning_rate': 9.333333333333334e-05, 'epoch': 0.2}
{'loss': 2.5124, 'grad_norm': 0.0, 'learning_rate': 9.318518518518519e-05, 'epoch': 0.2}
{'loss': 2.5282, 'grad_norm': 0.0, 'learning_rate': 9.303703703703705e-05, 'epoch': 0.21}
{'loss': 2.5342, 'grad_norm': 0.0, 'learning_rate': 9.28888888888889e-05, 'epoch': 0.21}
{'loss': 2.5997, 'grad_norm': 0.0, 'learning_rate': 9.274074074074076e-05, 'epoch': 0.22}
{'loss': 2.5905, 'grad_norm': 0.0, 'learning_rate': 9.25925925925926e-05, 'epoch': 0.22}
[1m[33mswanlab[0m[0m: Step 50 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 50 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3186, 'eval_samples_per_second': 21.462, 'eval_steps_per_second': 2.683, 'epoch': 0.22}
{'loss': 2.4599, 'grad_norm': 0.0, 'learning_rate': 9.244444444444445e-05, 'epoch': 0.23}
{'loss': 2.5434, 'grad_norm': 0.0, 'learning_rate': 9.229629629629631e-05, 'epoch': 0.23}
{'loss': 2.5092, 'grad_norm': 0.0, 'learning_rate': 9.214814814814815e-05, 'epoch': 0.24}
{'loss': 2.5178, 'grad_norm': 0.0, 'learning_rate': 9.200000000000001e-05, 'epoch': 0.24}
{'loss': 2.4531, 'grad_norm': 0.0, 'learning_rate': 9.185185185185186e-05, 'epoch': 0.24}
{'loss': 2.5101, 'grad_norm': 0.0, 'learning_rate': 9.17037037037037e-05, 'epoch': 0.25}
{'loss': 2.493, 'grad_norm': 0.0, 'learning_rate': 9.155555555555557e-05, 'epoch': 0.25}
{'loss': 2.5902, 'grad_norm': 0.0, 'learning_rate': 9.140740740740741e-05, 'epoch': 0.26}
{'loss': 2.4542, 'grad_norm': 0.0, 'learning_rate': 9.125925925925927e-05, 'epoch': 0.26}
{'loss': 2.6209, 'grad_norm': 0.0, 'learning_rate': 9.111111111111112e-05, 'epoch': 0.27}
[1m[33mswanlab[0m[0m: Step 60 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 60 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3208, 'eval_samples_per_second': 21.457, 'eval_steps_per_second': 2.682, 'epoch': 0.27}
{'loss': 2.5953, 'grad_norm': 0.0, 'learning_rate': 9.096296296296298e-05, 'epoch': 0.27}
{'loss': 2.519, 'grad_norm': 0.0, 'learning_rate': 9.081481481481482e-05, 'epoch': 0.28}
{'loss': 2.6278, 'grad_norm': 0.0, 'learning_rate': 9.066666666666667e-05, 'epoch': 0.28}
{'loss': 2.6537, 'grad_norm': 0.0, 'learning_rate': 9.051851851851853e-05, 'epoch': 0.28}
{'loss': 2.4537, 'grad_norm': 0.0, 'learning_rate': 9.037037037037038e-05, 'epoch': 0.29}
{'loss': 2.6246, 'grad_norm': 0.0, 'learning_rate': 9.022222222222224e-05, 'epoch': 0.29}
{'loss': 2.6122, 'grad_norm': 0.0, 'learning_rate': 9.007407407407408e-05, 'epoch': 0.3}
{'loss': 2.5274, 'grad_norm': 0.0, 'learning_rate': 8.992592592592594e-05, 'epoch': 0.3}
{'loss': 2.5487, 'grad_norm': 0.0, 'learning_rate': 8.977777777777779e-05, 'epoch': 0.31}
{'loss': 2.5433, 'grad_norm': 0.0, 'learning_rate': 8.962962962962963e-05, 'epoch': 0.31}
[1m[33mswanlab[0m[0m: Step 70 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 70 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3192, 'eval_samples_per_second': 21.461, 'eval_steps_per_second': 2.683, 'epoch': 0.31}
{'loss': 2.5562, 'grad_norm': 0.0, 'learning_rate': 8.94814814814815e-05, 'epoch': 0.32}
{'loss': 2.6256, 'grad_norm': 0.0, 'learning_rate': 8.933333333333334e-05, 'epoch': 0.32}
{'loss': 2.5069, 'grad_norm': 0.0, 'learning_rate': 8.918518518518519e-05, 'epoch': 0.32}
{'loss': 2.673, 'grad_norm': 0.0, 'learning_rate': 8.903703703703705e-05, 'epoch': 0.33}
{'loss': 2.5618, 'grad_norm': 0.0, 'learning_rate': 8.888888888888889e-05, 'epoch': 0.33}
{'loss': 2.6378, 'grad_norm': 0.0, 'learning_rate': 8.874074074074075e-05, 'epoch': 0.34}
{'loss': 2.5099, 'grad_norm': 0.0, 'learning_rate': 8.85925925925926e-05, 'epoch': 0.34}
{'loss': 2.5193, 'grad_norm': 0.0, 'learning_rate': 8.844444444444445e-05, 'epoch': 0.35}
{'loss': 2.5823, 'grad_norm': 0.0, 'learning_rate': 8.82962962962963e-05, 'epoch': 0.35}
{'loss': 2.5865, 'grad_norm': 0.0, 'learning_rate': 8.814814814814815e-05, 'epoch': 0.36}
[1m[33mswanlab[0m[0m: Step 80 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 80 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3213, 'eval_samples_per_second': 21.456, 'eval_steps_per_second': 2.682, 'epoch': 0.36}
{'loss': 2.5057, 'grad_norm': 0.0, 'learning_rate': 8.800000000000001e-05, 'epoch': 0.36}
{'loss': 2.5133, 'grad_norm': 0.0, 'learning_rate': 8.785185185185186e-05, 'epoch': 0.36}
{'loss': 2.6433, 'grad_norm': 0.0, 'learning_rate': 8.77037037037037e-05, 'epoch': 0.37}
{'loss': 2.6106, 'grad_norm': 0.0, 'learning_rate': 8.755555555555556e-05, 'epoch': 0.37}
{'loss': 2.484, 'grad_norm': 0.0, 'learning_rate': 8.740740740740741e-05, 'epoch': 0.38}
{'loss': 2.5908, 'grad_norm': 0.0, 'learning_rate': 8.725925925925927e-05, 'epoch': 0.38}
{'loss': 2.5571, 'grad_norm': 0.0, 'learning_rate': 8.711111111111112e-05, 'epoch': 0.39}
{'loss': 2.508, 'grad_norm': 0.0, 'learning_rate': 8.696296296296296e-05, 'epoch': 0.39}
{'loss': 2.5557, 'grad_norm': 0.0, 'learning_rate': 8.681481481481482e-05, 'epoch': 0.4}
{'loss': 2.5036, 'grad_norm': 0.0, 'learning_rate': 8.666666666666667e-05, 'epoch': 0.4}
[1m[33mswanlab[0m[0m: Step 90 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 90 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3133, 'eval_samples_per_second': 21.475, 'eval_steps_per_second': 2.684, 'epoch': 0.4}
{'loss': 2.5253, 'grad_norm': 0.0, 'learning_rate': 8.651851851851851e-05, 'epoch': 0.4}
{'loss': 2.4653, 'grad_norm': 0.0, 'learning_rate': 8.637037037037037e-05, 'epoch': 0.41}
{'loss': 2.6082, 'grad_norm': 0.0, 'learning_rate': 8.622222222222222e-05, 'epoch': 0.41}
{'loss': 2.419, 'grad_norm': 0.0, 'learning_rate': 8.607407407407408e-05, 'epoch': 0.42}
{'loss': 2.4836, 'grad_norm': 0.0, 'learning_rate': 8.592592592592593e-05, 'epoch': 0.42}
{'loss': 2.4631, 'grad_norm': 0.0, 'learning_rate': 8.577777777777777e-05, 'epoch': 0.43}
{'loss': 2.4956, 'grad_norm': 0.0, 'learning_rate': 8.562962962962963e-05, 'epoch': 0.43}
{'loss': 2.3991, 'grad_norm': 0.0, 'learning_rate': 8.548148148148148e-05, 'epoch': 0.44}
{'loss': 2.6425, 'grad_norm': 0.0, 'learning_rate': 8.533333333333334e-05, 'epoch': 0.44}
{'loss': 2.6012, 'grad_norm': 0.0, 'learning_rate': 8.518518518518518e-05, 'epoch': 0.44}
[1m[33mswanlab[0m[0m: Step 100 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 100 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3263, 'eval_samples_per_second': 21.445, 'eval_steps_per_second': 2.681, 'epoch': 0.44}
{'loss': 2.5823, 'grad_norm': 0.0, 'learning_rate': 8.503703703703703e-05, 'epoch': 0.45}
{'loss': 2.4709, 'grad_norm': 0.0, 'learning_rate': 8.488888888888889e-05, 'epoch': 0.45}
{'loss': 2.45, 'grad_norm': 0.0, 'learning_rate': 8.474074074074074e-05, 'epoch': 0.46}
{'loss': 2.6155, 'grad_norm': 0.0, 'learning_rate': 8.45925925925926e-05, 'epoch': 0.46}
{'loss': 2.5391, 'grad_norm': 0.0, 'learning_rate': 8.444444444444444e-05, 'epoch': 0.47}
{'loss': 2.5949, 'grad_norm': 0.0, 'learning_rate': 8.429629629629629e-05, 'epoch': 0.47}
{'loss': 2.4175, 'grad_norm': 0.0, 'learning_rate': 8.414814814814815e-05, 'epoch': 0.48}
{'loss': 2.4311, 'grad_norm': 0.0, 'learning_rate': 8.4e-05, 'epoch': 0.48}
{'loss': 2.5642, 'grad_norm': 0.0, 'learning_rate': 8.385185185185186e-05, 'epoch': 0.48}
{'loss': 2.5334, 'grad_norm': 0.0, 'learning_rate': 8.37037037037037e-05, 'epoch': 0.49}
[1m[33mswanlab[0m[0m: Step 110 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 110 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3178, 'eval_samples_per_second': 21.464, 'eval_steps_per_second': 2.683, 'epoch': 0.49}
{'loss': 2.6137, 'grad_norm': 0.0, 'learning_rate': 8.355555555555556e-05, 'epoch': 0.49}
{'loss': 2.5129, 'grad_norm': 0.0, 'learning_rate': 8.340740740740741e-05, 'epoch': 0.5}
{'loss': 2.5093, 'grad_norm': 0.0, 'learning_rate': 8.325925925925925e-05, 'epoch': 0.5}
{'loss': 2.4551, 'grad_norm': 0.0, 'learning_rate': 8.311111111111111e-05, 'epoch': 0.51}
{'loss': 2.6123, 'grad_norm': 0.0, 'learning_rate': 8.296296296296296e-05, 'epoch': 0.51}
{'loss': 2.5886, 'grad_norm': 0.0, 'learning_rate': 8.281481481481482e-05, 'epoch': 0.52}
{'loss': 2.5401, 'grad_norm': 0.0, 'learning_rate': 8.266666666666667e-05, 'epoch': 0.52}
{'loss': 2.573, 'grad_norm': 0.0, 'learning_rate': 8.251851851851851e-05, 'epoch': 0.52}
{'loss': 2.5824, 'grad_norm': 0.0, 'learning_rate': 8.237037037037037e-05, 'epoch': 0.53}
{'loss': 2.5192, 'grad_norm': 0.0, 'learning_rate': 8.222222222222222e-05, 'epoch': 0.53}
[1m[33mswanlab[0m[0m: Step 120 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 120 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3167, 'eval_samples_per_second': 21.467, 'eval_steps_per_second': 2.683, 'epoch': 0.53}
{'loss': 2.5047, 'grad_norm': 0.0, 'learning_rate': 8.207407407407408e-05, 'epoch': 0.54}
{'loss': 2.5858, 'grad_norm': 0.0, 'learning_rate': 8.192592592592592e-05, 'epoch': 0.54}
{'loss': 2.4635, 'grad_norm': 0.0, 'learning_rate': 8.177777777777778e-05, 'epoch': 0.55}
{'loss': 2.5333, 'grad_norm': 0.0, 'learning_rate': 8.162962962962963e-05, 'epoch': 0.55}
{'loss': 2.5194, 'grad_norm': 0.0, 'learning_rate': 8.148148148148148e-05, 'epoch': 0.56}
{'loss': 2.5701, 'grad_norm': 0.0, 'learning_rate': 8.133333333333334e-05, 'epoch': 0.56}
{'loss': 2.5203, 'grad_norm': 0.0, 'learning_rate': 8.118518518518518e-05, 'epoch': 0.56}
{'loss': 2.5802, 'grad_norm': 0.0, 'learning_rate': 8.103703703703704e-05, 'epoch': 0.57}
{'loss': 2.5127, 'grad_norm': 0.0, 'learning_rate': 8.088888888888889e-05, 'epoch': 0.57}
{'loss': 2.4487, 'grad_norm': 0.0, 'learning_rate': 8.074074074074075e-05, 'epoch': 0.58}
[1m[33mswanlab[0m[0m: Step 130 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 130 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3177, 'eval_samples_per_second': 21.464, 'eval_steps_per_second': 2.683, 'epoch': 0.58}
{'loss': 2.5497, 'grad_norm': 0.0, 'learning_rate': 8.05925925925926e-05, 'epoch': 0.58}
{'loss': 2.5275, 'grad_norm': 0.0, 'learning_rate': 8.044444444444444e-05, 'epoch': 0.59}
{'loss': 2.5819, 'grad_norm': 0.0, 'learning_rate': 8.02962962962963e-05, 'epoch': 0.59}
{'loss': 2.4654, 'grad_norm': 0.0, 'learning_rate': 8.014814814814815e-05, 'epoch': 0.6}
{'loss': 2.5835, 'grad_norm': 0.0, 'learning_rate': 8e-05, 'epoch': 0.6}
{'loss': 2.681, 'grad_norm': 0.0, 'learning_rate': 7.985185185185185e-05, 'epoch': 0.6}
{'loss': 2.499, 'grad_norm': 0.0, 'learning_rate': 7.97037037037037e-05, 'epoch': 0.61}
{'loss': 2.4803, 'grad_norm': 0.0, 'learning_rate': 7.955555555555556e-05, 'epoch': 0.61}
{'loss': 2.4812, 'grad_norm': 0.0, 'learning_rate': 7.94074074074074e-05, 'epoch': 0.62}
{'loss': 2.4343, 'grad_norm': 0.0, 'learning_rate': 7.925925925925926e-05, 'epoch': 0.62}
[1m[33mswanlab[0m[0m: Step 140 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 140 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3353, 'eval_samples_per_second': 21.424, 'eval_steps_per_second': 2.678, 'epoch': 0.62}
{'loss': 2.5371, 'grad_norm': 0.0, 'learning_rate': 7.911111111111111e-05, 'epoch': 0.63}
{'loss': 2.6196, 'grad_norm': 0.0, 'learning_rate': 7.896296296296297e-05, 'epoch': 0.63}
{'loss': 2.6175, 'grad_norm': 0.0, 'learning_rate': 7.881481481481482e-05, 'epoch': 0.64}
{'loss': 2.3898, 'grad_norm': 0.0, 'learning_rate': 7.866666666666666e-05, 'epoch': 0.64}
{'loss': 2.5861, 'grad_norm': 0.0, 'learning_rate': 7.851851851851852e-05, 'epoch': 0.64}
{'loss': 2.5807, 'grad_norm': 0.0, 'learning_rate': 7.837037037037037e-05, 'epoch': 0.65}
{'loss': 2.5342, 'grad_norm': 0.0, 'learning_rate': 7.822222222222223e-05, 'epoch': 0.65}
{'loss': 2.6106, 'grad_norm': 0.0, 'learning_rate': 7.807407407407408e-05, 'epoch': 0.66}
{'loss': 2.6214, 'grad_norm': 0.0, 'learning_rate': 7.792592592592592e-05, 'epoch': 0.66}
{'loss': 2.537, 'grad_norm': 0.0, 'learning_rate': 7.777777777777778e-05, 'epoch': 0.67}
[1m[33mswanlab[0m[0m: Step 150 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 150 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.321, 'eval_samples_per_second': 21.457, 'eval_steps_per_second': 2.682, 'epoch': 0.67}
{'loss': 2.5233, 'grad_norm': 0.0, 'learning_rate': 7.762962962962963e-05, 'epoch': 0.67}
{'loss': 2.5471, 'grad_norm': 0.0, 'learning_rate': 7.748148148148149e-05, 'epoch': 0.68}
{'loss': 2.6755, 'grad_norm': 0.0, 'learning_rate': 7.733333333333333e-05, 'epoch': 0.68}
{'loss': 2.5638, 'grad_norm': 0.0, 'learning_rate': 7.71851851851852e-05, 'epoch': 0.68}
{'loss': 2.6333, 'grad_norm': 0.0, 'learning_rate': 7.703703703703704e-05, 'epoch': 0.69}
{'loss': 2.6338, 'grad_norm': 0.0, 'learning_rate': 7.688888888888889e-05, 'epoch': 0.69}
{'loss': 2.5465, 'grad_norm': 0.0, 'learning_rate': 7.674074074074075e-05, 'epoch': 0.7}
{'loss': 2.509, 'grad_norm': 0.0, 'learning_rate': 7.659259259259259e-05, 'epoch': 0.7}
{'loss': 2.5185, 'grad_norm': 0.0, 'learning_rate': 7.644444444444445e-05, 'epoch': 0.71}
{'loss': 2.5898, 'grad_norm': 0.0, 'learning_rate': 7.62962962962963e-05, 'epoch': 0.71}
[1m[33mswanlab[0m[0m: Step 160 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 160 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3189, 'eval_samples_per_second': 21.462, 'eval_steps_per_second': 2.683, 'epoch': 0.71}
{'loss': 2.563, 'grad_norm': 0.0, 'learning_rate': 7.614814814814816e-05, 'epoch': 0.72}
{'loss': 2.5535, 'grad_norm': 0.0, 'learning_rate': 7.6e-05, 'epoch': 0.72}
{'loss': 2.5757, 'grad_norm': 0.0, 'learning_rate': 7.585185185185185e-05, 'epoch': 0.72}
{'loss': 2.4344, 'grad_norm': 0.0, 'learning_rate': 7.570370370370371e-05, 'epoch': 0.73}
{'loss': 2.5508, 'grad_norm': 0.0, 'learning_rate': 7.555555555555556e-05, 'epoch': 0.73}
{'loss': 2.4761, 'grad_norm': 0.0, 'learning_rate': 7.540740740740742e-05, 'epoch': 0.74}
{'loss': 2.487, 'grad_norm': 0.0, 'learning_rate': 7.525925925925926e-05, 'epoch': 0.74}
{'loss': 2.6576, 'grad_norm': 0.0, 'learning_rate': 7.511111111111111e-05, 'epoch': 0.75}
{'loss': 2.4734, 'grad_norm': 0.0, 'learning_rate': 7.496296296296297e-05, 'epoch': 0.75}
{'loss': 2.5228, 'grad_norm': 0.0, 'learning_rate': 7.481481481481481e-05, 'epoch': 0.76}
[1m[33mswanlab[0m[0m: Step 170 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 170 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3281, 'eval_samples_per_second': 21.441, 'eval_steps_per_second': 2.68, 'epoch': 0.76}
{'loss': 2.5998, 'grad_norm': 0.0, 'learning_rate': 7.466666666666667e-05, 'epoch': 0.76}
{'loss': 2.5186, 'grad_norm': 0.0, 'learning_rate': 7.451851851851852e-05, 'epoch': 0.76}
{'loss': 2.5245, 'grad_norm': 0.0, 'learning_rate': 7.437037037037038e-05, 'epoch': 0.77}
{'loss': 2.4449, 'grad_norm': 0.0, 'learning_rate': 7.422222222222223e-05, 'epoch': 0.77}
{'loss': 2.5531, 'grad_norm': 0.0, 'learning_rate': 7.407407407407407e-05, 'epoch': 0.78}
{'loss': 2.6467, 'grad_norm': 0.0, 'learning_rate': 7.392592592592593e-05, 'epoch': 0.78}
{'loss': 2.5203, 'grad_norm': 0.0, 'learning_rate': 7.377777777777778e-05, 'epoch': 0.79}
{'loss': 2.6559, 'grad_norm': 0.0, 'learning_rate': 7.362962962962964e-05, 'epoch': 0.79}
{'loss': 2.5419, 'grad_norm': 0.0, 'learning_rate': 7.348148148148149e-05, 'epoch': 0.8}
{'loss': 2.4571, 'grad_norm': 0.0, 'learning_rate': 7.333333333333333e-05, 'epoch': 0.8}
[1m[33mswanlab[0m[0m: Step 180 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 180 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3192, 'eval_samples_per_second': 21.461, 'eval_steps_per_second': 2.683, 'epoch': 0.8}
{'loss': 2.6839, 'grad_norm': 0.0, 'learning_rate': 7.318518518518519e-05, 'epoch': 0.8}
{'loss': 2.4253, 'grad_norm': 0.0, 'learning_rate': 7.303703703703704e-05, 'epoch': 0.81}
{'loss': 2.6, 'grad_norm': 0.0, 'learning_rate': 7.28888888888889e-05, 'epoch': 0.81}
{'loss': 2.5258, 'grad_norm': 0.0, 'learning_rate': 7.274074074074074e-05, 'epoch': 0.82}
{'loss': 2.6737, 'grad_norm': 0.0, 'learning_rate': 7.25925925925926e-05, 'epoch': 0.82}
{'loss': 2.5529, 'grad_norm': 0.0, 'learning_rate': 7.244444444444445e-05, 'epoch': 0.83}
{'loss': 2.5074, 'grad_norm': 0.0, 'learning_rate': 7.22962962962963e-05, 'epoch': 0.83}
{'loss': 2.5194, 'grad_norm': 0.0, 'learning_rate': 7.214814814814816e-05, 'epoch': 0.84}
{'loss': 2.4644, 'grad_norm': 0.0, 'learning_rate': 7.2e-05, 'epoch': 0.84}
{'loss': 2.4624, 'grad_norm': 0.0, 'learning_rate': 7.185185185185186e-05, 'epoch': 0.84}
[1m[33mswanlab[0m[0m: Step 190 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 190 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.4444, 'eval_samples_per_second': 21.176, 'eval_steps_per_second': 2.647, 'epoch': 0.84}
{'loss': 2.5378, 'grad_norm': 0.0, 'learning_rate': 7.170370370370371e-05, 'epoch': 0.85}
{'loss': 2.5507, 'grad_norm': 0.0, 'learning_rate': 7.155555555555555e-05, 'epoch': 0.85}
{'loss': 2.4748, 'grad_norm': 0.0, 'learning_rate': 7.140740740740741e-05, 'epoch': 0.86}
{'loss': 2.5998, 'grad_norm': 0.0, 'learning_rate': 7.125925925925926e-05, 'epoch': 0.86}
{'loss': 2.4797, 'grad_norm': 0.0, 'learning_rate': 7.111111111111112e-05, 'epoch': 0.87}
{'loss': 2.6362, 'grad_norm': 0.0, 'learning_rate': 7.096296296296297e-05, 'epoch': 0.87}
{'loss': 2.5129, 'grad_norm': 0.0, 'learning_rate': 7.081481481481483e-05, 'epoch': 0.88}
{'loss': 2.6309, 'grad_norm': 0.0, 'learning_rate': 7.066666666666667e-05, 'epoch': 0.88}
{'loss': 2.6058, 'grad_norm': 0.0, 'learning_rate': 7.051851851851852e-05, 'epoch': 0.88}
{'loss': 2.5007, 'grad_norm': 0.0, 'learning_rate': 7.037037037037038e-05, 'epoch': 0.89}
[1m[33mswanlab[0m[0m: Step 200 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 200 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3495, 'eval_samples_per_second': 21.391, 'eval_steps_per_second': 2.674, 'epoch': 0.89}
{'loss': 2.4895, 'grad_norm': 0.0, 'learning_rate': 7.022222222222222e-05, 'epoch': 0.89}
{'loss': 2.5703, 'grad_norm': 0.0, 'learning_rate': 7.007407407407408e-05, 'epoch': 0.9}
{'loss': 2.5055, 'grad_norm': 0.0, 'learning_rate': 6.992592592592593e-05, 'epoch': 0.9}
{'loss': 2.4653, 'grad_norm': 0.0, 'learning_rate': 6.977777777777779e-05, 'epoch': 0.91}
{'loss': 2.4913, 'grad_norm': 0.0, 'learning_rate': 6.962962962962964e-05, 'epoch': 0.91}
{'loss': 2.5448, 'grad_norm': 0.0, 'learning_rate': 6.948148148148148e-05, 'epoch': 0.92}
{'loss': 2.4641, 'grad_norm': 0.0, 'learning_rate': 6.933333333333334e-05, 'epoch': 0.92}
{'loss': 2.4532, 'grad_norm': 0.0, 'learning_rate': 6.918518518518519e-05, 'epoch': 0.92}
{'loss': 2.6116, 'grad_norm': 0.0, 'learning_rate': 6.903703703703705e-05, 'epoch': 0.93}
{'loss': 2.5346, 'grad_norm': 0.0, 'learning_rate': 6.88888888888889e-05, 'epoch': 0.93}
[1m[33mswanlab[0m[0m: Step 210 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 210 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3103, 'eval_samples_per_second': 21.482, 'eval_steps_per_second': 2.685, 'epoch': 0.93}
{'loss': 2.5512, 'grad_norm': 0.0, 'learning_rate': 6.874074074074074e-05, 'epoch': 0.94}
{'loss': 2.4483, 'grad_norm': 0.0, 'learning_rate': 6.85925925925926e-05, 'epoch': 0.94}
{'loss': 2.601, 'grad_norm': 0.0, 'learning_rate': 6.844444444444445e-05, 'epoch': 0.95}
{'loss': 2.4746, 'grad_norm': 0.0, 'learning_rate': 6.829629629629631e-05, 'epoch': 0.95}
{'loss': 2.4713, 'grad_norm': 0.0, 'learning_rate': 6.814814814814815e-05, 'epoch': 0.96}
{'loss': 2.591, 'grad_norm': 0.0, 'learning_rate': 6.800000000000001e-05, 'epoch': 0.96}
{'loss': 2.448, 'grad_norm': 0.0, 'learning_rate': 6.785185185185186e-05, 'epoch': 0.96}
{'loss': 2.5373, 'grad_norm': 0.0, 'learning_rate': 6.77037037037037e-05, 'epoch': 0.97}
{'loss': 2.5563, 'grad_norm': 0.0, 'learning_rate': 6.755555555555557e-05, 'epoch': 0.97}
{'loss': 2.4825, 'grad_norm': 0.0, 'learning_rate': 6.740740740740741e-05, 'epoch': 0.98}
[1m[33mswanlab[0m[0m: Step 220 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 220 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3157, 'eval_samples_per_second': 21.469, 'eval_steps_per_second': 2.684, 'epoch': 0.98}
{'loss': 2.5917, 'grad_norm': 0.0, 'learning_rate': 6.725925925925927e-05, 'epoch': 0.98}
{'loss': 2.535, 'grad_norm': 0.0, 'learning_rate': 6.711111111111112e-05, 'epoch': 0.99}
{'loss': 2.5922, 'grad_norm': 0.0, 'learning_rate': 6.696296296296296e-05, 'epoch': 0.99}
{'loss': 2.4853, 'grad_norm': 0.0, 'learning_rate': 6.681481481481482e-05, 'epoch': 1.0}
{'loss': 2.5926, 'grad_norm': 0.0, 'learning_rate': 6.666666666666667e-05, 'epoch': 1.0}
{'loss': 2.5446, 'grad_norm': 0.0, 'learning_rate': 6.651851851851853e-05, 'epoch': 1.0}
{'loss': 2.6098, 'grad_norm': 0.0, 'learning_rate': 6.637037037037038e-05, 'epoch': 1.01}
{'loss': 2.4893, 'grad_norm': 0.0, 'learning_rate': 6.622222222222224e-05, 'epoch': 1.01}
{'loss': 2.4987, 'grad_norm': 0.0, 'learning_rate': 6.607407407407408e-05, 'epoch': 1.02}
{'loss': 2.5206, 'grad_norm': 0.0, 'learning_rate': 6.592592592592593e-05, 'epoch': 1.02}
[1m[33mswanlab[0m[0m: Step 230 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 230 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3366, 'eval_samples_per_second': 21.421, 'eval_steps_per_second': 2.678, 'epoch': 1.02}
{'loss': 2.5896, 'grad_norm': 0.0, 'learning_rate': 6.577777777777779e-05, 'epoch': 1.03}
{'loss': 2.5271, 'grad_norm': 0.0, 'learning_rate': 6.562962962962963e-05, 'epoch': 1.03}
{'loss': 2.4188, 'grad_norm': 0.0, 'learning_rate': 6.54814814814815e-05, 'epoch': 1.04}
{'loss': 2.6531, 'grad_norm': 0.0, 'learning_rate': 6.533333333333334e-05, 'epoch': 1.04}
{'loss': 2.6416, 'grad_norm': 0.0, 'learning_rate': 6.51851851851852e-05, 'epoch': 1.04}
{'loss': 2.5629, 'grad_norm': 0.0, 'learning_rate': 6.503703703703705e-05, 'epoch': 1.05}
{'loss': 2.5682, 'grad_norm': 0.0, 'learning_rate': 6.488888888888889e-05, 'epoch': 1.05}
{'loss': 2.5863, 'grad_norm': 0.0, 'learning_rate': 6.474074074074075e-05, 'epoch': 1.06}
{'loss': 2.5286, 'grad_norm': 0.0, 'learning_rate': 6.45925925925926e-05, 'epoch': 1.06}
{'loss': 2.5327, 'grad_norm': 0.0, 'learning_rate': 6.444444444444446e-05, 'epoch': 1.07}
[1m[33mswanlab[0m[0m: Step 240 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 240 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3394, 'eval_samples_per_second': 21.415, 'eval_steps_per_second': 2.677, 'epoch': 1.07}
{'loss': 2.5292, 'grad_norm': 0.0, 'learning_rate': 6.42962962962963e-05, 'epoch': 1.07}
{'loss': 2.5797, 'grad_norm': 0.0, 'learning_rate': 6.414814814814815e-05, 'epoch': 1.08}
{'loss': 2.4537, 'grad_norm': 0.0, 'learning_rate': 6.400000000000001e-05, 'epoch': 1.08}
{'loss': 2.5995, 'grad_norm': 0.0, 'learning_rate': 6.385185185185186e-05, 'epoch': 1.08}
{'loss': 2.5411, 'grad_norm': 0.0, 'learning_rate': 6.37037037037037e-05, 'epoch': 1.09}
{'loss': 2.4676, 'grad_norm': 0.0, 'learning_rate': 6.355555555555556e-05, 'epoch': 1.09}
{'loss': 2.5897, 'grad_norm': 0.0, 'learning_rate': 6.340740740740741e-05, 'epoch': 1.1}
{'loss': 2.4746, 'grad_norm': 0.0, 'learning_rate': 6.325925925925927e-05, 'epoch': 1.1}
{'loss': 2.4758, 'grad_norm': 0.0, 'learning_rate': 6.311111111111112e-05, 'epoch': 1.11}
{'loss': 2.4913, 'grad_norm': 0.0, 'learning_rate': 6.296296296296296e-05, 'epoch': 1.11}
[1m[33mswanlab[0m[0m: Step 250 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 250 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3131, 'eval_samples_per_second': 21.475, 'eval_steps_per_second': 2.684, 'epoch': 1.11}
{'loss': 2.6103, 'grad_norm': 0.0, 'learning_rate': 6.281481481481482e-05, 'epoch': 1.12}
{'loss': 2.5841, 'grad_norm': 0.0, 'learning_rate': 6.266666666666667e-05, 'epoch': 1.12}
{'loss': 2.5734, 'grad_norm': 0.0, 'learning_rate': 6.251851851851853e-05, 'epoch': 1.12}
{'loss': 2.5521, 'grad_norm': 0.0, 'learning_rate': 6.237037037037037e-05, 'epoch': 1.13}
{'loss': 2.6595, 'grad_norm': 0.0, 'learning_rate': 6.222222222222222e-05, 'epoch': 1.13}
{'loss': 2.4662, 'grad_norm': 0.0, 'learning_rate': 6.207407407407408e-05, 'epoch': 1.14}
{'loss': 2.6036, 'grad_norm': 0.0, 'learning_rate': 6.192592592592593e-05, 'epoch': 1.14}
{'loss': 2.5175, 'grad_norm': 0.0, 'learning_rate': 6.177777777777779e-05, 'epoch': 1.15}
{'loss': 2.3893, 'grad_norm': 0.0, 'learning_rate': 6.162962962962963e-05, 'epoch': 1.15}
{'loss': 2.6002, 'grad_norm': 0.0, 'learning_rate': 6.148148148148148e-05, 'epoch': 1.16}
[1m[33mswanlab[0m[0m: Step 260 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 260 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3433, 'eval_samples_per_second': 21.406, 'eval_steps_per_second': 2.676, 'epoch': 1.16}
{'loss': 2.5597, 'grad_norm': 0.0, 'learning_rate': 6.133333333333334e-05, 'epoch': 1.16}
{'loss': 2.5693, 'grad_norm': 0.0, 'learning_rate': 6.118518518518518e-05, 'epoch': 1.16}
{'loss': 2.5482, 'grad_norm': 0.0, 'learning_rate': 6.103703703703703e-05, 'epoch': 1.17}
{'loss': 2.6348, 'grad_norm': 0.0, 'learning_rate': 6.08888888888889e-05, 'epoch': 1.17}
{'loss': 2.5303, 'grad_norm': 0.0, 'learning_rate': 6.074074074074074e-05, 'epoch': 1.18}
{'loss': 2.5612, 'grad_norm': 0.0, 'learning_rate': 6.05925925925926e-05, 'epoch': 1.18}
{'loss': 2.5896, 'grad_norm': 0.0, 'learning_rate': 6.044444444444445e-05, 'epoch': 1.19}
{'loss': 2.6002, 'grad_norm': 0.0, 'learning_rate': 6.0296296296296295e-05, 'epoch': 1.19}
{'loss': 2.6044, 'grad_norm': 0.0, 'learning_rate': 6.0148148148148155e-05, 'epoch': 1.2}
{'loss': 2.45, 'grad_norm': 0.0, 'learning_rate': 6e-05, 'epoch': 1.2}
[1m[33mswanlab[0m[0m: Step 270 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 270 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.333, 'eval_samples_per_second': 21.429, 'eval_steps_per_second': 2.679, 'epoch': 1.2}
{'loss': 2.6329, 'grad_norm': 0.0, 'learning_rate': 5.985185185185186e-05, 'epoch': 1.2}
{'loss': 2.4556, 'grad_norm': 0.0, 'learning_rate': 5.970370370370371e-05, 'epoch': 1.21}
{'loss': 2.4982, 'grad_norm': 0.0, 'learning_rate': 5.9555555555555554e-05, 'epoch': 1.21}
{'loss': 2.6342, 'grad_norm': 0.0, 'learning_rate': 5.9407407407407414e-05, 'epoch': 1.22}
{'loss': 2.612, 'grad_norm': 0.0, 'learning_rate': 5.925925925925926e-05, 'epoch': 1.22}
{'loss': 2.5107, 'grad_norm': 0.0, 'learning_rate': 5.911111111111112e-05, 'epoch': 1.23}
{'loss': 2.4485, 'grad_norm': 0.0, 'learning_rate': 5.8962962962962966e-05, 'epoch': 1.23}
{'loss': 2.6122, 'grad_norm': 0.0, 'learning_rate': 5.8814814814814826e-05, 'epoch': 1.24}
{'loss': 2.6439, 'grad_norm': 0.0, 'learning_rate': 5.866666666666667e-05, 'epoch': 1.24}
{'loss': 2.4098, 'grad_norm': 0.0, 'learning_rate': 5.851851851851852e-05, 'epoch': 1.24}
[1m[33mswanlab[0m[0m: Step 280 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 280 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3356, 'eval_samples_per_second': 21.423, 'eval_steps_per_second': 2.678, 'epoch': 1.24}
{'loss': 2.5514, 'grad_norm': 0.0, 'learning_rate': 5.837037037037038e-05, 'epoch': 1.25}
{'loss': 2.604, 'grad_norm': 0.0, 'learning_rate': 5.8222222222222224e-05, 'epoch': 1.25}
{'loss': 2.5832, 'grad_norm': 0.0, 'learning_rate': 5.8074074074074084e-05, 'epoch': 1.26}
{'loss': 2.5222, 'grad_norm': 0.0, 'learning_rate': 5.792592592592593e-05, 'epoch': 1.26}
{'loss': 2.4516, 'grad_norm': 0.0, 'learning_rate': 5.7777777777777776e-05, 'epoch': 1.27}
{'loss': 2.4645, 'grad_norm': 0.0, 'learning_rate': 5.7629629629629636e-05, 'epoch': 1.27}
{'loss': 2.4775, 'grad_norm': 0.0, 'learning_rate': 5.748148148148148e-05, 'epoch': 1.28}
{'loss': 2.5051, 'grad_norm': 0.0, 'learning_rate': 5.7333333333333336e-05, 'epoch': 1.28}
{'loss': 2.5034, 'grad_norm': 0.0, 'learning_rate': 5.718518518518519e-05, 'epoch': 1.28}
{'loss': 2.5305, 'grad_norm': 0.0, 'learning_rate': 5.703703703703704e-05, 'epoch': 1.29}
[1m[33mswanlab[0m[0m: Step 290 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 290 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3205, 'eval_samples_per_second': 21.458, 'eval_steps_per_second': 2.682, 'epoch': 1.29}
{'loss': 2.4949, 'grad_norm': 0.0, 'learning_rate': 5.6888888888888895e-05, 'epoch': 1.29}
{'loss': 2.4979, 'grad_norm': 0.0, 'learning_rate': 5.674074074074074e-05, 'epoch': 1.3}
{'loss': 2.5471, 'grad_norm': 0.0, 'learning_rate': 5.6592592592592594e-05, 'epoch': 1.3}
{'loss': 2.5404, 'grad_norm': 0.0, 'learning_rate': 5.644444444444445e-05, 'epoch': 1.31}
{'loss': 2.6317, 'grad_norm': 0.0, 'learning_rate': 5.62962962962963e-05, 'epoch': 1.31}
{'loss': 2.495, 'grad_norm': 0.0, 'learning_rate': 5.614814814814815e-05, 'epoch': 1.32}
{'loss': 2.4795, 'grad_norm': 0.0, 'learning_rate': 5.6000000000000006e-05, 'epoch': 1.32}
{'loss': 2.5512, 'grad_norm': 0.0, 'learning_rate': 5.585185185185185e-05, 'epoch': 1.32}
{'loss': 2.6276, 'grad_norm': 0.0, 'learning_rate': 5.5703703703703705e-05, 'epoch': 1.33}
{'loss': 2.5506, 'grad_norm': 0.0, 'learning_rate': 5.555555555555556e-05, 'epoch': 1.33}
[1m[33mswanlab[0m[0m: Step 300 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 300 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3124, 'eval_samples_per_second': 21.477, 'eval_steps_per_second': 2.685, 'epoch': 1.33}
{'loss': 2.5067, 'grad_norm': 0.0, 'learning_rate': 5.540740740740741e-05, 'epoch': 1.34}
{'loss': 2.4743, 'grad_norm': 0.0, 'learning_rate': 5.5259259259259264e-05, 'epoch': 1.34}
{'loss': 2.4919, 'grad_norm': 0.0, 'learning_rate': 5.511111111111111e-05, 'epoch': 1.35}
{'loss': 2.5456, 'grad_norm': 0.0, 'learning_rate': 5.4962962962962964e-05, 'epoch': 1.35}
{'loss': 2.4641, 'grad_norm': 0.0, 'learning_rate': 5.4814814814814817e-05, 'epoch': 1.36}
{'loss': 2.625, 'grad_norm': 0.0, 'learning_rate': 5.466666666666666e-05, 'epoch': 1.36}
{'loss': 2.5445, 'grad_norm': 0.0, 'learning_rate': 5.451851851851852e-05, 'epoch': 1.36}
{'loss': 2.5482, 'grad_norm': 0.0, 'learning_rate': 5.437037037037037e-05, 'epoch': 1.37}
{'loss': 2.5122, 'grad_norm': 0.0, 'learning_rate': 5.422222222222223e-05, 'epoch': 1.37}
{'loss': 2.5949, 'grad_norm': 0.0, 'learning_rate': 5.4074074074074075e-05, 'epoch': 1.38}
[1m[33mswanlab[0m[0m: Step 310 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 310 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3293, 'eval_samples_per_second': 21.438, 'eval_steps_per_second': 2.68, 'epoch': 1.38}
{'loss': 2.6138, 'grad_norm': 0.0, 'learning_rate': 5.392592592592592e-05, 'epoch': 1.38}
{'loss': 2.4658, 'grad_norm': 0.0, 'learning_rate': 5.377777777777778e-05, 'epoch': 1.39}
{'loss': 2.5397, 'grad_norm': 0.0, 'learning_rate': 5.362962962962963e-05, 'epoch': 1.39}
{'loss': 2.4463, 'grad_norm': 0.0, 'learning_rate': 5.348148148148149e-05, 'epoch': 1.4}
{'loss': 2.6286, 'grad_norm': 0.0, 'learning_rate': 5.333333333333333e-05, 'epoch': 1.4}
{'loss': 2.5337, 'grad_norm': 0.0, 'learning_rate': 5.318518518518518e-05, 'epoch': 1.4}
{'loss': 2.5195, 'grad_norm': 0.0, 'learning_rate': 5.303703703703704e-05, 'epoch': 1.41}
{'loss': 2.5195, 'grad_norm': 0.0, 'learning_rate': 5.2888888888888885e-05, 'epoch': 1.41}
{'loss': 2.69, 'grad_norm': 0.0, 'learning_rate': 5.2740740740740745e-05, 'epoch': 1.42}
{'loss': 2.5215, 'grad_norm': 0.0, 'learning_rate': 5.259259259259259e-05, 'epoch': 1.42}
[1m[33mswanlab[0m[0m: Step 320 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 320 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3401, 'eval_samples_per_second': 21.413, 'eval_steps_per_second': 2.677, 'epoch': 1.42}
{'loss': 2.5697, 'grad_norm': 0.0, 'learning_rate': 5.244444444444445e-05, 'epoch': 1.43}
{'loss': 2.5328, 'grad_norm': 0.0, 'learning_rate': 5.22962962962963e-05, 'epoch': 1.43}
{'loss': 2.4453, 'grad_norm': 0.0, 'learning_rate': 5.2148148148148144e-05, 'epoch': 1.44}
{'loss': 2.4873, 'grad_norm': 0.0, 'learning_rate': 5.2000000000000004e-05, 'epoch': 1.44}
{'loss': 2.5917, 'grad_norm': 0.0, 'learning_rate': 5.185185185185185e-05, 'epoch': 1.44}
{'loss': 2.5, 'grad_norm': 0.0, 'learning_rate': 5.170370370370371e-05, 'epoch': 1.45}
{'loss': 2.5952, 'grad_norm': 0.0, 'learning_rate': 5.1555555555555556e-05, 'epoch': 1.45}
{'loss': 2.661, 'grad_norm': 0.0, 'learning_rate': 5.1407407407407416e-05, 'epoch': 1.46}
{'loss': 2.5911, 'grad_norm': 0.0, 'learning_rate': 5.125925925925926e-05, 'epoch': 1.46}
{'loss': 2.4636, 'grad_norm': 0.0, 'learning_rate': 5.111111111111111e-05, 'epoch': 1.47}
[1m[33mswanlab[0m[0m: Step 330 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 330 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3371, 'eval_samples_per_second': 21.42, 'eval_steps_per_second': 2.677, 'epoch': 1.47}
{'loss': 2.5767, 'grad_norm': 0.0, 'learning_rate': 5.096296296296297e-05, 'epoch': 1.47}
{'loss': 2.5046, 'grad_norm': 0.0, 'learning_rate': 5.0814814814814814e-05, 'epoch': 1.48}
{'loss': 2.5227, 'grad_norm': 0.0, 'learning_rate': 5.0666666666666674e-05, 'epoch': 1.48}
{'loss': 2.5577, 'grad_norm': 0.0, 'learning_rate': 5.051851851851852e-05, 'epoch': 1.48}
{'loss': 2.5945, 'grad_norm': 0.0, 'learning_rate': 5.0370370370370366e-05, 'epoch': 1.49}
{'loss': 2.5185, 'grad_norm': 0.0, 'learning_rate': 5.0222222222222226e-05, 'epoch': 1.49}
{'loss': 2.6201, 'grad_norm': 0.0, 'learning_rate': 5.007407407407407e-05, 'epoch': 1.5}
{'loss': 2.4027, 'grad_norm': 0.0, 'learning_rate': 4.9925925925925926e-05, 'epoch': 1.5}
{'loss': 2.4454, 'grad_norm': 0.0, 'learning_rate': 4.977777777777778e-05, 'epoch': 1.51}
{'loss': 2.7273, 'grad_norm': 0.0, 'learning_rate': 4.962962962962963e-05, 'epoch': 1.51}
[1m[33mswanlab[0m[0m: Step 340 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 340 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3356, 'eval_samples_per_second': 21.423, 'eval_steps_per_second': 2.678, 'epoch': 1.51}
{'loss': 2.6089, 'grad_norm': 0.0, 'learning_rate': 4.9481481481481485e-05, 'epoch': 1.52}
{'loss': 2.4495, 'grad_norm': 0.0, 'learning_rate': 4.933333333333334e-05, 'epoch': 1.52}
{'loss': 2.5588, 'grad_norm': 0.0, 'learning_rate': 4.918518518518519e-05, 'epoch': 1.52}
{'loss': 2.5949, 'grad_norm': 0.0, 'learning_rate': 4.903703703703704e-05, 'epoch': 1.53}
{'loss': 2.4858, 'grad_norm': 0.0, 'learning_rate': 4.888888888888889e-05, 'epoch': 1.53}
{'loss': 2.4874, 'grad_norm': 0.0, 'learning_rate': 4.874074074074074e-05, 'epoch': 1.54}
{'loss': 2.4651, 'grad_norm': 0.0, 'learning_rate': 4.8592592592592596e-05, 'epoch': 1.54}
{'loss': 2.5879, 'grad_norm': 0.0, 'learning_rate': 4.844444444444445e-05, 'epoch': 1.55}
{'loss': 2.6179, 'grad_norm': 0.0, 'learning_rate': 4.82962962962963e-05, 'epoch': 1.55}
{'loss': 2.6253, 'grad_norm': 0.0, 'learning_rate': 4.814814814814815e-05, 'epoch': 1.56}
[1m[33mswanlab[0m[0m: Step 350 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 350 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3118, 'eval_samples_per_second': 21.478, 'eval_steps_per_second': 2.685, 'epoch': 1.56}
{'loss': 2.428, 'grad_norm': 0.0, 'learning_rate': 4.8e-05, 'epoch': 1.56}
{'loss': 2.5066, 'grad_norm': 0.0, 'learning_rate': 4.7851851851851854e-05, 'epoch': 1.56}
{'loss': 2.4845, 'grad_norm': 0.0, 'learning_rate': 4.770370370370371e-05, 'epoch': 1.57}
{'loss': 2.4749, 'grad_norm': 0.0, 'learning_rate': 4.755555555555556e-05, 'epoch': 1.57}
{'loss': 2.5364, 'grad_norm': 0.0, 'learning_rate': 4.740740740740741e-05, 'epoch': 1.58}
{'loss': 2.4909, 'grad_norm': 0.0, 'learning_rate': 4.7259259259259266e-05, 'epoch': 1.58}
{'loss': 2.5796, 'grad_norm': 0.0, 'learning_rate': 4.711111111111111e-05, 'epoch': 1.59}
{'loss': 2.4715, 'grad_norm': 0.0, 'learning_rate': 4.6962962962962966e-05, 'epoch': 1.59}
{'loss': 2.5768, 'grad_norm': 0.0, 'learning_rate': 4.681481481481482e-05, 'epoch': 1.6}
{'loss': 2.5645, 'grad_norm': 0.0, 'learning_rate': 4.666666666666667e-05, 'epoch': 1.6}
[1m[33mswanlab[0m[0m: Step 360 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 360 on key train/global_step already exists, ignored.
{'eval_loss': 2.566577196121216, 'eval_runtime': 9.3173, 'eval_samples_per_second': 21.466, 'eval_steps_per_second': 2.683, 'epoch': 1.6}
{'loss': 2.5847, 'grad_norm': 0.0, 'learning_rate': 4.6518518518518525e-05, 'epoch': 1.6}
{'loss': 2.4364, 'grad_norm': 0.0, 'learning_rate': 4.637037037037038e-05, 'epoch': 1.61}
{'loss': 2.6119, 'grad_norm': 0.0, 'learning_rate': 4.6222222222222224e-05, 'epoch': 1.61}
{'loss': 2.5395, 'grad_norm': 0.0, 'learning_rate': 4.607407407407408e-05, 'epoch': 1.62}
{'loss': 2.4686, 'grad_norm': 0.0, 'learning_rate': 4.592592592592593e-05, 'epoch': 1.62}
{'loss': 2.394, 'grad_norm': 0.0, 'learning_rate': 4.577777777777778e-05, 'epoch': 1.63}
{'loss': 2.4648, 'grad_norm': 0.0, 'learning_rate': 4.5629629629629636e-05, 'epoch': 1.63}
{'loss': 2.6618, 'grad_norm': 0.0, 'learning_rate': 4.548148148148149e-05, 'epoch': 1.64}
{'loss': 2.509, 'grad_norm': 0.0, 'learning_rate': 4.5333333333333335e-05, 'epoch': 1.64}
{'loss': 2.507, 'grad_norm': 0.0, 'learning_rate': 4.518518518518519e-05, 'epoch': 1.64}
