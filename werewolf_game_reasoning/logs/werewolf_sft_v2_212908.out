Mon May  5 20:21:44 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H800                    On  | 00000000:43:00.0 Off |                    0 |
| N/A   22C    P0              65W / 700W |      4MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
|  No running processes found                                                           |
+---------------------------------------------------------------------------------------+
/home/rliubk/.conda/envs/werewolf/bin/python
PyTorch: 2.2.0+cu121, CUDA: True, 设备: NVIDIA H800
===== 开始 SFT 微调 (v2 - 禁用FP16) Mon May  5 08:21:51 PM HKT 2025 =====
开始训练 - 阶段: sft
数据目录: .
输出目录: output
模型路径: Qwen/Qwen2.5-1.5B
批次大小: 1，梯度累积: 4
评估批次大小: 1
SwanLab: 使用提供的API密钥
加载SFT数据集: train_zh.csv
开始处理SFT数据: 12134 样本
加载tokenizer: Qwen/Qwen2.5-1.5B
使用最大序列长度: 8192
开始tokenize数据...
Tokenize完成，训练集大小: 10920 样本
加载基础模型: Qwen/Qwen2.5-1.5B
加载LoRA适配器权重: output/basic
trainable params: 4,702,208 || all params: 1,548,416,512 || trainable%: 0.3037
配置训练参数 - 禁用FP16混合精度
正在使用API密钥登录SwanLab...
[1m[34mswanlab[0m[0m: \ Waiting for the swanlab cloud response.[1m[34mswanlab[0m[0m: | Waiting for the swanlab cloud response.[1m[34mswanlab[0m[0m: / Waiting for the swanlab cloud response.[1m[34mswanlab[0m[0m: - Waiting for the swanlab cloud response.[1m[34mswanlab[0m[0m: \ Waiting for the swanlab cloud response.[1m[34mswanlab[0m[0m: | Waiting for the swanlab cloud response.                                                                                                    SwanLab登录成功!
开始SFT训练...
[1m[34mswanlab[0m[0m: \ Getting project...[1m[34mswanlab[0m[0m: | Getting project...[1m[34mswanlab[0m[0m: / Getting project...[1m[34mswanlab[0m[0m: - Getting project...[1m[34mswanlab[0m[0m: \ Getting project...[1m[34mswanlab[0m[0m: | Getting project...[1m[34mswanlab[0m[0m: / Getting project...                                                                                                    [1m[34mswanlab[0m[0m: \ Creating experiment...[1m[34mswanlab[0m[0m: | Creating experiment...[1m[34mswanlab[0m[0m: / Creating experiment...[1m[34mswanlab[0m[0m: - Creating experiment...[1m[34mswanlab[0m[0m: \ Creating experiment...[1m[34mswanlab[0m[0m: | Creating experiment...[1m[34mswanlab[0m[0m: / Creating experiment...[1m[34mswanlab[0m[0m: - Creating experiment...                                                                                                    [1m[34mswanlab[0m[0m: Tracking run with swanlab version 0.5.7
[1m[34mswanlab[0m[0m: Run data will be saved locally in [35m[1m/home/rliubk/llm-project/werewolf_game_reasoning/swanlog/run-20250505_202221-a3b1799d[0m[0m
[1m[34mswanlab[0m[0m: 👋 Hi [1m[39msurmountrt[0m[0m, welcome to swanlab!
[1m[34mswanlab[0m[0m: Syncing run [33msft[0m to the cloud
[1m[34mswanlab[0m[0m: 🏠 View project at [34m[4mhttps://swanlab.cn/@surmountrt/Werewolf-LoRA[0m[0m
[1m[34mswanlab[0m[0m: 🚀 View run at [34m[4mhttps://swanlab.cn/@surmountrt/Werewolf-LoRA/runs/6jooanbpchhizbi2h83j0[0m[0m
{'loss': 2.4354, 'grad_norm': 1.1807260513305664, 'learning_rate': 4.0650406504065046e-07, 'epoch': 0.0}
{'loss': 2.5737, 'grad_norm': 1.408429503440857, 'learning_rate': 8.130081300813009e-07, 'epoch': 0.0}
{'loss': 2.3571, 'grad_norm': 1.3173985481262207, 'learning_rate': 1.2195121951219514e-06, 'epoch': 0.0}
{'loss': 2.4204, 'grad_norm': 1.1332097053527832, 'learning_rate': 1.6260162601626018e-06, 'epoch': 0.0}
{'loss': 2.4305, 'grad_norm': 1.208814263343811, 'learning_rate': 2.0325203252032523e-06, 'epoch': 0.0}
{'loss': 2.3606, 'grad_norm': 1.194399118423462, 'learning_rate': 2.4390243902439027e-06, 'epoch': 0.0}
{'loss': 2.4122, 'grad_norm': 1.3456549644470215, 'learning_rate': 2.8455284552845528e-06, 'epoch': 0.0}
{'loss': 2.4875, 'grad_norm': 1.2045505046844482, 'learning_rate': 3.2520325203252037e-06, 'epoch': 0.0}
{'loss': 2.5446, 'grad_norm': 0.993188738822937, 'learning_rate': 3.6585365853658537e-06, 'epoch': 0.0}
{'loss': 2.2822, 'grad_norm': 1.0967234373092651, 'learning_rate': 4.0650406504065046e-06, 'epoch': 0.0}
[1m[33mswanlab[0m[0m: Step 10 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 10 on key train/global_step already exists, ignored.
{'eval_loss': 2.4522597789764404, 'eval_runtime': 326.7826, 'eval_samples_per_second': 3.715, 'eval_steps_per_second': 3.715, 'epoch': 0.0}
{'loss': 2.3175, 'grad_norm': 1.1855803728103638, 'learning_rate': 4.471544715447155e-06, 'epoch': 0.0}
{'loss': 2.3798, 'grad_norm': 1.1233888864517212, 'learning_rate': 4.8780487804878055e-06, 'epoch': 0.0}
{'loss': 2.3091, 'grad_norm': 1.2168267965316772, 'learning_rate': 5.2845528455284555e-06, 'epoch': 0.0}
{'loss': 2.3482, 'grad_norm': 1.104172945022583, 'learning_rate': 5.6910569105691056e-06, 'epoch': 0.01}
{'loss': 2.3381, 'grad_norm': 1.4444849491119385, 'learning_rate': 6.0975609756097564e-06, 'epoch': 0.01}
{'loss': 2.4472, 'grad_norm': 1.2118523120880127, 'learning_rate': 6.504065040650407e-06, 'epoch': 0.01}
{'loss': 2.3639, 'grad_norm': 1.2675775289535522, 'learning_rate': 6.910569105691057e-06, 'epoch': 0.01}
{'loss': 2.1979, 'grad_norm': 1.2124836444854736, 'learning_rate': 7.317073170731707e-06, 'epoch': 0.01}
{'loss': 2.3736, 'grad_norm': 1.1547139883041382, 'learning_rate': 7.723577235772358e-06, 'epoch': 0.01}
{'loss': 2.3241, 'grad_norm': 1.1410959959030151, 'learning_rate': 8.130081300813009e-06, 'epoch': 0.01}
[1m[33mswanlab[0m[0m: Step 20 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 20 on key train/global_step already exists, ignored.
{'eval_loss': 2.412365674972534, 'eval_runtime': 326.8684, 'eval_samples_per_second': 3.714, 'eval_steps_per_second': 3.714, 'epoch': 0.01}
{'loss': 2.4366, 'grad_norm': 1.2570022344589233, 'learning_rate': 8.53658536585366e-06, 'epoch': 0.01}
{'loss': 2.5075, 'grad_norm': 0.9350789189338684, 'learning_rate': 8.94308943089431e-06, 'epoch': 0.01}
{'loss': 2.3451, 'grad_norm': 0.996505081653595, 'learning_rate': 9.34959349593496e-06, 'epoch': 0.01}
{'loss': 2.4491, 'grad_norm': 1.051774024963379, 'learning_rate': 9.756097560975611e-06, 'epoch': 0.01}
{'loss': 2.3839, 'grad_norm': 0.9073569178581238, 'learning_rate': 1.016260162601626e-05, 'epoch': 0.01}
{'loss': 2.3958, 'grad_norm': 1.5927023887634277, 'learning_rate': 1.0569105691056911e-05, 'epoch': 0.01}
{'loss': 2.3234, 'grad_norm': 1.0582877397537231, 'learning_rate': 1.0975609756097562e-05, 'epoch': 0.01}
{'loss': 2.3005, 'grad_norm': 1.1481232643127441, 'learning_rate': 1.1382113821138211e-05, 'epoch': 0.01}
{'loss': 2.3921, 'grad_norm': 0.9161113500595093, 'learning_rate': 1.1788617886178862e-05, 'epoch': 0.01}
{'loss': 2.3973, 'grad_norm': 1.3125858306884766, 'learning_rate': 1.2195121951219513e-05, 'epoch': 0.01}
[1m[33mswanlab[0m[0m: Step 30 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 30 on key train/global_step already exists, ignored.
{'eval_loss': 2.3516244888305664, 'eval_runtime': 326.8496, 'eval_samples_per_second': 3.714, 'eval_steps_per_second': 3.714, 'epoch': 0.01}
{'loss': 2.4244, 'grad_norm': 0.9008913040161133, 'learning_rate': 1.2601626016260162e-05, 'epoch': 0.01}
{'loss': 2.2565, 'grad_norm': 1.0559351444244385, 'learning_rate': 1.3008130081300815e-05, 'epoch': 0.01}
{'loss': 2.3623, 'grad_norm': 0.9710964560508728, 'learning_rate': 1.3414634146341466e-05, 'epoch': 0.01}
{'loss': 2.1046, 'grad_norm': 0.9186581969261169, 'learning_rate': 1.3821138211382115e-05, 'epoch': 0.01}
{'loss': 2.2958, 'grad_norm': 1.1416815519332886, 'learning_rate': 1.4227642276422764e-05, 'epoch': 0.01}
{'loss': 2.353, 'grad_norm': 0.9226109981536865, 'learning_rate': 1.4634146341463415e-05, 'epoch': 0.01}
{'loss': 2.2396, 'grad_norm': 0.8293136954307556, 'learning_rate': 1.5040650406504067e-05, 'epoch': 0.01}
{'loss': 2.4254, 'grad_norm': 0.9112761616706848, 'learning_rate': 1.5447154471544717e-05, 'epoch': 0.01}
{'loss': 2.3863, 'grad_norm': 0.9158889055252075, 'learning_rate': 1.5853658536585366e-05, 'epoch': 0.01}
{'loss': 2.4708, 'grad_norm': 0.8299440741539001, 'learning_rate': 1.6260162601626018e-05, 'epoch': 0.01}
[1m[33mswanlab[0m[0m: Step 40 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 40 on key train/global_step already exists, ignored.
{'eval_loss': 2.2731287479400635, 'eval_runtime': 326.6766, 'eval_samples_per_second': 3.716, 'eval_steps_per_second': 3.716, 'epoch': 0.01}
{'loss': 2.3508, 'grad_norm': 0.7720086574554443, 'learning_rate': 1.6666666666666667e-05, 'epoch': 0.02}
{'loss': 2.1803, 'grad_norm': 0.8971328139305115, 'learning_rate': 1.707317073170732e-05, 'epoch': 0.02}
{'loss': 2.3714, 'grad_norm': 0.9551953673362732, 'learning_rate': 1.747967479674797e-05, 'epoch': 0.02}
{'loss': 2.3284, 'grad_norm': 0.8126462697982788, 'learning_rate': 1.788617886178862e-05, 'epoch': 0.02}
{'loss': 2.3389, 'grad_norm': 0.8575080633163452, 'learning_rate': 1.8292682926829268e-05, 'epoch': 0.02}
{'loss': 2.3447, 'grad_norm': 0.7832810282707214, 'learning_rate': 1.869918699186992e-05, 'epoch': 0.02}
{'loss': 2.4705, 'grad_norm': 0.8090999126434326, 'learning_rate': 1.9105691056910573e-05, 'epoch': 0.02}
{'loss': 2.211, 'grad_norm': 0.9688745737075806, 'learning_rate': 1.9512195121951222e-05, 'epoch': 0.02}
{'loss': 2.1467, 'grad_norm': 0.9135887026786804, 'learning_rate': 1.991869918699187e-05, 'epoch': 0.02}
{'loss': 2.2606, 'grad_norm': 0.7019591331481934, 'learning_rate': 2.032520325203252e-05, 'epoch': 0.02}
[1m[33mswanlab[0m[0m: Step 50 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 50 on key train/global_step already exists, ignored.
{'eval_loss': 2.1757566928863525, 'eval_runtime': 326.4387, 'eval_samples_per_second': 3.719, 'eval_steps_per_second': 3.719, 'epoch': 0.02}
{'loss': 2.1634, 'grad_norm': 1.0046828985214233, 'learning_rate': 2.073170731707317e-05, 'epoch': 0.02}
{'loss': 2.1424, 'grad_norm': 0.7694976925849915, 'learning_rate': 2.1138211382113822e-05, 'epoch': 0.02}
{'loss': 2.2878, 'grad_norm': 0.865962028503418, 'learning_rate': 2.1544715447154475e-05, 'epoch': 0.02}
{'loss': 2.2397, 'grad_norm': 0.90448397397995, 'learning_rate': 2.1951219512195124e-05, 'epoch': 0.02}
{'loss': 2.0216, 'grad_norm': 1.0173530578613281, 'learning_rate': 2.2357723577235773e-05, 'epoch': 0.02}
{'loss': 2.1647, 'grad_norm': 0.7731962203979492, 'learning_rate': 2.2764227642276422e-05, 'epoch': 0.02}
{'loss': 2.068, 'grad_norm': 0.7913800477981567, 'learning_rate': 2.3170731707317075e-05, 'epoch': 0.02}
{'loss': 2.2275, 'grad_norm': 0.8766810894012451, 'learning_rate': 2.3577235772357724e-05, 'epoch': 0.02}
{'loss': 2.2035, 'grad_norm': 1.0228992700576782, 'learning_rate': 2.3983739837398377e-05, 'epoch': 0.02}
{'loss': 2.1041, 'grad_norm': 0.9332002997398376, 'learning_rate': 2.4390243902439026e-05, 'epoch': 0.02}
[1m[33mswanlab[0m[0m: Step 60 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 60 on key train/global_step already exists, ignored.
{'eval_loss': 2.040968179702759, 'eval_runtime': 326.2162, 'eval_samples_per_second': 3.721, 'eval_steps_per_second': 3.721, 'epoch': 0.02}
{'loss': 1.9946, 'grad_norm': 1.0200774669647217, 'learning_rate': 2.4796747967479675e-05, 'epoch': 0.02}
{'loss': 2.1248, 'grad_norm': 0.9349056482315063, 'learning_rate': 2.5203252032520324e-05, 'epoch': 0.02}
{'loss': 2.299, 'grad_norm': 0.7300223708152771, 'learning_rate': 2.5609756097560977e-05, 'epoch': 0.02}
{'loss': 2.0009, 'grad_norm': 0.9820848703384399, 'learning_rate': 2.601626016260163e-05, 'epoch': 0.02}
{'loss': 1.991, 'grad_norm': 1.0291283130645752, 'learning_rate': 2.642276422764228e-05, 'epoch': 0.02}
{'loss': 1.8844, 'grad_norm': 0.9412071108818054, 'learning_rate': 2.682926829268293e-05, 'epoch': 0.02}
{'loss': 1.8764, 'grad_norm': 0.9445374608039856, 'learning_rate': 2.7235772357723577e-05, 'epoch': 0.02}
{'loss': 2.0493, 'grad_norm': 0.993418276309967, 'learning_rate': 2.764227642276423e-05, 'epoch': 0.02}
{'loss': 1.9275, 'grad_norm': 0.9592738151550293, 'learning_rate': 2.8048780487804882e-05, 'epoch': 0.03}
{'loss': 2.0795, 'grad_norm': 0.841105043888092, 'learning_rate': 2.8455284552845528e-05, 'epoch': 0.03}
[1m[33mswanlab[0m[0m: Step 70 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 70 on key train/global_step already exists, ignored.
{'eval_loss': 1.8460652828216553, 'eval_runtime': 326.2213, 'eval_samples_per_second': 3.721, 'eval_steps_per_second': 3.721, 'epoch': 0.03}
{'loss': 1.9344, 'grad_norm': 0.7738112211227417, 'learning_rate': 2.886178861788618e-05, 'epoch': 0.03}
{'loss': 1.5763, 'grad_norm': 1.4108299016952515, 'learning_rate': 2.926829268292683e-05, 'epoch': 0.03}
{'loss': 1.653, 'grad_norm': 1.230282187461853, 'learning_rate': 2.9674796747967482e-05, 'epoch': 0.03}
{'loss': 1.7795, 'grad_norm': 1.1350009441375732, 'learning_rate': 3.0081300813008135e-05, 'epoch': 0.03}
{'loss': 1.9683, 'grad_norm': 0.8457537889480591, 'learning_rate': 3.048780487804878e-05, 'epoch': 0.03}
{'loss': 1.7007, 'grad_norm': 1.1538017988204956, 'learning_rate': 3.089430894308943e-05, 'epoch': 0.03}
{'loss': 1.7716, 'grad_norm': 1.0437917709350586, 'learning_rate': 3.130081300813008e-05, 'epoch': 0.03}
{'loss': 1.687, 'grad_norm': 1.09328031539917, 'learning_rate': 3.170731707317073e-05, 'epoch': 0.03}
{'loss': 1.7055, 'grad_norm': 0.9789184927940369, 'learning_rate': 3.2113821138211384e-05, 'epoch': 0.03}
{'loss': 1.8462, 'grad_norm': 0.9023700952529907, 'learning_rate': 3.2520325203252037e-05, 'epoch': 0.03}
[1m[33mswanlab[0m[0m: Step 80 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 80 on key train/global_step already exists, ignored.
{'eval_loss': 1.637189269065857, 'eval_runtime': 326.1738, 'eval_samples_per_second': 3.722, 'eval_steps_per_second': 3.722, 'epoch': 0.03}
{'loss': 1.8689, 'grad_norm': 0.833107054233551, 'learning_rate': 3.292682926829269e-05, 'epoch': 0.03}
{'loss': 1.2809, 'grad_norm': 1.19161057472229, 'learning_rate': 3.3333333333333335e-05, 'epoch': 0.03}
{'loss': 1.4932, 'grad_norm': 1.124289631843567, 'learning_rate': 3.373983739837399e-05, 'epoch': 0.03}
{'loss': 1.4891, 'grad_norm': 1.09165620803833, 'learning_rate': 3.414634146341464e-05, 'epoch': 0.03}
{'loss': 1.3986, 'grad_norm': 1.0194751024246216, 'learning_rate': 3.4552845528455286e-05, 'epoch': 0.03}
{'loss': 1.6055, 'grad_norm': 1.1413490772247314, 'learning_rate': 3.495934959349594e-05, 'epoch': 0.03}
{'loss': 1.7743, 'grad_norm': 0.8215764760971069, 'learning_rate': 3.5365853658536584e-05, 'epoch': 0.03}
{'loss': 1.403, 'grad_norm': 0.9572280645370483, 'learning_rate': 3.577235772357724e-05, 'epoch': 0.03}
{'loss': 1.5911, 'grad_norm': 0.8137934803962708, 'learning_rate': 3.617886178861789e-05, 'epoch': 0.03}
{'loss': 1.5199, 'grad_norm': 0.9657096862792969, 'learning_rate': 3.6585365853658535e-05, 'epoch': 0.03}
[1m[33mswanlab[0m[0m: Step 90 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 90 on key train/global_step already exists, ignored.
{'eval_loss': 1.4930168390274048, 'eval_runtime': 326.0041, 'eval_samples_per_second': 3.724, 'eval_steps_per_second': 3.724, 'epoch': 0.03}
{'loss': 1.7257, 'grad_norm': 0.774365246295929, 'learning_rate': 3.699186991869919e-05, 'epoch': 0.03}
{'loss': 1.2441, 'grad_norm': 0.9638116955757141, 'learning_rate': 3.739837398373984e-05, 'epoch': 0.03}
{'loss': 1.0293, 'grad_norm': 0.9455052614212036, 'learning_rate': 3.780487804878049e-05, 'epoch': 0.03}
{'loss': 1.0716, 'grad_norm': 0.8377805948257446, 'learning_rate': 3.8211382113821145e-05, 'epoch': 0.03}
{'loss': 1.3948, 'grad_norm': 1.3332194089889526, 'learning_rate': 3.861788617886179e-05, 'epoch': 0.03}
{'loss': 1.2058, 'grad_norm': 0.9706263542175293, 'learning_rate': 3.9024390243902444e-05, 'epoch': 0.04}
{'loss': 1.6998, 'grad_norm': 0.6947608590126038, 'learning_rate': 3.943089430894309e-05, 'epoch': 0.04}
{'loss': 1.1725, 'grad_norm': 1.067426085472107, 'learning_rate': 3.983739837398374e-05, 'epoch': 0.04}
{'loss': 1.2434, 'grad_norm': 0.7970749735832214, 'learning_rate': 4.0243902439024395e-05, 'epoch': 0.04}
{'loss': 1.5179, 'grad_norm': 0.8729394674301147, 'learning_rate': 4.065040650406504e-05, 'epoch': 0.04}
[1m[33mswanlab[0m[0m: Step 100 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 100 on key train/global_step already exists, ignored.
{'eval_loss': 1.3956992626190186, 'eval_runtime': 325.7534, 'eval_samples_per_second': 3.727, 'eval_steps_per_second': 3.727, 'epoch': 0.04}
{'loss': 1.785, 'grad_norm': 0.7873782515525818, 'learning_rate': 4.105691056910569e-05, 'epoch': 0.04}
{'loss': 1.8136, 'grad_norm': 0.7723170518875122, 'learning_rate': 4.146341463414634e-05, 'epoch': 0.04}
{'loss': 1.4924, 'grad_norm': 0.8328036665916443, 'learning_rate': 4.186991869918699e-05, 'epoch': 0.04}
{'loss': 1.4669, 'grad_norm': 0.7091415524482727, 'learning_rate': 4.2276422764227644e-05, 'epoch': 0.04}
{'loss': 1.5315, 'grad_norm': 0.6786538362503052, 'learning_rate': 4.26829268292683e-05, 'epoch': 0.04}
{'loss': 1.0947, 'grad_norm': 1.1244758367538452, 'learning_rate': 4.308943089430895e-05, 'epoch': 0.04}
{'loss': 1.1985, 'grad_norm': 0.7981528043746948, 'learning_rate': 4.3495934959349595e-05, 'epoch': 0.04}
{'loss': 1.4568, 'grad_norm': 1.5748635530471802, 'learning_rate': 4.390243902439025e-05, 'epoch': 0.04}
{'loss': 1.2935, 'grad_norm': 0.8763983845710754, 'learning_rate': 4.43089430894309e-05, 'epoch': 0.04}
{'loss': 1.0778, 'grad_norm': 1.140655279159546, 'learning_rate': 4.4715447154471546e-05, 'epoch': 0.04}
[1m[33mswanlab[0m[0m: Step 110 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 110 on key train/global_step already exists, ignored.
{'eval_loss': 1.3250523805618286, 'eval_runtime': 326.0029, 'eval_samples_per_second': 3.724, 'eval_steps_per_second': 3.724, 'epoch': 0.04}
{'loss': 1.47, 'grad_norm': 0.9930562376976013, 'learning_rate': 4.51219512195122e-05, 'epoch': 0.04}
{'loss': 1.2498, 'grad_norm': 0.791010856628418, 'learning_rate': 4.5528455284552844e-05, 'epoch': 0.04}
{'loss': 1.5441, 'grad_norm': 0.797151505947113, 'learning_rate': 4.59349593495935e-05, 'epoch': 0.04}
{'loss': 1.0569, 'grad_norm': 1.1353365182876587, 'learning_rate': 4.634146341463415e-05, 'epoch': 0.04}
{'loss': 1.646, 'grad_norm': 0.7540895342826843, 'learning_rate': 4.6747967479674795e-05, 'epoch': 0.04}
{'loss': 1.5238, 'grad_norm': 0.7477717399597168, 'learning_rate': 4.715447154471545e-05, 'epoch': 0.04}
{'loss': 1.2654, 'grad_norm': 0.8240853548049927, 'learning_rate': 4.75609756097561e-05, 'epoch': 0.04}
{'loss': 1.7033, 'grad_norm': 0.9059382677078247, 'learning_rate': 4.796747967479675e-05, 'epoch': 0.04}
{'loss': 1.3664, 'grad_norm': 0.7693507671356201, 'learning_rate': 4.8373983739837406e-05, 'epoch': 0.04}
{'loss': 1.1451, 'grad_norm': 0.9565718770027161, 'learning_rate': 4.878048780487805e-05, 'epoch': 0.04}
[1m[33mswanlab[0m[0m: Step 120 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 120 on key train/global_step already exists, ignored.
{'eval_loss': 1.2634810209274292, 'eval_runtime': 325.7944, 'eval_samples_per_second': 3.726, 'eval_steps_per_second': 3.726, 'epoch': 0.04}
{'loss': 1.0194, 'grad_norm': 0.7601773142814636, 'learning_rate': 4.9186991869918704e-05, 'epoch': 0.04}
{'loss': 1.3935, 'grad_norm': 0.8008573055267334, 'learning_rate': 4.959349593495935e-05, 'epoch': 0.04}
{'loss': 1.0496, 'grad_norm': 1.2699434757232666, 'learning_rate': 5e-05, 'epoch': 0.05}
{'loss': 1.2898, 'grad_norm': 0.7755095958709717, 'learning_rate': 5.040650406504065e-05, 'epoch': 0.05}
{'loss': 1.3896, 'grad_norm': 1.0492304563522339, 'learning_rate': 5.081300813008131e-05, 'epoch': 0.05}
{'loss': 0.7599, 'grad_norm': 1.302497386932373, 'learning_rate': 5.121951219512195e-05, 'epoch': 0.05}
{'loss': 1.1285, 'grad_norm': 1.4924302101135254, 'learning_rate': 5.16260162601626e-05, 'epoch': 0.05}
{'loss': 1.2666, 'grad_norm': 1.299282193183899, 'learning_rate': 5.203252032520326e-05, 'epoch': 0.05}
{'loss': 1.5795, 'grad_norm': 0.8754943609237671, 'learning_rate': 5.2439024390243904e-05, 'epoch': 0.05}
{'loss': 1.1697, 'grad_norm': 1.0396995544433594, 'learning_rate': 5.284552845528456e-05, 'epoch': 0.05}
[1m[33mswanlab[0m[0m: Step 130 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 130 on key train/global_step already exists, ignored.
{'eval_loss': 1.2119355201721191, 'eval_runtime': 325.5108, 'eval_samples_per_second': 3.73, 'eval_steps_per_second': 3.73, 'epoch': 0.05}
{'loss': 1.1065, 'grad_norm': 1.1425278186798096, 'learning_rate': 5.32520325203252e-05, 'epoch': 0.05}
{'loss': 1.4487, 'grad_norm': 0.9633607864379883, 'learning_rate': 5.365853658536586e-05, 'epoch': 0.05}
{'loss': 1.2326, 'grad_norm': 0.7477051019668579, 'learning_rate': 5.406504065040651e-05, 'epoch': 0.05}
{'loss': 0.8111, 'grad_norm': 1.1598808765411377, 'learning_rate': 5.4471544715447154e-05, 'epoch': 0.05}
{'loss': 0.4326, 'grad_norm': 1.158067226409912, 'learning_rate': 5.487804878048781e-05, 'epoch': 0.05}
{'loss': 1.4247, 'grad_norm': 0.7105021476745605, 'learning_rate': 5.528455284552846e-05, 'epoch': 0.05}
{'loss': 1.0037, 'grad_norm': 1.4563802480697632, 'learning_rate': 5.5691056910569105e-05, 'epoch': 0.05}
{'loss': 1.3359, 'grad_norm': 0.6715726852416992, 'learning_rate': 5.6097560975609764e-05, 'epoch': 0.05}
{'loss': 1.2322, 'grad_norm': 0.791408121585846, 'learning_rate': 5.650406504065041e-05, 'epoch': 0.05}
{'loss': 1.2801, 'grad_norm': 0.8475920557975769, 'learning_rate': 5.6910569105691056e-05, 'epoch': 0.05}
[1m[33mswanlab[0m[0m: Step 140 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 140 on key train/global_step already exists, ignored.
{'eval_loss': 1.1686697006225586, 'eval_runtime': 325.5126, 'eval_samples_per_second': 3.73, 'eval_steps_per_second': 3.73, 'epoch': 0.05}
{'loss': 1.62, 'grad_norm': 0.6819143891334534, 'learning_rate': 5.731707317073171e-05, 'epoch': 0.05}
{'loss': 1.1084, 'grad_norm': 0.8842762112617493, 'learning_rate': 5.772357723577236e-05, 'epoch': 0.05}
{'loss': 1.3378, 'grad_norm': 1.0945054292678833, 'learning_rate': 5.813008130081301e-05, 'epoch': 0.05}
{'loss': 1.3741, 'grad_norm': 0.7774190306663513, 'learning_rate': 5.853658536585366e-05, 'epoch': 0.05}
{'loss': 1.2846, 'grad_norm': 0.9604109525680542, 'learning_rate': 5.894308943089432e-05, 'epoch': 0.05}
{'loss': 1.5015, 'grad_norm': 0.7124897837638855, 'learning_rate': 5.9349593495934964e-05, 'epoch': 0.05}
{'loss': 1.6447, 'grad_norm': 0.7210645079612732, 'learning_rate': 5.975609756097561e-05, 'epoch': 0.05}
{'loss': 0.9033, 'grad_norm': 0.9963303208351135, 'learning_rate': 6.016260162601627e-05, 'epoch': 0.05}
{'loss': 1.1626, 'grad_norm': 0.8116875886917114, 'learning_rate': 6.0569105691056915e-05, 'epoch': 0.05}
{'loss': 0.702, 'grad_norm': 0.9261677861213684, 'learning_rate': 6.097560975609756e-05, 'epoch': 0.05}
[1m[33mswanlab[0m[0m: Step 150 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 150 on key train/global_step already exists, ignored.
{'eval_loss': 1.1325774192810059, 'eval_runtime': 325.3308, 'eval_samples_per_second': 3.732, 'eval_steps_per_second': 3.732, 'epoch': 0.05}
{'loss': 1.5099, 'grad_norm': 0.797307014465332, 'learning_rate': 6.138211382113821e-05, 'epoch': 0.06}
{'loss': 0.9342, 'grad_norm': 1.264517068862915, 'learning_rate': 6.178861788617887e-05, 'epoch': 0.06}
{'loss': 1.3985, 'grad_norm': 0.8709571957588196, 'learning_rate': 6.219512195121952e-05, 'epoch': 0.06}
{'loss': 1.1526, 'grad_norm': 0.7828341722488403, 'learning_rate': 6.260162601626016e-05, 'epoch': 0.06}
{'loss': 0.9792, 'grad_norm': 0.9936427474021912, 'learning_rate': 6.300813008130082e-05, 'epoch': 0.06}
{'loss': 1.3017, 'grad_norm': 0.8182734251022339, 'learning_rate': 6.341463414634146e-05, 'epoch': 0.06}
{'loss': 1.555, 'grad_norm': 0.9314256906509399, 'learning_rate': 6.382113821138212e-05, 'epoch': 0.06}
{'loss': 1.1697, 'grad_norm': 0.7473167777061462, 'learning_rate': 6.422764227642277e-05, 'epoch': 0.06}
{'loss': 1.0986, 'grad_norm': 0.8253703713417053, 'learning_rate': 6.463414634146342e-05, 'epoch': 0.06}
{'loss': 1.012, 'grad_norm': 0.870027482509613, 'learning_rate': 6.504065040650407e-05, 'epoch': 0.06}
[1m[33mswanlab[0m[0m: Step 160 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 160 on key train/global_step already exists, ignored.
{'eval_loss': 1.1029951572418213, 'eval_runtime': 326.4229, 'eval_samples_per_second': 3.719, 'eval_steps_per_second': 3.719, 'epoch': 0.06}
{'loss': 1.0619, 'grad_norm': 0.7855833172798157, 'learning_rate': 6.544715447154471e-05, 'epoch': 0.06}
{'loss': 1.439, 'grad_norm': 0.8225124478340149, 'learning_rate': 6.585365853658538e-05, 'epoch': 0.06}
{'loss': 1.0387, 'grad_norm': 1.1338658332824707, 'learning_rate': 6.626016260162602e-05, 'epoch': 0.06}
{'loss': 1.2, 'grad_norm': 0.9418333172798157, 'learning_rate': 6.666666666666667e-05, 'epoch': 0.06}
{'loss': 1.2466, 'grad_norm': 0.8764670491218567, 'learning_rate': 6.707317073170732e-05, 'epoch': 0.06}
{'loss': 1.1503, 'grad_norm': 0.8701038956642151, 'learning_rate': 6.747967479674798e-05, 'epoch': 0.06}
{'loss': 1.0542, 'grad_norm': 0.843986988067627, 'learning_rate': 6.788617886178861e-05, 'epoch': 0.06}
{'loss': 0.6188, 'grad_norm': 1.1796833276748657, 'learning_rate': 6.829268292682928e-05, 'epoch': 0.06}
{'loss': 1.4088, 'grad_norm': 0.9781550765037537, 'learning_rate': 6.869918699186992e-05, 'epoch': 0.06}
{'loss': 1.3439, 'grad_norm': 0.7705179452896118, 'learning_rate': 6.910569105691057e-05, 'epoch': 0.06}
[1m[33mswanlab[0m[0m: Step 170 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 170 on key train/global_step already exists, ignored.
{'eval_loss': 1.0805726051330566, 'eval_runtime': 326.3851, 'eval_samples_per_second': 3.72, 'eval_steps_per_second': 3.72, 'epoch': 0.06}
{'loss': 1.5823, 'grad_norm': 0.7216205596923828, 'learning_rate': 6.951219512195122e-05, 'epoch': 0.06}
{'loss': 1.1847, 'grad_norm': 1.0226901769638062, 'learning_rate': 6.991869918699188e-05, 'epoch': 0.06}
{'loss': 0.8384, 'grad_norm': 0.8261892795562744, 'learning_rate': 7.032520325203253e-05, 'epoch': 0.06}
{'loss': 1.3156, 'grad_norm': 0.9352695345878601, 'learning_rate': 7.073170731707317e-05, 'epoch': 0.06}
{'loss': 0.9791, 'grad_norm': 0.799106240272522, 'learning_rate': 7.113821138211383e-05, 'epoch': 0.06}
{'loss': 0.5151, 'grad_norm': 1.1050435304641724, 'learning_rate': 7.154471544715447e-05, 'epoch': 0.06}
{'loss': 0.8357, 'grad_norm': 0.8891284465789795, 'learning_rate': 7.195121951219513e-05, 'epoch': 0.06}
{'loss': 1.3811, 'grad_norm': 0.8139363527297974, 'learning_rate': 7.235772357723578e-05, 'epoch': 0.07}
{'loss': 1.4443, 'grad_norm': 0.9767664074897766, 'learning_rate': 7.276422764227643e-05, 'epoch': 0.07}
{'loss': 0.8104, 'grad_norm': 0.9169828295707703, 'learning_rate': 7.317073170731707e-05, 'epoch': 0.07}
[1m[33mswanlab[0m[0m: Step 180 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 180 on key train/global_step already exists, ignored.
{'eval_loss': 1.0600314140319824, 'eval_runtime': 326.2805, 'eval_samples_per_second': 3.721, 'eval_steps_per_second': 3.721, 'epoch': 0.07}
{'loss': 1.1296, 'grad_norm': 0.9910956025123596, 'learning_rate': 7.357723577235772e-05, 'epoch': 0.07}
{'loss': 1.0413, 'grad_norm': 0.8450402617454529, 'learning_rate': 7.398373983739838e-05, 'epoch': 0.07}
{'loss': 0.7378, 'grad_norm': 0.9390578269958496, 'learning_rate': 7.439024390243903e-05, 'epoch': 0.07}
{'loss': 0.9185, 'grad_norm': 0.8823808431625366, 'learning_rate': 7.479674796747968e-05, 'epoch': 0.07}
{'loss': 1.0597, 'grad_norm': 0.9445410966873169, 'learning_rate': 7.520325203252033e-05, 'epoch': 0.07}
{'loss': 1.1521, 'grad_norm': 0.8242700695991516, 'learning_rate': 7.560975609756099e-05, 'epoch': 0.07}
{'loss': 0.7578, 'grad_norm': 0.7502871155738831, 'learning_rate': 7.601626016260162e-05, 'epoch': 0.07}
{'loss': 0.8034, 'grad_norm': 0.9505245089530945, 'learning_rate': 7.642276422764229e-05, 'epoch': 0.07}
{'loss': 0.8383, 'grad_norm': 0.7800757884979248, 'learning_rate': 7.682926829268293e-05, 'epoch': 0.07}
{'loss': 0.9856, 'grad_norm': 0.9595729112625122, 'learning_rate': 7.723577235772358e-05, 'epoch': 0.07}
[1m[33mswanlab[0m[0m: Step 190 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 190 on key train/global_step already exists, ignored.
{'eval_loss': 1.0435426235198975, 'eval_runtime': 326.1941, 'eval_samples_per_second': 3.722, 'eval_steps_per_second': 3.722, 'epoch': 0.07}
{'loss': 1.0965, 'grad_norm': 0.9546048045158386, 'learning_rate': 7.764227642276422e-05, 'epoch': 0.07}
{'loss': 1.4218, 'grad_norm': 0.86136394739151, 'learning_rate': 7.804878048780489e-05, 'epoch': 0.07}
{'loss': 1.0795, 'grad_norm': 0.8369916677474976, 'learning_rate': 7.845528455284553e-05, 'epoch': 0.07}
{'loss': 0.8774, 'grad_norm': 0.8701663017272949, 'learning_rate': 7.886178861788618e-05, 'epoch': 0.07}
{'loss': 1.4439, 'grad_norm': 0.8177838325500488, 'learning_rate': 7.926829268292683e-05, 'epoch': 0.07}
{'loss': 0.6939, 'grad_norm': 0.9791259169578552, 'learning_rate': 7.967479674796748e-05, 'epoch': 0.07}
{'loss': 0.7174, 'grad_norm': 0.8090195655822754, 'learning_rate': 8.008130081300814e-05, 'epoch': 0.07}
{'loss': 1.0039, 'grad_norm': 0.974938154220581, 'learning_rate': 8.048780487804879e-05, 'epoch': 0.07}
{'loss': 1.098, 'grad_norm': 0.9081343412399292, 'learning_rate': 8.089430894308944e-05, 'epoch': 0.07}
{'loss': 0.9419, 'grad_norm': 0.9195163249969482, 'learning_rate': 8.130081300813008e-05, 'epoch': 0.07}
[1m[33mswanlab[0m[0m: Step 200 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 200 on key train/global_step already exists, ignored.
{'eval_loss': 1.0287655591964722, 'eval_runtime': 326.3062, 'eval_samples_per_second': 3.72, 'eval_steps_per_second': 3.72, 'epoch': 0.07}
{'loss': 0.9942, 'grad_norm': 0.799994945526123, 'learning_rate': 8.170731707317073e-05, 'epoch': 0.07}
{'loss': 0.9711, 'grad_norm': 0.8157487511634827, 'learning_rate': 8.211382113821139e-05, 'epoch': 0.07}
{'loss': 1.0726, 'grad_norm': 1.0199737548828125, 'learning_rate': 8.252032520325204e-05, 'epoch': 0.07}
{'loss': 0.4108, 'grad_norm': 1.018051266670227, 'learning_rate': 8.292682926829268e-05, 'epoch': 0.07}
{'loss': 1.0264, 'grad_norm': 0.7914999127388, 'learning_rate': 8.333333333333334e-05, 'epoch': 0.08}
{'loss': 1.2872, 'grad_norm': 0.9539749622344971, 'learning_rate': 8.373983739837398e-05, 'epoch': 0.08}
{'loss': 1.1894, 'grad_norm': 0.8810439705848694, 'learning_rate': 8.414634146341464e-05, 'epoch': 0.08}
{'loss': 1.0429, 'grad_norm': 0.927557110786438, 'learning_rate': 8.455284552845529e-05, 'epoch': 0.08}
{'loss': 1.4287, 'grad_norm': 0.9995114803314209, 'learning_rate': 8.495934959349594e-05, 'epoch': 0.08}
{'loss': 1.0268, 'grad_norm': 0.9358929991722107, 'learning_rate': 8.53658536585366e-05, 'epoch': 0.08}
[1m[33mswanlab[0m[0m: Step 210 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 210 on key train/global_step already exists, ignored.
{'eval_loss': 1.0142097473144531, 'eval_runtime': 326.217, 'eval_samples_per_second': 3.721, 'eval_steps_per_second': 3.721, 'epoch': 0.08}
{'loss': 1.0984, 'grad_norm': 0.9699081182479858, 'learning_rate': 8.577235772357723e-05, 'epoch': 0.08}
{'loss': 1.0904, 'grad_norm': 1.2407060861587524, 'learning_rate': 8.61788617886179e-05, 'epoch': 0.08}
{'loss': 1.0374, 'grad_norm': 0.9110095500946045, 'learning_rate': 8.658536585365854e-05, 'epoch': 0.08}
{'loss': 1.1573, 'grad_norm': 0.9530538320541382, 'learning_rate': 8.699186991869919e-05, 'epoch': 0.08}
{'loss': 1.3791, 'grad_norm': 0.9679622650146484, 'learning_rate': 8.739837398373984e-05, 'epoch': 0.08}
{'loss': 1.0592, 'grad_norm': 0.9601581692695618, 'learning_rate': 8.78048780487805e-05, 'epoch': 0.08}
{'loss': 0.8911, 'grad_norm': 1.0071333646774292, 'learning_rate': 8.821138211382113e-05, 'epoch': 0.08}
{'loss': 1.0545, 'grad_norm': 1.3248298168182373, 'learning_rate': 8.86178861788618e-05, 'epoch': 0.08}
{'loss': 1.1423, 'grad_norm': 0.9773963689804077, 'learning_rate': 8.902439024390244e-05, 'epoch': 0.08}
{'loss': 1.5965, 'grad_norm': 0.9770312905311584, 'learning_rate': 8.943089430894309e-05, 'epoch': 0.08}
[1m[33mswanlab[0m[0m: Step 220 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 220 on key train/global_step already exists, ignored.
{'eval_loss': 1.0004335641860962, 'eval_runtime': 326.375, 'eval_samples_per_second': 3.72, 'eval_steps_per_second': 3.72, 'epoch': 0.08}
{'loss': 1.1743, 'grad_norm': 0.8625432252883911, 'learning_rate': 8.983739837398374e-05, 'epoch': 0.08}
{'loss': 1.4241, 'grad_norm': 0.939493715763092, 'learning_rate': 9.02439024390244e-05, 'epoch': 0.08}
{'loss': 0.3218, 'grad_norm': 0.8956961631774902, 'learning_rate': 9.065040650406505e-05, 'epoch': 0.08}
{'loss': 1.3027, 'grad_norm': 1.0732840299606323, 'learning_rate': 9.105691056910569e-05, 'epoch': 0.08}
{'loss': 1.2285, 'grad_norm': 0.9051477313041687, 'learning_rate': 9.146341463414635e-05, 'epoch': 0.08}
{'loss': 1.2564, 'grad_norm': 0.9119907021522522, 'learning_rate': 9.1869918699187e-05, 'epoch': 0.08}
{'loss': 0.7164, 'grad_norm': 1.102318286895752, 'learning_rate': 9.227642276422765e-05, 'epoch': 0.08}
{'loss': 1.1222, 'grad_norm': 1.0719971656799316, 'learning_rate': 9.26829268292683e-05, 'epoch': 0.08}
{'loss': 1.5062, 'grad_norm': 1.0267590284347534, 'learning_rate': 9.308943089430895e-05, 'epoch': 0.08}
{'loss': 1.2783, 'grad_norm': 1.1460020542144775, 'learning_rate': 9.349593495934959e-05, 'epoch': 0.08}
[1m[33mswanlab[0m[0m: Step 230 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 230 on key train/global_step already exists, ignored.
{'eval_loss': 0.9867081046104431, 'eval_runtime': 326.2496, 'eval_samples_per_second': 3.721, 'eval_steps_per_second': 3.721, 'epoch': 0.08}
{'loss': 1.2625, 'grad_norm': 0.9326720833778381, 'learning_rate': 9.390243902439024e-05, 'epoch': 0.08}
{'loss': 1.0007, 'grad_norm': 0.8374457359313965, 'learning_rate': 9.43089430894309e-05, 'epoch': 0.08}
{'loss': 0.886, 'grad_norm': 0.9565045237541199, 'learning_rate': 9.471544715447155e-05, 'epoch': 0.09}
{'loss': 1.226, 'grad_norm': 1.0060887336730957, 'learning_rate': 9.51219512195122e-05, 'epoch': 0.09}
{'loss': 1.2974, 'grad_norm': 0.965057373046875, 'learning_rate': 9.552845528455285e-05, 'epoch': 0.09}
{'loss': 1.1341, 'grad_norm': 0.9149584174156189, 'learning_rate': 9.59349593495935e-05, 'epoch': 0.09}
{'loss': 1.1951, 'grad_norm': 0.9415076375007629, 'learning_rate': 9.634146341463415e-05, 'epoch': 0.09}
{'loss': 1.5786, 'grad_norm': 0.8042377829551697, 'learning_rate': 9.674796747967481e-05, 'epoch': 0.09}
{'loss': 0.915, 'grad_norm': 1.0071464776992798, 'learning_rate': 9.715447154471545e-05, 'epoch': 0.09}
{'loss': 0.9203, 'grad_norm': 1.0512903928756714, 'learning_rate': 9.75609756097561e-05, 'epoch': 0.09}
[1m[33mswanlab[0m[0m: Step 240 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 240 on key train/global_step already exists, ignored.
{'eval_loss': 0.9765913486480713, 'eval_runtime': 326.4291, 'eval_samples_per_second': 3.719, 'eval_steps_per_second': 3.719, 'epoch': 0.09}
{'loss': 0.8083, 'grad_norm': 0.9783133864402771, 'learning_rate': 9.796747967479674e-05, 'epoch': 0.09}
{'loss': 1.1461, 'grad_norm': 1.0788142681121826, 'learning_rate': 9.837398373983741e-05, 'epoch': 0.09}
{'loss': 0.5311, 'grad_norm': 0.8150444030761719, 'learning_rate': 9.878048780487805e-05, 'epoch': 0.09}
{'loss': 0.3778, 'grad_norm': 0.8614550232887268, 'learning_rate': 9.91869918699187e-05, 'epoch': 0.09}
{'loss': 1.2005, 'grad_norm': 1.261496663093567, 'learning_rate': 9.959349593495935e-05, 'epoch': 0.09}
{'loss': 0.6729, 'grad_norm': 0.9277626276016235, 'learning_rate': 0.0001, 'epoch': 0.09}
{'loss': 1.1888, 'grad_norm': 1.0038126707077026, 'learning_rate': 9.999999609013937e-05, 'epoch': 0.09}
{'loss': 1.0591, 'grad_norm': 0.9760969281196594, 'learning_rate': 9.999998436055809e-05, 'epoch': 0.09}
{'loss': 1.5231, 'grad_norm': 0.9807142019271851, 'learning_rate': 9.999996481125796e-05, 'epoch': 0.09}
{'loss': 0.6553, 'grad_norm': 0.7625811696052551, 'learning_rate': 9.999993744224208e-05, 'epoch': 0.09}
[1m[33mswanlab[0m[0m: Step 250 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 250 on key train/global_step already exists, ignored.
{'eval_loss': 0.9678136706352234, 'eval_runtime': 325.6397, 'eval_samples_per_second': 3.728, 'eval_steps_per_second': 3.728, 'epoch': 0.09}
{'loss': 1.1123, 'grad_norm': 0.8316835165023804, 'learning_rate': 9.999990225351471e-05, 'epoch': 0.09}
{'loss': 1.3295, 'grad_norm': 1.090338945388794, 'learning_rate': 9.999985924508137e-05, 'epoch': 0.09}
{'loss': 1.1545, 'grad_norm': 0.9618340134620667, 'learning_rate': 9.999980841694876e-05, 'epoch': 0.09}
{'loss': 0.5995, 'grad_norm': 1.2908791303634644, 'learning_rate': 9.999974976912485e-05, 'epoch': 0.09}
{'loss': 0.5124, 'grad_norm': 0.9467799663543701, 'learning_rate': 9.99996833016188e-05, 'epoch': 0.09}
{'loss': 1.0339, 'grad_norm': 1.189963459968567, 'learning_rate': 9.999960901444101e-05, 'epoch': 0.09}
{'loss': 0.6512, 'grad_norm': 0.8844425082206726, 'learning_rate': 9.999952690760311e-05, 'epoch': 0.09}
{'loss': 1.301, 'grad_norm': 1.1616827249526978, 'learning_rate': 9.99994369811179e-05, 'epoch': 0.09}
{'loss': 1.3988, 'grad_norm': 1.2586623430252075, 'learning_rate': 9.999933923499951e-05, 'epoch': 0.09}
{'loss': 1.1402, 'grad_norm': 0.9692146182060242, 'learning_rate': 9.999923366926318e-05, 'epoch': 0.1}
[1m[33mswanlab[0m[0m: Step 260 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 260 on key train/global_step already exists, ignored.
{'eval_loss': 0.9588657021522522, 'eval_runtime': 325.3078, 'eval_samples_per_second': 3.732, 'eval_steps_per_second': 3.732, 'epoch': 0.1}
{'loss': 1.407, 'grad_norm': 0.9378979206085205, 'learning_rate': 9.999912028392541e-05, 'epoch': 0.1}
{'loss': 0.7351, 'grad_norm': 0.9625810980796814, 'learning_rate': 9.999899907900399e-05, 'epoch': 0.1}
{'loss': 0.8858, 'grad_norm': 0.8823745250701904, 'learning_rate': 9.999887005451781e-05, 'epoch': 0.1}
{'loss': 0.5598, 'grad_norm': 0.8266088962554932, 'learning_rate': 9.999873321048709e-05, 'epoch': 0.1}
{'loss': 1.0751, 'grad_norm': 0.8318604230880737, 'learning_rate': 9.999858854693322e-05, 'epoch': 0.1}
{'loss': 0.7, 'grad_norm': 1.0188854932785034, 'learning_rate': 9.999843606387881e-05, 'epoch': 0.1}
{'loss': 1.3393, 'grad_norm': 0.9574480056762695, 'learning_rate': 9.999827576134774e-05, 'epoch': 0.1}
{'loss': 1.0392, 'grad_norm': 0.9648979902267456, 'learning_rate': 9.999810763936506e-05, 'epoch': 0.1}
{'loss': 0.8513, 'grad_norm': 1.0630820989608765, 'learning_rate': 9.999793169795706e-05, 'epoch': 0.1}
{'loss': 1.0787, 'grad_norm': 1.019271969795227, 'learning_rate': 9.999774793715127e-05, 'epoch': 0.1}
[1m[33mswanlab[0m[0m: Step 270 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 270 on key train/global_step already exists, ignored.
{'eval_loss': 0.9519684314727783, 'eval_runtime': 325.2146, 'eval_samples_per_second': 3.733, 'eval_steps_per_second': 3.733, 'epoch': 0.1}
{'loss': 0.9236, 'grad_norm': 1.244348168373108, 'learning_rate': 9.999755635697641e-05, 'epoch': 0.1}
{'loss': 0.585, 'grad_norm': 0.8256751298904419, 'learning_rate': 9.999735695746243e-05, 'epoch': 0.1}
{'loss': 1.2308, 'grad_norm': 0.9725598692893982, 'learning_rate': 9.999714973864058e-05, 'epoch': 0.1}
{'loss': 1.2803, 'grad_norm': 1.0194612741470337, 'learning_rate': 9.999693470054321e-05, 'epoch': 0.1}
{'loss': 0.7972, 'grad_norm': 0.9247444868087769, 'learning_rate': 9.999671184320397e-05, 'epoch': 0.1}
{'loss': 0.9197, 'grad_norm': 0.9991945624351501, 'learning_rate': 9.99964811666577e-05, 'epoch': 0.1}
{'loss': 1.0605, 'grad_norm': 0.920225977897644, 'learning_rate': 9.99962426709405e-05, 'epoch': 0.1}
{'loss': 0.5206, 'grad_norm': 1.0983390808105469, 'learning_rate': 9.999599635608964e-05, 'epoch': 0.1}
{'loss': 0.8541, 'grad_norm': 1.3666099309921265, 'learning_rate': 9.999574222214367e-05, 'epoch': 0.1}
{'loss': 1.1514, 'grad_norm': 1.1414284706115723, 'learning_rate': 9.999548026914232e-05, 'epoch': 0.1}
[1m[33mswanlab[0m[0m: Step 280 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 280 on key train/global_step already exists, ignored.
{'eval_loss': 0.9441777467727661, 'eval_runtime': 325.2598, 'eval_samples_per_second': 3.732, 'eval_steps_per_second': 3.732, 'epoch': 0.1}
{'loss': 1.1395, 'grad_norm': 0.9987568855285645, 'learning_rate': 9.999521049712656e-05, 'epoch': 0.1}
{'loss': 1.1423, 'grad_norm': 1.0681555271148682, 'learning_rate': 9.999493290613859e-05, 'epoch': 0.1}
{'loss': 0.7758, 'grad_norm': 1.0330630540847778, 'learning_rate': 9.99946474962218e-05, 'epoch': 0.1}
{'loss': 0.9989, 'grad_norm': 1.0309786796569824, 'learning_rate': 9.999435426742085e-05, 'epoch': 0.1}
{'loss': 0.6259, 'grad_norm': 1.076762080192566, 'learning_rate': 9.999405321978159e-05, 'epoch': 0.1}
{'loss': 0.7263, 'grad_norm': 1.3180322647094727, 'learning_rate': 9.999374435335112e-05, 'epoch': 0.1}
{'loss': 0.598, 'grad_norm': 0.9275753498077393, 'learning_rate': 9.99934276681777e-05, 'epoch': 0.11}
{'loss': 0.5035, 'grad_norm': 0.8699234127998352, 'learning_rate': 9.999310316431092e-05, 'epoch': 0.11}
{'loss': 0.9862, 'grad_norm': 1.049354910850525, 'learning_rate': 9.999277084180147e-05, 'epoch': 0.11}
{'loss': 0.8874, 'grad_norm': 1.1622639894485474, 'learning_rate': 9.999243070070137e-05, 'epoch': 0.11}
[1m[33mswanlab[0m[0m: Step 290 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 290 on key train/global_step already exists, ignored.
{'eval_loss': 0.9381031394004822, 'eval_runtime': 325.3056, 'eval_samples_per_second': 3.732, 'eval_steps_per_second': 3.732, 'epoch': 0.11}
{'loss': 1.2315, 'grad_norm': 0.9852805137634277, 'learning_rate': 9.999208274106378e-05, 'epoch': 0.11}
{'loss': 0.7952, 'grad_norm': 0.9185624718666077, 'learning_rate': 9.999172696294314e-05, 'epoch': 0.11}
{'loss': 0.841, 'grad_norm': 1.0557913780212402, 'learning_rate': 9.999136336639509e-05, 'epoch': 0.11}
{'loss': 1.2972, 'grad_norm': 1.0769879817962646, 'learning_rate': 9.99909919514765e-05, 'epoch': 0.11}
{'loss': 0.9179, 'grad_norm': 1.0326718091964722, 'learning_rate': 9.999061271824544e-05, 'epoch': 0.11}
{'loss': 0.9148, 'grad_norm': 0.9868219494819641, 'learning_rate': 9.999022566676123e-05, 'epoch': 0.11}
{'loss': 0.5898, 'grad_norm': 0.8961410522460938, 'learning_rate': 9.998983079708442e-05, 'epoch': 0.11}
{'loss': 1.4796, 'grad_norm': 1.020047664642334, 'learning_rate': 9.998942810927673e-05, 'epoch': 0.11}
{'loss': 1.3382, 'grad_norm': 0.906444787979126, 'learning_rate': 9.998901760340115e-05, 'epoch': 0.11}
{'loss': 1.1606, 'grad_norm': 1.0148162841796875, 'learning_rate': 9.99885992795219e-05, 'epoch': 0.11}
[1m[33mswanlab[0m[0m: Step 300 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 300 on key train/global_step already exists, ignored.
{'eval_loss': 0.9282341003417969, 'eval_runtime': 327.5054, 'eval_samples_per_second': 3.707, 'eval_steps_per_second': 3.707, 'epoch': 0.11}
{'loss': 0.9052, 'grad_norm': 1.0428061485290527, 'learning_rate': 9.998817313770439e-05, 'epoch': 0.11}
{'loss': 1.1539, 'grad_norm': 0.9352127313613892, 'learning_rate': 9.998773917801525e-05, 'epoch': 0.11}
{'loss': 0.6392, 'grad_norm': 1.0218499898910522, 'learning_rate': 9.998729740052237e-05, 'epoch': 0.11}
{'loss': 0.4947, 'grad_norm': 0.7467933893203735, 'learning_rate': 9.998684780529484e-05, 'epoch': 0.11}
{'loss': 0.9528, 'grad_norm': 0.9980430006980896, 'learning_rate': 9.998639039240299e-05, 'epoch': 0.11}
{'loss': 0.3521, 'grad_norm': 0.8421357870101929, 'learning_rate': 9.998592516191832e-05, 'epoch': 0.11}
{'loss': 0.8174, 'grad_norm': 1.079756259918213, 'learning_rate': 9.99854521139136e-05, 'epoch': 0.11}
{'loss': 0.7362, 'grad_norm': 0.9219433665275574, 'learning_rate': 9.998497124846282e-05, 'epoch': 0.11}
{'loss': 0.7786, 'grad_norm': 1.1924407482147217, 'learning_rate': 9.998448256564118e-05, 'epoch': 0.11}
{'loss': 1.2103, 'grad_norm': 1.3578217029571533, 'learning_rate': 9.998398606552513e-05, 'epoch': 0.11}
[1m[33mswanlab[0m[0m: Step 310 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 310 on key train/global_step already exists, ignored.
{'eval_loss': 0.9244602918624878, 'eval_runtime': 326.9799, 'eval_samples_per_second': 3.713, 'eval_steps_per_second': 3.713, 'epoch': 0.11}
{'loss': 0.9806, 'grad_norm': 1.0997436046600342, 'learning_rate': 9.998348174819229e-05, 'epoch': 0.11}
{'loss': 0.7293, 'grad_norm': 1.0640251636505127, 'learning_rate': 9.998296961372153e-05, 'epoch': 0.11}
{'loss': 1.1729, 'grad_norm': 1.1742395162582397, 'learning_rate': 9.998244966219298e-05, 'epoch': 0.11}
{'loss': 0.9521, 'grad_norm': 1.198685884475708, 'learning_rate': 9.998192189368794e-05, 'epoch': 0.12}
{'loss': 0.7657, 'grad_norm': 0.9107562899589539, 'learning_rate': 9.998138630828892e-05, 'epoch': 0.12}
{'loss': 0.9737, 'grad_norm': 0.7683629989624023, 'learning_rate': 9.998084290607972e-05, 'epoch': 0.12}
{'loss': 1.2287, 'grad_norm': 1.0940275192260742, 'learning_rate': 9.99802916871453e-05, 'epoch': 0.12}
{'loss': 1.0949, 'grad_norm': 0.9643294811248779, 'learning_rate': 9.997973265157192e-05, 'epoch': 0.12}
{'loss': 1.294, 'grad_norm': 1.0150808095932007, 'learning_rate': 9.997916579944695e-05, 'epoch': 0.12}
{'loss': 1.2284, 'grad_norm': 1.1065548658370972, 'learning_rate': 9.997859113085906e-05, 'epoch': 0.12}
[1m[33mswanlab[0m[0m: Step 320 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 320 on key train/global_step already exists, ignored.
{'eval_loss': 0.9165626168251038, 'eval_runtime': 326.9318, 'eval_samples_per_second': 3.713, 'eval_steps_per_second': 3.713, 'epoch': 0.12}
{'loss': 0.6237, 'grad_norm': 0.9520495533943176, 'learning_rate': 9.997800864589812e-05, 'epoch': 0.12}
{'loss': 0.7892, 'grad_norm': 0.935294508934021, 'learning_rate': 9.997741834465524e-05, 'epoch': 0.12}
{'loss': 0.8712, 'grad_norm': 0.9223976135253906, 'learning_rate': 9.997682022722275e-05, 'epoch': 0.12}
{'loss': 0.8371, 'grad_norm': 0.9312877058982849, 'learning_rate': 9.997621429369416e-05, 'epoch': 0.12}
{'loss': 1.1179, 'grad_norm': 1.1610571146011353, 'learning_rate': 9.997560054416426e-05, 'epoch': 0.12}
{'loss': 1.1057, 'grad_norm': 1.1732457876205444, 'learning_rate': 9.997497897872904e-05, 'epoch': 0.12}
{'loss': 0.7018, 'grad_norm': 0.6929117441177368, 'learning_rate': 9.997434959748569e-05, 'epoch': 0.12}
{'loss': 0.9698, 'grad_norm': 1.0455793142318726, 'learning_rate': 9.997371240053265e-05, 'epoch': 0.12}
{'loss': 0.7431, 'grad_norm': 0.9631350636482239, 'learning_rate': 9.997306738796957e-05, 'epoch': 0.12}
{'loss': 0.9372, 'grad_norm': 0.8899025917053223, 'learning_rate': 9.997241455989734e-05, 'epoch': 0.12}
[1m[33mswanlab[0m[0m: Step 330 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 330 on key train/global_step already exists, ignored.
{'eval_loss': 0.9118994474411011, 'eval_runtime': 326.619, 'eval_samples_per_second': 3.717, 'eval_steps_per_second': 3.717, 'epoch': 0.12}
{'loss': 0.9547, 'grad_norm': 0.9096298813819885, 'learning_rate': 9.997175391641805e-05, 'epoch': 0.12}
{'loss': 0.7453, 'grad_norm': 0.8569766283035278, 'learning_rate': 9.997108545763501e-05, 'epoch': 0.12}
{'loss': 0.6156, 'grad_norm': 0.7623046040534973, 'learning_rate': 9.997040918365279e-05, 'epoch': 0.12}
{'loss': 0.726, 'grad_norm': 0.9908808469772339, 'learning_rate': 9.996972509457712e-05, 'epoch': 0.12}
{'loss': 0.9045, 'grad_norm': 1.0667710304260254, 'learning_rate': 9.996903319051502e-05, 'epoch': 0.12}
{'loss': 0.9484, 'grad_norm': 1.4858301877975464, 'learning_rate': 9.996833347157468e-05, 'epoch': 0.12}
{'loss': 1.261, 'grad_norm': 1.1142442226409912, 'learning_rate': 9.996762593786555e-05, 'epoch': 0.12}
{'loss': 0.81, 'grad_norm': 0.8562672138214111, 'learning_rate': 9.996691058949827e-05, 'epoch': 0.12}
{'loss': 0.9332, 'grad_norm': 1.0218836069107056, 'learning_rate': 9.996618742658471e-05, 'epoch': 0.12}
{'loss': 1.3817, 'grad_norm': 1.0430124998092651, 'learning_rate': 9.996545644923798e-05, 'epoch': 0.12}
[1m[33mswanlab[0m[0m: Step 340 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 340 on key train/global_step already exists, ignored.
{'eval_loss': 0.9044989943504333, 'eval_runtime': 326.6943, 'eval_samples_per_second': 3.716, 'eval_steps_per_second': 3.716, 'epoch': 0.12}
{'loss': 0.7842, 'grad_norm': 1.158512830734253, 'learning_rate': 9.996471765757241e-05, 'epoch': 0.12}
{'loss': 1.393, 'grad_norm': 1.0737135410308838, 'learning_rate': 9.996397105170353e-05, 'epoch': 0.13}
{'loss': 0.7327, 'grad_norm': 0.8984323740005493, 'learning_rate': 9.996321663174811e-05, 'epoch': 0.13}
{'loss': 0.728, 'grad_norm': 1.1021811962127686, 'learning_rate': 9.996245439782413e-05, 'epoch': 0.13}
{'loss': 1.1889, 'grad_norm': 1.0985757112503052, 'learning_rate': 9.99616843500508e-05, 'epoch': 0.13}
{'loss': 1.1921, 'grad_norm': 1.0747137069702148, 'learning_rate': 9.996090648854856e-05, 'epoch': 0.13}
{'loss': 0.9078, 'grad_norm': 1.0248847007751465, 'learning_rate': 9.996012081343904e-05, 'epoch': 0.13}
{'loss': 0.8922, 'grad_norm': 1.0538058280944824, 'learning_rate': 9.995932732484516e-05, 'epoch': 0.13}
{'loss': 0.9803, 'grad_norm': 0.9366456866264343, 'learning_rate': 9.995852602289097e-05, 'epoch': 0.13}
{'loss': 0.858, 'grad_norm': 0.8727009296417236, 'learning_rate': 9.995771690770184e-05, 'epoch': 0.13}
[1m[33mswanlab[0m[0m: Step 350 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 350 on key train/global_step already exists, ignored.
{'eval_loss': 0.9003121852874756, 'eval_runtime': 327.6689, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 3.705, 'epoch': 0.13}
{'loss': 0.9925, 'grad_norm': 1.1546971797943115, 'learning_rate': 9.995689997940425e-05, 'epoch': 0.13}
{'loss': 1.2278, 'grad_norm': 1.2265123128890991, 'learning_rate': 9.9956075238126e-05, 'epoch': 0.13}
{'loss': 0.8254, 'grad_norm': 1.1120303869247437, 'learning_rate': 9.995524268399607e-05, 'epoch': 0.13}
{'loss': 0.6803, 'grad_norm': 0.970176637172699, 'learning_rate': 9.995440231714469e-05, 'epoch': 0.13}
{'loss': 1.2819, 'grad_norm': 1.0955147743225098, 'learning_rate': 9.995355413770322e-05, 'epoch': 0.13}
{'loss': 0.9392, 'grad_norm': 1.0591999292373657, 'learning_rate': 9.995269814580439e-05, 'epoch': 0.13}
{'loss': 0.8478, 'grad_norm': 1.0823293924331665, 'learning_rate': 9.995183434158202e-05, 'epoch': 0.13}
{'loss': 1.1368, 'grad_norm': 1.0338075160980225, 'learning_rate': 9.995096272517122e-05, 'epoch': 0.13}
{'loss': 1.3568, 'grad_norm': 1.3271547555923462, 'learning_rate': 9.99500832967083e-05, 'epoch': 0.13}
{'loss': 1.0559, 'grad_norm': 1.0851223468780518, 'learning_rate': 9.994919605633081e-05, 'epoch': 0.13}
[1m[33mswanlab[0m[0m: Step 360 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 360 on key train/global_step already exists, ignored.
{'eval_loss': 0.8969533443450928, 'eval_runtime': 327.8208, 'eval_samples_per_second': 3.703, 'eval_steps_per_second': 3.703, 'epoch': 0.13}
{'loss': 0.5014, 'grad_norm': 1.1121644973754883, 'learning_rate': 9.994830100417753e-05, 'epoch': 0.13}
{'loss': 1.139, 'grad_norm': 1.257051944732666, 'learning_rate': 9.99473981403884e-05, 'epoch': 0.13}
{'loss': 1.12, 'grad_norm': 1.1944279670715332, 'learning_rate': 9.994648746510463e-05, 'epoch': 0.13}
{'loss': 0.9484, 'grad_norm': 1.0565859079360962, 'learning_rate': 9.994556897846865e-05, 'epoch': 0.13}
{'loss': 0.6576, 'grad_norm': 0.8487881422042847, 'learning_rate': 9.994464268062412e-05, 'epoch': 0.13}
{'loss': 1.1784, 'grad_norm': 1.0621976852416992, 'learning_rate': 9.994370857171588e-05, 'epoch': 0.13}
{'loss': 0.8847, 'grad_norm': 1.1692007780075073, 'learning_rate': 9.994276665189006e-05, 'epoch': 0.13}
{'loss': 0.7769, 'grad_norm': 0.9568784236907959, 'learning_rate': 9.994181692129394e-05, 'epoch': 0.13}
{'loss': 0.9275, 'grad_norm': 1.0426416397094727, 'learning_rate': 9.994085938007606e-05, 'epoch': 0.14}
{'loss': 1.3411, 'grad_norm': 1.1558138132095337, 'learning_rate': 9.993989402838617e-05, 'epoch': 0.14}
[1m[33mswanlab[0m[0m: Step 370 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 370 on key train/global_step already exists, ignored.
{'eval_loss': 0.8923903107643127, 'eval_runtime': 327.9021, 'eval_samples_per_second': 3.702, 'eval_steps_per_second': 3.702, 'epoch': 0.14}
{'loss': 0.9058, 'grad_norm': 0.9626848697662354, 'learning_rate': 9.993892086637524e-05, 'epoch': 0.14}
{'loss': 0.7114, 'grad_norm': 1.0112080574035645, 'learning_rate': 9.993793989419549e-05, 'epoch': 0.14}
{'loss': 1.0677, 'grad_norm': 1.008086085319519, 'learning_rate': 9.993695111200032e-05, 'epoch': 0.14}
{'loss': 0.9847, 'grad_norm': 1.0170484781265259, 'learning_rate': 9.993595451994439e-05, 'epoch': 0.14}
{'loss': 0.8521, 'grad_norm': 1.0283879041671753, 'learning_rate': 9.993495011818352e-05, 'epoch': 0.14}
{'loss': 0.951, 'grad_norm': 1.1425178050994873, 'learning_rate': 9.993393790687484e-05, 'epoch': 0.14}
{'loss': 1.0197, 'grad_norm': 1.2385247945785522, 'learning_rate': 9.993291788617663e-05, 'epoch': 0.14}
{'loss': 1.0866, 'grad_norm': 1.2062256336212158, 'learning_rate': 9.99318900562484e-05, 'epoch': 0.14}
{'loss': 0.7098, 'grad_norm': 0.9161548018455505, 'learning_rate': 9.993085441725095e-05, 'epoch': 0.14}
{'loss': 0.5382, 'grad_norm': 1.0275720357894897, 'learning_rate': 9.99298109693462e-05, 'epoch': 0.14}
[1m[33mswanlab[0m[0m: Step 380 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 380 on key train/global_step already exists, ignored.
{'eval_loss': 0.889988124370575, 'eval_runtime': 327.6569, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 3.705, 'epoch': 0.14}
{'loss': 1.0468, 'grad_norm': 1.248546838760376, 'learning_rate': 9.992875971269736e-05, 'epoch': 0.14}
{'loss': 0.8407, 'grad_norm': 1.4772382974624634, 'learning_rate': 9.992770064746882e-05, 'epoch': 0.14}
{'loss': 1.472, 'grad_norm': 1.1852599382400513, 'learning_rate': 9.992663377382623e-05, 'epoch': 0.14}
{'loss': 1.1356, 'grad_norm': 1.2033355236053467, 'learning_rate': 9.992555909193643e-05, 'epoch': 0.14}
{'loss': 0.7733, 'grad_norm': 1.1887590885162354, 'learning_rate': 9.992447660196753e-05, 'epoch': 0.14}
{'loss': 0.8272, 'grad_norm': 1.365098476409912, 'learning_rate': 9.992338630408877e-05, 'epoch': 0.14}
{'loss': 0.7711, 'grad_norm': 1.0497910976409912, 'learning_rate': 9.992228819847071e-05, 'epoch': 0.14}
{'loss': 0.77, 'grad_norm': 1.1315890550613403, 'learning_rate': 9.992118228528509e-05, 'epoch': 0.14}
{'loss': 0.7035, 'grad_norm': 0.9317522048950195, 'learning_rate': 9.992006856470484e-05, 'epoch': 0.14}
{'loss': 0.8994, 'grad_norm': 0.9163861274719238, 'learning_rate': 9.991894703690414e-05, 'epoch': 0.14}
[1m[33mswanlab[0m[0m: Step 390 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 390 on key train/global_step already exists, ignored.
{'eval_loss': 0.8876945972442627, 'eval_runtime': 327.6532, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 3.705, 'epoch': 0.14}
{'loss': 0.8643, 'grad_norm': 1.0113011598587036, 'learning_rate': 9.991781770205841e-05, 'epoch': 0.14}
{'loss': 0.5059, 'grad_norm': 1.2991456985473633, 'learning_rate': 9.991668056034427e-05, 'epoch': 0.14}
{'loss': 0.956, 'grad_norm': 1.1037832498550415, 'learning_rate': 9.991553561193953e-05, 'epoch': 0.14}
{'loss': 0.6762, 'grad_norm': 1.3028960227966309, 'learning_rate': 9.991438285702331e-05, 'epoch': 0.14}
{'loss': 1.0079, 'grad_norm': 1.4279154539108276, 'learning_rate': 9.991322229577585e-05, 'epoch': 0.14}
{'loss': 0.589, 'grad_norm': 0.9074159264564514, 'learning_rate': 9.991205392837868e-05, 'epoch': 0.15}
{'loss': 0.6162, 'grad_norm': 1.0587316751480103, 'learning_rate': 9.99108777550145e-05, 'epoch': 0.15}
{'loss': 1.0554, 'grad_norm': 1.4230082035064697, 'learning_rate': 9.99096937758673e-05, 'epoch': 0.15}
{'loss': 0.8521, 'grad_norm': 1.1686733961105347, 'learning_rate': 9.99085019911222e-05, 'epoch': 0.15}
{'loss': 0.5415, 'grad_norm': 0.8225346803665161, 'learning_rate': 9.990730240096561e-05, 'epoch': 0.15}
[1m[33mswanlab[0m[0m: Step 400 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 400 on key train/global_step already exists, ignored.
{'eval_loss': 0.881127119064331, 'eval_runtime': 327.59, 'eval_samples_per_second': 3.706, 'eval_steps_per_second': 3.706, 'epoch': 0.15}
{'loss': 1.0061, 'grad_norm': 0.9785767793655396, 'learning_rate': 9.990609500558515e-05, 'epoch': 0.15}
{'loss': 0.837, 'grad_norm': 0.9121781587600708, 'learning_rate': 9.990487980516962e-05, 'epoch': 0.15}
{'loss': 1.0882, 'grad_norm': 1.16127610206604, 'learning_rate': 9.99036567999091e-05, 'epoch': 0.15}
{'loss': 1.3082, 'grad_norm': 1.5153783559799194, 'learning_rate': 9.990242598999486e-05, 'epoch': 0.15}
{'loss': 0.8811, 'grad_norm': 1.0372884273529053, 'learning_rate': 9.990118737561938e-05, 'epoch': 0.15}
{'loss': 0.8998, 'grad_norm': 0.9651708006858826, 'learning_rate': 9.989994095697636e-05, 'epoch': 0.15}
{'loss': 1.1211, 'grad_norm': 1.115947961807251, 'learning_rate': 9.989868673426075e-05, 'epoch': 0.15}
{'loss': 0.7681, 'grad_norm': 1.122528314590454, 'learning_rate': 9.98974247076687e-05, 'epoch': 0.15}
{'loss': 1.1305, 'grad_norm': 1.1726967096328735, 'learning_rate': 9.989615487739759e-05, 'epoch': 0.15}
{'loss': 0.8303, 'grad_norm': 1.1397143602371216, 'learning_rate': 9.989487724364601e-05, 'epoch': 0.15}
[1m[33mswanlab[0m[0m: Step 410 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 410 on key train/global_step already exists, ignored.
{'eval_loss': 0.8766501545906067, 'eval_runtime': 327.874, 'eval_samples_per_second': 3.703, 'eval_steps_per_second': 3.703, 'epoch': 0.15}
{'loss': 1.0857, 'grad_norm': 1.0417745113372803, 'learning_rate': 9.989359180661378e-05, 'epoch': 0.15}
{'loss': 1.0254, 'grad_norm': 1.067773699760437, 'learning_rate': 9.989229856650191e-05, 'epoch': 0.15}
{'loss': 0.8157, 'grad_norm': 0.976482093334198, 'learning_rate': 9.989099752351269e-05, 'epoch': 0.15}
{'loss': 1.5125, 'grad_norm': 1.2339369058609009, 'learning_rate': 9.988968867784958e-05, 'epoch': 0.15}
{'loss': 1.1391, 'grad_norm': 1.244255542755127, 'learning_rate': 9.988837202971726e-05, 'epoch': 0.15}
{'loss': 1.1063, 'grad_norm': 1.0673149824142456, 'learning_rate': 9.988704757932168e-05, 'epoch': 0.15}
{'loss': 1.034, 'grad_norm': 1.1457414627075195, 'learning_rate': 9.988571532686995e-05, 'epoch': 0.15}
{'loss': 1.0877, 'grad_norm': 0.901581883430481, 'learning_rate': 9.988437527257045e-05, 'epoch': 0.15}
{'loss': 1.2469, 'grad_norm': 1.1595642566680908, 'learning_rate': 9.988302741663272e-05, 'epoch': 0.15}
{'loss': 0.8498, 'grad_norm': 0.9295127987861633, 'learning_rate': 9.98816717592676e-05, 'epoch': 0.15}
[1m[33mswanlab[0m[0m: Step 420 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 420 on key train/global_step already exists, ignored.
{'eval_loss': 0.8719693422317505, 'eval_runtime': 327.6427, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 3.705, 'epoch': 0.15}
{'loss': 0.8145, 'grad_norm': 1.079867959022522, 'learning_rate': 9.988030830068709e-05, 'epoch': 0.15}
{'loss': 0.7041, 'grad_norm': 1.2736891508102417, 'learning_rate': 9.987893704110441e-05, 'epoch': 0.15}
{'loss': 0.5195, 'grad_norm': 0.8818795084953308, 'learning_rate': 9.987755798073404e-05, 'epoch': 0.15}
{'loss': 0.8265, 'grad_norm': 1.188575267791748, 'learning_rate': 9.987617111979167e-05, 'epoch': 0.16}
{'loss': 0.78, 'grad_norm': 0.9216428399085999, 'learning_rate': 9.987477645849415e-05, 'epoch': 0.16}
{'loss': 1.1789, 'grad_norm': 1.1995275020599365, 'learning_rate': 9.987337399705962e-05, 'epoch': 0.16}
{'loss': 0.8771, 'grad_norm': 1.8373411893844604, 'learning_rate': 9.987196373570744e-05, 'epoch': 0.16}
{'loss': 0.9624, 'grad_norm': 1.1435261964797974, 'learning_rate': 9.987054567465815e-05, 'epoch': 0.16}
{'loss': 1.0131, 'grad_norm': 1.062085747718811, 'learning_rate': 9.986911981413351e-05, 'epoch': 0.16}
{'loss': 0.7636, 'grad_norm': 0.9780181050300598, 'learning_rate': 9.986768615435654e-05, 'epoch': 0.16}
[1m[33mswanlab[0m[0m: Step 430 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 430 on key train/global_step already exists, ignored.
{'eval_loss': 0.8682220578193665, 'eval_runtime': 327.6755, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 3.705, 'epoch': 0.16}
{'loss': 0.5906, 'grad_norm': 1.0371886491775513, 'learning_rate': 9.986624469555146e-05, 'epoch': 0.16}
{'loss': 1.2759, 'grad_norm': 1.4337824583053589, 'learning_rate': 9.986479543794367e-05, 'epoch': 0.16}
{'loss': 0.4386, 'grad_norm': 0.9549670815467834, 'learning_rate': 9.986333838175987e-05, 'epoch': 0.16}
{'loss': 0.9073, 'grad_norm': 1.1188794374465942, 'learning_rate': 9.986187352722791e-05, 'epoch': 0.16}
{'loss': 1.1357, 'grad_norm': 1.3983302116394043, 'learning_rate': 9.986040087457688e-05, 'epoch': 0.16}
{'loss': 0.5628, 'grad_norm': 1.0847103595733643, 'learning_rate': 9.985892042403712e-05, 'epoch': 0.16}
{'loss': 0.8207, 'grad_norm': 1.1598190069198608, 'learning_rate': 9.985743217584016e-05, 'epoch': 0.16}
{'loss': 0.8984, 'grad_norm': 0.8508354425430298, 'learning_rate': 9.985593613021872e-05, 'epoch': 0.16}
{'loss': 0.977, 'grad_norm': 1.0188215970993042, 'learning_rate': 9.985443228740681e-05, 'epoch': 0.16}
{'loss': 0.5136, 'grad_norm': 0.8284507393836975, 'learning_rate': 9.98529206476396e-05, 'epoch': 0.16}
[1m[33mswanlab[0m[0m: Step 440 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 440 on key train/global_step already exists, ignored.
{'eval_loss': 0.8646613359451294, 'eval_runtime': 327.6976, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 3.705, 'epoch': 0.16}
{'loss': 0.8695, 'grad_norm': 1.0171877145767212, 'learning_rate': 9.985140121115352e-05, 'epoch': 0.16}
{'loss': 1.2097, 'grad_norm': 1.1601454019546509, 'learning_rate': 9.984987397818621e-05, 'epoch': 0.16}
{'loss': 0.7684, 'grad_norm': 1.1360671520233154, 'learning_rate': 9.984833894897647e-05, 'epoch': 0.16}
{'loss': 0.6738, 'grad_norm': 0.8518962264060974, 'learning_rate': 9.984679612376443e-05, 'epoch': 0.16}
{'loss': 0.6646, 'grad_norm': 1.0060768127441406, 'learning_rate': 9.984524550279133e-05, 'epoch': 0.16}
{'loss': 0.5852, 'grad_norm': 0.8444593548774719, 'learning_rate': 9.984368708629972e-05, 'epoch': 0.16}
{'loss': 1.0368, 'grad_norm': 1.1035454273223877, 'learning_rate': 9.984212087453331e-05, 'epoch': 0.16}
{'loss': 0.8586, 'grad_norm': 0.8452848792076111, 'learning_rate': 9.984054686773703e-05, 'epoch': 0.16}
{'loss': 0.1133, 'grad_norm': 0.7748528718948364, 'learning_rate': 9.983896506615706e-05, 'epoch': 0.16}
{'loss': 0.764, 'grad_norm': 0.9527171850204468, 'learning_rate': 9.98373754700408e-05, 'epoch': 0.16}
[1m[33mswanlab[0m[0m: Step 450 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 450 on key train/global_step already exists, ignored.
{'eval_loss': 0.8620173931121826, 'eval_runtime': 327.7226, 'eval_samples_per_second': 3.704, 'eval_steps_per_second': 3.704, 'epoch': 0.16}
{'loss': 0.6171, 'grad_norm': 0.8623696565628052, 'learning_rate': 9.983577807963685e-05, 'epoch': 0.17}
{'loss': 0.7506, 'grad_norm': 0.8432179093360901, 'learning_rate': 9.983417289519501e-05, 'epoch': 0.17}
{'loss': 0.569, 'grad_norm': 0.8420207500457764, 'learning_rate': 9.983255991696632e-05, 'epoch': 0.17}
{'loss': 0.7279, 'grad_norm': 0.8683856725692749, 'learning_rate': 9.983093914520309e-05, 'epoch': 0.17}
{'loss': 0.5614, 'grad_norm': 0.9396867156028748, 'learning_rate': 9.982931058015874e-05, 'epoch': 0.17}
{'loss': 1.1806, 'grad_norm': 1.5803786516189575, 'learning_rate': 9.982767422208801e-05, 'epoch': 0.17}
{'loss': 0.9929, 'grad_norm': 1.0630779266357422, 'learning_rate': 9.982603007124679e-05, 'epoch': 0.17}
{'loss': 1.1582, 'grad_norm': 1.18901789188385, 'learning_rate': 9.982437812789222e-05, 'epoch': 0.17}
{'loss': 0.6314, 'grad_norm': 0.9520888924598694, 'learning_rate': 9.982271839228268e-05, 'epoch': 0.17}
{'loss': 0.6636, 'grad_norm': 1.0704718828201294, 'learning_rate': 9.982105086467772e-05, 'epoch': 0.17}
[1m[33mswanlab[0m[0m: Step 460 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 460 on key train/global_step already exists, ignored.
{'eval_loss': 0.8600401282310486, 'eval_runtime': 327.3337, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.17}
{'loss': 1.0832, 'grad_norm': 0.9803924560546875, 'learning_rate': 9.981937554533814e-05, 'epoch': 0.17}
{'loss': 0.8377, 'grad_norm': 1.027549386024475, 'learning_rate': 9.981769243452595e-05, 'epoch': 0.17}
{'loss': 1.3847, 'grad_norm': 1.280500054359436, 'learning_rate': 9.981600153250438e-05, 'epoch': 0.17}
{'loss': 1.0744, 'grad_norm': 1.1576601266860962, 'learning_rate': 9.981430283953786e-05, 'epoch': 0.17}
{'loss': 1.0767, 'grad_norm': 1.2650495767593384, 'learning_rate': 9.981259635589209e-05, 'epoch': 0.17}
{'loss': 0.998, 'grad_norm': 0.9910540580749512, 'learning_rate': 9.981088208183392e-05, 'epoch': 0.17}
{'loss': 1.1725, 'grad_norm': 1.0992141962051392, 'learning_rate': 9.980916001763148e-05, 'epoch': 0.17}
{'loss': 0.9399, 'grad_norm': 1.085988163948059, 'learning_rate': 9.980743016355407e-05, 'epoch': 0.17}
{'loss': 0.8349, 'grad_norm': 1.047810435295105, 'learning_rate': 9.980569251987226e-05, 'epoch': 0.17}
{'loss': 0.8124, 'grad_norm': 0.9491277933120728, 'learning_rate': 9.980394708685776e-05, 'epoch': 0.17}
[1m[33mswanlab[0m[0m: Step 470 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 470 on key train/global_step already exists, ignored.
{'eval_loss': 0.8559582233428955, 'eval_runtime': 327.4116, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.17}
{'loss': 1.1822, 'grad_norm': 1.1351910829544067, 'learning_rate': 9.98021938647836e-05, 'epoch': 0.17}
{'loss': 1.1977, 'grad_norm': 1.2274141311645508, 'learning_rate': 9.980043285392393e-05, 'epoch': 0.17}
{'loss': 0.8378, 'grad_norm': 1.2245728969573975, 'learning_rate': 9.979866405455418e-05, 'epoch': 0.17}
{'loss': 0.9504, 'grad_norm': 1.374566674232483, 'learning_rate': 9.979688746695098e-05, 'epoch': 0.17}
{'loss': 0.7812, 'grad_norm': 1.0485947132110596, 'learning_rate': 9.97951030913922e-05, 'epoch': 0.17}
{'loss': 1.1078, 'grad_norm': 1.0290849208831787, 'learning_rate': 9.979331092815686e-05, 'epoch': 0.17}
{'loss': 0.8694, 'grad_norm': 1.0589619874954224, 'learning_rate': 9.979151097752527e-05, 'epoch': 0.17}
{'loss': 1.1525, 'grad_norm': 1.1698423624038696, 'learning_rate': 9.978970323977894e-05, 'epoch': 0.18}
{'loss': 0.9336, 'grad_norm': 1.0254608392715454, 'learning_rate': 9.978788771520058e-05, 'epoch': 0.18}
{'loss': 0.9566, 'grad_norm': 1.0395469665527344, 'learning_rate': 9.978606440407412e-05, 'epoch': 0.18}
[1m[33mswanlab[0m[0m: Step 480 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 480 on key train/global_step already exists, ignored.
{'eval_loss': 0.8507027626037598, 'eval_runtime': 327.3512, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.18}
{'loss': 0.6164, 'grad_norm': 0.760418713092804, 'learning_rate': 9.978423330668475e-05, 'epoch': 0.18}
{'loss': 1.1554, 'grad_norm': 1.2291877269744873, 'learning_rate': 9.978239442331881e-05, 'epoch': 0.18}
{'loss': 0.9419, 'grad_norm': 0.9477577209472656, 'learning_rate': 9.978054775426389e-05, 'epoch': 0.18}
{'loss': 0.6345, 'grad_norm': 1.0132375955581665, 'learning_rate': 9.97786932998088e-05, 'epoch': 0.18}
{'loss': 1.1021, 'grad_norm': 1.1971497535705566, 'learning_rate': 9.97768310602436e-05, 'epoch': 0.18}
{'loss': 1.0036, 'grad_norm': 1.1024694442749023, 'learning_rate': 9.977496103585949e-05, 'epoch': 0.18}
{'loss': 1.1106, 'grad_norm': 1.0824291706085205, 'learning_rate': 9.977308322694895e-05, 'epoch': 0.18}
{'loss': 1.0314, 'grad_norm': 1.1280707120895386, 'learning_rate': 9.977119763380567e-05, 'epoch': 0.18}
{'loss': 0.9095, 'grad_norm': 1.0214455127716064, 'learning_rate': 9.976930425672454e-05, 'epoch': 0.18}
{'loss': 0.9548, 'grad_norm': 0.97348952293396, 'learning_rate': 9.976740309600165e-05, 'epoch': 0.18}
[1m[33mswanlab[0m[0m: Step 490 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 490 on key train/global_step already exists, ignored.
{'eval_loss': 0.8478575348854065, 'eval_runtime': 327.2593, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.18}
{'loss': 0.7512, 'grad_norm': 1.0172902345657349, 'learning_rate': 9.976549415193437e-05, 'epoch': 0.18}
{'loss': 0.9435, 'grad_norm': 1.198768973350525, 'learning_rate': 9.976357742482121e-05, 'epoch': 0.18}
{'loss': 0.5604, 'grad_norm': 1.0586323738098145, 'learning_rate': 9.976165291496196e-05, 'epoch': 0.18}
{'loss': 1.1083, 'grad_norm': 1.0834991931915283, 'learning_rate': 9.975972062265761e-05, 'epoch': 0.18}
{'loss': 0.7315, 'grad_norm': 0.8768467903137207, 'learning_rate': 9.975778054821032e-05, 'epoch': 0.18}
{'loss': 0.1626, 'grad_norm': 0.6670326590538025, 'learning_rate': 9.975583269192355e-05, 'epoch': 0.18}
{'loss': 0.8936, 'grad_norm': 1.332012414932251, 'learning_rate': 9.97538770541019e-05, 'epoch': 0.18}
{'loss': 0.9882, 'grad_norm': 1.231974720954895, 'learning_rate': 9.975191363505127e-05, 'epoch': 0.18}
{'loss': 1.1423, 'grad_norm': 1.1001023054122925, 'learning_rate': 9.974994243507866e-05, 'epoch': 0.18}
{'loss': 0.9723, 'grad_norm': 0.9759262204170227, 'learning_rate': 9.974796345449242e-05, 'epoch': 0.18}
[1m[33mswanlab[0m[0m: Step 500 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 500 on key train/global_step already exists, ignored.
{'eval_loss': 0.8481660485267639, 'eval_runtime': 327.5961, 'eval_samples_per_second': 3.706, 'eval_steps_per_second': 3.706, 'epoch': 0.18}
{'loss': 0.9036, 'grad_norm': 1.1992706060409546, 'learning_rate': 9.9745976693602e-05, 'epoch': 0.18}
{'loss': 1.1238, 'grad_norm': 1.1435718536376953, 'learning_rate': 9.974398215271815e-05, 'epoch': 0.18}
{'loss': 0.9114, 'grad_norm': 1.1875684261322021, 'learning_rate': 9.974197983215278e-05, 'epoch': 0.18}
{'loss': 1.0612, 'grad_norm': 1.0531724691390991, 'learning_rate': 9.973996973221907e-05, 'epoch': 0.18}
{'loss': 0.8669, 'grad_norm': 1.1926544904708862, 'learning_rate': 9.973795185323138e-05, 'epoch': 0.18}
{'loss': 1.3323, 'grad_norm': 1.1264086961746216, 'learning_rate': 9.973592619550528e-05, 'epoch': 0.19}
{'loss': 1.1434, 'grad_norm': 1.2676304578781128, 'learning_rate': 9.973389275935759e-05, 'epoch': 0.19}
{'loss': 1.3853, 'grad_norm': 0.9532020688056946, 'learning_rate': 9.973185154510632e-05, 'epoch': 0.19}
{'loss': 0.9607, 'grad_norm': 1.0205210447311401, 'learning_rate': 9.972980255307068e-05, 'epoch': 0.19}
{'loss': 0.8306, 'grad_norm': 0.9765514135360718, 'learning_rate': 9.972774578357117e-05, 'epoch': 0.19}
[1m[33mswanlab[0m[0m: Step 510 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 510 on key train/global_step already exists, ignored.
{'eval_loss': 0.8437750339508057, 'eval_runtime': 327.2538, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.19}
{'loss': 1.1149, 'grad_norm': 1.4054756164550781, 'learning_rate': 9.972568123692943e-05, 'epoch': 0.19}
{'loss': 0.7529, 'grad_norm': 1.0071746110916138, 'learning_rate': 9.972360891346833e-05, 'epoch': 0.19}
{'loss': 0.7835, 'grad_norm': 0.99601811170578, 'learning_rate': 9.9721528813512e-05, 'epoch': 0.19}
{'loss': 0.7615, 'grad_norm': 1.1219260692596436, 'learning_rate': 9.971944093738575e-05, 'epoch': 0.19}
{'loss': 0.9671, 'grad_norm': 1.5208262205123901, 'learning_rate': 9.971734528541608e-05, 'epoch': 0.19}
{'loss': 0.9615, 'grad_norm': 1.368390440940857, 'learning_rate': 9.971524185793078e-05, 'epoch': 0.19}
{'loss': 1.089, 'grad_norm': 1.0059301853179932, 'learning_rate': 9.97131306552588e-05, 'epoch': 0.19}
{'loss': 0.9721, 'grad_norm': 1.1268367767333984, 'learning_rate': 9.971101167773031e-05, 'epoch': 0.19}
{'loss': 1.0473, 'grad_norm': 1.221368670463562, 'learning_rate': 9.970888492567671e-05, 'epoch': 0.19}
{'loss': 0.9721, 'grad_norm': 0.9733850359916687, 'learning_rate': 9.970675039943062e-05, 'epoch': 0.19}
[1m[33mswanlab[0m[0m: Step 520 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 520 on key train/global_step already exists, ignored.
{'eval_loss': 0.8396456837654114, 'eval_runtime': 327.2846, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.19}
{'loss': 0.8932, 'grad_norm': 1.1364036798477173, 'learning_rate': 9.970460809932586e-05, 'epoch': 0.19}
{'loss': 1.121, 'grad_norm': 1.0552141666412354, 'learning_rate': 9.970245802569749e-05, 'epoch': 0.19}
{'loss': 0.9471, 'grad_norm': 1.098437786102295, 'learning_rate': 9.970030017888175e-05, 'epoch': 0.19}
{'loss': 0.6184, 'grad_norm': 1.048923134803772, 'learning_rate': 9.969813455921611e-05, 'epoch': 0.19}
{'loss': 0.8153, 'grad_norm': 0.9921844601631165, 'learning_rate': 9.969596116703927e-05, 'epoch': 0.19}
{'loss': 1.1591, 'grad_norm': 1.124369740486145, 'learning_rate': 9.969378000269116e-05, 'epoch': 0.19}
{'loss': 0.9498, 'grad_norm': 1.1854286193847656, 'learning_rate': 9.969159106651286e-05, 'epoch': 0.19}
{'loss': 1.1395, 'grad_norm': 1.0754406452178955, 'learning_rate': 9.968939435884674e-05, 'epoch': 0.19}
{'loss': 0.9642, 'grad_norm': 1.1052416563034058, 'learning_rate': 9.968718988003636e-05, 'epoch': 0.19}
{'loss': 0.6606, 'grad_norm': 1.0246385335922241, 'learning_rate': 9.968497763042643e-05, 'epoch': 0.19}
[1m[33mswanlab[0m[0m: Step 530 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 530 on key train/global_step already exists, ignored.
{'eval_loss': 0.8376800417900085, 'eval_runtime': 327.5239, 'eval_samples_per_second': 3.707, 'eval_steps_per_second': 3.707, 'epoch': 0.19}
{'loss': 0.7012, 'grad_norm': 1.088755488395691, 'learning_rate': 9.9682757610363e-05, 'epoch': 0.19}
{'loss': 0.5646, 'grad_norm': 1.146515130996704, 'learning_rate': 9.968052982019325e-05, 'epoch': 0.19}
{'loss': 1.0531, 'grad_norm': 1.1840590238571167, 'learning_rate': 9.967829426026556e-05, 'epoch': 0.2}
{'loss': 0.6998, 'grad_norm': 0.8987073302268982, 'learning_rate': 9.96760509309296e-05, 'epoch': 0.2}
{'loss': 1.2566, 'grad_norm': 1.1376078128814697, 'learning_rate': 9.96737998325362e-05, 'epoch': 0.2}
{'loss': 1.0303, 'grad_norm': 1.266257643699646, 'learning_rate': 9.967154096543742e-05, 'epoch': 0.2}
{'loss': 0.7255, 'grad_norm': 1.0580382347106934, 'learning_rate': 9.966927432998651e-05, 'epoch': 0.2}
{'loss': 0.6665, 'grad_norm': 1.083937406539917, 'learning_rate': 9.9666999926538e-05, 'epoch': 0.2}
{'loss': 0.6587, 'grad_norm': 0.9462631940841675, 'learning_rate': 9.966471775544759e-05, 'epoch': 0.2}
{'loss': 0.9091, 'grad_norm': 1.0921152830123901, 'learning_rate': 9.966242781707217e-05, 'epoch': 0.2}
[1m[33mswanlab[0m[0m: Step 540 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 540 on key train/global_step already exists, ignored.
{'eval_loss': 0.8356728553771973, 'eval_runtime': 327.311, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.2}
{'loss': 0.9594, 'grad_norm': 1.0871033668518066, 'learning_rate': 9.966013011176989e-05, 'epoch': 0.2}
{'loss': 0.8593, 'grad_norm': 1.0065350532531738, 'learning_rate': 9.96578246399001e-05, 'epoch': 0.2}
{'loss': 0.7474, 'grad_norm': 1.1094422340393066, 'learning_rate': 9.965551140182335e-05, 'epoch': 0.2}
{'loss': 0.7987, 'grad_norm': 1.1739447116851807, 'learning_rate': 9.965319039790143e-05, 'epoch': 0.2}
{'loss': 0.6224, 'grad_norm': 1.0183160305023193, 'learning_rate': 9.965086162849733e-05, 'epoch': 0.2}
{'loss': 0.8479, 'grad_norm': 0.9296939373016357, 'learning_rate': 9.964852509397526e-05, 'epoch': 0.2}
{'loss': 0.7531, 'grad_norm': 1.1030688285827637, 'learning_rate': 9.964618079470062e-05, 'epoch': 0.2}
{'loss': 1.1927, 'grad_norm': 0.9485145211219788, 'learning_rate': 9.964382873104009e-05, 'epoch': 0.2}
{'loss': 0.767, 'grad_norm': 1.094789981842041, 'learning_rate': 9.964146890336148e-05, 'epoch': 0.2}
{'loss': 1.0308, 'grad_norm': 1.1076325178146362, 'learning_rate': 9.963910131203386e-05, 'epoch': 0.2}
[1m[33mswanlab[0m[0m: Step 550 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 550 on key train/global_step already exists, ignored.
{'eval_loss': 0.8356127142906189, 'eval_runtime': 327.3579, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.2}
{'loss': 0.7339, 'grad_norm': 1.1457374095916748, 'learning_rate': 9.96367259574275e-05, 'epoch': 0.2}
{'loss': 0.7791, 'grad_norm': 1.1681276559829712, 'learning_rate': 9.963434283991393e-05, 'epoch': 0.2}
{'loss': 0.8278, 'grad_norm': 1.0169419050216675, 'learning_rate': 9.963195195986583e-05, 'epoch': 0.2}
{'loss': 0.6318, 'grad_norm': 1.2934491634368896, 'learning_rate': 9.96295533176571e-05, 'epoch': 0.2}
{'loss': 0.4753, 'grad_norm': 0.8601409792900085, 'learning_rate': 9.962714691366293e-05, 'epoch': 0.2}
{'loss': 0.6937, 'grad_norm': 1.133936882019043, 'learning_rate': 9.962473274825962e-05, 'epoch': 0.2}
{'loss': 0.8321, 'grad_norm': 1.0340478420257568, 'learning_rate': 9.962231082182474e-05, 'epoch': 0.2}
{'loss': 0.8945, 'grad_norm': 0.9816802144050598, 'learning_rate': 9.961988113473708e-05, 'epoch': 0.2}
{'loss': 0.8213, 'grad_norm': 1.1056146621704102, 'learning_rate': 9.961744368737663e-05, 'epoch': 0.2}
{'loss': 0.5154, 'grad_norm': 0.7928311824798584, 'learning_rate': 9.961499848012456e-05, 'epoch': 0.21}
[1m[33mswanlab[0m[0m: Step 560 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 560 on key train/global_step already exists, ignored.
{'eval_loss': 0.8339780569076538, 'eval_runtime': 327.3067, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.21}
{'loss': 0.9666, 'grad_norm': 1.2290575504302979, 'learning_rate': 9.961254551336334e-05, 'epoch': 0.21}
{'loss': 1.1982, 'grad_norm': 1.2957661151885986, 'learning_rate': 9.961008478747655e-05, 'epoch': 0.21}
{'loss': 0.8484, 'grad_norm': 1.0971542596817017, 'learning_rate': 9.960761630284907e-05, 'epoch': 0.21}
{'loss': 0.8474, 'grad_norm': 0.953036367893219, 'learning_rate': 9.960514005986694e-05, 'epoch': 0.21}
{'loss': 0.7811, 'grad_norm': 1.0240076780319214, 'learning_rate': 9.960265605891744e-05, 'epoch': 0.21}
{'loss': 1.1162, 'grad_norm': 1.0296927690505981, 'learning_rate': 9.960016430038903e-05, 'epoch': 0.21}
{'loss': 1.0502, 'grad_norm': 1.071537971496582, 'learning_rate': 9.959766478467145e-05, 'epoch': 0.21}
{'loss': 0.4031, 'grad_norm': 0.8144804239273071, 'learning_rate': 9.959515751215557e-05, 'epoch': 0.21}
{'loss': 1.1542, 'grad_norm': 1.1751326322555542, 'learning_rate': 9.959264248323353e-05, 'epoch': 0.21}
{'loss': 0.8598, 'grad_norm': 1.1022826433181763, 'learning_rate': 9.959011969829866e-05, 'epoch': 0.21}
[1m[33mswanlab[0m[0m: Step 570 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 570 on key train/global_step already exists, ignored.
{'eval_loss': 0.8276901245117188, 'eval_runtime': 327.5198, 'eval_samples_per_second': 3.707, 'eval_steps_per_second': 3.707, 'epoch': 0.21}
{'loss': 0.8597, 'grad_norm': 0.9263461232185364, 'learning_rate': 9.958758915774553e-05, 'epoch': 0.21}
{'loss': 0.821, 'grad_norm': 1.2210025787353516, 'learning_rate': 9.958505086196987e-05, 'epoch': 0.21}
{'loss': 1.0628, 'grad_norm': 1.1573150157928467, 'learning_rate': 9.958250481136869e-05, 'epoch': 0.21}
{'loss': 0.6692, 'grad_norm': 0.9953874945640564, 'learning_rate': 9.957995100634015e-05, 'epoch': 0.21}
{'loss': 0.767, 'grad_norm': 0.9432519674301147, 'learning_rate': 9.957738944728368e-05, 'epoch': 0.21}
{'loss': 1.259, 'grad_norm': 1.117294430732727, 'learning_rate': 9.957482013459986e-05, 'epoch': 0.21}
{'loss': 0.7243, 'grad_norm': 0.772933304309845, 'learning_rate': 9.957224306869053e-05, 'epoch': 0.21}
{'loss': 0.9733, 'grad_norm': 1.0624427795410156, 'learning_rate': 9.956965824995871e-05, 'epoch': 0.21}
{'loss': 0.9578, 'grad_norm': 1.0104694366455078, 'learning_rate': 9.956706567880871e-05, 'epoch': 0.21}
{'loss': 1.2447, 'grad_norm': 1.24178946018219, 'learning_rate': 9.956446535564594e-05, 'epoch': 0.21}
[1m[33mswanlab[0m[0m: Step 580 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 580 on key train/global_step already exists, ignored.
{'eval_loss': 0.8246873021125793, 'eval_runtime': 327.304, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.21}
{'loss': 1.0617, 'grad_norm': 1.0477226972579956, 'learning_rate': 9.95618572808771e-05, 'epoch': 0.21}
{'loss': 0.8818, 'grad_norm': 1.2544986009597778, 'learning_rate': 9.955924145491005e-05, 'epoch': 0.21}
{'loss': 0.6712, 'grad_norm': 1.0142126083374023, 'learning_rate': 9.955661787815391e-05, 'epoch': 0.21}
{'loss': 1.1826, 'grad_norm': 1.2064528465270996, 'learning_rate': 9.955398655101902e-05, 'epoch': 0.21}
{'loss': 0.8581, 'grad_norm': 0.9963505864143372, 'learning_rate': 9.955134747391685e-05, 'epoch': 0.21}
{'loss': 0.7276, 'grad_norm': 1.0992692708969116, 'learning_rate': 9.954870064726017e-05, 'epoch': 0.21}
{'loss': 0.3748, 'grad_norm': 0.7912733554840088, 'learning_rate': 9.954604607146294e-05, 'epoch': 0.22}
{'loss': 1.0881, 'grad_norm': 1.2960811853408813, 'learning_rate': 9.954338374694029e-05, 'epoch': 0.22}
{'loss': 0.756, 'grad_norm': 0.9827867150306702, 'learning_rate': 9.95407136741086e-05, 'epoch': 0.22}
{'loss': 0.4413, 'grad_norm': 0.8458946943283081, 'learning_rate': 9.953803585338548e-05, 'epoch': 0.22}
[1m[33mswanlab[0m[0m: Step 590 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 590 on key train/global_step already exists, ignored.
{'eval_loss': 0.8228771090507507, 'eval_runtime': 327.1813, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.22}
{'loss': 1.1109, 'grad_norm': 1.0875670909881592, 'learning_rate': 9.95353502851897e-05, 'epoch': 0.22}
{'loss': 0.8039, 'grad_norm': 1.2154154777526855, 'learning_rate': 9.953265696994128e-05, 'epoch': 0.22}
{'loss': 1.0297, 'grad_norm': 1.4536972045898438, 'learning_rate': 9.952995590806142e-05, 'epoch': 0.22}
{'loss': 0.6342, 'grad_norm': 1.0598618984222412, 'learning_rate': 9.952724709997259e-05, 'epoch': 0.22}
{'loss': 0.7657, 'grad_norm': 0.9784420728683472, 'learning_rate': 9.952453054609838e-05, 'epoch': 0.22}
{'loss': 0.5094, 'grad_norm': 0.8810468316078186, 'learning_rate': 9.952180624686369e-05, 'epoch': 0.22}
{'loss': 0.8548, 'grad_norm': 1.4341065883636475, 'learning_rate': 9.951907420269457e-05, 'epoch': 0.22}
{'loss': 1.2658, 'grad_norm': 1.4510468244552612, 'learning_rate': 9.95163344140183e-05, 'epoch': 0.22}
{'loss': 0.5939, 'grad_norm': 0.8377417922019958, 'learning_rate': 9.951358688126335e-05, 'epoch': 0.22}
{'loss': 0.9345, 'grad_norm': 1.203303575515747, 'learning_rate': 9.951083160485944e-05, 'epoch': 0.22}
[1m[33mswanlab[0m[0m: Step 600 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 600 on key train/global_step already exists, ignored.
{'eval_loss': 0.8207150101661682, 'eval_runtime': 327.387, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.22}
{'loss': 0.8021, 'grad_norm': 1.360903263092041, 'learning_rate': 9.950806858523748e-05, 'epoch': 0.22}
{'loss': 0.5615, 'grad_norm': 0.9058175086975098, 'learning_rate': 9.950529782282955e-05, 'epoch': 0.22}
{'loss': 0.7993, 'grad_norm': 1.0997648239135742, 'learning_rate': 9.950251931806903e-05, 'epoch': 0.22}
{'loss': 0.745, 'grad_norm': 0.9863609075546265, 'learning_rate': 9.949973307139045e-05, 'epoch': 0.22}
{'loss': 0.3577, 'grad_norm': 0.7844063639640808, 'learning_rate': 9.949693908322955e-05, 'epoch': 0.22}
{'loss': 1.063, 'grad_norm': 1.2611771821975708, 'learning_rate': 9.94941373540233e-05, 'epoch': 0.22}
{'loss': 1.0482, 'grad_norm': 1.1790293455123901, 'learning_rate': 9.94913278842099e-05, 'epoch': 0.22}
{'loss': 0.5137, 'grad_norm': 0.9569603204727173, 'learning_rate': 9.948851067422871e-05, 'epoch': 0.22}
{'loss': 1.1234, 'grad_norm': 1.3023709058761597, 'learning_rate': 9.948568572452031e-05, 'epoch': 0.22}
{'loss': 0.8423, 'grad_norm': 1.2228574752807617, 'learning_rate': 9.948285303552654e-05, 'epoch': 0.22}
[1m[33mswanlab[0m[0m: Step 610 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 610 on key train/global_step already exists, ignored.
{'eval_loss': 0.816953182220459, 'eval_runtime': 327.2974, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.22}
{'loss': 0.6881, 'grad_norm': 1.152138590812683, 'learning_rate': 9.94800126076904e-05, 'epoch': 0.22}
{'loss': 0.8224, 'grad_norm': 0.8533918857574463, 'learning_rate': 9.947716444145612e-05, 'epoch': 0.22}
{'loss': 0.988, 'grad_norm': 1.3168138265609741, 'learning_rate': 9.947430853726914e-05, 'epoch': 0.22}
{'loss': 0.9225, 'grad_norm': 1.2558847665786743, 'learning_rate': 9.947144489557612e-05, 'epoch': 0.22}
{'loss': 0.8006, 'grad_norm': 1.2126314640045166, 'learning_rate': 9.946857351682488e-05, 'epoch': 0.23}
{'loss': 0.3419, 'grad_norm': 0.8736874461174011, 'learning_rate': 9.946569440146452e-05, 'epoch': 0.23}
{'loss': 1.2447, 'grad_norm': 1.3162871599197388, 'learning_rate': 9.946280754994531e-05, 'epoch': 0.23}
{'loss': 0.5868, 'grad_norm': 0.8455754518508911, 'learning_rate': 9.945991296271873e-05, 'epoch': 0.23}
{'loss': 0.6976, 'grad_norm': 1.4413223266601562, 'learning_rate': 9.945701064023746e-05, 'epoch': 0.23}
{'loss': 0.9443, 'grad_norm': 0.9476346969604492, 'learning_rate': 9.945410058295546e-05, 'epoch': 0.23}
[1m[33mswanlab[0m[0m: Step 620 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 620 on key train/global_step already exists, ignored.
{'eval_loss': 0.8156238794326782, 'eval_runtime': 327.2144, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.23}
{'loss': 1.3627, 'grad_norm': 1.054233431816101, 'learning_rate': 9.945118279132782e-05, 'epoch': 0.23}
{'loss': 0.8138, 'grad_norm': 1.3350008726119995, 'learning_rate': 9.944825726581084e-05, 'epoch': 0.23}
{'loss': 0.6572, 'grad_norm': 1.0361144542694092, 'learning_rate': 9.944532400686209e-05, 'epoch': 0.23}
{'loss': 0.7536, 'grad_norm': 0.9970215559005737, 'learning_rate': 9.944238301494031e-05, 'epoch': 0.23}
{'loss': 0.7754, 'grad_norm': 1.4946709871292114, 'learning_rate': 9.943943429050543e-05, 'epoch': 0.23}
{'loss': 0.8586, 'grad_norm': 1.2150723934173584, 'learning_rate': 9.943647783401867e-05, 'epoch': 0.23}
{'loss': 0.5972, 'grad_norm': 1.0873425006866455, 'learning_rate': 9.943351364594233e-05, 'epoch': 0.23}
{'loss': 0.6544, 'grad_norm': 0.9278303384780884, 'learning_rate': 9.943054172674003e-05, 'epoch': 0.23}
{'loss': 0.74, 'grad_norm': 1.1607599258422852, 'learning_rate': 9.942756207687657e-05, 'epoch': 0.23}
{'loss': 0.7075, 'grad_norm': 1.1111189126968384, 'learning_rate': 9.942457469681794e-05, 'epoch': 0.23}
[1m[33mswanlab[0m[0m: Step 630 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 630 on key train/global_step already exists, ignored.
{'eval_loss': 0.815135657787323, 'eval_runtime': 327.3807, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.23}
{'loss': 1.2631, 'grad_norm': 1.12138032913208, 'learning_rate': 9.942157958703136e-05, 'epoch': 0.23}
{'loss': 0.9382, 'grad_norm': 0.9274953007698059, 'learning_rate': 9.941857674798523e-05, 'epoch': 0.23}
{'loss': 0.7657, 'grad_norm': 1.175951600074768, 'learning_rate': 9.941556618014917e-05, 'epoch': 0.23}
{'loss': 1.0515, 'grad_norm': 1.1940786838531494, 'learning_rate': 9.941254788399406e-05, 'epoch': 0.23}
{'loss': 1.2101, 'grad_norm': 1.3334087133407593, 'learning_rate': 9.94095218599919e-05, 'epoch': 0.23}
{'loss': 0.5166, 'grad_norm': 1.027343988418579, 'learning_rate': 9.940648810861597e-05, 'epoch': 0.23}
{'loss': 1.0597, 'grad_norm': 1.7913880348205566, 'learning_rate': 9.940344663034071e-05, 'epoch': 0.23}
{'loss': 0.8935, 'grad_norm': 1.4586163759231567, 'learning_rate': 9.940039742564182e-05, 'epoch': 0.23}
{'loss': 0.6545, 'grad_norm': 1.112516164779663, 'learning_rate': 9.939734049499614e-05, 'epoch': 0.23}
{'loss': 0.7141, 'grad_norm': 0.9575780034065247, 'learning_rate': 9.939427583888178e-05, 'epoch': 0.23}
[1m[33mswanlab[0m[0m: Step 640 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 640 on key train/global_step already exists, ignored.
{'eval_loss': 0.8176533579826355, 'eval_runtime': 327.016, 'eval_samples_per_second': 3.712, 'eval_steps_per_second': 3.712, 'epoch': 0.23}
{'loss': 1.0823, 'grad_norm': 1.4482518434524536, 'learning_rate': 9.939120345777806e-05, 'epoch': 0.23}
{'loss': 1.1128, 'grad_norm': 1.1859896183013916, 'learning_rate': 9.938812335216543e-05, 'epoch': 0.24}
{'loss': 0.8373, 'grad_norm': 0.9205965995788574, 'learning_rate': 9.938503552252563e-05, 'epoch': 0.24}
{'loss': 1.1991, 'grad_norm': 1.12591552734375, 'learning_rate': 9.938193996934158e-05, 'epoch': 0.24}
{'loss': 0.9205, 'grad_norm': 1.102999210357666, 'learning_rate': 9.937883669309741e-05, 'epoch': 0.24}
{'loss': 0.4926, 'grad_norm': 1.0237016677856445, 'learning_rate': 9.937572569427845e-05, 'epoch': 0.24}
{'loss': 0.2916, 'grad_norm': 1.0192047357559204, 'learning_rate': 9.937260697337123e-05, 'epoch': 0.24}
{'loss': 1.0189, 'grad_norm': 1.3133485317230225, 'learning_rate': 9.936948053086352e-05, 'epoch': 0.24}
{'loss': 0.7309, 'grad_norm': 0.9719817042350769, 'learning_rate': 9.936634636724426e-05, 'epoch': 0.24}
{'loss': 0.8321, 'grad_norm': 0.9258187413215637, 'learning_rate': 9.936320448300364e-05, 'epoch': 0.24}
[1m[33mswanlab[0m[0m: Step 650 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 650 on key train/global_step already exists, ignored.
{'eval_loss': 0.8093917369842529, 'eval_runtime': 327.2781, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.24}
{'loss': 0.9028, 'grad_norm': 1.2184230089187622, 'learning_rate': 9.936005487863302e-05, 'epoch': 0.24}
{'loss': 0.5078, 'grad_norm': 0.8279833197593689, 'learning_rate': 9.935689755462499e-05, 'epoch': 0.24}
{'loss': 0.6873, 'grad_norm': 0.9921261072158813, 'learning_rate': 9.935373251147331e-05, 'epoch': 0.24}
{'loss': 0.5695, 'grad_norm': 1.0263558626174927, 'learning_rate': 9.935055974967299e-05, 'epoch': 0.24}
{'loss': 0.7134, 'grad_norm': 1.0412720441818237, 'learning_rate': 9.934737926972024e-05, 'epoch': 0.24}
{'loss': 0.6527, 'grad_norm': 1.0102465152740479, 'learning_rate': 9.934419107211247e-05, 'epoch': 0.24}
{'loss': 0.5357, 'grad_norm': 1.0470749139785767, 'learning_rate': 9.93409951573483e-05, 'epoch': 0.24}
{'loss': 0.771, 'grad_norm': 1.158207893371582, 'learning_rate': 9.933779152592753e-05, 'epoch': 0.24}
{'loss': 0.6935, 'grad_norm': 1.1137950420379639, 'learning_rate': 9.93345801783512e-05, 'epoch': 0.24}
{'loss': 0.5258, 'grad_norm': 0.813948929309845, 'learning_rate': 9.933136111512156e-05, 'epoch': 0.24}
[1m[33mswanlab[0m[0m: Step 660 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 660 on key train/global_step already exists, ignored.
{'eval_loss': 0.8091380596160889, 'eval_runtime': 327.0763, 'eval_samples_per_second': 3.712, 'eval_steps_per_second': 3.712, 'epoch': 0.24}
{'loss': 0.1599, 'grad_norm': 0.9806516170501709, 'learning_rate': 9.932813433674204e-05, 'epoch': 0.24}
{'loss': 1.16, 'grad_norm': 1.237111210823059, 'learning_rate': 9.932489984371731e-05, 'epoch': 0.24}
{'loss': 1.1286, 'grad_norm': 1.4969452619552612, 'learning_rate': 9.932165763655319e-05, 'epoch': 0.24}
{'loss': 0.6107, 'grad_norm': 1.103185772895813, 'learning_rate': 9.931840771575677e-05, 'epoch': 0.24}
{'loss': 1.2087, 'grad_norm': 1.1281152963638306, 'learning_rate': 9.931515008183633e-05, 'epoch': 0.24}
{'loss': 0.791, 'grad_norm': 1.1380813121795654, 'learning_rate': 9.931188473530132e-05, 'epoch': 0.24}
{'loss': 0.7798, 'grad_norm': 1.4193660020828247, 'learning_rate': 9.930861167666244e-05, 'epoch': 0.24}
{'loss': 0.7888, 'grad_norm': 1.8080477714538574, 'learning_rate': 9.930533090643155e-05, 'epoch': 0.24}
{'loss': 0.545, 'grad_norm': 1.0334244966506958, 'learning_rate': 9.930204242512177e-05, 'epoch': 0.25}
{'loss': 0.9137, 'grad_norm': 1.0360954999923706, 'learning_rate': 9.92987462332474e-05, 'epoch': 0.25}
[1m[33mswanlab[0m[0m: Step 670 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 670 on key train/global_step already exists, ignored.
{'eval_loss': 0.807817816734314, 'eval_runtime': 327.0445, 'eval_samples_per_second': 3.712, 'eval_steps_per_second': 3.712, 'epoch': 0.25}
{'loss': 0.8552, 'grad_norm': 1.2254188060760498, 'learning_rate': 9.929544233132396e-05, 'epoch': 0.25}
{'loss': 0.6828, 'grad_norm': 1.1890597343444824, 'learning_rate': 9.929213071986811e-05, 'epoch': 0.25}
{'loss': 0.5784, 'grad_norm': 0.9906372427940369, 'learning_rate': 9.928881139939781e-05, 'epoch': 0.25}
{'loss': 0.7768, 'grad_norm': 1.0650447607040405, 'learning_rate': 9.928548437043219e-05, 'epoch': 0.25}
{'loss': 0.4975, 'grad_norm': 0.8480598330497742, 'learning_rate': 9.928214963349155e-05, 'epoch': 0.25}
{'loss': 0.7787, 'grad_norm': 1.292184591293335, 'learning_rate': 9.927880718909743e-05, 'epoch': 0.25}
{'loss': 0.9132, 'grad_norm': 1.064723253250122, 'learning_rate': 9.927545703777259e-05, 'epoch': 0.25}
{'loss': 0.1186, 'grad_norm': 0.7522180080413818, 'learning_rate': 9.927209918004095e-05, 'epoch': 0.25}
{'loss': 1.1011, 'grad_norm': 1.2626142501831055, 'learning_rate': 9.926873361642768e-05, 'epoch': 0.25}
{'loss': 0.4467, 'grad_norm': 0.8493808507919312, 'learning_rate': 9.926536034745911e-05, 'epoch': 0.25}
[1m[33mswanlab[0m[0m: Step 680 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 680 on key train/global_step already exists, ignored.
{'eval_loss': 0.8066816329956055, 'eval_runtime': 327.2465, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.25}
{'loss': 1.0191, 'grad_norm': 1.2501461505889893, 'learning_rate': 9.926197937366284e-05, 'epoch': 0.25}
{'loss': 0.8175, 'grad_norm': 1.042434573173523, 'learning_rate': 9.92585906955676e-05, 'epoch': 0.25}
{'loss': 0.7666, 'grad_norm': 0.8303159475326538, 'learning_rate': 9.925519431370336e-05, 'epoch': 0.25}
{'loss': 0.963, 'grad_norm': 1.1317625045776367, 'learning_rate': 9.925179022860132e-05, 'epoch': 0.25}
{'loss': 1.0534, 'grad_norm': 1.2410553693771362, 'learning_rate': 9.924837844079385e-05, 'epoch': 0.25}
{'loss': 0.4634, 'grad_norm': 1.2067456245422363, 'learning_rate': 9.924495895081454e-05, 'epoch': 0.25}
{'loss': 0.6335, 'grad_norm': 1.0784274339675903, 'learning_rate': 9.924153175919816e-05, 'epoch': 0.25}
{'loss': 1.1523, 'grad_norm': 1.269621729850769, 'learning_rate': 9.923809686648073e-05, 'epoch': 0.25}
{'loss': 0.7528, 'grad_norm': 1.0683839321136475, 'learning_rate': 9.923465427319941e-05, 'epoch': 0.25}
{'loss': 0.9456, 'grad_norm': 0.9957156181335449, 'learning_rate': 9.923120397989264e-05, 'epoch': 0.25}
[1m[33mswanlab[0m[0m: Step 690 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 690 on key train/global_step already exists, ignored.
{'eval_loss': 0.8071786761283875, 'eval_runtime': 327.0886, 'eval_samples_per_second': 3.712, 'eval_steps_per_second': 3.712, 'epoch': 0.25}
{'loss': 0.9247, 'grad_norm': 1.2168176174163818, 'learning_rate': 9.92277459871e-05, 'epoch': 0.25}
{'loss': 1.2411, 'grad_norm': 1.2713829278945923, 'learning_rate': 9.922428029536234e-05, 'epoch': 0.25}
{'loss': 0.5331, 'grad_norm': 1.0346338748931885, 'learning_rate': 9.922080690522162e-05, 'epoch': 0.25}
{'loss': 0.7671, 'grad_norm': 0.9564691781997681, 'learning_rate': 9.921732581722111e-05, 'epoch': 0.25}
{'loss': 1.0792, 'grad_norm': 1.29441499710083, 'learning_rate': 9.92138370319052e-05, 'epoch': 0.25}
{'loss': 0.8443, 'grad_norm': 1.1589274406433105, 'learning_rate': 9.921034054981953e-05, 'epoch': 0.25}
{'loss': 0.9679, 'grad_norm': 1.279909372329712, 'learning_rate': 9.920683637151092e-05, 'epoch': 0.26}
{'loss': 1.0697, 'grad_norm': 1.310913324356079, 'learning_rate': 9.92033244975274e-05, 'epoch': 0.26}
{'loss': 0.7068, 'grad_norm': 0.9942982196807861, 'learning_rate': 9.919980492841824e-05, 'epoch': 0.26}
{'loss': 0.8107, 'grad_norm': 1.238340973854065, 'learning_rate': 9.919627766473385e-05, 'epoch': 0.26}
[1m[33mswanlab[0m[0m: Step 700 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 700 on key train/global_step already exists, ignored.
{'eval_loss': 0.80259770154953, 'eval_runtime': 327.0266, 'eval_samples_per_second': 3.712, 'eval_steps_per_second': 3.712, 'epoch': 0.26}
{'loss': 0.7882, 'grad_norm': 1.191250205039978, 'learning_rate': 9.919274270702588e-05, 'epoch': 0.26}
{'loss': 0.7214, 'grad_norm': 1.1794793605804443, 'learning_rate': 9.918920005584719e-05, 'epoch': 0.26}
{'loss': 0.9194, 'grad_norm': 1.0727580785751343, 'learning_rate': 9.918564971175181e-05, 'epoch': 0.26}
{'loss': 0.7565, 'grad_norm': 1.1784909963607788, 'learning_rate': 9.918209167529501e-05, 'epoch': 0.26}
{'loss': 1.0987, 'grad_norm': 1.0133516788482666, 'learning_rate': 9.917852594703326e-05, 'epoch': 0.26}
{'loss': 0.9554, 'grad_norm': 0.9062074422836304, 'learning_rate': 9.917495252752418e-05, 'epoch': 0.26}
{'loss': 0.7112, 'grad_norm': 1.11226487159729, 'learning_rate': 9.917137141732667e-05, 'epoch': 0.26}
{'loss': 0.3035, 'grad_norm': 0.8328918218612671, 'learning_rate': 9.916778261700077e-05, 'epoch': 0.26}
{'loss': 0.8674, 'grad_norm': 1.290934681892395, 'learning_rate': 9.916418612710777e-05, 'epoch': 0.26}
{'loss': 0.7269, 'grad_norm': 1.0061774253845215, 'learning_rate': 9.916058194821013e-05, 'epoch': 0.26}
[1m[33mswanlab[0m[0m: Step 710 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 710 on key train/global_step already exists, ignored.
{'eval_loss': 0.8012221455574036, 'eval_runtime': 327.1923, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.26}
{'loss': 0.6291, 'grad_norm': 0.9279139041900635, 'learning_rate': 9.915697008087153e-05, 'epoch': 0.26}
{'loss': 1.4507, 'grad_norm': 1.0667636394500732, 'learning_rate': 9.915335052565683e-05, 'epoch': 0.26}
{'loss': 0.6881, 'grad_norm': 1.23924720287323, 'learning_rate': 9.914972328313213e-05, 'epoch': 0.26}
{'loss': 0.5444, 'grad_norm': 1.1016414165496826, 'learning_rate': 9.914608835386467e-05, 'epoch': 0.26}
{'loss': 1.0563, 'grad_norm': 1.1046645641326904, 'learning_rate': 9.9142445738423e-05, 'epoch': 0.26}
{'loss': 0.5066, 'grad_norm': 0.8323281407356262, 'learning_rate': 9.913879543737674e-05, 'epoch': 0.26}
{'loss': 1.0394, 'grad_norm': 1.979046106338501, 'learning_rate': 9.913513745129681e-05, 'epoch': 0.26}
{'loss': 0.755, 'grad_norm': 1.0701696872711182, 'learning_rate': 9.91314717807553e-05, 'epoch': 0.26}
{'loss': 0.4787, 'grad_norm': 0.8303736448287964, 'learning_rate': 9.912779842632549e-05, 'epoch': 0.26}
{'loss': 0.9547, 'grad_norm': 1.1576988697052002, 'learning_rate': 9.912411738858187e-05, 'epoch': 0.26}
[1m[33mswanlab[0m[0m: Step 720 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 720 on key train/global_step already exists, ignored.
{'eval_loss': 0.7999892830848694, 'eval_runtime': 327.3726, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.26}
{'loss': 0.7379, 'grad_norm': 1.1561638116836548, 'learning_rate': 9.912042866810013e-05, 'epoch': 0.26}
{'loss': 1.2147, 'grad_norm': 1.1343388557434082, 'learning_rate': 9.91167322654572e-05, 'epoch': 0.26}
{'loss': 0.8538, 'grad_norm': 1.061799168586731, 'learning_rate': 9.911302818123114e-05, 'epoch': 0.26}
{'loss': 0.6762, 'grad_norm': 0.9658262133598328, 'learning_rate': 9.910931641600126e-05, 'epoch': 0.27}
{'loss': 1.0771, 'grad_norm': 1.132776141166687, 'learning_rate': 9.910559697034805e-05, 'epoch': 0.27}
{'loss': 0.9479, 'grad_norm': 1.1882350444793701, 'learning_rate': 9.910186984485321e-05, 'epoch': 0.27}
{'loss': 0.565, 'grad_norm': 0.8812717199325562, 'learning_rate': 9.909813504009966e-05, 'epoch': 0.27}
{'loss': 0.9805, 'grad_norm': 1.1373343467712402, 'learning_rate': 9.90943925566715e-05, 'epoch': 0.27}
{'loss': 0.8311, 'grad_norm': 1.0082951784133911, 'learning_rate': 9.909064239515403e-05, 'epoch': 0.27}
{'loss': 0.966, 'grad_norm': 1.203153371810913, 'learning_rate': 9.908688455613374e-05, 'epoch': 0.27}
[1m[33mswanlab[0m[0m: Step 730 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 730 on key train/global_step already exists, ignored.
{'eval_loss': 0.7986170649528503, 'eval_runtime': 327.6801, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 3.705, 'epoch': 0.27}
{'loss': 0.8989, 'grad_norm': 1.2315497398376465, 'learning_rate': 9.908311904019834e-05, 'epoch': 0.27}
{'loss': 0.9685, 'grad_norm': 1.2874791622161865, 'learning_rate': 9.907934584793675e-05, 'epoch': 0.27}
{'loss': 0.3693, 'grad_norm': 0.8147260546684265, 'learning_rate': 9.907556497993906e-05, 'epoch': 0.27}
{'loss': 0.9365, 'grad_norm': 1.301050066947937, 'learning_rate': 9.90717764367966e-05, 'epoch': 0.27}
{'loss': 0.4603, 'grad_norm': 1.0517706871032715, 'learning_rate': 9.906798021910184e-05, 'epoch': 0.27}
{'loss': 1.128, 'grad_norm': 1.2831835746765137, 'learning_rate': 9.906417632744853e-05, 'epoch': 0.27}
{'loss': 0.9035, 'grad_norm': 1.3524868488311768, 'learning_rate': 9.906036476243154e-05, 'epoch': 0.27}
{'loss': 0.7573, 'grad_norm': 1.3020100593566895, 'learning_rate': 9.9056545524647e-05, 'epoch': 0.27}
{'loss': 0.9345, 'grad_norm': 1.204641580581665, 'learning_rate': 9.90527186146922e-05, 'epoch': 0.27}
{'loss': 1.0683, 'grad_norm': 1.175588607788086, 'learning_rate': 9.904888403316569e-05, 'epoch': 0.27}
[1m[33mswanlab[0m[0m: Step 740 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 740 on key train/global_step already exists, ignored.
{'eval_loss': 0.7951207160949707, 'eval_runtime': 327.4316, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.27}
{'loss': 1.0317, 'grad_norm': 1.1599712371826172, 'learning_rate': 9.904504178066713e-05, 'epoch': 0.27}
{'loss': 0.4978, 'grad_norm': 0.7025723457336426, 'learning_rate': 9.904119185779743e-05, 'epoch': 0.27}
{'loss': 0.8776, 'grad_norm': 1.1400872468948364, 'learning_rate': 9.903733426515872e-05, 'epoch': 0.27}
{'loss': 1.1331, 'grad_norm': 1.1656086444854736, 'learning_rate': 9.90334690033543e-05, 'epoch': 0.27}
{'loss': 1.1321, 'grad_norm': 1.2106457948684692, 'learning_rate': 9.902959607298866e-05, 'epoch': 0.27}
{'loss': 0.778, 'grad_norm': 1.0696020126342773, 'learning_rate': 9.902571547466753e-05, 'epoch': 0.27}
{'loss': 0.6382, 'grad_norm': 0.9905250072479248, 'learning_rate': 9.902182720899778e-05, 'epoch': 0.27}
{'loss': 0.8821, 'grad_norm': 1.2064964771270752, 'learning_rate': 9.901793127658753e-05, 'epoch': 0.27}
{'loss': 1.0007, 'grad_norm': 1.1065466403961182, 'learning_rate': 9.90140276780461e-05, 'epoch': 0.27}
{'loss': 1.2162, 'grad_norm': 1.1656101942062378, 'learning_rate': 9.901011641398398e-05, 'epoch': 0.27}
[1m[33mswanlab[0m[0m: Step 750 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 750 on key train/global_step already exists, ignored.
{'eval_loss': 0.793969988822937, 'eval_runtime': 327.2592, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.27}
{'loss': 0.6777, 'grad_norm': 1.1036456823349, 'learning_rate': 9.900619748501285e-05, 'epoch': 0.28}
{'loss': 0.7457, 'grad_norm': 0.9198763370513916, 'learning_rate': 9.900227089174562e-05, 'epoch': 0.28}
{'loss': 0.9699, 'grad_norm': 1.2632700204849243, 'learning_rate': 9.899833663479642e-05, 'epoch': 0.28}
{'loss': 0.9544, 'grad_norm': 1.2511670589447021, 'learning_rate': 9.89943947147805e-05, 'epoch': 0.28}
{'loss': 0.9269, 'grad_norm': 1.0748214721679688, 'learning_rate': 9.899044513231436e-05, 'epoch': 0.28}
{'loss': 0.6436, 'grad_norm': 0.7119568586349487, 'learning_rate': 9.898648788801572e-05, 'epoch': 0.28}
{'loss': 0.8095, 'grad_norm': 1.2759491205215454, 'learning_rate': 9.898252298250345e-05, 'epoch': 0.28}
{'loss': 0.708, 'grad_norm': 0.9705768823623657, 'learning_rate': 9.897855041639764e-05, 'epoch': 0.28}
{'loss': 0.7917, 'grad_norm': 0.8675347566604614, 'learning_rate': 9.897457019031959e-05, 'epoch': 0.28}
{'loss': 1.0672, 'grad_norm': 1.1148391962051392, 'learning_rate': 9.897058230489177e-05, 'epoch': 0.28}
[1m[33mswanlab[0m[0m: Step 760 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 760 on key train/global_step already exists, ignored.
{'eval_loss': 0.7924638986587524, 'eval_runtime': 327.5253, 'eval_samples_per_second': 3.707, 'eval_steps_per_second': 3.707, 'epoch': 0.28}
{'loss': 0.7842, 'grad_norm': 1.1274610757827759, 'learning_rate': 9.896658676073787e-05, 'epoch': 0.28}
{'loss': 1.0018, 'grad_norm': 1.1870673894882202, 'learning_rate': 9.896258355848278e-05, 'epoch': 0.28}
{'loss': 0.8505, 'grad_norm': 1.2337968349456787, 'learning_rate': 9.895857269875255e-05, 'epoch': 0.28}
{'loss': 1.135, 'grad_norm': 1.2054729461669922, 'learning_rate': 9.89545541821745e-05, 'epoch': 0.28}
{'loss': 1.096, 'grad_norm': 1.064205288887024, 'learning_rate': 9.895052800937706e-05, 'epoch': 0.28}
{'loss': 0.8299, 'grad_norm': 1.0832945108413696, 'learning_rate': 9.894649418098991e-05, 'epoch': 0.28}
{'loss': 1.1695, 'grad_norm': 1.0782830715179443, 'learning_rate': 9.894245269764395e-05, 'epoch': 0.28}
{'loss': 0.274, 'grad_norm': 0.7383642196655273, 'learning_rate': 9.893840355997121e-05, 'epoch': 0.28}
{'loss': 0.8594, 'grad_norm': 1.1311874389648438, 'learning_rate': 9.893434676860499e-05, 'epoch': 0.28}
{'loss': 0.8765, 'grad_norm': 0.9916790723800659, 'learning_rate': 9.893028232417969e-05, 'epoch': 0.28}
[1m[33mswanlab[0m[0m: Step 770 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 770 on key train/global_step already exists, ignored.
{'eval_loss': 0.7876769304275513, 'eval_runtime': 327.2754, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.28}
{'loss': 0.8766, 'grad_norm': 1.0644536018371582, 'learning_rate': 9.892621022733102e-05, 'epoch': 0.28}
{'loss': 0.8679, 'grad_norm': 0.8796265125274658, 'learning_rate': 9.892213047869581e-05, 'epoch': 0.28}
{'loss': 0.5601, 'grad_norm': 0.9248084425926208, 'learning_rate': 9.891804307891213e-05, 'epoch': 0.28}
{'loss': 0.6086, 'grad_norm': 0.8340782523155212, 'learning_rate': 9.89139480286192e-05, 'epoch': 0.28}
{'loss': 0.7005, 'grad_norm': 1.0176606178283691, 'learning_rate': 9.890984532845747e-05, 'epoch': 0.28}
{'loss': 1.0427, 'grad_norm': 1.130948781967163, 'learning_rate': 9.890573497906859e-05, 'epoch': 0.28}
{'loss': 0.6829, 'grad_norm': 1.1295078992843628, 'learning_rate': 9.890161698109539e-05, 'epoch': 0.28}
{'loss': 0.4859, 'grad_norm': 1.0704433917999268, 'learning_rate': 9.88974913351819e-05, 'epoch': 0.28}
{'loss': 0.7061, 'grad_norm': 0.8743248581886292, 'learning_rate': 9.889335804197335e-05, 'epoch': 0.29}
{'loss': 0.8251, 'grad_norm': 1.0792971849441528, 'learning_rate': 9.888921710211616e-05, 'epoch': 0.29}
[1m[33mswanlab[0m[0m: Step 780 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 780 on key train/global_step already exists, ignored.
{'eval_loss': 0.7881146669387817, 'eval_runtime': 327.3747, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.29}
{'loss': 0.9134, 'grad_norm': 1.0608539581298828, 'learning_rate': 9.888506851625796e-05, 'epoch': 0.29}
{'loss': 0.5939, 'grad_norm': 0.8051620721817017, 'learning_rate': 9.888091228504757e-05, 'epoch': 0.29}
{'loss': 0.6648, 'grad_norm': 0.9349941611289978, 'learning_rate': 9.887674840913496e-05, 'epoch': 0.29}
{'loss': 0.7117, 'grad_norm': 0.9659472703933716, 'learning_rate': 9.88725768891714e-05, 'epoch': 0.29}
{'loss': 0.4338, 'grad_norm': 0.800702691078186, 'learning_rate': 9.886839772580925e-05, 'epoch': 0.29}
{'loss': 0.9983, 'grad_norm': 1.2242833375930786, 'learning_rate': 9.886421091970211e-05, 'epoch': 0.29}
{'loss': 0.847, 'grad_norm': 1.2262192964553833, 'learning_rate': 9.88600164715048e-05, 'epoch': 0.29}
{'loss': 1.0295, 'grad_norm': 1.2125864028930664, 'learning_rate': 9.885581438187327e-05, 'epoch': 0.29}
{'loss': 0.8896, 'grad_norm': 1.3812092542648315, 'learning_rate': 9.885160465146473e-05, 'epoch': 0.29}
{'loss': 0.7567, 'grad_norm': 1.1774775981903076, 'learning_rate': 9.884738728093754e-05, 'epoch': 0.29}
[1m[33mswanlab[0m[0m: Step 790 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 790 on key train/global_step already exists, ignored.
{'eval_loss': 0.7840166091918945, 'eval_runtime': 327.2264, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.29}
{'loss': 0.7901, 'grad_norm': 1.1329708099365234, 'learning_rate': 9.884316227095129e-05, 'epoch': 0.29}
{'loss': 0.5383, 'grad_norm': 1.0605822801589966, 'learning_rate': 9.883892962216677e-05, 'epoch': 0.29}
{'loss': 0.9705, 'grad_norm': 1.1966456174850464, 'learning_rate': 9.883468933524589e-05, 'epoch': 0.29}
{'loss': 0.7696, 'grad_norm': 0.9514212608337402, 'learning_rate': 9.883044141085183e-05, 'epoch': 0.29}
{'loss': 0.8677, 'grad_norm': 1.1405186653137207, 'learning_rate': 9.882618584964895e-05, 'epoch': 0.29}
{'loss': 0.5838, 'grad_norm': 1.0636260509490967, 'learning_rate': 9.88219226523028e-05, 'epoch': 0.29}
{'loss': 1.0569, 'grad_norm': 1.0384414196014404, 'learning_rate': 9.881765181948009e-05, 'epoch': 0.29}
{'loss': 0.644, 'grad_norm': 0.9786311984062195, 'learning_rate': 9.881337335184878e-05, 'epoch': 0.29}
{'loss': 0.8205, 'grad_norm': 1.0963752269744873, 'learning_rate': 9.880908725007801e-05, 'epoch': 0.29}
{'loss': 0.867, 'grad_norm': 1.0863831043243408, 'learning_rate': 9.880479351483806e-05, 'epoch': 0.29}
[1m[33mswanlab[0m[0m: Step 800 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 800 on key train/global_step already exists, ignored.
{'eval_loss': 0.7820793390274048, 'eval_runtime': 327.1979, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.29}
{'loss': 0.7447, 'grad_norm': 1.0942734479904175, 'learning_rate': 9.880049214680049e-05, 'epoch': 0.29}
{'loss': 0.8688, 'grad_norm': 1.0777238607406616, 'learning_rate': 9.879618314663799e-05, 'epoch': 0.29}
{'loss': 1.1743, 'grad_norm': 1.1754035949707031, 'learning_rate': 9.879186651502448e-05, 'epoch': 0.29}
{'loss': 0.7702, 'grad_norm': 1.159253478050232, 'learning_rate': 9.878754225263502e-05, 'epoch': 0.29}
{'loss': 0.6038, 'grad_norm': 0.6935550570487976, 'learning_rate': 9.878321036014593e-05, 'epoch': 0.29}
{'loss': 0.5984, 'grad_norm': 0.9063940048217773, 'learning_rate': 9.877887083823469e-05, 'epoch': 0.3}
{'loss': 1.0616, 'grad_norm': 1.1460014581680298, 'learning_rate': 9.877452368757998e-05, 'epoch': 0.3}
{'loss': 0.7729, 'grad_norm': 1.001702070236206, 'learning_rate': 9.877016890886165e-05, 'epoch': 0.3}
{'loss': 0.8463, 'grad_norm': 1.0934048891067505, 'learning_rate': 9.876580650276078e-05, 'epoch': 0.3}
{'loss': 0.9164, 'grad_norm': 1.1604536771774292, 'learning_rate': 9.876143646995963e-05, 'epoch': 0.3}
[1m[33mswanlab[0m[0m: Step 810 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 810 on key train/global_step already exists, ignored.
{'eval_loss': 0.7820639610290527, 'eval_runtime': 327.5362, 'eval_samples_per_second': 3.706, 'eval_steps_per_second': 3.706, 'epoch': 0.3}
{'loss': 0.8358, 'grad_norm': 1.1912323236465454, 'learning_rate': 9.875705881114164e-05, 'epoch': 0.3}
{'loss': 0.8456, 'grad_norm': 0.95912104845047, 'learning_rate': 9.875267352699146e-05, 'epoch': 0.3}
{'loss': 0.8707, 'grad_norm': 0.9119742512702942, 'learning_rate': 9.874828061819491e-05, 'epoch': 0.3}
{'loss': 0.6918, 'grad_norm': 1.0992026329040527, 'learning_rate': 9.874388008543903e-05, 'epoch': 0.3}
{'loss': 1.1282, 'grad_norm': 1.184781789779663, 'learning_rate': 9.873947192941202e-05, 'epoch': 0.3}
{'loss': 0.7154, 'grad_norm': 0.9853927493095398, 'learning_rate': 9.873505615080332e-05, 'epoch': 0.3}
{'loss': 0.8808, 'grad_norm': 1.1566894054412842, 'learning_rate': 9.873063275030351e-05, 'epoch': 0.3}
{'loss': 0.5233, 'grad_norm': 0.9885205030441284, 'learning_rate': 9.872620172860439e-05, 'epoch': 0.3}
{'loss': 0.9953, 'grad_norm': 0.9802234768867493, 'learning_rate': 9.872176308639895e-05, 'epoch': 0.3}
{'loss': 1.0009, 'grad_norm': 1.1099801063537598, 'learning_rate': 9.871731682438138e-05, 'epoch': 0.3}
[1m[33mswanlab[0m[0m: Step 820 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 820 on key train/global_step already exists, ignored.
{'eval_loss': 0.7795964479446411, 'eval_runtime': 327.3981, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.3}
{'loss': 0.9962, 'grad_norm': 1.1471744775772095, 'learning_rate': 9.871286294324702e-05, 'epoch': 0.3}
{'loss': 0.8214, 'grad_norm': 1.1438868045806885, 'learning_rate': 9.870840144369246e-05, 'epoch': 0.3}
{'loss': 1.0718, 'grad_norm': 1.3076481819152832, 'learning_rate': 9.870393232641546e-05, 'epoch': 0.3}
{'loss': 0.911, 'grad_norm': 0.9871701002120972, 'learning_rate': 9.869945559211494e-05, 'epoch': 0.3}
{'loss': 0.7453, 'grad_norm': 1.12319016456604, 'learning_rate': 9.869497124149103e-05, 'epoch': 0.3}
{'loss': 0.7691, 'grad_norm': 1.1355507373809814, 'learning_rate': 9.869047927524508e-05, 'epoch': 0.3}
{'loss': 0.7057, 'grad_norm': 0.9399113655090332, 'learning_rate': 9.868597969407961e-05, 'epoch': 0.3}
{'loss': 1.0728, 'grad_norm': 1.2070138454437256, 'learning_rate': 9.868147249869833e-05, 'epoch': 0.3}
{'loss': 0.5409, 'grad_norm': 0.8674232959747314, 'learning_rate': 9.867695768980612e-05, 'epoch': 0.3}
{'loss': 0.6333, 'grad_norm': 0.9943962693214417, 'learning_rate': 9.867243526810908e-05, 'epoch': 0.3}
[1m[33mswanlab[0m[0m: Step 830 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 830 on key train/global_step already exists, ignored.
{'eval_loss': 0.778329610824585, 'eval_runtime': 327.4207, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.3}
{'loss': 0.7626, 'grad_norm': 1.0625247955322266, 'learning_rate': 9.866790523431448e-05, 'epoch': 0.3}
{'loss': 0.8338, 'grad_norm': 1.1781176328659058, 'learning_rate': 9.866336758913083e-05, 'epoch': 0.3}
{'loss': 0.9566, 'grad_norm': 1.083023190498352, 'learning_rate': 9.865882233326775e-05, 'epoch': 0.31}
{'loss': 1.1605, 'grad_norm': 1.2424211502075195, 'learning_rate': 9.865426946743614e-05, 'epoch': 0.31}
{'loss': 0.7536, 'grad_norm': 0.9316428303718567, 'learning_rate': 9.8649708992348e-05, 'epoch': 0.31}
{'loss': 0.8461, 'grad_norm': 1.1892809867858887, 'learning_rate': 9.864514090871657e-05, 'epoch': 0.31}
{'loss': 0.8716, 'grad_norm': 1.1371171474456787, 'learning_rate': 9.864056521725628e-05, 'epoch': 0.31}
{'loss': 1.1188, 'grad_norm': 1.1516894102096558, 'learning_rate': 9.863598191868274e-05, 'epoch': 0.31}
{'loss': 0.7531, 'grad_norm': 1.051652193069458, 'learning_rate': 9.863139101371277e-05, 'epoch': 0.31}
{'loss': 1.0346, 'grad_norm': 1.1545228958129883, 'learning_rate': 9.862679250306433e-05, 'epoch': 0.31}
[1m[33mswanlab[0m[0m: Step 840 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 840 on key train/global_step already exists, ignored.
{'eval_loss': 0.7739566564559937, 'eval_runtime': 327.6677, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 3.705, 'epoch': 0.31}
{'loss': 0.4826, 'grad_norm': 0.7235641479492188, 'learning_rate': 9.862218638745662e-05, 'epoch': 0.31}
{'loss': 0.4579, 'grad_norm': 1.0222992897033691, 'learning_rate': 9.861757266761002e-05, 'epoch': 0.31}
{'loss': 0.5129, 'grad_norm': 0.7495096325874329, 'learning_rate': 9.861295134424608e-05, 'epoch': 0.31}
{'loss': 0.5856, 'grad_norm': 0.908821165561676, 'learning_rate': 9.860832241808752e-05, 'epoch': 0.31}
{'loss': 0.8012, 'grad_norm': 1.1390935182571411, 'learning_rate': 9.860368588985834e-05, 'epoch': 0.31}
{'loss': 0.9163, 'grad_norm': 1.1138277053833008, 'learning_rate': 9.859904176028362e-05, 'epoch': 0.31}
{'loss': 1.0379, 'grad_norm': 1.0534601211547852, 'learning_rate': 9.85943900300897e-05, 'epoch': 0.31}
{'loss': 1.0509, 'grad_norm': 1.0486798286437988, 'learning_rate': 9.858973070000406e-05, 'epoch': 0.31}
{'loss': 0.9833, 'grad_norm': 1.27480947971344, 'learning_rate': 9.858506377075542e-05, 'epoch': 0.31}
{'loss': 0.8251, 'grad_norm': 1.2859852313995361, 'learning_rate': 9.858038924307364e-05, 'epoch': 0.31}
[1m[33mswanlab[0m[0m: Step 850 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 850 on key train/global_step already exists, ignored.
{'eval_loss': 0.7732362747192383, 'eval_runtime': 327.2529, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.31}
{'loss': 0.5991, 'grad_norm': 0.8009073138237, 'learning_rate': 9.85757071176898e-05, 'epoch': 0.31}
{'loss': 0.6399, 'grad_norm': 1.4325305223464966, 'learning_rate': 9.857101739533616e-05, 'epoch': 0.31}
{'loss': 0.5126, 'grad_norm': 0.8361289501190186, 'learning_rate': 9.856632007674616e-05, 'epoch': 0.31}
{'loss': 0.8523, 'grad_norm': 1.194187879562378, 'learning_rate': 9.856161516265444e-05, 'epoch': 0.31}
{'loss': 1.0713, 'grad_norm': 1.0777673721313477, 'learning_rate': 9.855690265379682e-05, 'epoch': 0.31}
{'loss': 0.8858, 'grad_norm': 1.1318018436431885, 'learning_rate': 9.855218255091032e-05, 'epoch': 0.31}
{'loss': 0.6429, 'grad_norm': 0.9378726482391357, 'learning_rate': 9.85474548547331e-05, 'epoch': 0.31}
{'loss': 0.9921, 'grad_norm': 1.1639407873153687, 'learning_rate': 9.854271956600462e-05, 'epoch': 0.31}
{'loss': 1.0737, 'grad_norm': 1.350834608078003, 'learning_rate': 9.853797668546538e-05, 'epoch': 0.31}
{'loss': 0.7646, 'grad_norm': 1.2679954767227173, 'learning_rate': 9.853322621385716e-05, 'epoch': 0.32}
[1m[33mswanlab[0m[0m: Step 860 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 860 on key train/global_step already exists, ignored.
{'eval_loss': 0.770867109298706, 'eval_runtime': 327.4814, 'eval_samples_per_second': 3.707, 'eval_steps_per_second': 3.707, 'epoch': 0.32}
{'loss': 0.9772, 'grad_norm': 1.176344633102417, 'learning_rate': 9.852846815192294e-05, 'epoch': 0.32}
{'loss': 0.8421, 'grad_norm': 1.122532844543457, 'learning_rate': 9.852370250040681e-05, 'epoch': 0.32}
{'loss': 0.774, 'grad_norm': 1.0954844951629639, 'learning_rate': 9.85189292600541e-05, 'epoch': 0.32}
{'loss': 0.821, 'grad_norm': 1.0062555074691772, 'learning_rate': 9.851414843161135e-05, 'epoch': 0.32}
{'loss': 0.4936, 'grad_norm': 1.0534112453460693, 'learning_rate': 9.850936001582622e-05, 'epoch': 0.32}
{'loss': 0.625, 'grad_norm': 1.011589527130127, 'learning_rate': 9.85045640134476e-05, 'epoch': 0.32}
{'loss': 0.715, 'grad_norm': 1.2455037832260132, 'learning_rate': 9.849976042522558e-05, 'epoch': 0.32}
{'loss': 0.3766, 'grad_norm': 0.8319311738014221, 'learning_rate': 9.849494925191138e-05, 'epoch': 0.32}
{'loss': 0.7702, 'grad_norm': 1.5536563396453857, 'learning_rate': 9.849013049425748e-05, 'epoch': 0.32}
{'loss': 0.6084, 'grad_norm': 1.1046972274780273, 'learning_rate': 9.848530415301747e-05, 'epoch': 0.32}
[1m[33mswanlab[0m[0m: Step 870 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 870 on key train/global_step already exists, ignored.
{'eval_loss': 0.7692927122116089, 'eval_runtime': 327.262, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.32}
{'loss': 0.7227, 'grad_norm': 1.2415125370025635, 'learning_rate': 9.848047022894617e-05, 'epoch': 0.32}
{'loss': 1.0913, 'grad_norm': 1.2451372146606445, 'learning_rate': 9.847562872279958e-05, 'epoch': 0.32}
{'loss': 1.057, 'grad_norm': 1.204676628112793, 'learning_rate': 9.847077963533491e-05, 'epoch': 0.32}
{'loss': 0.673, 'grad_norm': 0.965294361114502, 'learning_rate': 9.84659229673105e-05, 'epoch': 0.32}
{'loss': 0.7528, 'grad_norm': 0.8812766075134277, 'learning_rate': 9.846105871948593e-05, 'epoch': 0.32}
{'loss': 0.458, 'grad_norm': 0.707874596118927, 'learning_rate': 9.845618689262192e-05, 'epoch': 0.32}
{'loss': 0.9167, 'grad_norm': 1.2558364868164062, 'learning_rate': 9.845130748748041e-05, 'epoch': 0.32}
{'loss': 0.5695, 'grad_norm': 0.9629396796226501, 'learning_rate': 9.844642050482448e-05, 'epoch': 0.32}
{'loss': 0.5458, 'grad_norm': 0.9343413710594177, 'learning_rate': 9.844152594541848e-05, 'epoch': 0.32}
{'loss': 0.3364, 'grad_norm': 0.9498879909515381, 'learning_rate': 9.843662381002788e-05, 'epoch': 0.32}
[1m[33mswanlab[0m[0m: Step 880 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 880 on key train/global_step already exists, ignored.
{'eval_loss': 0.7720434665679932, 'eval_runtime': 327.4227, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.32}
{'loss': 0.7565, 'grad_norm': 1.2618563175201416, 'learning_rate': 9.843171409941929e-05, 'epoch': 0.32}
{'loss': 0.6665, 'grad_norm': 1.0626991987228394, 'learning_rate': 9.842679681436062e-05, 'epoch': 0.32}
{'loss': 1.0087, 'grad_norm': 1.3144457340240479, 'learning_rate': 9.842187195562089e-05, 'epoch': 0.32}
{'loss': 0.8487, 'grad_norm': 1.1430591344833374, 'learning_rate': 9.841693952397033e-05, 'epoch': 0.32}
{'loss': 0.5749, 'grad_norm': 0.9849126935005188, 'learning_rate': 9.841199952018032e-05, 'epoch': 0.32}
{'loss': 0.8848, 'grad_norm': 0.9876025319099426, 'learning_rate': 9.840705194502347e-05, 'epoch': 0.32}
{'loss': 0.9635, 'grad_norm': 1.1729395389556885, 'learning_rate': 9.840209679927355e-05, 'epoch': 0.32}
{'loss': 0.6427, 'grad_norm': 1.0619174242019653, 'learning_rate': 9.839713408370551e-05, 'epoch': 0.33}
{'loss': 0.7068, 'grad_norm': 1.104231595993042, 'learning_rate': 9.839216379909549e-05, 'epoch': 0.33}
{'loss': 0.2903, 'grad_norm': 0.9351949095726013, 'learning_rate': 9.838718594622083e-05, 'epoch': 0.33}
[1m[33mswanlab[0m[0m: Step 890 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 890 on key train/global_step already exists, ignored.
{'eval_loss': 0.7656203508377075, 'eval_runtime': 327.3797, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.33}
{'loss': 1.0011, 'grad_norm': 1.2678899765014648, 'learning_rate': 9.838220052586003e-05, 'epoch': 0.33}
{'loss': 0.5589, 'grad_norm': 0.9660629630088806, 'learning_rate': 9.837720753879276e-05, 'epoch': 0.33}
{'loss': 0.6187, 'grad_norm': 1.0385102033615112, 'learning_rate': 9.837220698579992e-05, 'epoch': 0.33}
{'loss': 0.7306, 'grad_norm': 1.2459887266159058, 'learning_rate': 9.836719886766356e-05, 'epoch': 0.33}
{'loss': 0.6926, 'grad_norm': 1.0523074865341187, 'learning_rate': 9.836218318516695e-05, 'epoch': 0.33}
{'loss': 0.9562, 'grad_norm': 1.4630014896392822, 'learning_rate': 9.835715993909447e-05, 'epoch': 0.33}
{'loss': 0.8283, 'grad_norm': 1.1869665384292603, 'learning_rate': 9.835212913023175e-05, 'epoch': 0.33}
{'loss': 0.4884, 'grad_norm': 0.9427247643470764, 'learning_rate': 9.834709075936558e-05, 'epoch': 0.33}
{'loss': 0.9608, 'grad_norm': 1.1606805324554443, 'learning_rate': 9.834204482728394e-05, 'epoch': 0.33}
{'loss': 0.8896, 'grad_norm': 1.1623631715774536, 'learning_rate': 9.833699133477598e-05, 'epoch': 0.33}
[1m[33mswanlab[0m[0m: Step 900 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 900 on key train/global_step already exists, ignored.
{'eval_loss': 0.7645209431648254, 'eval_runtime': 327.2493, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.33}
{'loss': 0.8457, 'grad_norm': 1.3561530113220215, 'learning_rate': 9.833193028263202e-05, 'epoch': 0.33}
{'loss': 0.763, 'grad_norm': 1.0572583675384521, 'learning_rate': 9.83268616716436e-05, 'epoch': 0.33}
{'loss': 0.9348, 'grad_norm': 1.1050447225570679, 'learning_rate': 9.832178550260343e-05, 'epoch': 0.33}
{'loss': 0.4847, 'grad_norm': 1.0378488302230835, 'learning_rate': 9.831670177630536e-05, 'epoch': 0.33}
{'loss': 0.7146, 'grad_norm': 0.9310539364814758, 'learning_rate': 9.83116104935445e-05, 'epoch': 0.33}
{'loss': 0.9207, 'grad_norm': 1.0916906595230103, 'learning_rate': 9.830651165511706e-05, 'epoch': 0.33}
{'loss': 0.4522, 'grad_norm': 0.9482269883155823, 'learning_rate': 9.83014052618205e-05, 'epoch': 0.33}
{'loss': 1.0197, 'grad_norm': 1.0866763591766357, 'learning_rate': 9.829629131445342e-05, 'epoch': 0.33}
{'loss': 1.0493, 'grad_norm': 1.1825202703475952, 'learning_rate': 9.829116981381561e-05, 'epoch': 0.33}
{'loss': 0.4898, 'grad_norm': 0.852511465549469, 'learning_rate': 9.828604076070804e-05, 'epoch': 0.33}
[1m[33mswanlab[0m[0m: Step 910 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 910 on key train/global_step already exists, ignored.
{'eval_loss': 0.7627753615379333, 'eval_runtime': 327.1736, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.33}
{'loss': 0.5835, 'grad_norm': 0.8720936179161072, 'learning_rate': 9.828090415593288e-05, 'epoch': 0.33}
{'loss': 0.9893, 'grad_norm': 1.113255262374878, 'learning_rate': 9.827576000029344e-05, 'epoch': 0.33}
{'loss': 0.8246, 'grad_norm': 1.1843687295913696, 'learning_rate': 9.827060829459427e-05, 'epoch': 0.33}
{'loss': 0.6322, 'grad_norm': 0.8423638343811035, 'learning_rate': 9.826544903964105e-05, 'epoch': 0.33}
{'loss': 0.8879, 'grad_norm': 1.056490421295166, 'learning_rate': 9.826028223624067e-05, 'epoch': 0.34}
{'loss': 0.9999, 'grad_norm': 1.1328520774841309, 'learning_rate': 9.825510788520115e-05, 'epoch': 0.34}
{'loss': 0.8819, 'grad_norm': 0.8787379264831543, 'learning_rate': 9.824992598733179e-05, 'epoch': 0.34}
{'loss': 0.5745, 'grad_norm': 0.8312644958496094, 'learning_rate': 9.824473654344297e-05, 'epoch': 0.34}
{'loss': 1.0439, 'grad_norm': 1.1996480226516724, 'learning_rate': 9.82395395543463e-05, 'epoch': 0.34}
{'loss': 0.8651, 'grad_norm': 1.2311816215515137, 'learning_rate': 9.823433502085457e-05, 'epoch': 0.34}
[1m[33mswanlab[0m[0m: Step 920 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 920 on key train/global_step already exists, ignored.
{'eval_loss': 0.7612864375114441, 'eval_runtime': 327.3456, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.34}
{'loss': 1.0068, 'grad_norm': 1.3041355609893799, 'learning_rate': 9.822912294378173e-05, 'epoch': 0.34}
{'loss': 0.9916, 'grad_norm': 1.2931513786315918, 'learning_rate': 9.822390332394291e-05, 'epoch': 0.34}
{'loss': 0.8383, 'grad_norm': 1.4038472175598145, 'learning_rate': 9.821867616215444e-05, 'epoch': 0.34}
{'loss': 0.3265, 'grad_norm': 0.8383054733276367, 'learning_rate': 9.821344145923381e-05, 'epoch': 0.34}
{'loss': 0.9019, 'grad_norm': 1.1307048797607422, 'learning_rate': 9.820819921599973e-05, 'epoch': 0.34}
{'loss': 0.8181, 'grad_norm': 1.0510389804840088, 'learning_rate': 9.820294943327201e-05, 'epoch': 0.34}
{'loss': 0.5644, 'grad_norm': 1.0634840726852417, 'learning_rate': 9.819769211187174e-05, 'epoch': 0.34}
{'loss': 0.4753, 'grad_norm': 0.8968350291252136, 'learning_rate': 9.819242725262108e-05, 'epoch': 0.34}
{'loss': 0.663, 'grad_norm': 1.1967413425445557, 'learning_rate': 9.818715485634347e-05, 'epoch': 0.34}
{'loss': 0.4718, 'grad_norm': 0.9889925122261047, 'learning_rate': 9.818187492386346e-05, 'epoch': 0.34}
[1m[33mswanlab[0m[0m: Step 930 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 930 on key train/global_step already exists, ignored.
{'eval_loss': 0.7592704892158508, 'eval_runtime': 327.1728, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.34}
{'loss': 0.8262, 'grad_norm': 1.0418626070022583, 'learning_rate': 9.817658745600682e-05, 'epoch': 0.34}
{'loss': 0.6334, 'grad_norm': 1.2074071168899536, 'learning_rate': 9.817129245360045e-05, 'epoch': 0.34}
{'loss': 0.5937, 'grad_norm': 0.9383836388587952, 'learning_rate': 9.816598991747248e-05, 'epoch': 0.34}
{'loss': 0.8004, 'grad_norm': 1.3374853134155273, 'learning_rate': 9.816067984845219e-05, 'epoch': 0.34}
{'loss': 0.8071, 'grad_norm': 0.9805819392204285, 'learning_rate': 9.815536224737005e-05, 'epoch': 0.34}
{'loss': 0.6584, 'grad_norm': 1.1915425062179565, 'learning_rate': 9.815003711505772e-05, 'epoch': 0.34}
{'loss': 0.8597, 'grad_norm': 1.1640576124191284, 'learning_rate': 9.814470445234798e-05, 'epoch': 0.34}
{'loss': 0.7501, 'grad_norm': 1.1025605201721191, 'learning_rate': 9.813936426007487e-05, 'epoch': 0.34}
{'loss': 0.6797, 'grad_norm': 1.1659200191497803, 'learning_rate': 9.813401653907353e-05, 'epoch': 0.34}
{'loss': 1.0001, 'grad_norm': 1.2829374074935913, 'learning_rate': 9.812866129018035e-05, 'epoch': 0.34}
[1m[33mswanlab[0m[0m: Step 940 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 940 on key train/global_step already exists, ignored.
{'eval_loss': 0.7600950598716736, 'eval_runtime': 327.4396, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.34}
{'loss': 0.8745, 'grad_norm': 1.2248430252075195, 'learning_rate': 9.812329851423283e-05, 'epoch': 0.34}
{'loss': 0.7711, 'grad_norm': 0.9027082920074463, 'learning_rate': 9.811792821206969e-05, 'epoch': 0.35}
{'loss': 0.6153, 'grad_norm': 1.0369566679000854, 'learning_rate': 9.811255038453082e-05, 'epoch': 0.35}
{'loss': 0.9313, 'grad_norm': 1.3949699401855469, 'learning_rate': 9.810716503245729e-05, 'epoch': 0.35}
{'loss': 1.0042, 'grad_norm': 1.2478952407836914, 'learning_rate': 9.810177215669132e-05, 'epoch': 0.35}
{'loss': 0.864, 'grad_norm': 1.1814417839050293, 'learning_rate': 9.809637175807634e-05, 'epoch': 0.35}
{'loss': 0.844, 'grad_norm': 1.0287998914718628, 'learning_rate': 9.80909638374569e-05, 'epoch': 0.35}
{'loss': 0.9557, 'grad_norm': 1.3256025314331055, 'learning_rate': 9.808554839567885e-05, 'epoch': 0.35}
{'loss': 0.8718, 'grad_norm': 1.3112703561782837, 'learning_rate': 9.808012543358906e-05, 'epoch': 0.35}
{'loss': 0.5945, 'grad_norm': 0.9695655703544617, 'learning_rate': 9.807469495203569e-05, 'epoch': 0.35}
[1m[33mswanlab[0m[0m: Step 950 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 950 on key train/global_step already exists, ignored.
{'eval_loss': 0.7567372918128967, 'eval_runtime': 327.3581, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.35}
{'loss': 0.6246, 'grad_norm': 1.1786280870437622, 'learning_rate': 9.806925695186804e-05, 'epoch': 0.35}
{'loss': 0.8303, 'grad_norm': 1.1194394826889038, 'learning_rate': 9.806381143393656e-05, 'epoch': 0.35}
{'loss': 0.8908, 'grad_norm': 0.9049245119094849, 'learning_rate': 9.80583583990929e-05, 'epoch': 0.35}
{'loss': 1.1789, 'grad_norm': 1.258041262626648, 'learning_rate': 9.805289784818991e-05, 'epoch': 0.35}
{'loss': 0.5002, 'grad_norm': 0.8707952499389648, 'learning_rate': 9.804742978208156e-05, 'epoch': 0.35}
{'loss': 0.5833, 'grad_norm': 0.9960780739784241, 'learning_rate': 9.804195420162305e-05, 'epoch': 0.35}
{'loss': 0.693, 'grad_norm': 1.306080937385559, 'learning_rate': 9.80364711076707e-05, 'epoch': 0.35}
{'loss': 0.846, 'grad_norm': 1.271544337272644, 'learning_rate': 9.803098050108205e-05, 'epoch': 0.35}
{'loss': 0.8417, 'grad_norm': 1.1751207113265991, 'learning_rate': 9.802548238271583e-05, 'epoch': 0.35}
{'loss': 1.156, 'grad_norm': 1.374721884727478, 'learning_rate': 9.801997675343189e-05, 'epoch': 0.35}
[1m[33mswanlab[0m[0m: Step 960 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 960 on key train/global_step already exists, ignored.
{'eval_loss': 0.7541972398757935, 'eval_runtime': 327.1486, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.35}
{'loss': 0.6776, 'grad_norm': 1.1367096900939941, 'learning_rate': 9.801446361409125e-05, 'epoch': 0.35}
{'loss': 0.6492, 'grad_norm': 0.9844064712524414, 'learning_rate': 9.800894296555618e-05, 'epoch': 0.35}
{'loss': 0.9081, 'grad_norm': 1.067413330078125, 'learning_rate': 9.800341480869006e-05, 'epoch': 0.35}
{'loss': 0.933, 'grad_norm': 1.1371705532073975, 'learning_rate': 9.799787914435747e-05, 'epoch': 0.35}
{'loss': 0.5984, 'grad_norm': 1.1732884645462036, 'learning_rate': 9.799233597342414e-05, 'epoch': 0.35}
{'loss': 0.7774, 'grad_norm': 1.1243844032287598, 'learning_rate': 9.7986785296757e-05, 'epoch': 0.35}
{'loss': 0.6759, 'grad_norm': 1.0725167989730835, 'learning_rate': 9.798122711522418e-05, 'epoch': 0.35}
{'loss': 0.6494, 'grad_norm': 1.050357699394226, 'learning_rate': 9.797566142969488e-05, 'epoch': 0.35}
{'loss': 0.5241, 'grad_norm': 1.2919644117355347, 'learning_rate': 9.79700882410396e-05, 'epoch': 0.35}
{'loss': 0.8622, 'grad_norm': 1.1615428924560547, 'learning_rate': 9.796450755012991e-05, 'epoch': 0.36}
[1m[33mswanlab[0m[0m: Step 970 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 970 on key train/global_step already exists, ignored.
{'eval_loss': 0.75200355052948, 'eval_runtime': 327.0941, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.36}
{'loss': 0.6718, 'grad_norm': 1.0100725889205933, 'learning_rate': 9.795891935783864e-05, 'epoch': 0.36}
{'loss': 0.3324, 'grad_norm': 0.7357797026634216, 'learning_rate': 9.795332366503973e-05, 'epoch': 0.36}
{'loss': 0.7519, 'grad_norm': 1.1396440267562866, 'learning_rate': 9.794772047260832e-05, 'epoch': 0.36}
{'loss': 1.0384, 'grad_norm': 1.3570111989974976, 'learning_rate': 9.794210978142072e-05, 'epoch': 0.36}
{'loss': 1.142, 'grad_norm': 1.3632065057754517, 'learning_rate': 9.793649159235441e-05, 'epoch': 0.36}
{'loss': 0.602, 'grad_norm': 1.1707762479782104, 'learning_rate': 9.793086590628804e-05, 'epoch': 0.36}
{'loss': 1.1762, 'grad_norm': 1.203464150428772, 'learning_rate': 9.792523272410143e-05, 'epoch': 0.36}
{'loss': 0.9281, 'grad_norm': 1.303985595703125, 'learning_rate': 9.79195920466756e-05, 'epoch': 0.36}
{'loss': 0.8997, 'grad_norm': 1.0598905086517334, 'learning_rate': 9.791394387489271e-05, 'epoch': 0.36}
{'loss': 0.8023, 'grad_norm': 1.1625584363937378, 'learning_rate': 9.790828820963609e-05, 'epoch': 0.36}
[1m[33mswanlab[0m[0m: Step 980 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 980 on key train/global_step already exists, ignored.
{'eval_loss': 0.7505658268928528, 'eval_runtime': 327.2376, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.36}
{'loss': 0.3857, 'grad_norm': 0.9506374001502991, 'learning_rate': 9.790262505179026e-05, 'epoch': 0.36}
{'loss': 0.8279, 'grad_norm': 1.3643198013305664, 'learning_rate': 9.789695440224093e-05, 'epoch': 0.36}
{'loss': 0.6401, 'grad_norm': 1.24534273147583, 'learning_rate': 9.789127626187494e-05, 'epoch': 0.36}
{'loss': 0.692, 'grad_norm': 1.2048041820526123, 'learning_rate': 9.78855906315803e-05, 'epoch': 0.36}
{'loss': 0.8556, 'grad_norm': 1.1675148010253906, 'learning_rate': 9.787989751224622e-05, 'epoch': 0.36}
{'loss': 1.0203, 'grad_norm': 1.2845025062561035, 'learning_rate': 9.787419690476309e-05, 'epoch': 0.36}
{'loss': 0.9794, 'grad_norm': 1.1818854808807373, 'learning_rate': 9.786848881002245e-05, 'epoch': 0.36}
{'loss': 0.8711, 'grad_norm': 1.1942224502563477, 'learning_rate': 9.786277322891702e-05, 'epoch': 0.36}
{'loss': 0.8446, 'grad_norm': 1.1802453994750977, 'learning_rate': 9.785705016234065e-05, 'epoch': 0.36}
{'loss': 0.6593, 'grad_norm': 1.0423508882522583, 'learning_rate': 9.785131961118844e-05, 'epoch': 0.36}
[1m[33mswanlab[0m[0m: Step 990 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 990 on key train/global_step already exists, ignored.
{'eval_loss': 0.7486959099769592, 'eval_runtime': 327.2053, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.36}
{'loss': 0.9901, 'grad_norm': 1.1059452295303345, 'learning_rate': 9.784558157635657e-05, 'epoch': 0.36}
{'loss': 0.8658, 'grad_norm': 1.1842581033706665, 'learning_rate': 9.783983605874248e-05, 'epoch': 0.36}
{'loss': 0.5326, 'grad_norm': 1.102605938911438, 'learning_rate': 9.783408305924472e-05, 'epoch': 0.36}
{'loss': 0.8932, 'grad_norm': 1.048669695854187, 'learning_rate': 9.782832257876302e-05, 'epoch': 0.36}
{'loss': 0.9832, 'grad_norm': 1.2197686433792114, 'learning_rate': 9.782255461819829e-05, 'epoch': 0.36}
{'loss': 1.0868, 'grad_norm': 0.936531126499176, 'learning_rate': 9.781677917845262e-05, 'epoch': 0.36}
{'loss': 0.8361, 'grad_norm': 1.2299665212631226, 'learning_rate': 9.781099626042924e-05, 'epoch': 0.37}
{'loss': 0.5528, 'grad_norm': 1.1293967962265015, 'learning_rate': 9.780520586503258e-05, 'epoch': 0.37}
{'loss': 0.7283, 'grad_norm': 1.2500337362289429, 'learning_rate': 9.779940799316821e-05, 'epoch': 0.37}
{'loss': 0.9616, 'grad_norm': 1.2410144805908203, 'learning_rate': 9.77936026457429e-05, 'epoch': 0.37}
[1m[33mswanlab[0m[0m: Step 1000 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1000 on key train/global_step already exists, ignored.
{'eval_loss': 0.7468338012695312, 'eval_runtime': 327.1221, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.37}
{'loss': 0.9333, 'grad_norm': 1.1073404550552368, 'learning_rate': 9.778778982366456e-05, 'epoch': 0.37}
{'loss': 0.5281, 'grad_norm': 1.0993115901947021, 'learning_rate': 9.778196952784229e-05, 'epoch': 0.37}
{'loss': 0.4245, 'grad_norm': 0.7856203317642212, 'learning_rate': 9.777614175918636e-05, 'epoch': 0.37}
{'loss': 0.8975, 'grad_norm': 1.3514466285705566, 'learning_rate': 9.777030651860819e-05, 'epoch': 0.37}
{'loss': 0.7812, 'grad_norm': 1.1188114881515503, 'learning_rate': 9.776446380702037e-05, 'epoch': 0.37}
{'loss': 0.5006, 'grad_norm': 0.9767030477523804, 'learning_rate': 9.77586136253367e-05, 'epoch': 0.37}
{'loss': 0.8184, 'grad_norm': 1.293859839439392, 'learning_rate': 9.775275597447208e-05, 'epoch': 0.37}
{'loss': 1.0637, 'grad_norm': 1.5133970975875854, 'learning_rate': 9.774689085534263e-05, 'epoch': 0.37}
{'loss': 1.3363, 'grad_norm': 1.1703358888626099, 'learning_rate': 9.774101826886561e-05, 'epoch': 0.37}
{'loss': 0.6152, 'grad_norm': 0.869731068611145, 'learning_rate': 9.77351382159595e-05, 'epoch': 0.37}
[1m[33mswanlab[0m[0m: Step 1010 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1010 on key train/global_step already exists, ignored.
{'eval_loss': 0.7492358088493347, 'eval_runtime': 327.1637, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.37}
{'loss': 0.6982, 'grad_norm': 1.0465480089187622, 'learning_rate': 9.772925069754386e-05, 'epoch': 0.37}
{'loss': 0.4114, 'grad_norm': 1.852435827255249, 'learning_rate': 9.772335571453947e-05, 'epoch': 0.37}
{'loss': 0.8293, 'grad_norm': 1.2009365558624268, 'learning_rate': 9.771745326786831e-05, 'epoch': 0.37}
{'loss': 1.0111, 'grad_norm': 1.3534619808197021, 'learning_rate': 9.771154335845345e-05, 'epoch': 0.37}
{'loss': 0.765, 'grad_norm': 1.464500904083252, 'learning_rate': 9.77056259872192e-05, 'epoch': 0.37}
{'loss': 0.5418, 'grad_norm': 0.8290925621986389, 'learning_rate': 9.769970115509098e-05, 'epoch': 0.37}
{'loss': 0.2801, 'grad_norm': 0.9169389605522156, 'learning_rate': 9.769376886299538e-05, 'epoch': 0.37}
{'loss': 0.6115, 'grad_norm': 1.0434982776641846, 'learning_rate': 9.768782911186022e-05, 'epoch': 0.37}
{'loss': 0.8689, 'grad_norm': 1.393538236618042, 'learning_rate': 9.768188190261444e-05, 'epoch': 0.37}
{'loss': 0.7882, 'grad_norm': 1.876379370689392, 'learning_rate': 9.767592723618813e-05, 'epoch': 0.37}
[1m[33mswanlab[0m[0m: Step 1020 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1020 on key train/global_step already exists, ignored.
{'eval_loss': 0.7475573420524597, 'eval_runtime': 327.1096, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.37}
{'loss': 0.7328, 'grad_norm': 1.2036547660827637, 'learning_rate': 9.766996511351259e-05, 'epoch': 0.37}
{'loss': 0.7575, 'grad_norm': 1.1195441484451294, 'learning_rate': 9.766399553552021e-05, 'epoch': 0.37}
{'loss': 0.6643, 'grad_norm': 1.209708333015442, 'learning_rate': 9.765801850314466e-05, 'epoch': 0.37}
{'loss': 0.7472, 'grad_norm': 0.9957442283630371, 'learning_rate': 9.76520340173207e-05, 'epoch': 0.38}
{'loss': 0.6209, 'grad_norm': 1.1523388624191284, 'learning_rate': 9.764604207898425e-05, 'epoch': 0.38}
{'loss': 0.6001, 'grad_norm': 1.0337855815887451, 'learning_rate': 9.764004268907243e-05, 'epoch': 0.38}
{'loss': 1.0852, 'grad_norm': 1.2038376331329346, 'learning_rate': 9.763403584852351e-05, 'epoch': 0.38}
{'loss': 0.7589, 'grad_norm': 0.9364312291145325, 'learning_rate': 9.762802155827693e-05, 'epoch': 0.38}
{'loss': 0.6025, 'grad_norm': 1.0817995071411133, 'learning_rate': 9.762199981927328e-05, 'epoch': 0.38}
{'loss': 1.1096, 'grad_norm': 1.4377063512802124, 'learning_rate': 9.761597063245433e-05, 'epoch': 0.38}
[1m[33mswanlab[0m[0m: Step 1030 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1030 on key train/global_step already exists, ignored.
{'eval_loss': 0.7455630898475647, 'eval_runtime': 327.1888, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.38}
{'loss': 1.0112, 'grad_norm': 1.1525287628173828, 'learning_rate': 9.760993399876301e-05, 'epoch': 0.38}
{'loss': 0.6186, 'grad_norm': 0.9730115532875061, 'learning_rate': 9.760388991914343e-05, 'epoch': 0.38}
{'loss': 1.1004, 'grad_norm': 1.1437536478042603, 'learning_rate': 9.759783839454084e-05, 'epoch': 0.38}
{'loss': 0.9835, 'grad_norm': 1.1293890476226807, 'learning_rate': 9.759177942590165e-05, 'epoch': 0.38}
{'loss': 0.864, 'grad_norm': 1.1966205835342407, 'learning_rate': 9.758571301417347e-05, 'epoch': 0.38}
{'loss': 0.7015, 'grad_norm': 1.017713189125061, 'learning_rate': 9.757963916030505e-05, 'epoch': 0.38}
{'loss': 0.8787, 'grad_norm': 1.249738335609436, 'learning_rate': 9.757355786524632e-05, 'epoch': 0.38}
{'loss': 0.9722, 'grad_norm': 1.1923846006393433, 'learning_rate': 9.756746912994832e-05, 'epoch': 0.38}
{'loss': 0.833, 'grad_norm': 1.0806572437286377, 'learning_rate': 9.756137295536333e-05, 'epoch': 0.38}
{'loss': 1.1019, 'grad_norm': 1.1726200580596924, 'learning_rate': 9.755526934244475e-05, 'epoch': 0.38}
[1m[33mswanlab[0m[0m: Step 1040 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1040 on key train/global_step already exists, ignored.
{'eval_loss': 0.7406055927276611, 'eval_runtime': 326.9782, 'eval_samples_per_second': 3.713, 'eval_steps_per_second': 3.713, 'epoch': 0.38}
{'loss': 0.911, 'grad_norm': 0.9777591824531555, 'learning_rate': 9.754915829214713e-05, 'epoch': 0.38}
{'loss': 0.7141, 'grad_norm': 0.9028063416481018, 'learning_rate': 9.754303980542623e-05, 'epoch': 0.38}
{'loss': 0.7708, 'grad_norm': 1.44351065158844, 'learning_rate': 9.753691388323894e-05, 'epoch': 0.38}
{'loss': 0.2733, 'grad_norm': 0.9021912217140198, 'learning_rate': 9.753078052654332e-05, 'epoch': 0.38}
{'loss': 0.7673, 'grad_norm': 1.250643014907837, 'learning_rate': 9.752463973629859e-05, 'epoch': 0.38}
{'loss': 0.85, 'grad_norm': 1.2376303672790527, 'learning_rate': 9.751849151346513e-05, 'epoch': 0.38}
{'loss': 0.9325, 'grad_norm': 1.372674584388733, 'learning_rate': 9.75123358590045e-05, 'epoch': 0.38}
{'loss': 0.5738, 'grad_norm': 1.311962366104126, 'learning_rate': 9.750617277387942e-05, 'epoch': 0.38}
{'loss': 0.7542, 'grad_norm': 1.0933055877685547, 'learning_rate': 9.750000225905371e-05, 'epoch': 0.38}
{'loss': 0.8445, 'grad_norm': 1.1476072072982788, 'learning_rate': 9.749382431549248e-05, 'epoch': 0.38}
[1m[33mswanlab[0m[0m: Step 1050 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1050 on key train/global_step already exists, ignored.
{'eval_loss': 0.7380634546279907, 'eval_runtime': 327.2709, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.38}
{'loss': 0.9267, 'grad_norm': 1.1176480054855347, 'learning_rate': 9.748763894416186e-05, 'epoch': 0.38}
{'loss': 0.9597, 'grad_norm': 1.1329936981201172, 'learning_rate': 9.748144614602926e-05, 'epoch': 0.39}
{'loss': 0.5786, 'grad_norm': 0.912164568901062, 'learning_rate': 9.747524592206315e-05, 'epoch': 0.39}
{'loss': 0.869, 'grad_norm': 1.274705410003662, 'learning_rate': 9.746903827323324e-05, 'epoch': 0.39}
{'loss': 0.632, 'grad_norm': 1.1870931386947632, 'learning_rate': 9.746282320051037e-05, 'epoch': 0.39}
{'loss': 1.0047, 'grad_norm': 1.1214872598648071, 'learning_rate': 9.745660070486653e-05, 'epoch': 0.39}
{'loss': 0.7481, 'grad_norm': 1.23750901222229, 'learning_rate': 9.74503707872749e-05, 'epoch': 0.39}
{'loss': 0.7588, 'grad_norm': 1.021355390548706, 'learning_rate': 9.744413344870979e-05, 'epoch': 0.39}
{'loss': 0.3939, 'grad_norm': 0.9299391508102417, 'learning_rate': 9.74378886901467e-05, 'epoch': 0.39}
{'loss': 0.7567, 'grad_norm': 1.3727869987487793, 'learning_rate': 9.743163651256226e-05, 'epoch': 0.39}
[1m[33mswanlab[0m[0m: Step 1060 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1060 on key train/global_step already exists, ignored.
{'eval_loss': 0.7372454404830933, 'eval_runtime': 327.3795, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.39}
{'loss': 0.9666, 'grad_norm': 1.1149613857269287, 'learning_rate': 9.742537691693428e-05, 'epoch': 0.39}
{'loss': 0.6145, 'grad_norm': 0.9749336242675781, 'learning_rate': 9.741910990424174e-05, 'epoch': 0.39}
{'loss': 0.7274, 'grad_norm': 1.2709192037582397, 'learning_rate': 9.741283547546474e-05, 'epoch': 0.39}
{'loss': 0.9152, 'grad_norm': 1.2501808404922485, 'learning_rate': 9.740655363158458e-05, 'epoch': 0.39}
{'loss': 0.6523, 'grad_norm': 0.9793238639831543, 'learning_rate': 9.740026437358372e-05, 'epoch': 0.39}
{'loss': 0.6635, 'grad_norm': 1.1175546646118164, 'learning_rate': 9.739396770244574e-05, 'epoch': 0.39}
{'loss': 0.8475, 'grad_norm': 1.388317346572876, 'learning_rate': 9.738766361915542e-05, 'epoch': 0.39}
{'loss': 0.6661, 'grad_norm': 1.1236671209335327, 'learning_rate': 9.738135212469867e-05, 'epoch': 0.39}
{'loss': 0.8175, 'grad_norm': 1.2604398727416992, 'learning_rate': 9.737503322006259e-05, 'epoch': 0.39}
{'loss': 0.8613, 'grad_norm': 1.0604767799377441, 'learning_rate': 9.73687069062354e-05, 'epoch': 0.39}
[1m[33mswanlab[0m[0m: Step 1070 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1070 on key train/global_step already exists, ignored.
{'eval_loss': 0.733832836151123, 'eval_runtime': 327.4958, 'eval_samples_per_second': 3.707, 'eval_steps_per_second': 3.707, 'epoch': 0.39}
{'loss': 0.5569, 'grad_norm': 0.9099407196044922, 'learning_rate': 9.736237318420653e-05, 'epoch': 0.39}
{'loss': 0.8433, 'grad_norm': 1.2835382223129272, 'learning_rate': 9.73560320549665e-05, 'epoch': 0.39}
{'loss': 0.8528, 'grad_norm': 1.4890114068984985, 'learning_rate': 9.734968351950706e-05, 'epoch': 0.39}
{'loss': 0.9365, 'grad_norm': 1.2701643705368042, 'learning_rate': 9.734332757882108e-05, 'epoch': 0.39}
{'loss': 0.9227, 'grad_norm': 1.1355109214782715, 'learning_rate': 9.733696423390257e-05, 'epoch': 0.39}
{'loss': 0.4829, 'grad_norm': 0.9084652662277222, 'learning_rate': 9.733059348574676e-05, 'epoch': 0.39}
{'loss': 0.7554, 'grad_norm': 1.5553044080734253, 'learning_rate': 9.732421533534997e-05, 'epoch': 0.39}
{'loss': 0.3674, 'grad_norm': 1.0044233798980713, 'learning_rate': 9.73178297837097e-05, 'epoch': 0.39}
{'loss': 0.7713, 'grad_norm': 0.9621245861053467, 'learning_rate': 9.731143683182464e-05, 'epoch': 0.4}
{'loss': 0.8155, 'grad_norm': 1.1997791528701782, 'learning_rate': 9.730503648069462e-05, 'epoch': 0.4}
[1m[33mswanlab[0m[0m: Step 1080 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1080 on key train/global_step already exists, ignored.
{'eval_loss': 0.7342174053192139, 'eval_runtime': 327.5728, 'eval_samples_per_second': 3.706, 'eval_steps_per_second': 3.706, 'epoch': 0.4}
{'loss': 0.8209, 'grad_norm': 1.1819267272949219, 'learning_rate': 9.729862873132059e-05, 'epoch': 0.4}
{'loss': 1.0823, 'grad_norm': 1.3262872695922852, 'learning_rate': 9.729221358470468e-05, 'epoch': 0.4}
{'loss': 0.4652, 'grad_norm': 0.9332996010780334, 'learning_rate': 9.728579104185023e-05, 'epoch': 0.4}
{'loss': 0.3536, 'grad_norm': 1.109463095664978, 'learning_rate': 9.727936110376164e-05, 'epoch': 0.4}
{'loss': 1.1314, 'grad_norm': 1.1797829866409302, 'learning_rate': 9.727292377144455e-05, 'epoch': 0.4}
{'loss': 0.4318, 'grad_norm': 1.2105252742767334, 'learning_rate': 9.726647904590571e-05, 'epoch': 0.4}
{'loss': 0.8977, 'grad_norm': 1.3536924123764038, 'learning_rate': 9.726002692815304e-05, 'epoch': 0.4}
{'loss': 0.6594, 'grad_norm': 1.2360622882843018, 'learning_rate': 9.72535674191956e-05, 'epoch': 0.4}
{'loss': 0.6944, 'grad_norm': 1.1397552490234375, 'learning_rate': 9.724710052004365e-05, 'epoch': 0.4}
{'loss': 0.63, 'grad_norm': 1.208768367767334, 'learning_rate': 9.724062623170855e-05, 'epoch': 0.4}
[1m[33mswanlab[0m[0m: Step 1090 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1090 on key train/global_step already exists, ignored.
{'eval_loss': 0.7311382293701172, 'eval_runtime': 327.3476, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.4}
{'loss': 0.7369, 'grad_norm': 1.0643670558929443, 'learning_rate': 9.723414455520287e-05, 'epoch': 0.4}
{'loss': 0.9106, 'grad_norm': 1.0196017026901245, 'learning_rate': 9.722765549154029e-05, 'epoch': 0.4}
{'loss': 0.7113, 'grad_norm': 1.3225009441375732, 'learning_rate': 9.722115904173568e-05, 'epoch': 0.4}
{'loss': 0.748, 'grad_norm': 0.9014216661453247, 'learning_rate': 9.721465520680501e-05, 'epoch': 0.4}
{'loss': 1.0398, 'grad_norm': 1.0684127807617188, 'learning_rate': 9.720814398776547e-05, 'epoch': 0.4}
{'loss': 0.886, 'grad_norm': 1.2883429527282715, 'learning_rate': 9.72016253856354e-05, 'epoch': 0.4}
{'loss': 0.3099, 'grad_norm': 0.9016198515892029, 'learning_rate': 9.719509940143425e-05, 'epoch': 0.4}
{'loss': 0.8615, 'grad_norm': 1.0977634191513062, 'learning_rate': 9.718856603618263e-05, 'epoch': 0.4}
{'loss': 0.9303, 'grad_norm': 1.2195179462432861, 'learning_rate': 9.718202529090234e-05, 'epoch': 0.4}
{'loss': 0.88, 'grad_norm': 1.1458501815795898, 'learning_rate': 9.717547716661632e-05, 'epoch': 0.4}
[1m[33mswanlab[0m[0m: Step 1100 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1100 on key train/global_step already exists, ignored.
{'eval_loss': 0.7286005020141602, 'eval_runtime': 327.1596, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.4}
{'loss': 0.745, 'grad_norm': 1.046945333480835, 'learning_rate': 9.716892166434867e-05, 'epoch': 0.4}
{'loss': 0.5408, 'grad_norm': 1.063732385635376, 'learning_rate': 9.71623587851246e-05, 'epoch': 0.4}
{'loss': 0.719, 'grad_norm': 1.1669071912765503, 'learning_rate': 9.715578852997055e-05, 'epoch': 0.4}
{'loss': 0.3809, 'grad_norm': 0.8977034687995911, 'learning_rate': 9.714921089991403e-05, 'epoch': 0.4}
{'loss': 0.7175, 'grad_norm': 1.440247893333435, 'learning_rate': 9.714262589598378e-05, 'epoch': 0.4}
{'loss': 0.7113, 'grad_norm': 1.151671051979065, 'learning_rate': 9.713603351920964e-05, 'epoch': 0.41}
{'loss': 0.7543, 'grad_norm': 1.1319752931594849, 'learning_rate': 9.71294337706226e-05, 'epoch': 0.41}
{'loss': 0.7293, 'grad_norm': 1.0795537233352661, 'learning_rate': 9.712282665125488e-05, 'epoch': 0.41}
{'loss': 0.755, 'grad_norm': 1.2174640893936157, 'learning_rate': 9.711621216213973e-05, 'epoch': 0.41}
{'loss': 0.6377, 'grad_norm': 1.115134596824646, 'learning_rate': 9.710959030431167e-05, 'epoch': 0.41}
[1m[33mswanlab[0m[0m: Step 1110 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1110 on key train/global_step already exists, ignored.
{'eval_loss': 0.729058027267456, 'eval_runtime': 327.1043, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.41}
{'loss': 0.6426, 'grad_norm': 0.9092136025428772, 'learning_rate': 9.71029610788063e-05, 'epoch': 0.41}
{'loss': 0.6188, 'grad_norm': 1.020467758178711, 'learning_rate': 9.70963244866604e-05, 'epoch': 0.41}
{'loss': 0.9632, 'grad_norm': 1.274570345878601, 'learning_rate': 9.70896805289119e-05, 'epoch': 0.41}
{'loss': 0.5386, 'grad_norm': 1.059658408164978, 'learning_rate': 9.708302920659986e-05, 'epoch': 0.41}
{'loss': 0.4853, 'grad_norm': 0.9157177805900574, 'learning_rate': 9.707637052076453e-05, 'epoch': 0.41}
{'loss': 0.6738, 'grad_norm': 1.3580604791641235, 'learning_rate': 9.706970447244727e-05, 'epoch': 0.41}
{'loss': 0.4216, 'grad_norm': 1.0441052913665771, 'learning_rate': 9.706303106269066e-05, 'epoch': 0.41}
{'loss': 0.617, 'grad_norm': 1.04804265499115, 'learning_rate': 9.705635029253832e-05, 'epoch': 0.41}
{'loss': 1.1007, 'grad_norm': 1.6156656742095947, 'learning_rate': 9.704966216303512e-05, 'epoch': 0.41}
{'loss': 0.7588, 'grad_norm': 1.2036420106887817, 'learning_rate': 9.704296667522704e-05, 'epoch': 0.41}
[1m[33mswanlab[0m[0m: Step 1120 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1120 on key train/global_step already exists, ignored.
{'eval_loss': 0.7290172576904297, 'eval_runtime': 327.3067, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.41}
{'loss': 0.7884, 'grad_norm': 1.274336814880371, 'learning_rate': 9.703626383016122e-05, 'epoch': 0.41}
{'loss': 0.8855, 'grad_norm': 1.0918828248977661, 'learning_rate': 9.702955362888595e-05, 'epoch': 0.41}
{'loss': 0.6528, 'grad_norm': 1.118255376815796, 'learning_rate': 9.702283607245066e-05, 'epoch': 0.41}
{'loss': 0.7188, 'grad_norm': 1.2424495220184326, 'learning_rate': 9.701611116190595e-05, 'epoch': 0.41}
{'loss': 0.7632, 'grad_norm': 1.345710039138794, 'learning_rate': 9.700937889830355e-05, 'epoch': 0.41}
{'loss': 0.8445, 'grad_norm': 1.260467529296875, 'learning_rate': 9.700263928269635e-05, 'epoch': 0.41}
{'loss': 0.8577, 'grad_norm': 1.171414852142334, 'learning_rate': 9.699589231613837e-05, 'epoch': 0.41}
{'loss': 0.696, 'grad_norm': 1.15547776222229, 'learning_rate': 9.698913799968483e-05, 'epoch': 0.41}
{'loss': 0.8615, 'grad_norm': 1.294776439666748, 'learning_rate': 9.698237633439206e-05, 'epoch': 0.41}
{'loss': 0.8298, 'grad_norm': 0.9895334839820862, 'learning_rate': 9.697560732131753e-05, 'epoch': 0.41}
[1m[33mswanlab[0m[0m: Step 1130 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1130 on key train/global_step already exists, ignored.
{'eval_loss': 0.7290365695953369, 'eval_runtime': 327.1554, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.41}
{'loss': 0.777, 'grad_norm': 1.2588953971862793, 'learning_rate': 9.69688309615199e-05, 'epoch': 0.41}
{'loss': 1.0478, 'grad_norm': 1.2754989862442017, 'learning_rate': 9.696204725605891e-05, 'epoch': 0.41}
{'loss': 0.6708, 'grad_norm': 0.9502053260803223, 'learning_rate': 9.695525620599554e-05, 'epoch': 0.42}
{'loss': 0.6866, 'grad_norm': 1.259202241897583, 'learning_rate': 9.694845781239187e-05, 'epoch': 0.42}
{'loss': 1.1294, 'grad_norm': 1.1026870012283325, 'learning_rate': 9.694165207631111e-05, 'epoch': 0.42}
{'loss': 1.062, 'grad_norm': 1.241424798965454, 'learning_rate': 9.693483899881764e-05, 'epoch': 0.42}
{'loss': 0.5996, 'grad_norm': 0.9703335165977478, 'learning_rate': 9.6928018580977e-05, 'epoch': 0.42}
{'loss': 0.9629, 'grad_norm': 1.2015035152435303, 'learning_rate': 9.692119082385586e-05, 'epoch': 0.42}
{'loss': 0.9171, 'grad_norm': 1.225719928741455, 'learning_rate': 9.691435572852204e-05, 'epoch': 0.42}
{'loss': 0.4506, 'grad_norm': 1.0723364353179932, 'learning_rate': 9.690751329604452e-05, 'epoch': 0.42}
[1m[33mswanlab[0m[0m: Step 1140 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1140 on key train/global_step already exists, ignored.
{'eval_loss': 0.7245553135871887, 'eval_runtime': 326.9279, 'eval_samples_per_second': 3.713, 'eval_steps_per_second': 3.713, 'epoch': 0.42}
{'loss': 0.6002, 'grad_norm': 1.2595912218093872, 'learning_rate': 9.69006635274934e-05, 'epoch': 0.42}
{'loss': 0.6862, 'grad_norm': 1.122470498085022, 'learning_rate': 9.689380642393998e-05, 'epoch': 0.42}
{'loss': 0.4363, 'grad_norm': 0.9614905118942261, 'learning_rate': 9.688694198645663e-05, 'epoch': 0.42}
{'loss': 0.2816, 'grad_norm': 0.8695048689842224, 'learning_rate': 9.688007021611692e-05, 'epoch': 0.42}
{'loss': 0.8101, 'grad_norm': 1.2717418670654297, 'learning_rate': 9.687319111399558e-05, 'epoch': 0.42}
{'loss': 0.8121, 'grad_norm': 1.1632663011550903, 'learning_rate': 9.686630468116846e-05, 'epoch': 0.42}
{'loss': 0.6324, 'grad_norm': 1.1793689727783203, 'learning_rate': 9.685941091871254e-05, 'epoch': 0.42}
{'loss': 0.8595, 'grad_norm': 1.383225440979004, 'learning_rate': 9.685250982770597e-05, 'epoch': 0.42}
{'loss': 0.8991, 'grad_norm': 1.2944855690002441, 'learning_rate': 9.684560140922805e-05, 'epoch': 0.42}
{'loss': 0.8609, 'grad_norm': 1.2476311922073364, 'learning_rate': 9.683868566435922e-05, 'epoch': 0.42}
[1m[33mswanlab[0m[0m: Step 1150 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1150 on key train/global_step already exists, ignored.
{'eval_loss': 0.7237295508384705, 'eval_runtime': 327.6554, 'eval_samples_per_second': 3.705, 'eval_steps_per_second': 3.705, 'epoch': 0.42}
{'loss': 0.8882, 'grad_norm': 1.5429545640945435, 'learning_rate': 9.683176259418105e-05, 'epoch': 0.42}
{'loss': 0.8623, 'grad_norm': 1.4271893501281738, 'learning_rate': 9.682483219977629e-05, 'epoch': 0.42}
{'loss': 0.5269, 'grad_norm': 0.9882667064666748, 'learning_rate': 9.68178944822288e-05, 'epoch': 0.42}
{'loss': 0.4636, 'grad_norm': 0.9252533316612244, 'learning_rate': 9.68109494426236e-05, 'epoch': 0.42}
{'loss': 0.8434, 'grad_norm': 1.3515888452529907, 'learning_rate': 9.680399708204688e-05, 'epoch': 0.42}
{'loss': 0.926, 'grad_norm': 1.2459907531738281, 'learning_rate': 9.679703740158593e-05, 'epoch': 0.42}
{'loss': 0.7363, 'grad_norm': 1.353151798248291, 'learning_rate': 9.679007040232918e-05, 'epoch': 0.42}
{'loss': 0.7077, 'grad_norm': 1.3464953899383545, 'learning_rate': 9.678309608536626e-05, 'epoch': 0.42}
{'loss': 0.7852, 'grad_norm': 1.3816523551940918, 'learning_rate': 9.677611445178793e-05, 'epoch': 0.42}
{'loss': 0.7954, 'grad_norm': 1.2198331356048584, 'learning_rate': 9.676912550268604e-05, 'epoch': 0.42}
[1m[33mswanlab[0m[0m: Step 1160 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1160 on key train/global_step already exists, ignored.
{'eval_loss': 0.7203530073165894, 'eval_runtime': 327.402, 'eval_samples_per_second': 3.708, 'eval_steps_per_second': 3.708, 'epoch': 0.42}
{'loss': 0.7181, 'grad_norm': 1.1685866117477417, 'learning_rate': 9.676212923915365e-05, 'epoch': 0.43}
{'loss': 0.8677, 'grad_norm': 1.2869329452514648, 'learning_rate': 9.675512566228493e-05, 'epoch': 0.43}
{'loss': 0.5382, 'grad_norm': 1.249133586883545, 'learning_rate': 9.674811477317518e-05, 'epoch': 0.43}
{'loss': 1.0181, 'grad_norm': 1.2834572792053223, 'learning_rate': 9.67410965729209e-05, 'epoch': 0.43}
{'loss': 0.6201, 'grad_norm': 1.0592528581619263, 'learning_rate': 9.673407106261968e-05, 'epoch': 0.43}
{'loss': 1.1102, 'grad_norm': 1.2662451267242432, 'learning_rate': 9.672703824337026e-05, 'epoch': 0.43}
{'loss': 0.8773, 'grad_norm': 1.066486120223999, 'learning_rate': 9.671999811627256e-05, 'epoch': 0.43}
{'loss': 0.9811, 'grad_norm': 1.1617976427078247, 'learning_rate': 9.671295068242759e-05, 'epoch': 0.43}
{'loss': 0.4734, 'grad_norm': 0.8960211277008057, 'learning_rate': 9.670589594293755e-05, 'epoch': 0.43}
{'loss': 0.8055, 'grad_norm': 1.36154043674469, 'learning_rate': 9.669883389890573e-05, 'epoch': 0.43}
[1m[33mswanlab[0m[0m: Step 1170 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1170 on key train/global_step already exists, ignored.
{'eval_loss': 0.719220757484436, 'eval_runtime': 327.2669, 'eval_samples_per_second': 3.71, 'eval_steps_per_second': 3.71, 'epoch': 0.43}
{'loss': 0.7302, 'grad_norm': 1.0677167177200317, 'learning_rate': 9.669176455143662e-05, 'epoch': 0.43}
{'loss': 0.944, 'grad_norm': 1.1659815311431885, 'learning_rate': 9.668468790163584e-05, 'epoch': 0.43}
{'loss': 0.8921, 'grad_norm': 1.2360775470733643, 'learning_rate': 9.667760395061011e-05, 'epoch': 0.43}
{'loss': 0.8834, 'grad_norm': 1.1623984575271606, 'learning_rate': 9.667051269946735e-05, 'epoch': 0.43}
{'loss': 0.4448, 'grad_norm': 0.8305831551551819, 'learning_rate': 9.666341414931655e-05, 'epoch': 0.43}
{'loss': 0.84, 'grad_norm': 1.2378944158554077, 'learning_rate': 9.66563083012679e-05, 'epoch': 0.43}
{'loss': 0.6692, 'grad_norm': 1.0628231763839722, 'learning_rate': 9.664919515643276e-05, 'epoch': 0.43}
{'loss': 0.9726, 'grad_norm': 1.2796180248260498, 'learning_rate': 9.664207471592353e-05, 'epoch': 0.43}
{'loss': 1.0181, 'grad_norm': 1.2487188577651978, 'learning_rate': 9.663494698085381e-05, 'epoch': 0.43}
{'loss': 0.9101, 'grad_norm': 1.2356621026992798, 'learning_rate': 9.662781195233837e-05, 'epoch': 0.43}
[1m[33mswanlab[0m[0m: Step 1180 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1180 on key train/global_step already exists, ignored.
{'eval_loss': 0.7155988812446594, 'eval_runtime': 327.3065, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.43}
{'loss': 0.4418, 'grad_norm': 0.7560021877288818, 'learning_rate': 9.662066963149307e-05, 'epoch': 0.43}
{'loss': 1.0473, 'grad_norm': 1.3405693769454956, 'learning_rate': 9.661352001943493e-05, 'epoch': 0.43}
{'loss': 0.7663, 'grad_norm': 1.0085371732711792, 'learning_rate': 9.660636311728212e-05, 'epoch': 0.43}
{'loss': 0.7287, 'grad_norm': 0.9924250841140747, 'learning_rate': 9.659919892615393e-05, 'epoch': 0.43}
{'loss': 0.9987, 'grad_norm': 1.0363917350769043, 'learning_rate': 9.659202744717078e-05, 'epoch': 0.43}
{'loss': 0.8335, 'grad_norm': 1.3416215181350708, 'learning_rate': 9.658484868145429e-05, 'epoch': 0.43}
{'loss': 0.3599, 'grad_norm': 0.949804961681366, 'learning_rate': 9.657766263012715e-05, 'epoch': 0.43}
{'loss': 0.8141, 'grad_norm': 1.117350459098816, 'learning_rate': 9.657046929431324e-05, 'epoch': 0.44}
{'loss': 0.7496, 'grad_norm': 0.9193905591964722, 'learning_rate': 9.656326867513753e-05, 'epoch': 0.44}
{'loss': 0.9274, 'grad_norm': 1.3346081972122192, 'learning_rate': 9.655606077372618e-05, 'epoch': 0.44}
[1m[33mswanlab[0m[0m: Step 1190 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1190 on key train/global_step already exists, ignored.
{'eval_loss': 0.715469479560852, 'eval_runtime': 327.29, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.44}
{'loss': 0.7742, 'grad_norm': 1.2723034620285034, 'learning_rate': 9.654884559120646e-05, 'epoch': 0.44}
{'loss': 1.0154, 'grad_norm': 1.370092749595642, 'learning_rate': 9.654162312870677e-05, 'epoch': 0.44}
{'loss': 0.8297, 'grad_norm': 1.015793800354004, 'learning_rate': 9.653439338735669e-05, 'epoch': 0.44}
{'loss': 0.4369, 'grad_norm': 1.1564339399337769, 'learning_rate': 9.652715636828687e-05, 'epoch': 0.44}
{'loss': 0.8023, 'grad_norm': 1.2716490030288696, 'learning_rate': 9.651991207262918e-05, 'epoch': 0.44}
{'loss': 0.6121, 'grad_norm': 1.0381717681884766, 'learning_rate': 9.651266050151657e-05, 'epoch': 0.44}
{'loss': 0.9813, 'grad_norm': 1.4982566833496094, 'learning_rate': 9.650540165608315e-05, 'epoch': 0.44}
{'loss': 0.7494, 'grad_norm': 1.5675123929977417, 'learning_rate': 9.649813553746416e-05, 'epoch': 0.44}
{'loss': 0.4226, 'grad_norm': 0.9030483961105347, 'learning_rate': 9.649086214679599e-05, 'epoch': 0.44}
{'loss': 0.8512, 'grad_norm': 1.2961080074310303, 'learning_rate': 9.648358148521614e-05, 'epoch': 0.44}
[1m[33mswanlab[0m[0m: Step 1200 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1200 on key train/global_step already exists, ignored.
{'eval_loss': 0.7148517966270447, 'eval_runtime': 327.4837, 'eval_samples_per_second': 3.707, 'eval_steps_per_second': 3.707, 'epoch': 0.44}
{'loss': 0.8883, 'grad_norm': 1.240808129310608, 'learning_rate': 9.647629355386327e-05, 'epoch': 0.44}
{'loss': 0.978, 'grad_norm': 1.184745192527771, 'learning_rate': 9.646899835387719e-05, 'epoch': 0.44}
{'loss': 0.751, 'grad_norm': 1.2933979034423828, 'learning_rate': 9.64616958863988e-05, 'epoch': 0.44}
{'loss': 0.5706, 'grad_norm': 1.0720919370651245, 'learning_rate': 9.645438615257019e-05, 'epoch': 0.44}
{'loss': 0.9729, 'grad_norm': 1.1275339126586914, 'learning_rate': 9.644706915353454e-05, 'epoch': 0.44}
{'loss': 0.6888, 'grad_norm': 1.3230440616607666, 'learning_rate': 9.64397448904362e-05, 'epoch': 0.44}
{'loss': 1.071, 'grad_norm': 1.2715210914611816, 'learning_rate': 9.643241336442064e-05, 'epoch': 0.44}
{'loss': 0.4459, 'grad_norm': 0.900000810623169, 'learning_rate': 9.642507457663447e-05, 'epoch': 0.44}
{'loss': 0.9106, 'grad_norm': 1.0923316478729248, 'learning_rate': 9.641772852822545e-05, 'epoch': 0.44}
{'loss': 0.7294, 'grad_norm': 1.1705766916275024, 'learning_rate': 9.641037522034246e-05, 'epoch': 0.44}
[1m[33mswanlab[0m[0m: Step 1210 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1210 on key train/global_step already exists, ignored.
{'eval_loss': 0.7128203511238098, 'eval_runtime': 327.3389, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.44}
{'loss': 0.6784, 'grad_norm': 1.1198688745498657, 'learning_rate': 9.64030146541355e-05, 'epoch': 0.44}
{'loss': 0.7904, 'grad_norm': 1.2532726526260376, 'learning_rate': 9.63956468307557e-05, 'epoch': 0.44}
{'loss': 0.7532, 'grad_norm': 1.0595868825912476, 'learning_rate': 9.638827175135541e-05, 'epoch': 0.44}
{'loss': 0.8963, 'grad_norm': 1.3086423873901367, 'learning_rate': 9.638088941708799e-05, 'epoch': 0.44}
{'loss': 0.5249, 'grad_norm': 1.1372431516647339, 'learning_rate': 9.637349982910803e-05, 'epoch': 0.45}
{'loss': 0.4426, 'grad_norm': 0.7975536584854126, 'learning_rate': 9.636610298857121e-05, 'epoch': 0.45}
{'loss': 0.925, 'grad_norm': 1.435209035873413, 'learning_rate': 9.635869889663435e-05, 'epoch': 0.45}
{'loss': 0.8457, 'grad_norm': 1.3516138792037964, 'learning_rate': 9.635128755445541e-05, 'epoch': 0.45}
{'loss': 0.8966, 'grad_norm': 1.0652806758880615, 'learning_rate': 9.634386896319351e-05, 'epoch': 0.45}
{'loss': 0.8957, 'grad_norm': 1.327199101448059, 'learning_rate': 9.633644312400883e-05, 'epoch': 0.45}
[1m[33mswanlab[0m[0m: Step 1220 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1220 on key train/global_step already exists, ignored.
{'eval_loss': 0.7096975445747375, 'eval_runtime': 327.4688, 'eval_samples_per_second': 3.707, 'eval_steps_per_second': 3.707, 'epoch': 0.45}
{'loss': 0.9261, 'grad_norm': 1.231490969657898, 'learning_rate': 9.632901003806277e-05, 'epoch': 0.45}
{'loss': 0.7478, 'grad_norm': 1.1755698919296265, 'learning_rate': 9.63215697065178e-05, 'epoch': 0.45}
{'loss': 0.7768, 'grad_norm': 1.2419378757476807, 'learning_rate': 9.631412213053755e-05, 'epoch': 0.45}
{'loss': 0.6133, 'grad_norm': 0.9860924482345581, 'learning_rate': 9.630666731128678e-05, 'epoch': 0.45}
{'loss': 0.7015, 'grad_norm': 1.1494247913360596, 'learning_rate': 9.629920524993138e-05, 'epoch': 0.45}
{'loss': 0.6314, 'grad_norm': 1.2799384593963623, 'learning_rate': 9.629173594763839e-05, 'epoch': 0.45}
{'loss': 0.6991, 'grad_norm': 1.2646912336349487, 'learning_rate': 9.628425940557596e-05, 'epoch': 0.45}
{'loss': 1.0225, 'grad_norm': 1.4174396991729736, 'learning_rate': 9.627677562491337e-05, 'epoch': 0.45}
{'loss': 0.7756, 'grad_norm': 1.0866236686706543, 'learning_rate': 9.626928460682106e-05, 'epoch': 0.45}
{'loss': 0.7984, 'grad_norm': 1.1118324995040894, 'learning_rate': 9.626178635247054e-05, 'epoch': 0.45}
[1m[33mswanlab[0m[0m: Step 1230 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1230 on key train/global_step already exists, ignored.
{'eval_loss': 0.7093915343284607, 'eval_runtime': 327.5664, 'eval_samples_per_second': 3.706, 'eval_steps_per_second': 3.706, 'epoch': 0.45}
{'loss': 0.5886, 'grad_norm': 0.9200209975242615, 'learning_rate': 9.625428086303455e-05, 'epoch': 0.45}
{'loss': 1.039, 'grad_norm': 1.1880308389663696, 'learning_rate': 9.624676813968687e-05, 'epoch': 0.45}
{'loss': 0.6144, 'grad_norm': 1.407127857208252, 'learning_rate': 9.623924818360248e-05, 'epoch': 0.45}
{'loss': 0.7105, 'grad_norm': 1.2340667247772217, 'learning_rate': 9.623172099595743e-05, 'epoch': 0.45}
{'loss': 0.8463, 'grad_norm': 1.2997792959213257, 'learning_rate': 9.622418657792893e-05, 'epoch': 0.45}
{'loss': 0.7398, 'grad_norm': 1.0635383129119873, 'learning_rate': 9.621664493069533e-05, 'epoch': 0.45}
{'loss': 0.366, 'grad_norm': 1.1455693244934082, 'learning_rate': 9.620909605543612e-05, 'epoch': 0.45}
{'loss': 0.7822, 'grad_norm': 1.0235668420791626, 'learning_rate': 9.620153995333188e-05, 'epoch': 0.45}
{'loss': 0.6339, 'grad_norm': 1.279742956161499, 'learning_rate': 9.619397662556435e-05, 'epoch': 0.45}
{'loss': 0.8835, 'grad_norm': 1.5149728059768677, 'learning_rate': 9.618640607331637e-05, 'epoch': 0.45}
[1m[33mswanlab[0m[0m: Step 1240 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1240 on key train/global_step already exists, ignored.
{'eval_loss': 0.7066676616668701, 'eval_runtime': 327.5259, 'eval_samples_per_second': 3.707, 'eval_steps_per_second': 3.707, 'epoch': 0.45}
{'loss': 0.6181, 'grad_norm': 1.144757866859436, 'learning_rate': 9.617882829777198e-05, 'epoch': 0.45}
{'loss': 0.5138, 'grad_norm': 0.898604691028595, 'learning_rate': 9.617124330011624e-05, 'epoch': 0.45}
{'loss': 0.9172, 'grad_norm': 1.202249526977539, 'learning_rate': 9.616365108153547e-05, 'epoch': 0.46}
{'loss': 0.7455, 'grad_norm': 1.2417546510696411, 'learning_rate': 9.6156051643217e-05, 'epoch': 0.46}
{'loss': 0.8137, 'grad_norm': 1.286643385887146, 'learning_rate': 9.614844498634934e-05, 'epoch': 0.46}
{'loss': 0.86, 'grad_norm': 1.2280532121658325, 'learning_rate': 9.614083111212216e-05, 'epoch': 0.46}
{'loss': 0.7014, 'grad_norm': 1.3524885177612305, 'learning_rate': 9.613321002172622e-05, 'epoch': 0.46}
{'loss': 0.7591, 'grad_norm': 1.2973774671554565, 'learning_rate': 9.612558171635338e-05, 'epoch': 0.46}
{'loss': 0.7661, 'grad_norm': 1.1641961336135864, 'learning_rate': 9.611794619719671e-05, 'epoch': 0.46}
{'loss': 0.6287, 'grad_norm': 2.8230698108673096, 'learning_rate': 9.611030346545035e-05, 'epoch': 0.46}
[1m[33mswanlab[0m[0m: Step 1250 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1250 on key train/global_step already exists, ignored.
{'eval_loss': 0.7065222263336182, 'eval_runtime': 327.2901, 'eval_samples_per_second': 3.709, 'eval_steps_per_second': 3.709, 'epoch': 0.46}
{'loss': 0.4892, 'grad_norm': 1.119346022605896, 'learning_rate': 9.610265352230956e-05, 'epoch': 0.46}
{'loss': 0.6682, 'grad_norm': 1.2806673049926758, 'learning_rate': 9.609499636897077e-05, 'epoch': 0.46}
{'loss': 0.2402, 'grad_norm': 0.9317693114280701, 'learning_rate': 9.608733200663151e-05, 'epoch': 0.46}
{'loss': 0.3648, 'grad_norm': 1.0685707330703735, 'learning_rate': 9.607966043649046e-05, 'epoch': 0.46}
{'loss': 0.5946, 'grad_norm': 1.3905078172683716, 'learning_rate': 9.607198165974738e-05, 'epoch': 0.46}
{'loss': 1.0235, 'grad_norm': 3.0971407890319824, 'learning_rate': 9.606429567760319e-05, 'epoch': 0.46}
{'loss': 0.6361, 'grad_norm': 1.4192543029785156, 'learning_rate': 9.605660249125996e-05, 'epoch': 0.46}
{'loss': 0.6856, 'grad_norm': 1.016917109489441, 'learning_rate': 9.604890210192085e-05, 'epoch': 0.46}
{'loss': 0.8948, 'grad_norm': 1.2760342359542847, 'learning_rate': 9.604119451079015e-05, 'epoch': 0.46}
{'loss': 0.5674, 'grad_norm': 0.9377330541610718, 'learning_rate': 9.603347971907328e-05, 'epoch': 0.46}
[1m[33mswanlab[0m[0m: Step 1260 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1260 on key train/global_step already exists, ignored.
{'eval_loss': 0.7061220407485962, 'eval_runtime': 327.0154, 'eval_samples_per_second': 3.712, 'eval_steps_per_second': 3.712, 'epoch': 0.46}
{'loss': 0.7724, 'grad_norm': 1.3685868978500366, 'learning_rate': 9.602575772797682e-05, 'epoch': 0.46}
{'loss': 0.7361, 'grad_norm': 1.1051931381225586, 'learning_rate': 9.601802853870843e-05, 'epoch': 0.46}
{'loss': 0.9149, 'grad_norm': 1.1235417127609253, 'learning_rate': 9.601029215247689e-05, 'epoch': 0.46}
{'loss': 1.0873, 'grad_norm': 1.39596426486969, 'learning_rate': 9.600254857049215e-05, 'epoch': 0.46}
{'loss': 0.3967, 'grad_norm': 1.0526740550994873, 'learning_rate': 9.599479779396528e-05, 'epoch': 0.46}
{'loss': 0.6909, 'grad_norm': 1.171878457069397, 'learning_rate': 9.598703982410842e-05, 'epoch': 0.46}
{'loss': 0.3512, 'grad_norm': 1.0235188007354736, 'learning_rate': 9.59792746621349e-05, 'epoch': 0.46}
{'loss': 0.634, 'grad_norm': 1.0186110734939575, 'learning_rate': 9.597150230925914e-05, 'epoch': 0.46}
{'loss': 0.9351, 'grad_norm': 1.4655170440673828, 'learning_rate': 9.596372276669667e-05, 'epoch': 0.46}
{'loss': 0.8279, 'grad_norm': 1.191089391708374, 'learning_rate': 9.595593603566422e-05, 'epoch': 0.47}
[1m[33mswanlab[0m[0m: Step 1270 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1270 on key train/global_step already exists, ignored.
{'eval_loss': 0.7045026421546936, 'eval_runtime': 326.8983, 'eval_samples_per_second': 3.714, 'eval_steps_per_second': 3.714, 'epoch': 0.47}
{'loss': 1.0863, 'grad_norm': 1.2936800718307495, 'learning_rate': 9.594814211737955e-05, 'epoch': 0.47}
{'loss': 0.807, 'grad_norm': 1.150005578994751, 'learning_rate': 9.594034101306159e-05, 'epoch': 0.47}
{'loss': 0.6327, 'grad_norm': 0.9702546000480652, 'learning_rate': 9.593253272393039e-05, 'epoch': 0.47}
{'loss': 0.3969, 'grad_norm': 0.9769794344902039, 'learning_rate': 9.592471725120714e-05, 'epoch': 0.47}
{'loss': 0.7679, 'grad_norm': 1.4004119634628296, 'learning_rate': 9.591689459611413e-05, 'epoch': 0.47}
{'loss': 0.761, 'grad_norm': 1.3859682083129883, 'learning_rate': 9.590906475987476e-05, 'epoch': 0.47}
{'loss': 0.7549, 'grad_norm': 1.040541172027588, 'learning_rate': 9.590122774371359e-05, 'epoch': 0.47}
{'loss': 0.8962, 'grad_norm': 1.1352590322494507, 'learning_rate': 9.589338354885629e-05, 'epoch': 0.47}
{'loss': 0.9494, 'grad_norm': 1.216615915298462, 'learning_rate': 9.588553217652962e-05, 'epoch': 0.47}
{'loss': 0.5677, 'grad_norm': 0.9420251846313477, 'learning_rate': 9.587767362796153e-05, 'epoch': 0.47}
[1m[33mswanlab[0m[0m: Step 1280 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1280 on key train/global_step already exists, ignored.
{'eval_loss': 0.7042204141616821, 'eval_runtime': 326.9005, 'eval_samples_per_second': 3.714, 'eval_steps_per_second': 3.714, 'epoch': 0.47}
{'loss': 0.5323, 'grad_norm': 1.219765543937683, 'learning_rate': 9.586980790438105e-05, 'epoch': 0.47}
{'loss': 0.8459, 'grad_norm': 1.3166252374649048, 'learning_rate': 9.58619350070183e-05, 'epoch': 0.47}
{'loss': 0.4451, 'grad_norm': 1.0667998790740967, 'learning_rate': 9.585405493710457e-05, 'epoch': 0.47}
{'loss': 0.9247, 'grad_norm': 1.6336212158203125, 'learning_rate': 9.584616769587229e-05, 'epoch': 0.47}
{'loss': 0.4769, 'grad_norm': 1.127168893814087, 'learning_rate': 9.583827328455494e-05, 'epoch': 0.47}
{'loss': 0.6809, 'grad_norm': 1.1243362426757812, 'learning_rate': 9.583037170438718e-05, 'epoch': 0.47}
{'loss': 0.8918, 'grad_norm': 1.6343134641647339, 'learning_rate': 9.582246295660478e-05, 'epoch': 0.47}
{'loss': 0.669, 'grad_norm': 1.2081178426742554, 'learning_rate': 9.58145470424446e-05, 'epoch': 0.47}
{'loss': 0.8622, 'grad_norm': 1.2694412469863892, 'learning_rate': 9.580662396314469e-05, 'epoch': 0.47}
{'loss': 0.5463, 'grad_norm': 1.0286532640457153, 'learning_rate': 9.579869371994413e-05, 'epoch': 0.47}
[1m[33mswanlab[0m[0m: Step 1290 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1290 on key train/global_step already exists, ignored.
{'eval_loss': 0.70130455493927, 'eval_runtime': 326.4077, 'eval_samples_per_second': 3.719, 'eval_steps_per_second': 3.719, 'epoch': 0.47}
{'loss': 0.5566, 'grad_norm': 1.178612470626831, 'learning_rate': 9.579075631408317e-05, 'epoch': 0.47}
{'loss': 0.6452, 'grad_norm': 1.3962150812149048, 'learning_rate': 9.57828117468032e-05, 'epoch': 0.47}
{'loss': 0.8396, 'grad_norm': 1.6736418008804321, 'learning_rate': 9.57748600193467e-05, 'epoch': 0.47}
{'loss': 0.5558, 'grad_norm': 1.0474839210510254, 'learning_rate': 9.576690113295725e-05, 'epoch': 0.47}
{'loss': 0.7522, 'grad_norm': 1.2454702854156494, 'learning_rate': 9.57589350888796e-05, 'epoch': 0.47}
{'loss': 0.7535, 'grad_norm': 1.170978307723999, 'learning_rate': 9.575096188835961e-05, 'epoch': 0.47}
{'loss': 0.8403, 'grad_norm': 1.2352946996688843, 'learning_rate': 9.574298153264422e-05, 'epoch': 0.48}
{'loss': 0.4101, 'grad_norm': 0.9333877563476562, 'learning_rate': 9.573499402298152e-05, 'epoch': 0.48}
{'loss': 0.8028, 'grad_norm': 1.3114326000213623, 'learning_rate': 9.572699936062069e-05, 'epoch': 0.48}
{'loss': 0.6739, 'grad_norm': 1.1433689594268799, 'learning_rate': 9.571899754681209e-05, 'epoch': 0.48}
[1m[33mswanlab[0m[0m: Step 1300 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1300 on key train/global_step already exists, ignored.
{'eval_loss': 0.6973986625671387, 'eval_runtime': 326.5842, 'eval_samples_per_second': 3.717, 'eval_steps_per_second': 3.717, 'epoch': 0.48}
{'loss': 0.8331, 'grad_norm': 0.9502914547920227, 'learning_rate': 9.571098858280713e-05, 'epoch': 0.48}
{'loss': 0.8301, 'grad_norm': 1.3518610000610352, 'learning_rate': 9.570297246985837e-05, 'epoch': 0.48}
{'loss': 0.4799, 'grad_norm': 1.0950876474380493, 'learning_rate': 9.569494920921951e-05, 'epoch': 0.48}
{'loss': 0.5319, 'grad_norm': 1.0390498638153076, 'learning_rate': 9.56869188021453e-05, 'epoch': 0.48}
{'loss': 0.5314, 'grad_norm': 1.0244216918945312, 'learning_rate': 9.56788812498917e-05, 'epoch': 0.48}
{'loss': 0.644, 'grad_norm': 1.2496397495269775, 'learning_rate': 9.567083655371571e-05, 'epoch': 0.48}
{'loss': 0.5308, 'grad_norm': 1.0181382894515991, 'learning_rate': 9.566278471487547e-05, 'epoch': 0.48}
{'loss': 0.401, 'grad_norm': 0.9698922038078308, 'learning_rate': 9.565472573463027e-05, 'epoch': 0.48}
{'loss': 0.7062, 'grad_norm': 1.2115306854248047, 'learning_rate': 9.564665961424046e-05, 'epoch': 0.48}
{'loss': 0.4437, 'grad_norm': 0.9246317744255066, 'learning_rate': 9.563858635496756e-05, 'epoch': 0.48}
[1m[33mswanlab[0m[0m: Step 1310 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1310 on key train/global_step already exists, ignored.
{'eval_loss': 0.6963239312171936, 'eval_runtime': 326.7095, 'eval_samples_per_second': 3.716, 'eval_steps_per_second': 3.716, 'epoch': 0.48}
{'loss': 0.2243, 'grad_norm': 0.6905509233474731, 'learning_rate': 9.563050595807415e-05, 'epoch': 0.48}
{'loss': 0.9116, 'grad_norm': 1.258551001548767, 'learning_rate': 9.5622418424824e-05, 'epoch': 0.48}
{'loss': 0.7581, 'grad_norm': 1.0642157793045044, 'learning_rate': 9.561432375648193e-05, 'epoch': 0.48}
{'loss': 0.5728, 'grad_norm': 1.1867033243179321, 'learning_rate': 9.56062219543139e-05, 'epoch': 0.48}
{'loss': 1.02, 'grad_norm': 1.2863945960998535, 'learning_rate': 9.5598113019587e-05, 'epoch': 0.48}
{'loss': 0.8623, 'grad_norm': 1.172974705696106, 'learning_rate': 9.558999695356943e-05, 'epoch': 0.48}
{'loss': 0.7588, 'grad_norm': 1.3317445516586304, 'learning_rate': 9.558187375753046e-05, 'epoch': 0.48}
{'loss': 0.8412, 'grad_norm': 1.4449903964996338, 'learning_rate': 9.557374343274055e-05, 'epoch': 0.48}
{'loss': 0.9447, 'grad_norm': 1.5270731449127197, 'learning_rate': 9.556560598047122e-05, 'epoch': 0.48}
{'loss': 0.6417, 'grad_norm': 1.090330719947815, 'learning_rate': 9.555746140199511e-05, 'epoch': 0.48}
[1m[33mswanlab[0m[0m: Step 1320 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1320 on key train/global_step already exists, ignored.
{'eval_loss': 0.6944208741188049, 'eval_runtime': 326.651, 'eval_samples_per_second': 3.717, 'eval_steps_per_second': 3.717, 'epoch': 0.48}
{'loss': 0.3371, 'grad_norm': 1.0030713081359863, 'learning_rate': 9.554930969858602e-05, 'epoch': 0.48}
{'loss': 0.779, 'grad_norm': 1.4209438562393188, 'learning_rate': 9.554115087151881e-05, 'epoch': 0.48}
{'loss': 0.942, 'grad_norm': 1.317909836769104, 'learning_rate': 9.553298492206947e-05, 'epoch': 0.48}
{'loss': 0.9209, 'grad_norm': 1.5690538883209229, 'learning_rate': 9.552481185151513e-05, 'epoch': 0.48}
{'loss': 0.9695, 'grad_norm': 1.2152092456817627, 'learning_rate': 9.551663166113399e-05, 'epoch': 0.49}
{'loss': 0.8268, 'grad_norm': 1.205839991569519, 'learning_rate': 9.550844435220539e-05, 'epoch': 0.49}
{'loss': 0.7617, 'grad_norm': 1.2668198347091675, 'learning_rate': 9.55002499260098e-05, 'epoch': 0.49}
{'loss': 0.2379, 'grad_norm': 0.6956263184547424, 'learning_rate': 9.549204838382876e-05, 'epoch': 0.49}
{'loss': 0.8261, 'grad_norm': 1.7343953847885132, 'learning_rate': 9.548383972694496e-05, 'epoch': 0.49}
{'loss': 0.694, 'grad_norm': 1.2981024980545044, 'learning_rate': 9.547562395664218e-05, 'epoch': 0.49}
[1m[33mswanlab[0m[0m: Step 1330 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1330 on key train/global_step already exists, ignored.
{'eval_loss': 0.6951366066932678, 'eval_runtime': 326.5628, 'eval_samples_per_second': 3.718, 'eval_steps_per_second': 3.718, 'epoch': 0.49}
{'loss': 0.8833, 'grad_norm': 1.1890137195587158, 'learning_rate': 9.546740107420531e-05, 'epoch': 0.49}
{'loss': 0.5756, 'grad_norm': 1.2527095079421997, 'learning_rate': 9.545917108092038e-05, 'epoch': 0.49}
{'loss': 0.8322, 'grad_norm': 1.9497896432876587, 'learning_rate': 9.545093397807452e-05, 'epoch': 0.49}
{'loss': 1.0487, 'grad_norm': 1.878954291343689, 'learning_rate': 9.544268976695595e-05, 'epoch': 0.49}
{'loss': 0.6806, 'grad_norm': 1.7358156442642212, 'learning_rate': 9.543443844885403e-05, 'epoch': 0.49}
{'loss': 0.4364, 'grad_norm': 0.9076201319694519, 'learning_rate': 9.542618002505921e-05, 'epoch': 0.49}
{'loss': 1.0579, 'grad_norm': 1.3683995008468628, 'learning_rate': 9.541791449686308e-05, 'epoch': 0.49}
{'loss': 0.7057, 'grad_norm': 1.4997729063034058, 'learning_rate': 9.54096418655583e-05, 'epoch': 0.49}
{'loss': 0.8573, 'grad_norm': 1.1602213382720947, 'learning_rate': 9.540136213243866e-05, 'epoch': 0.49}
{'loss': 0.3279, 'grad_norm': 1.0139058828353882, 'learning_rate': 9.539307529879911e-05, 'epoch': 0.49}
[1m[33mswanlab[0m[0m: Step 1340 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1340 on key train/global_step already exists, ignored.
{'eval_loss': 0.693810760974884, 'eval_runtime': 326.6332, 'eval_samples_per_second': 3.717, 'eval_steps_per_second': 3.717, 'epoch': 0.49}
{'loss': 0.9624, 'grad_norm': 1.3014464378356934, 'learning_rate': 9.538478136593561e-05, 'epoch': 0.49}
{'loss': 0.6855, 'grad_norm': 1.339146614074707, 'learning_rate': 9.53764803351453e-05, 'epoch': 0.49}
{'loss': 0.5728, 'grad_norm': 1.2029927968978882, 'learning_rate': 9.536817220772644e-05, 'epoch': 0.49}
{'loss': 0.8147, 'grad_norm': 1.4158180952072144, 'learning_rate': 9.535985698497836e-05, 'epoch': 0.49}
{'loss': 0.478, 'grad_norm': 1.4509060382843018, 'learning_rate': 9.535153466820149e-05, 'epoch': 0.49}
{'loss': 0.6637, 'grad_norm': 1.288139820098877, 'learning_rate': 9.534320525869742e-05, 'epoch': 0.49}
{'loss': 0.851, 'grad_norm': 1.2662245035171509, 'learning_rate': 9.533486875776884e-05, 'epoch': 0.49}
{'loss': 0.5556, 'grad_norm': 1.0960131883621216, 'learning_rate': 9.53265251667195e-05, 'epoch': 0.49}
{'loss': 0.651, 'grad_norm': 0.9741668105125427, 'learning_rate': 9.53181744868543e-05, 'epoch': 0.49}
{'loss': 0.7378, 'grad_norm': 1.279191255569458, 'learning_rate': 9.530981671947923e-05, 'epoch': 0.49}
[1m[33mswanlab[0m[0m: Step 1350 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1350 on key train/global_step already exists, ignored.
{'eval_loss': 0.6919353008270264, 'eval_runtime': 326.7652, 'eval_samples_per_second': 3.715, 'eval_steps_per_second': 3.715, 'epoch': 0.49}
{'loss': 0.6212, 'grad_norm': 1.213263988494873, 'learning_rate': 9.530145186590141e-05, 'epoch': 0.49}
{'loss': 0.5457, 'grad_norm': 1.094364881515503, 'learning_rate': 9.529307992742907e-05, 'epoch': 0.5}
{'loss': 0.7679, 'grad_norm': 1.3308348655700684, 'learning_rate': 9.528470090537152e-05, 'epoch': 0.5}
{'loss': 0.5297, 'grad_norm': 1.0230263471603394, 'learning_rate': 9.527631480103917e-05, 'epoch': 0.5}
{'loss': 0.8478, 'grad_norm': 1.2510862350463867, 'learning_rate': 9.526792161574362e-05, 'epoch': 0.5}
{'loss': 0.8023, 'grad_norm': 1.2101556062698364, 'learning_rate': 9.525952135079746e-05, 'epoch': 0.5}
{'loss': 0.4307, 'grad_norm': 1.0802668333053589, 'learning_rate': 9.525111400751447e-05, 'epoch': 0.5}
{'loss': 0.5739, 'grad_norm': 1.0318095684051514, 'learning_rate': 9.52426995872095e-05, 'epoch': 0.5}
{'loss': 0.8046, 'grad_norm': 1.3132590055465698, 'learning_rate': 9.523427809119854e-05, 'epoch': 0.5}
{'loss': 0.6506, 'grad_norm': 1.145283579826355, 'learning_rate': 9.522584952079862e-05, 'epoch': 0.5}
[1m[33mswanlab[0m[0m: Step 1360 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1360 on key train/global_step already exists, ignored.
{'eval_loss': 0.6907675862312317, 'eval_runtime': 326.7806, 'eval_samples_per_second': 3.715, 'eval_steps_per_second': 3.715, 'epoch': 0.5}
{'loss': 0.9407, 'grad_norm': 1.0315738916397095, 'learning_rate': 9.521741387732799e-05, 'epoch': 0.5}
{'loss': 0.5906, 'grad_norm': 1.1943215131759644, 'learning_rate': 9.520897116210588e-05, 'epoch': 0.5}
{'loss': 0.5526, 'grad_norm': 1.1193984746932983, 'learning_rate': 9.52005213764527e-05, 'epoch': 0.5}
{'loss': 0.7515, 'grad_norm': 1.259595513343811, 'learning_rate': 9.519206452168996e-05, 'epoch': 0.5}
{'loss': 0.7382, 'grad_norm': 1.3876625299453735, 'learning_rate': 9.518360059914025e-05, 'epoch': 0.5}
{'loss': 0.4602, 'grad_norm': 0.9481674432754517, 'learning_rate': 9.517512961012729e-05, 'epoch': 0.5}
{'loss': 1.0389, 'grad_norm': 1.3672274351119995, 'learning_rate': 9.516665155597588e-05, 'epoch': 0.5}
{'loss': 0.6443, 'grad_norm': 1.2778156995773315, 'learning_rate': 9.515816643801197e-05, 'epoch': 0.5}
{'loss': 0.5468, 'grad_norm': 1.0095680952072144, 'learning_rate': 9.514967425756258e-05, 'epoch': 0.5}
{'loss': 0.7162, 'grad_norm': 1.1284213066101074, 'learning_rate': 9.51411750159558e-05, 'epoch': 0.5}
[1m[33mswanlab[0m[0m: Step 1370 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1370 on key train/global_step already exists, ignored.
{'eval_loss': 0.6879427433013916, 'eval_runtime': 326.9856, 'eval_samples_per_second': 3.713, 'eval_steps_per_second': 3.713, 'epoch': 0.5}
{'loss': 0.3978, 'grad_norm': 0.979199230670929, 'learning_rate': 9.513266871452091e-05, 'epoch': 0.5}
{'loss': 0.7217, 'grad_norm': 1.2395234107971191, 'learning_rate': 9.512415535458824e-05, 'epoch': 0.5}
{'loss': 0.5828, 'grad_norm': 1.532841682434082, 'learning_rate': 9.51156349374892e-05, 'epoch': 0.5}
{'loss': 0.7451, 'grad_norm': 1.4794811010360718, 'learning_rate': 9.510710746455636e-05, 'epoch': 0.5}
{'loss': 0.8624, 'grad_norm': 1.1975514888763428, 'learning_rate': 9.509857293712338e-05, 'epoch': 0.5}
{'loss': 0.7698, 'grad_norm': 1.0689079761505127, 'learning_rate': 9.509003135652499e-05, 'epoch': 0.5}
{'loss': 1.076, 'grad_norm': 1.239490032196045, 'learning_rate': 9.508148272409704e-05, 'epoch': 0.5}
{'loss': 0.2058, 'grad_norm': 0.8560236096382141, 'learning_rate': 9.507292704117654e-05, 'epoch': 0.5}
{'loss': 0.576, 'grad_norm': 1.2865023612976074, 'learning_rate': 9.506436430910149e-05, 'epoch': 0.51}
{'loss': 0.8933, 'grad_norm': 1.2467364072799683, 'learning_rate': 9.505579452921109e-05, 'epoch': 0.51}
[1m[33mswanlab[0m[0m: Step 1380 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1380 on key train/global_step already exists, ignored.
{'eval_loss': 0.686713457107544, 'eval_runtime': 326.7792, 'eval_samples_per_second': 3.715, 'eval_steps_per_second': 3.715, 'epoch': 0.51}
{'loss': 0.5417, 'grad_norm': 1.3885505199432373, 'learning_rate': 9.504721770284559e-05, 'epoch': 0.51}
{'loss': 1.1262, 'grad_norm': 1.294251799583435, 'learning_rate': 9.503863383134636e-05, 'epoch': 0.51}
{'loss': 0.8126, 'grad_norm': 1.3769441843032837, 'learning_rate': 9.503004291605587e-05, 'epoch': 0.51}
{'loss': 1.0597, 'grad_norm': 1.591406226158142, 'learning_rate': 9.50214449583177e-05, 'epoch': 0.51}
{'loss': 0.8671, 'grad_norm': 1.360514760017395, 'learning_rate': 9.501283995947652e-05, 'epoch': 0.51}
{'loss': 0.9217, 'grad_norm': 1.2047621011734009, 'learning_rate': 9.500422792087808e-05, 'epoch': 0.51}
{'loss': 0.8549, 'grad_norm': 1.2465641498565674, 'learning_rate': 9.499560884386929e-05, 'epoch': 0.51}
{'loss': 0.9069, 'grad_norm': 1.3628026247024536, 'learning_rate': 9.49869827297981e-05, 'epoch': 0.51}
{'loss': 0.5385, 'grad_norm': 1.165479302406311, 'learning_rate': 9.497834958001362e-05, 'epoch': 0.51}
{'loss': 0.5086, 'grad_norm': 0.765984296798706, 'learning_rate': 9.496970939586598e-05, 'epoch': 0.51}
[1m[33mswanlab[0m[0m: Step 1390 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1390 on key train/global_step already exists, ignored.
{'eval_loss': 0.6843752264976501, 'eval_runtime': 327.0028, 'eval_samples_per_second': 3.713, 'eval_steps_per_second': 3.713, 'epoch': 0.51}
{'loss': 0.7516, 'grad_norm': 1.2583180665969849, 'learning_rate': 9.496106217870648e-05, 'epoch': 0.51}
{'loss': 0.6471, 'grad_norm': 1.0148133039474487, 'learning_rate': 9.495240792988751e-05, 'epoch': 0.51}
{'loss': 0.7738, 'grad_norm': 1.6427719593048096, 'learning_rate': 9.494374665076251e-05, 'epoch': 0.51}
{'loss': 0.6767, 'grad_norm': 1.2822386026382446, 'learning_rate': 9.49350783426861e-05, 'epoch': 0.51}
{'loss': 0.8329, 'grad_norm': 1.1904743909835815, 'learning_rate': 9.492640300701392e-05, 'epoch': 0.51}
{'loss': 0.7822, 'grad_norm': 1.2045402526855469, 'learning_rate': 9.491772064510275e-05, 'epoch': 0.51}
{'loss': 1.0175, 'grad_norm': 1.2955538034439087, 'learning_rate': 9.490903125831048e-05, 'epoch': 0.51}
{'loss': 0.3949, 'grad_norm': 1.1452250480651855, 'learning_rate': 9.490033484799608e-05, 'epoch': 0.51}
{'loss': 0.7807, 'grad_norm': 1.388791799545288, 'learning_rate': 9.48916314155196e-05, 'epoch': 0.51}
{'loss': 0.6271, 'grad_norm': 1.073722004890442, 'learning_rate': 9.488292096224222e-05, 'epoch': 0.51}
[1m[33mswanlab[0m[0m: Step 1400 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1400 on key train/global_step already exists, ignored.
{'eval_loss': 0.6832455396652222, 'eval_runtime': 327.1618, 'eval_samples_per_second': 3.711, 'eval_steps_per_second': 3.711, 'epoch': 0.51}
{'loss': 0.9511, 'grad_norm': 1.3846471309661865, 'learning_rate': 9.487420348952623e-05, 'epoch': 0.51}
{'loss': 0.9608, 'grad_norm': 1.3911468982696533, 'learning_rate': 9.486547899873494e-05, 'epoch': 0.51}
{'loss': 0.9828, 'grad_norm': 1.655913233757019, 'learning_rate': 9.485674749123285e-05, 'epoch': 0.51}
{'loss': 0.4547, 'grad_norm': 1.21291983127594, 'learning_rate': 9.484800896838552e-05, 'epoch': 0.51}
{'loss': 0.8046, 'grad_norm': 1.2931560277938843, 'learning_rate': 9.483926343155958e-05, 'epoch': 0.51}
{'loss': 0.6834, 'grad_norm': 1.3536385297775269, 'learning_rate': 9.483051088212282e-05, 'epoch': 0.52}
{'loss': 0.3492, 'grad_norm': 0.9014006853103638, 'learning_rate': 9.482175132144406e-05, 'epoch': 0.52}
{'loss': 0.966, 'grad_norm': 1.4584031105041504, 'learning_rate': 9.481298475089327e-05, 'epoch': 0.52}
{'loss': 0.1926, 'grad_norm': 0.7877674102783203, 'learning_rate': 9.480421117184147e-05, 'epoch': 0.52}
{'loss': 0.931, 'grad_norm': 1.341248869895935, 'learning_rate': 9.47954305856608e-05, 'epoch': 0.52}
[1m[33mswanlab[0m[0m: Step 1410 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1410 on key train/global_step already exists, ignored.
{'eval_loss': 0.6809659004211426, 'eval_runtime': 326.6024, 'eval_samples_per_second': 3.717, 'eval_steps_per_second': 3.717, 'epoch': 0.52}
{'loss': 0.7318, 'grad_norm': 1.1574392318725586, 'learning_rate': 9.478664299372453e-05, 'epoch': 0.52}
{'loss': 0.9013, 'grad_norm': 1.2062089443206787, 'learning_rate': 9.477784839740694e-05, 'epoch': 0.52}
{'loss': 0.8159, 'grad_norm': 1.490764856338501, 'learning_rate': 9.476904679808349e-05, 'epoch': 0.52}
{'loss': 0.9136, 'grad_norm': 1.321075677871704, 'learning_rate': 9.476023819713069e-05, 'epoch': 0.52}
{'loss': 0.8368, 'grad_norm': 1.222957730293274, 'learning_rate': 9.475142259592615e-05, 'epoch': 0.52}
{'loss': 0.7031, 'grad_norm': 1.1409790515899658, 'learning_rate': 9.47425999958486e-05, 'epoch': 0.52}
{'loss': 0.8529, 'grad_norm': 1.5035254955291748, 'learning_rate': 9.473377039827783e-05, 'epoch': 0.52}
{'loss': 0.953, 'grad_norm': 1.9276602268218994, 'learning_rate': 9.472493380459474e-05, 'epoch': 0.52}
{'loss': 0.4681, 'grad_norm': 1.2627344131469727, 'learning_rate': 9.471609021618133e-05, 'epoch': 0.52}
{'loss': 0.7963, 'grad_norm': 1.0504446029663086, 'learning_rate': 9.470723963442068e-05, 'epoch': 0.52}
[1m[33mswanlab[0m[0m: Step 1420 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1420 on key train/global_step already exists, ignored.
{'eval_loss': 0.6810416579246521, 'eval_runtime': 326.8012, 'eval_samples_per_second': 3.715, 'eval_steps_per_second': 3.715, 'epoch': 0.52}
{'loss': 0.6345, 'grad_norm': 1.2734662294387817, 'learning_rate': 9.469838206069698e-05, 'epoch': 0.52}
{'loss': 0.6512, 'grad_norm': 1.2407243251800537, 'learning_rate': 9.468951749639551e-05, 'epoch': 0.52}
{'loss': 0.8464, 'grad_norm': 1.2594540119171143, 'learning_rate': 9.468064594290262e-05, 'epoch': 0.52}
{'loss': 0.4236, 'grad_norm': 1.0291568040847778, 'learning_rate': 9.467176740160578e-05, 'epoch': 0.52}
{'loss': 0.8159, 'grad_norm': 1.0616557598114014, 'learning_rate': 9.466288187389355e-05, 'epoch': 0.52}
{'loss': 0.8345, 'grad_norm': 1.5327239036560059, 'learning_rate': 9.465398936115557e-05, 'epoch': 0.52}
{'loss': 0.6626, 'grad_norm': 1.4050484895706177, 'learning_rate': 9.46450898647826e-05, 'epoch': 0.52}
{'loss': 0.9376, 'grad_norm': 1.6327470541000366, 'learning_rate': 9.463618338616643e-05, 'epoch': 0.52}
{'loss': 0.6731, 'grad_norm': 1.212368369102478, 'learning_rate': 9.462726992670001e-05, 'epoch': 0.52}
{'loss': 0.7452, 'grad_norm': 1.3464257717132568, 'learning_rate': 9.461834948777736e-05, 'epoch': 0.52}
[1m[33mswanlab[0m[0m: Step 1430 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1430 on key train/global_step already exists, ignored.
{'eval_loss': 0.6781340837478638, 'eval_runtime': 326.7973, 'eval_samples_per_second': 3.715, 'eval_steps_per_second': 3.715, 'epoch': 0.52}
{'loss': 0.6661, 'grad_norm': 1.2577704191207886, 'learning_rate': 9.46094220707936e-05, 'epoch': 0.52}
{'loss': 0.7966, 'grad_norm': 1.3859381675720215, 'learning_rate': 9.460048767714489e-05, 'epoch': 0.52}
{'loss': 0.4093, 'grad_norm': 1.412277102470398, 'learning_rate': 9.459154630822853e-05, 'epoch': 0.52}
{'loss': 0.8542, 'grad_norm': 1.5228643417358398, 'learning_rate': 9.458259796544292e-05, 'epoch': 0.53}
{'loss': 0.6927, 'grad_norm': 1.2761484384536743, 'learning_rate': 9.45736426501875e-05, 'epoch': 0.53}
{'loss': 0.6991, 'grad_norm': 1.1105051040649414, 'learning_rate': 9.456468036386288e-05, 'epoch': 0.53}
{'loss': 0.4363, 'grad_norm': 0.97035151720047, 'learning_rate': 9.455571110787067e-05, 'epoch': 0.53}
{'loss': 0.4727, 'grad_norm': 1.1658209562301636, 'learning_rate': 9.454673488361362e-05, 'epoch': 0.53}
{'loss': 1.0144, 'grad_norm': 1.3883037567138672, 'learning_rate': 9.453775169249557e-05, 'epoch': 0.53}
{'loss': 0.7515, 'grad_norm': 1.2413878440856934, 'learning_rate': 9.452876153592143e-05, 'epoch': 0.53}
[1m[33mswanlab[0m[0m: Step 1440 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1440 on key train/global_step already exists, ignored.
{'eval_loss': 0.6773684620857239, 'eval_runtime': 326.574, 'eval_samples_per_second': 3.717, 'eval_steps_per_second': 3.717, 'epoch': 0.53}
{'loss': 0.8405, 'grad_norm': 1.1138285398483276, 'learning_rate': 9.451976441529722e-05, 'epoch': 0.53}
{'loss': 0.713, 'grad_norm': 1.1542333364486694, 'learning_rate': 9.451076033203003e-05, 'epoch': 0.53}
{'loss': 0.7011, 'grad_norm': 1.1215258836746216, 'learning_rate': 9.450174928752807e-05, 'epoch': 0.53}
{'loss': 0.8828, 'grad_norm': 1.1311770677566528, 'learning_rate': 9.449273128320057e-05, 'epoch': 0.53}
{'loss': 0.5719, 'grad_norm': 1.2513090372085571, 'learning_rate': 9.448370632045796e-05, 'epoch': 0.53}
{'loss': 0.7602, 'grad_norm': 1.1464369297027588, 'learning_rate': 9.447467440071164e-05, 'epoch': 0.53}
{'loss': 0.8781, 'grad_norm': 1.299770712852478, 'learning_rate': 9.44656355253742e-05, 'epoch': 0.53}
{'loss': 0.6673, 'grad_norm': 1.1896286010742188, 'learning_rate': 9.445658969585922e-05, 'epoch': 0.53}
{'loss': 0.3874, 'grad_norm': 0.906169056892395, 'learning_rate': 9.444753691358144e-05, 'epoch': 0.53}
{'loss': 0.9542, 'grad_norm': 1.3932052850723267, 'learning_rate': 9.443847717995666e-05, 'epoch': 0.53}
[1m[33mswanlab[0m[0m: Step 1450 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1450 on key train/global_step already exists, ignored.
{'eval_loss': 0.6759127974510193, 'eval_runtime': 326.818, 'eval_samples_per_second': 3.715, 'eval_steps_per_second': 3.715, 'epoch': 0.53}
{'loss': 0.7233, 'grad_norm': 1.3547189235687256, 'learning_rate': 9.442941049640179e-05, 'epoch': 0.53}
{'loss': 0.6434, 'grad_norm': 1.142418384552002, 'learning_rate': 9.442033686433479e-05, 'epoch': 0.53}
{'loss': 0.7223, 'grad_norm': 1.297464370727539, 'learning_rate': 9.441125628517474e-05, 'epoch': 0.53}
{'loss': 1.0169, 'grad_norm': 1.3242191076278687, 'learning_rate': 9.440216876034177e-05, 'epoch': 0.53}
{'loss': 0.2789, 'grad_norm': 0.6634995937347412, 'learning_rate': 9.439307429125714e-05, 'epoch': 0.53}
{'loss': 0.9157, 'grad_norm': 1.1989178657531738, 'learning_rate': 9.438397287934315e-05, 'epoch': 0.53}
{'loss': 0.6917, 'grad_norm': 1.2734451293945312, 'learning_rate': 9.437486452602324e-05, 'epoch': 0.53}
{'loss': 0.6513, 'grad_norm': 1.2720497846603394, 'learning_rate': 9.436574923272188e-05, 'epoch': 0.53}
{'loss': 0.8227, 'grad_norm': 1.35330331325531, 'learning_rate': 9.435662700086467e-05, 'epoch': 0.53}
{'loss': 0.6887, 'grad_norm': 1.341896414756775, 'learning_rate': 9.434749783187826e-05, 'epoch': 0.53}
[1m[33mswanlab[0m[0m: Step 1460 on key train/epoch already exists, ignored.
[1m[33mswanlab[0m[0m: Step 1460 on key train/global_step already exists, ignored.
{'eval_loss': 0.677561342716217, 'eval_runtime': 326.7858, 'eval_samples_per_second': 3.715, 'eval_steps_per_second': 3.715, 'epoch': 0.53}
{'loss': 0.619, 'grad_norm': 1.4921650886535645, 'learning_rate': 9.433836172719041e-05, 'epoch': 0.54}
{'loss': 0.2631, 'grad_norm': 1.0379527807235718, 'learning_rate': 9.432921868822997e-05, 'epoch': 0.54}
{'loss': 0.4542, 'grad_norm': 1.1653326749801636, 'learning_rate': 9.432006871642684e-05, 'epoch': 0.54}
{'loss': 0.9552, 'grad_norm': 1.3884357213974, 'learning_rate': 9.431091181321202e-05, 'epoch': 0.54}
{'loss': 0.7189, 'grad_norm': 1.332637071609497, 'learning_rate': 9.430174798001762e-05, 'epoch': 0.54}
{'loss': 1.0551, 'grad_norm': 1.2955092191696167, 'learning_rate': 9.42925772182768e-05, 'epoch': 0.54}
{'loss': 0.7985, 'grad_norm': 1.1787241697311401, 'learning_rate': 9.42833995294238e-05, 'epoch': 0.54}
{'loss': 0.5173, 'grad_norm': 1.0923774242401123, 'learning_rate': 9.4274214914894e-05, 'epoch': 0.54}
{'loss': 0.33, 'grad_norm': 0.7469351291656494, 'learning_rate': 9.426502337612378e-05, 'epoch': 0.54}
{'loss': 0.6798, 'grad_norm': 1.1344118118286133, 'learning_rate': 9.425582491455067e-05, 'epoch': 0.54}
